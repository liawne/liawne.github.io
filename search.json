[{"categories":["tech"],"content":"# 说明 # 什么是 systemd systemd 是一个软件套件，它为 linux 操作系统提供一系列系统组件。它的主要目标是统一 linux 发行版中的服务配置和行为；它的主要组件是 system and service manager —— 一个用于启动用户空间和管理用户进程的 init 系统。它还提供各种守护程序和实用程序的替代品，包括设备管理（device management）、登录管理（login management）、网络连接管理（network connection management）和事件日志记录（event logging）。\n自 2015 年以来，大多数 linux 发行版都采用了 systemd，取代了其他 init 系统，例如 SysV init。\n# systemd的历史 最初开发 systemd 是 Red Hat 软件工程师 Lennart Poettering 和 Kay Sievers 于 2010 年启动的一个项目，目的是用来取代 linux 的传统 System V init。Poettering 在 2010 年 4 月发表的一篇题 重新思考 PID 1 的博客文章，引入了后来成为 systemd 的实验版本; 他们试图以多种方式超越 init 守护进程的效率。他们希望改进表达依赖关系的软件框架，来允许在系统启动期间同时或并行完成更多任务。\n2011 年 5 月，Fedora 成为第一个默认启用 systemd 的主要 linux 发行版，取代了 SysVinit。当时的理由是 systemd 在启动期间提供了广泛的并行化、更好的流程管理以及总体上更理智、基于依赖关系的系统控制方法。\n2012 年 10 月，Arch linux 将 systemd 设为默认值，也完成了从 SysVinit 的切换。\n2013 年 10 月至 2014 年 2 月 期间，Debian 技术委员会在经过长时间的辩论后，最终做出决定，在 Debian 8\"jessie\"上使用 systemd。\n2014 年 2 月，在 Debian 做出决定后，Mark Shuttleworth 在他的博客上宣布 Ubuntu 将跟随实施 systemd，放弃自己的 Upstart。\nsystemd的实现 # 设计 Poettering 将 systemd 开发描述为 never finished, never complete, but tracking progress of technology（远未完成、远未完美、只跟随技术进步）。\n2014 年 5 月，Poettering 通过提供以下三个通用功能进一步将 systemd 描述为pointless differences between distributions（版本之间无大差异）：\n 系统和服务管理器（通过应用各种配置来管理系统及其服务） 软件平台（作为开发其他软件的基础） 应用程序和内核之间的粘合剂（提供各种接口来暴露内核提供的功能）  systemd 包括诸如按需启动守护进程、快照支持、进程跟踪和抑制剂锁（Inhibitor Locks）等功能。它不仅仅是systemd init daemon的名字，还指代围绕它的整个软件包，除了systemd init守护进程之外，还包括守护进程journald、logind和networkd以及许多其他基础组件。\n2013 年 1 月，Poettering 将 systemd 描述为不是一个程序，而是一个包含 69 个单独二进制文件的大型软件套件。作为一个集成的软件套件，systemd 取代了由传统 init 守护进程控制的启动顺序和运行级别，以及在其控制下执行的 shell 脚本。systemd 还通过处理用户登录、系统控制台、设备热插拔（device hotplugging）、计划执行（替换 cron）、日志记录、主机名和语言环境来集成 Linux 系统上常见的许多其他服务。\n与 init 守护进程一样，systemd 是一个管理其他守护进程的守护进程，这些守护进程包括 systemd 本身都是后台进程。 systemd 是在引导期间启动的第一个守护进程，也是在关机期间终止的最后一个守护进程。systemd 守护进程充当用户空间进程树的根；第一个进程（PID 1）在 Unix 系统上具有特殊的作用，因为它会在原始父进程终止时替换进程的父进程，因此，第一个进程特别适合用于监控守护进程。\nsystemd 并行执行其启动序列的元素，这在理论上比传统的启动序列方法更快。对于进程间通信 (IPC)，systemd 使 Unix 域套接字（Unix domain sockets）和 D-Bus 可用于正在运行的守护进程。 systemd 本身的状态也可以保存在快照中以备将来调用。\n# 核心组件和库 systemd组件和库\n遵循 systemd 的集成方法，systemd 还提供各种守护程序和实用程序的替代品，包括启动 shell 脚本、pm-utils、inetd、acpid、syslog、watchdog、cron 和 atd。\nsystemd 的核心组件包括：\n systemd 是 linux 操作系统的系统和服务管理器。 systemctl 是一个自省和控制 systemd 系统和服务管理器状态的命令(不要与 sysctl 混淆)。 systemd-analyze 可用于确定系统启动性能统计数据，并从系统和服务管理器检索其他状态和跟踪信息。  systemd 使用 linux 内核的 cgroups 子系统而不是使用进程标识符 (PID) 来跟踪进程；因此，守护进程无法逃离 systemd，即使是通过 double-forking 也不行。\nsystemd 不仅使用 cgroup，还使用 systemd-nspawn 和 machinectl 来扩充它们，这两个实用程序有助于创建和管理 linux 容器。\n从版本 205 开始，systemd 还提供 ControlGroupInterface，它是 linux 内核 cgroups 的 API。linux 内核 linux 适用于支持 kernfs，并且正在被修改以支持统一的层次结构。\n统一层次的 cgroup 将由 systemd 通过 systemd-nspawn 独占访问\n# 辅助组件 除了提供 linux 初始化系统的主要目的之外，systemd 套件还可以提供其他功能，包括以下组件：\njournald\nsystemd-journald 是一个负责事件记录的守护进程，使用 append-only 的二进制文件作为其日志文件。系统管理员可以选择是否使用 systemd-journald、syslog-ng 或 rsyslog 记录系统事件。\nlibudev\nlibudev 是使用 udev 的标准库，它允许第三方应用程序查询 udev 资源。\nlocaled\n负责系统语言环境和键盘布局\nlogind\nsystemd-logind 是一个以各种方式管理用户登录和席位的守护进程。它是一个集成的登录管理器，提供多席位（multiseat）改进并取代不再维护的 ConsoleKit。对于 X11 显示管理器，切换到 logind 需要很少的移植。 logind 集成在 systemd version 30 中。\nnetworkd\nnetworkd 是处理网络接口配置的守护进程；在 verion 209 中，networkd 首次被集成到systemd，支持场景较少，仅限于静态分配的地址和对桥接配置的基本支持。2014 年 7 月，systemd 版本 215 发布，增加了 IPv4 主机的 DHCP 服务器和 VXLAN 支持等新功能。networkctl 可用于查看 systemd-networkd 所看到的网络链接的状态。 必须在 /lib/systemd/network/ 下添加新接口的配置作为以 .network 扩展名结尾的新文件。要添加新接口的配置，必须在 /lib/systemd/network/ 新增以 .network 扩展名结尾的新文件。\nresolved\nsystemd-boot\nsystemd-boot 是一个引导管理器，以前称为 gummiboot。 Kay Sievers 将其合并到 systemd with rev 220。\ntimedated\nsystemd-timedated 是一个守护进程，可用于控制与时间相关的设置，例如系统时间、系统时区或 UTC 和本地时区系统时钟之间的选择。timedated 可以通过 D-Bus 访问，在systemd 版本 30 中被集成。\ntimesyncd\ntmpfiles\nsystemd-tmpfiles 是一个负责创建和清理临时文件和目录的实用程序。它通常在启动时运行一次，然后以指定的时间间隔运行。\nudevd\nudev 是 linux 内核的设备管理器，它处理 /dev 目录和添加/删除设备时的所有用户空间操作，包括固件加载。2012 年 4 月，udev 的源代码树被合并到 systemd 源代码树中。 2014 年 5 月 29 日，通过 udev 加载固件的支持从 systemd 中删除，应该由内核应该负责加载固件。\n# systemd的配置 systemd 仅通过纯文本文件进行配置。\nsystemd 将每个守护进程的初始化指令记录在使用声明性语言的配置文件（称为\"单元文件(unit file)\"）中，替换传统上使用的每个守护进程启动 shell 脚本。配置文件支持 crudini 配置。\n单元文件（unit file） 类型包括：\n .service .socket .device (由 systemd 自动启动) .mount .automount .swap .target .path .timer (可以用作类似 cron 的作业调度程序) .snapshot .slice (用于对流程和资源进行分组和管理) .scope (用于对工作进程进行分组，不打算通过单元文件进行配置)  # 其他 # 参考内容 本文内容参考自：\n systemd  ","description":"systemd是什么，systemd的构成","tags":["linux","systemd","boot"],"title":"systemd介绍","uri":"/tech/basics/boot_process/systemd%E4%BB%8B%E7%BB%8D/"},{"categories":["tech"],"content":"# 说明 不清楚 legacy bios 和 uefi，gpt 和 mbr 的区别，理一下他们的来源和互相之间的关系\n# BIOS 和 UEFI BIOS 和 UEFI 是计算机的两个固件接口，它们充当操作系统和计算机固件之间的解释器。这两个接口都用于在计算机启动时初始化硬件组件并启动存储在硬盘驱动器上的操作系统。\n BIOS 通过读取硬盘驱动器的第一个扇区来工作，该扇区存储了要初始化的下一个设备地址或要执行的代码。BIOS 还会选择启动操作系统时需要初始化的引导设备。 UEFI 执行相同的任务，但实现略有不同。它将有关初始化和启动的所有信息存储在 .efi 文件而不是固件中。此文件存储在名为 ESP 的特殊分区内。ESP 分区还包含计算机上安装的操作系统的引导加载程序。  # BIOS 什么是 BIOS\nBIOS 是 Basic Input/Output System 的简称，也称为系统 BIOS、ROM BIOS 或 PC BIOS。它是嵌入在计算机主板芯片上的固件。\nBIOS 固件预装在 PC 的主板上; 它是一个非易失性固件，这意味着它的设置即使在断电后也不会消失或改变。\nBIOS 怎么工作\n当计算机启动时，BIOS 会加载并唤醒计算机的硬件组件，确保它们正常工作，然后加载引导加载程序来初始化已安装的操作系统。\nBIOS 必须在 16 位处理器模式下运行，并且只有 1 MB 的空间可以执行。在这种情况下，BIOS 无法同时初始化多个硬件设备，从而导致初始化所有硬件接口和设备时时间更长，启动过程变慢。\n选择 BIOS 的场景\n用户选择 Legacy BIOS 而不是 UEFI 的一些可能的原因：\n 如果不需要对计算机的运行方式进行精细控制，BIOS 是理想的选择。 如果只有小型驱动器或分区，BIOS 也足够了。尽管许多较新的硬盘驱动器超过了 BIOS 的 2 TB 限制，但并非每个用户都需要这么大的空间。 UEFI 的安全启动（secure boot）功能可能会导致 OEM 制造商阻止用户在其硬件上安装其他操作系统。如果使用 BIOS，则可以回避这个问题。 BIOS 提供对接口中硬件信息的访问，但并非所有的 UEFI 实现都可以这样做。可以在操作系统中访问硬件规格。   一些计算机用户使用 UEFI 启动，但仍将其称为\"BIOS\"，这容易让人感到困惑。即使 PC 使用术语 \"BIOS\"，如今购买的大多数现代 PC 都使用 UEFI 固件而不是 BIOS。为了区分 UEFI 和 BIOS，也有人将 UEFI 固件称为 UEFI BIOS，而 BIOS 则称为 Legacy BIOS 或传统 BIOS。\n # UEFI 什么是 UEFI\nUEFI（Unified Extensible Firmware Interface）：统一的可扩展固件接口，它是 EFI（Extensible Firmware Interface） 的逻辑继承。\nUEFI 发展历史\n在90年代中期，英特尔意识到 IBM BIOS（Basic Input/Output System（基本输入/输出系统）） 样式固件接口有其固有的限制。这些限制并不影响普通用户，但它们使生产高性能服务器变得困难。于是，英特尔于1998年开始开发 EFI 规范。2005年，英特尔停止了 EFI 规范的开发，并在维持所有权的同时将其捐赠给了 Unified EFI Forum。英特尔继续向供应商许可 EFI 规范，但 UEFI 规范归论坛所有。\nUEFI 的优势\nUEFI 的设计目标是在未来完全替换传统 BIOS，其具有许多传统 BIOS 无法实现的新特性和优势，部分突出的优势如下：\n 模块化设计 同 CPU 架构解偶（Itanium, x86, x86-64, ARM Arch32, Arm Arch64） 兼容 BIOS 接口和传统启动方式 从大于 2TiB 的磁盘引导的能力（注意2TB和2TiB之间的差异） UEFI 支持超过 4 个具有 GUID 分区表的主分区。 使用 UEFI 固件的计算机的启动过程比 BIOS 更快，UEFI 中的各种优化和增强功能可以让系统更快地启动。 UEFI 支持安全启动（secure boot），这意味着可以检查操作系统的有效性，以确保没有恶意软件篡改启动过程。 UEFI 支持 UEFI 固件本身的联网功能，有助于远程故障排除和 UEFI 配置。 UEFI 具有更简单的图形用户界面，并且还具有比传统 BIOS 更丰富的设置菜单。  EFI 引导管理器和 EFI 驱动程序之间的交互：  并非所有计算机或设备都支持 UEFI。要使用 UEFI 固件，磁盘上的硬件必须支持 UEFI。此外，系统盘需要是 GPT 盘。\n ESP 特殊分区\n UEFI 将有关初始化和启动的所有信息存储在 .efi 文件中，该文件存储在称为 EFI 系统分区 (ESP(EFI System Partition)) 的特殊分区上。 ESP 分区包含计算机上安装的操作系统的引导加载程序。 ESP 分区使用 FAT32 格式进行格式化，具有特定的分区类型代码 EF00，而不是通常用于 FAT32 驱动器的 0x0C。 许多操作系统会因为它被视为系统卷而将其隐藏。 在启动时，主板上的 UEFI 兼容固件会扫描所有磁盘以查找 ESP，并在其中查找这些可执行文件，在此过程中，MBR 的硬编码引导范例不再适用。 正是因为有了这个分区，UEFI 可以直接启动操作系统，省去 BIOS 自检过程，这也是 UEFI 启动速度更快的一个重要原因。  # MBR 和 GPT MBR（主引导记录（Master Boot Record）) 和 GPT（GUID 分区表（GUID Partition Table）） 是各种硬盘驱动器的两种分区方案，其中 GPT 是较新的标准。对于这两种分区方案，引导结构和数据处理方式都是不同的，速度不同，使用要求也不同。\n# MBR 什么是 MBR\n MBR 代表的是 Master Boot Record，主引导分区的意思。 MBR 只是硬盘的一部分，在它上面可以找到有关磁盘的所有信息;。 MBR 存储在引导扇区（boot sector），它包含了分区类型的详细信息以及引导计算机操作系统时所需的代码。 MBR 可以有很多不同的形式，但所有这些形式的共同点是它们都具有 512 字节的大小，都存储了分区表和引导代码（通常称为引导加载程序）。   1.MBR 不在分区中；它位于设备的第一个扇区，在第一个分区之前。\n2.存在于无分区设备或单个分区内的引导扇区称为卷引导记录 (VBR(volume boot record))。\n MBR 的特点\n如下：\n MBR 磁盘上可能的最大主分区数为 4，其中每个分区需要 16 字节空间，这使得所有分区总共需要 64 字节空间。 MBR 分区可以分为三种类型——主分区、扩展分区和逻辑分区。如上所述，它只能有 4 个主分区。扩展分区和逻辑分区克服了这一限制。 MBR 中的分区表仅包含有关主分区和扩展分区的详细信息。此外，重要的是要了解数据不能直接保存在扩展分区上，因此需要创建逻辑分区。 一些最新类型的 MBR 还可能添加了磁盘签名、时间戳和有关磁盘格式化的详细信息。 与可以支持四个分区的旧版本的 MBR 不同，最新版本能够支持多达 16 个分区。由于所有 MBR 的大小不超过 512 字节，因此使用 MBR 格式化的磁盘有 2TB 的可用磁盘空间上限（有些硬盘也有 1024 字节或 2048 字节扇区，但这会导致磁盘速度出现问题，因此不是明智的选择）。 它兼容所有版本的 Windows（32 位和 64 位）。  MBR 构成\n 传统MBR构成图  以windows上的MBR为例说明扩展分区   MBR 的限制 如下：\n MBR 风格的分区只能使用不超过 2TB 的磁盘空间。 它最多只能有 4 个主分区。如果创建主分区后有未分配的空间，我们可以通过创建扩展分区来使其可用，其中可以创建各种逻辑分区。  由于 MBR 的这些限制，用户通常会选择不同的分区样式。除了 MBR 之外，最常见的分区样式之一是 GPT。\n# GPT GPT 的来源\n同样的，英特尔对基于 BIOS 和 MBR 的引导模式不满意，于是开发了 GPT 规范。\n什么是 GPT\n GPT 代表的是 GUID（全局唯一标识符（globally unique identifier）） Partition Table，GUID分区表的意思。 GPT 是最新的磁盘分区方式，被称为 MBR 的继承者。 GPT 在整个驱动器上维护有关分区组织和操作系统启动代码的数据。这样可以确保在任何分区损坏或删除的情况下，仍然可以检索数据，并且引导过程不会出现问题。这也是 GPT 优于 MBR 的原因之一。  GPT 构成\n 纵向分布视图  横向视图   通过以上图片，我们可以看到GPT磁盘分为三个部分：\n 主分区表（Primary Partition Table）：这是保护 MBR、GPT 标头分区和分区表所在的位置。 普通数据分区（Normal Data Partition）：这是用于存储个人数据的位置。 备份分区表（Back up Partition Table）：此位置用于存储 GPT 标头和分区表的备份数据。这在主分区表损坏的情况下很有用。  GPT 的特点\n 与 MBR 相比，GPT 磁盘提供了更多的存储空间。用户可以创建多个分区。 GPT 磁盘系统可以创建多达 128 个分区。 GPT 格式的磁盘分区，分区表数据恢复更容易。 GPT 可以运行检查以确保数据安全。它使用 CRC 值来检查数据的安全性。如果数据损坏，它可以检测损坏并尝试从磁盘上的其他位置检索损坏的数据。与 MBR 相比，这使得 GPT 成为更可靠的选择。 GPT 中包含的一项非常有趣的功能称为 保护性MBR(Protective MBR)。此 MBR 仅考虑整个驱动器上的一个分区。在这种情况下，当用户尝试借助旧工具管理 GPT 时，该工具将读取分布在驱动器上的一个分区。这是保护性 MBR 确保旧工具不会认为 GPT 驱动器没有分区，并防止旧工具使用新 MBR 对 GPT 数据造成任何损坏。保护性 MBR 保护 GPT 数据，使其不会被删除。 与将一部分引导代码放入引导扇区的 MBR 不同，GPT 将引导代码和分区表分离了。  GPT 的限制\n如果必须将 GPT 用作引导驱动器，则系统需要基于 UEFI。在基于 BIOS 的系统中，GPT 驱动器不能用作主驱动器。\n用户选择 MBR 而不是 GPT 的唯一原因是当操作系统安装在基于 BIOS 的系统上并且驱动器将用作引导驱动器时。\n# GPT vs MBR 下面是 MBR 和 GPT 之间的综合比较表，该表突出显示了 MBR 和 GPT 之间的主要区别。    比较点 MBR GPT     主分区数 4 可达到128   最大分区大小 2 TB 18 EB   最大硬盘大小 2 TB 18 EB   安全性 无 CRC 值用于确保数据安全\n备份 GUID 分区表   适用于 BIOS UEFI   分区名称 存储在分区中 具有唯一的 GUID 和 36 个字符的名称   支持多重启动 支持较差 引导加载程序条目位于不同的分区中   数据还原 较难 相对简单   数据损坏 无法检测数据损坏 易于检测   分区寻址方法 CHS（Cylinder Head Cycle）或\nLBS（逻辑块寻址 Logical Block Addressing） LBA 是寻址分区的唯一方法   大小 512 字节 每个 LBA 512 字节\n每个分区条目为 128 字节   分区类型代码 1字节 使用 16 字节 GUID   稳定性 与 GPT 相比，稳定性较差 提供更多安全性   可启动版本的操作系统 引导 32 位操作系统 引导 64 位操作系统   存储 只支持 2TB 的容量\n磁盘大小 \u003e2TB 被标记为未分配且无法使用 可支持容量达944万TB的磁盘   性能 与 GPT 相比，性能较低 如果支持 UEFI 引导，则提供卓越的性能    上表列出了 MBR 与 GPT 的性能。基于上述几点，如果支持 UEFI 引导，GPT 在性能方面要优越得多。它还提供了稳定性和速度的优势，并增强了硬件的性能，这主要归功于 UEFI 的结构。\n# 一些疑问   MBR和GPT可以混用吗？\n 只有在支持 GPT 的系统上才能混用 MBR 和 GPT。\nGPT 需要 UEFI 接口，当系统支持 UEFI 时，引导分区必须位于 GPT 磁盘上，这一点很重要;但是，其他硬盘可以是 MBR 或 GPT。\n   UEFI 可以启动 MBR 吗？\n UEFI 可以同时支持 MBR 和 GPT。\nUEFI 与 GPT 配合使用可以很好地摆脱 MBR 的分区大小和数量限制。\n   如果将 GPT 转换为 MBR，是否有可能丢失数据？\n 如果通过工具将磁盘分区格式从 GPT 转换为 MBR 或从 MBR 转换为 GPT，则需要在转换前删除所有分区。\n   其他 # 相关名词解释 Secure Boot\n 安全启动（secure boot）是什么：是可执行文件的签名，如果签名与已在 UEFI 固件中注册的签名匹配，则主板将允许它启动; 否则不允许启动。  # 参考内容 https://fossbytes.com/uefi-bios-gpt-mbr-whats-difference/\nhttps://www.partitionwizard.com/partitionmagic/uefi-vs-bios.html\nhttps://www.freecodecamp.org/news/mbr-vs-gpt-whats-the-difference-between-an-mbr-partition-and-a-gpt-partition-solved/\nhttps://www.maketecheasier.com/differences-between-uefi-and-bios/#:~:text=BIOS%20uses%20the%20Master%20Boot,physical%20partitions%20to%20only%204.\nhttps://en.wikipedia.org/wiki/Master_boot_record\nhttps://www.partitionwizard.com/partitionmagic/uefi-vs-bios.html\nhttps://www.softwaretestinghelp.com/mbr-vs-gpt/\nhttps://www.alphr.com/mbr-vs-gpt/#:~:text=The%20main%20difference%20between%20MBR,boot%20off%20of%20GPT%20drives.\n","description":"介绍uefi和bios的差别，gpt和mbr的差别，以及他们互相之间的关系","tags":["uefi","bios","gpt","mbr"],"title":"uefi/bios，gpt/mbr的一些概念","uri":"/tech/basics/boot_process/uefibiosgptmbr%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["tech"],"content":"说明 启动 linux 计算机并使其可用需要分两个步骤：boot（引导） 和 startup（启动）。\n boot 流程在计算机开机时开始，在内核初始化和 systemd 启动时完成。 startup 流程在 boot 流程完成后开始，linux 计算机进入运行状态时结束。  linux 引导和启动过程由以下步骤组成：\n BIOS/UEFI POST（power-on self-test） boot loader (GRUB/GRUB2) kernel initialization（内核初始化） 启动 systemd/init（所有进程的父进程）  详细流程如下图： 基于 BIOS 的启动流程： 基于 UEFI 的启动流程： BIOS/UEFI POST 部分 linux 启动过程的第一步和 linux 系统无关，这是引导过程的硬件部分，对于任何操作系统都是一样的。当计算机首次通电时，它会运行 POST（开机自检）。POST 是 BIOS/UEFI 的一部分，其任务是确保计算机硬件正常运行。如果 POST 失败，计算机可能无法使用，因此引导过程不会继续。\nBIOS\nBIOS POST 检查硬件的基本可操作性，然后发出一个 BIOS 中断 INT 13H，它可以定位任何连接的可引导设备上的引导扇区。它将找到的包含有效引导记录的第一个引导扇区加载到 RAM 中，然后将控制权转移到从引导扇区加载的代码。\nUEFI\nEFI 引导过程不引用 MBR 中的代码，通常也不使用分区引导扇区中的代码。相反，EFI 加载由 EFI 的内置引导管理器指定的引导加载程序，此处是 GRUB。\nGRUB 部分 MBR 分区表磁盘： GPT 分区表磁盘：\nGRUB2 什么是 GRUB2\nGRUB2 代表 GRand Unified Bootloader version 2，它是当前大多数 Linux 发行版的主要引导加载程序\n grub2介绍请查看：grub2介绍\n BIOS 下 GRUB 流程 任一 GRUB 的主要功能是将 linux 内核加载到内存中并运行。两个 GRUB（grub 和 grub2） 版本的工作方式基本相同，并且具有相同的三个阶段。 虽然官方并没有使用三个阶段来说明 GRUB 的工作流程，但是这样理解会比较方便。\nStage 1\n如 BIOS/UEFI POST 部分所述，在 POST 结束时，BIOS 在连接的磁盘中搜索引导记录。引导记录通常位于主引导记录 (MBR) 中，它将找到的第一个 记录加载到内存中，然后开始执行开机。引导代码（即 GRUB2 stage 1）非常小，因为它必须与分区表一起放入硬盘驱动器上的第一个 512 字节扇区。在经典通用 MBR 中为实际引导代码分配的空间总量为 446 字节。阶段 1 的 446 字节文件名为 boot.img，不包含单独添加到引导记录的分区表。\n因为引导记录如此之小，写不了多少代码，功能有限。因此 stage 1 的唯一目的是定位和加载stage 1.5。为了做到这一点，GRUB 的 stage 1.5 必须位于引导记录本身和驱动器上的第一个分区之间的空间中。将 GRUB stage 1.5 加载到 RAM 后，stage 1 将控制权移交给stage 1.5。\nStage 1.5\n如上所述，GRUB 的 stage 1.5 必须位于引导记录本身和磁盘驱动器上的第一个分区之间的空间中。由于技术原因，这个空间在历史上一直未被使用。硬盘驱动器上的第一个分区从扇区 63 开始，MBR 在扇区 0，剩下 62512 字节扇区（31,744 字节）用于存储 GRUB stage 1.5 的 core.img 文件。core.img 文件是 25,389 字节，因此在 MBR 和存储它的第一个磁盘分区之间有足够的空间。\n由于 stage 1.5 可以容纳更多的代码，它可以有足够的代码来包含一些常见的文件系统驱动程序，例如标准 EXT 和其他 Linux 文件系统、FAT 和 NTFS。GRUB2 core.img 比旧的 GRUB1 stage 1.5 更复杂和更强大。这意味着 GRUB2 stage 2可以位于标准 EXT 文件系统上（不能位于lvm逻辑卷上）。所以stage 2文件的标准位置是在 /boot 文件系统中，特别是 /boot/grub2。\n需要特别注意的是，/boot 目录必须位于 GRUB 支持的文件系统上，因为并非所有文件系统都是 GRUB 支持的。stage 1.5 的功能是从加载文件系统驱动程序开始，以在 /boot 文件系统中定位 stage 2 文件并加载所需的驱动程序。\nGRUB2 stage 1.5 的功能是定位 Linux 内核并加载到 RAM 中，并将计算机的控制权交给内核，内核及其相关文件位于 /boot 目录中。内核文件是可识别的，因为它们都以 vmlinuz 开头。\nStage 2\nGRUB2 stage 2将选定的内核加载到内存中，并将计算机的控制权交给内核。\nUEFI 下 GRUB 的流程 /efi//grubx64.efi（x86-64 UEFI 系统）作为文件安装在 EFI 系统分区(ESP)中，并由固件直接引导，在 MBR 扇区 0 中没有 boot.img。此文件类似于 stage1 和 stage 1.5。\n对于 x86-64 UEFI 系统，stage2 是 /boot/grub/x86_64-efi/normal.mod 文件和其他 /boot/grub/ 文件。\n加载完 GRUB 后内容 菜单选择界面\nGRUB 提供一个菜单，用户可以在其中进行选择需要启动的操作系统。 GRUB 可以配置超时后自动加载指定的操作系统。\nkernel 部分 所有内核都采用自解压压缩格式以节省空间。内核与初始 RAM disk image 和硬盘驱动器的设备映射一起位于 /boot 目录中。\n在选定的内核加载到内存并开始执行后，内核首先需要从文件的压缩版本中提取自身，然后才能执行其他工作内容。一旦内核解压了自己，它就会加载 systemd（旧 SysV init 程序的替代品），并将控制权交给它。\n到此 boot process的结束。此时，linux 内核和 systemd 正在运行，但无法为用户执行任何任务，因为当前没有任何服务在运行。\nstartup 部分 startup process 随着 boot process 结束而开始，其作用是使 Linux 计算机进入可用于生产性工作的运行状态。\nsystemd systemd 是所有进程之母，它负责将 Linux 主机提升到可以完成生产性工作的状态。systemd 的功能比旧的 init 要广泛得多，可以管理运行中的 Linux 主机的方方面面，包括挂载文件系统、启动和管理使 Linux 主机高效工作所需的系统服务。\nsystemd 首先挂载 /etc/fstab 定义的文件系统，可以包括任何交换文件或分区。此时，systemd 可以访问位于 /etc 中的配置文件，包括它自己的。\nsystemd 使用其配置文件 /etc/systemd/system/default.target 来确定应将主机引导到哪个状态或目标。default.target 文件只是指向真正目标文件的符号链接。\n 对于桌面环境，通常是 graphics.target，相当于旧 SystemV init 中的运行runlevel 5。 对于服务器，默认值更可能是 multi-user.target，类似于 SystemV 中的运行runlevel 3。 Emergency.target 类似于单用户模式。  请注意，targets 和 service 都是 systemd units。\n下面的表 1 是 systemd target 与旧 SystemV 启动运行级别的比较。\nsystemd target alias 由 systemd 提供以实现向后兼容性。目标别名允许脚本使用 SystemV 命令（如 init 3）来更改运行级别，SystemV 命令会被转发到 systemd 进行解释和执行。 每个 target 都有一组在其配置文件中描述的依赖项，systemd 会启动所需的依赖项。这些依赖项是在特定功能级别上运行 Linux 主机所需的服务。当目标配置文件中列出的所有依赖项都加载并运行时，系统就在该目标级别（target level）运行。\nsystemd 还会查看旧的 SystemV 初始化目录以查看那里是否存在任何启动文件。如果存在，systemd 使用这些作为配置文件来启动文件描述的服务。\n下面的图 1 直接从 bootup man page 复制而来。它显示了 systemd 启动期间事件的一般顺序以及确保成功启动的基本排序要求。\n systemd 介绍请查看：systemd介绍\n sysinit.target 和 basic.target target 可以被视为启动过程中的检查点。尽管 systemd 将并行启动系统服务作为其设计目标之一，但在启动其他services 和 targets之前，仍然必须启动某些service和功能target。在满足该检查点所需的所有services 和 targets之前，无法通过这些检查点。\n因此，当sysinit.target所依赖的所有 units 都启动完成时，就完成了 sysinit.target的启动。所有这些units：挂载文件系统、设置swap、启动 udev，设置random generator seed，启动low-level services、cryptographic服务等必须完成，但在 sysinit.target 中，这些任务可以并行执行。\nsysinit.target 启动所有low-level services和units，系统需要这些services and units才能正常运行，并且需要继续完成 basic.target。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  local-fs-pre.target | v (various mounts and (various swap (various cryptsetup fsck services...) devices...) devices...) (various low-level (various low-level | | | services: udevd, API VFS mounts: v v v tmpfiles, random mqueue, configfs, local-fs.target swap.target cryptsetup.target seed, sysctl, ...) debugfs, ...) | | | | | \\__________________|_________________ | ___________________|____________________/ \\|/ v sysinit.target | ____________________________________/|\\________________________________________ / | | | \\ | | | | | v v | v v (various (various | (various rescue.service timers...) paths...) | sockets...) | | | | | v v v | v rescue.target timers.target paths.target | sockets.target | | | | v \\_________________ | ___________________/ \\|/ v basic.target | ____________________________________/| emergency.service / | | | | | | v v v v emergency.target display- (various system (various system manager.service services services) | required for | | graphical UIs) v | | multi-user.target | | | \\_________________ | _________________/ \\|/ v graphical.target   完成 sysinit.target 后，systemd 接下来启动 basic.target，启动完成它所需的所有units。basic.target 通过启动下一个 target 所需的 units 来提供一些附加功能。其中包括设置各种可执行目录、通信套接字和计时器的路径。\n最后，可以初始化用户级目标 multi-user.target 或 graphics.target。在满足 graphics.target 依赖关系之前，必须达到 multi-user.target。\n上面的文本图中，带下划线的 target 是通常的 startup targets。当达到这些 target 之一时，startup 流程就完成了。如果 multi-user.target 是默认值，那应该会在控制台上看到文本登录界面。如果 graphics.target 是默认值，那应该会看到图形登录界面。\n结论 GRUB2 和 systemd init 系统是大多数现代 Linux 发行版的 boot 和 startup 阶段的关键组件。尽管围绕 systemd 一直存在争议，但这两个组件可以顺利地协同工作，首先加载内核，然后启动 Linux 系统所需的所有系统服务。\n其他 # UEFI 中的多重引导 每个操作系统或 OEM 供应商都可以在 ESP(EFI system partition) 内维护自己的文件，而不会影响对方。因此使用 UEFI 进行多重引导，只是启动与特定操作系统的引导加载程序相对应的不同 EFI 应用程序的问题，不再需要依赖一个引导加载程序的链加载机制来加载另一个操作系统。\n# 什么是 bootloader bootloader（引导加载程序） 是由固件（BIOS 或 UEFI）启动的软件。它负责使用所需的内核参数和相应的 initramfs 映像来加载内核。 在 UEFI 的情况下，内核本身可以由 UEFI 使用 EFI 引导存根（ EFI boot stub） 直接启动。\n bootloader 必须能够访问内核和 initramfs 映像，否则系统将无法引导，因此在设置中，它必须支持访问 /boot。这意味着 bootloader 必须支持从块设备、堆叠块设备（LVM、RAID、dm-crypt、LUKS 等）访问内核和 initramfs 映像所在的文件系统的所有内容。\n\n# boot sector 如下展示了分布在硬盘扇区上的 GNU GRUB 的各种组件。当 GRUB 安装在硬盘上时，boot.img 会被写入该硬盘的引导扇区。 boot.img 的大小只有 446 字节。 # 参考内容 本文参考文章列表如下：\n Working with GRUB 2 An introduction to the Linux boot and startup processes linux system boot Trying to understand the boot loader process / GRUB? How grub2 works on a MBR partitioned disk and GPT partitioned disk? 启动流程、模块管理、BootLoader(Grub2) Arch boot process Linux系统启动过程 efi bootloaders and The EFI Boot Process  ","description":"linux系统的启动流程和各个阶段","tags":["linux","grub","boot","bootloader"],"title":"linux系统启动流程","uri":"/tech/basics/boot_process/linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["tech"],"content":"说明 # grubby 是什么 grubby 是一个可在不同架构下配置 bootloader 菜单条目的命令行工具。\n# 详细内容 grubby 用于更新和显示在特定架构下的引导程序（bootloader）配置文件信息。grubby 是被设计给需要查找有关当前引导环境信息来安装新内核的脚本使用。\n# 支持的架构  支持在x86_64系统上使用传统（legacy） BIOS或者现代 UEFI 固件的 GRUB2 引导加载程序（grub2 bootloader） 支持 ppc64 和 ppc64le 架构的硬件使用 OPAL 或 SLOF 作为固件的 GRUB2 引导加载程序。 支持 s390 和 s390x 架构及其 zipl 引导加载程序（zipl bootloader）。 不再支持 yaboot，从 power8 之后使用 grub2 或 petitboot 的 ppc 架构的硬件都是使用 GRUB2 配置文件格式。 传统引导加载程序 LILO, SILO和 ELILO 被弃用  # 默认行为 默认的引导加载程序主要由构建 grubby 的系统架构决定。每个系统架构都有一个首选的引导加载程序，每个引导加载程序都有其自己的配置文件; 如果没在命令行上配置选择 bootloader，则 grubby 将使用这些默认值来搜索现有配置; 如果找不到 bootloader 配置文件，grubby 将使用该系统架构的默认值, 这些默认值在下表中列出:\n   架构 bootloader 配置文件     x86_64 [BIOS] grub2 /boot/grub2/grub.cfg   x86_64 [UEFI] grub2 /boot/efi/EFI/redhat/grub.cfg   i386 grub2 /boot/grub2/grub.cfg   ia64 elilo /boot/efi/EFI/redhat/elilo.conf   ppc [\u003e=Power8] grub2 /boot/grub2/grub.cfg   ppc [\u003c=Power7] yaboot /etc/yaboot.conf   s390 zipl /etc/zipl.conf   s390x zipl /etc/zipl.conf    # 名词解释 boot entry\n 引导条目（boot entry）是一个选项的集合，该选项存储在配置文件中，并绑定到特定的内核版本。 实际使用中，系统至少有与系统已安装内核一样多的引导条目。 引导条目展示的文件名由存储在 /etc/machine-id 文件中的机器 ID 和内核版本组成。 引导条目配置文件包含有关内核版本，初始 ramdisk image 和 kernelopts（其中包含内核命令行参数） 环境变量的信息。 kernelopts 环境变量在 /boot/grub2/grubenv 文件中定义。 引导条目配置文件位于 /boot/loader/entries/directory 中，类似如下内容: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ cat /boot/grub/grub.cfg ...... ### BEGIN /etc/grub.d/10_linux ###  menuentry 'Manjaro Linux' --class manjaro --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-7afa0d3 2-fd8d-44cc-8e4e-784f2493f4ca' { savedefault load_video set gfxpayload=keep insmod gzio insmod part_gpt insmod ext2 search --no-floppy --fs-uuid --set=root 7afa0d32-fd8d-44cc-8e4e-784f2493f4ca linux /boot/vmlinuz-5.15-x86_64 root=UUID=7afa0d32-fd8d-44cc-8e4e-784f2493f4ca rw quiet apparmor=1 security=apparmor udev.log_priority=3 initrd /boot/amd-ucode.img /boot/initramfs-5.15-x86_64.img } ......     常用的 grubby 命令 # 添加新内核条目 1 2 3 4 5 6 7 8  # 假设已经构建了自己的内核，该内核已安装在服务器上，并希望为此新内核添加自定义条目，可以使用如下命令： $ grubby --add-kernel=new_kernel --title=\"entry_title\" --initrd=\"new_initrd\" --copy-default # 上一条命令使用了 --copy-default ，该参数会从我们的默认内核复制所有内核参数到此新内核条目，若要添加自己的自定义内核参数，可以使用： $ grubby --add-kernel=new_kernel --title=\"entry_title\" --initrd=\"new_initrd\" --args=kernel_args # 示例命令 $ grubby --grub2 --add-kernel=/boot/vmlinuz-4.18.0-193.el8.x86_64 --title=\"Red Hat Enterprise 8 Test\" --initrd=/boot/initramfs-4.18.0-193.el8.x86_64.img --copy-default   # 删除已有内核条目 请谨慎使用此命令，因为该命令会删除当前已有的内核的引导条目。如果删除了不正确内核的内核条目，系统可能无法启动，到时只能进入单用户模式修复损坏的服务器了。\n1 2 3 4 5  # 删除内核条目 $ grubby --remove-kernel=old_kernel # 或者使用索引进行删除 $ grubby --remove-kernel=menu_index   # 添加新的内核参数 1 2 3 4 5 6 7 8  # 添加新的内核参数 $ grubby --update-kernel=current_kernel --args=\"kernel_args\" # 具体命令示例 $ grubby --update-kernel=/boot/vmlinuz-$(uname -r) --args=\"ipv6.disable=1\" # 给当前所有可用内核统一添加内核参数 $ grubby --update-kernel=ALL --args=\"kernel_args\"   # 删除已有的内核参数 1 2 3 4 5 6 7 8  # 删除已有的内核参数 $ grubby --update-kernel=current_kernel --remove-args=\"kernel_args\" # 具体命令示例 $ grubby --update-kernel=/boot/vmlinuz-$(uname -r) --remove-args=\"ipv6.disable=1\" # 给当前所有可用内核统一删除内核参数 $ grubby --update-kernel=ALL --args=\"kernel_args\"   # 删除并添加内核参数 1 2 3 4 5  # 删除和添加内核参数可以同时使用 $ grubby --remove-args=\"kernel-args\" --args=\"kernel_args\" # 具体命令示例 $ grubby --update-kernel=/boot/vmlinuz-$(uname -r) --remove-args=\"quiet\" --args=\"console=ttsy0\"   # 列出所有安装的内核 1 2 3 4 5 6  # 列出所有已经安装的内核 $ grubby --info=ALL | grep ^kernel kernel=\"/boot/vmlinuz-4.18.0-193.14.3.el8_2.x86_64\" kernel=\"/boot/vmlinuz-4.18.0-193.1.2.el8_2.x86_64\" kernel=\"/boot/vmlinuz-4.18.0-193.el8.x86_64\" kernel=\"/boot/vmlinuz-0-rescue-d88fa2c7ff574ae782ec8c4288de4e85\"   # 获取更多有关内核启动条目的信息 获取更多的内核引导条目的信息可以通过命令 grubby --info，命令会提供诸如索引号，boot entry ID，应用于内核的参数等信息\n1 2 3 4 5 6 7 8  $ grubby --info=\"/boot/vmlinuz-$(uname -r)\" index=1 kernel=\"/boot/vmlinuz-4.18.0-193.1.2.el8_2.x86_64\" args=\"ro resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb biosdevname=0 net.ifnames=0 enforcing=0 $tuned_paramsconsole=ttsy0\" root=\"/dev/mapper/rhel-root\" initrd=\"/boot/initramfs-4.18.0-193.1.2.el8_2.x86_64.img $tuned_initrd\" title=\"Red Hat Enterprise Linux (4.18.0-193.1.2.el8_2.x86_64) 8.2 (Ootpa)\" id=\"d88fa2c7ff574ae782ec8c4288de4e85-4.18.0-193.1.2.el8_2.x86_64\"   # 列出默认内核的路径 默认内核是指系统启动时默认使用的内核\n1 2  $ grubby --default-kernel /boot/vmlinuz-4.18.0-193.el8.x86_64   # 列出默认内核在引导条目中的索引号 1 2  $ grubby --default-index 2   # 列出默认内核在引导条目中的标题 1 2  $ grubby --default-title Red Hat Enterprise Linux (4.18.0-193.1.2.el8_2.x86_64) 8.2 (Ootpa)   # 使用内核路径设置默认内核 1 2  # 更改默认内核（更改系统启动默认使用的内核） $ grubby --set-default=\"/boot/vmlinuz-4.18.0-193.1.2.el8_2.x86_64\"   # 使用索引设置默认内核 不使用内核 vmlinuz 来设置默认启动内核，我们还可以通过提供索引号来更改默认内核。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 获取所有已安装内核的索引号 $ grubby --info=ALL | grep -E \"^kernel|^index\" index=0 kernel=\"/boot/vmlinuz-4.18.0-193.14.3.el8_2.x86_64\" index=1 kernel=\"/boot/vmlinuz-4.18.0-193.1.2.el8_2.x86_64\" index=2 kernel=\"/boot/vmlinuz-4.18.0-193.el8.x86_64\" index=3 kernel=\"/boot/vmlinuz-4.18.0-193.el8.x86_64\" index=4 kernel=\"/boot/vmlinuz-0-rescue-d88fa2c7ff574ae782ec8c4288de4e85\" # 通过索引号设置默认内核 $ grubby --set-default-index=2   其他 # 参考内容 https://www.systutorials.com/docs/linux/man/8-grubby/ https://www.golinuxcloud.com/grubby-command-examples/\n","description":"grubby：用于配置 bootloader 菜单条目的命令行工具","tags":["grub","linux","basic","system"],"title":"grubby命令的使用","uri":"/tech/basics/boot_process/grubby%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"categories":["tech"],"content":"双系统安装配置 # 准备工作 当前准备安装 manjaro 的机器是联想小新pro, 已经装有正版 windows 11 系统。考虑到平时也会有用到 windows 办公的场景，所以准备安装双系统，日常使用 manjaro，manjaro 无法满足的场景再使用 windows。\n 刻录系统安装 U盘\n此操作比较简单，直接使用 dd 命令刻录即可; 需要提前下载好 manjaro 系统安装 iso 文件 1 2  # 镜像放在当前目录下，U 盘插入刻录 iso 文件的 linux 系统，识别为 /dev/sdb; 如下命令操作 $ sudo dd if=./manjaro-kde-21.1.4-210927-linux513.iso of=/dev/sdb status=progress    设置 BIOS 中 secure boot 为 disabled\n进入 BIOS 设置，将 secure boot 设置为 disabled，否则无法使用 U 盘装机; 现象是可以选择通过 U 盘启动，但进不了装机界面  # windows 操作内容 windows 默认把磁盘空间用完，需要在 windows 系统上调整分区大小，分出一块空间给 manjaro 使用\n 进入磁盘管理\n右键 windows 图标，选择磁盘管理  选择 D 盘进行缩容\nC 盘空间不建议缩容，对 D 盘做缩容操作  指定压缩卷空间大小即可\n 缩容后显示\n  # manjaro 系统安装 manjaro 安装后，需要保留 windows 的启动入口; linux 发行版安装系统时，默认会保留已有的 windows 启动入口; 反过来，先安装了 linux 发行版，再安装 windows 则不会保留 linux 的启动入口，需要自行修复。所以在给电脑安装双系统时，建议先装 windows 系统，再装 linux 系统。\n  进入安装入口\n此处选择了通过开源驱动启动，下一项为通过专有驱动启动，建议有特殊硬件的设备选择这一项\n  磁盘分区选择\n跳过前面的其他配置内容，磁盘分区需要细心配置，因为要保留 windows 的相应分区，此处选择在 windows 上缩容多出来的 free space 可用空间。\n Partitions/Replace a partition 选中 free space的分区。\n\n  图片显示可以看出，manjaro 使用的仍然是 nvme0n1p1 分区作为 /boot/efi的挂载分区，和 windows 是共用的。\n   分区完成 点击 next 完成分区操作，然后点击 install 完成系统安装   基础配置 # pacman 源地址修改 修改软件源，切换至国内，加快下载速度\n# 修改前备份 $ sudo cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup # 更新镜像源排名 $ sudo pacman-mirrors -i -c China -m rank $ sudo cp /etc/pacman.conf /etc/pacman.conf.backup # 添加ArchLinux中文社区源 $ sudo vi /etc/pacman.conf [archlinuxcn] SigLevel = Optional TrustedOnly # 清华源 Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch # 中科大源 #Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch # 使配置生效 $ sudo pacman-mirrors -g # 更新 pacman 数据库全面更新系统并签名 $ sudo pacman -Syyu \u0026\u0026 sudo pacman -S archlinuxcn-keyring # 先安装一些包，后续其他需要配置的包单独说明 $ sudo pacman -S acpi vim yay # 系统更新 使用 iso 镜像装完了系统，系统软件有些滞后，进行后续配置前，先更新一下系统软件\n# 更新软件包 $ sudo pacman -Syyu # sudo 配置免密 后续的很多配置都需要在命令行下操作，且需要 root 权限，设置 sudo 不需要输入密码，避免配置时总提示输入用户密码\n# 切换到root用户 $ sudo -i # 只需要配置10-installer文件即可，查看配置后的内容 $ sudo cat /etc/sudoers.d/10-installer %wheel ALL=(ALL) NOPASSWD: ALL # git 配置 安装 git\n$ sudo pacman -S git 配置git\n# 用户名 $ git config --global user.name \"\u003cusername\u003e\" # 邮箱 $ git config --global user.email \"\u003cmail-address\u003e\" # 提交时转换为 LF，检出时不转换 $ git config --global core.autocrlf false $ git config --global core.safecrlf false $ git config --global core.autocrlf input # 因为我的 trojan 代理 sock 端口是 1080 $ git config --global http.proxy socks5://127.0.0.1:7891 $ git config --global --add remote.origin.proxy \"\" $ git config --global core.editor \"vim\" # 字体配置 自己使用的系统语言配置是英文的，日常使用需要一些中文字体\n# 安装中文字体 $ sudo pacman -S wqy-zenhei $ sudo pacman -S wqy-bitmapfont $ sudo pacman -S wqy-microhei $ sudo pacman -S ttf-wps-fonts $ sudo pacman -S adobe-source-han-sans-cn-fonts $ sudo pacman -S adobe-source-han-serif-cn-fonts # 时间同步配置 系统时区在系统安装时已经选择了，默认选择 Asia/Shanghai 就可以\n# 若有调整需求，可以用下面命令调整，时区可以 tab tab 出来 $ timedatectl set-timezone Asia/Shanghai 自己的电脑是 windows 11 + manjaro 双系统，需要在 windows 下配置，让 windows 把硬件时间当作 UTC，避免双系统切换导致的时间错乱。\n# Win + R 进入 cmd，以管理员身份运行后在命令行中输入下面命令并回车 \u003cadmin\u003e# Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 在 manjaro 下设置硬件时间同步 utc 系统时间\n# 设置硬件时钟同步系统 utc 时间 $ sudo hwclock --systohc --utc UTC：Universal Time Coordinated，协调世界时\nGMT：Greenwich Mean Time，格林尼治平时\nwindows 与 linux 缺省看待系统硬件时间的方式是不一样的：\n windows 把系统硬件时间当作本地时间(local time)，即操作系统中显示的时间跟 BIOS 中显示的时间是一样的。 linux/unix/mac 把硬件时间当作 UTC，操作系统中显示的时间是硬件时间经过换算得来的，比如说北京时间是GMT+8，则系统中显示时间是硬件时间+8。  # 中文输入法配置 使用 fcitx5管理输入法\n# 安装 Fcitx5 主体、配置工具、输入法引擎及中文输入法模块 $ sudo pacman -S fcitx5-im fcitx5-chinese-addons fcitx5-qt fcitx5-gtk # 配置用户家目录下 pam 环境变量文件，（为了对齐，中间是一个 Tab 键） $ cat ~/.pam_environment GTK_IM_MODULE DEFAULT=fcitx QT_IM_MODULE DEFAULT=fcitx XMODIFIERS DEFAULT=\\@im=fcitx INPUT_METHOD DEFAULT=fcitx SDL_IM_MODULE DEFAULT=fcitx 注销后登陆，输入法显示出来了，进入云拼音和标点符号的配置\n 入口：system settings/regional settings/input method\n或者直接在系统托盘的键盘图标右键点击配置\n 调整云拼音的后端，也即云端词库，选择 Baidu ，google 不一定用的了 修改pinyin的切换候选词配置，默认是上下，需要调整配置到,/.。 # 命令历史记录配置 终端上可能会同时开启几个 tab,如果在多个 tab 上都有执行命令的话，.bash_history 不一定能保留所有的命令历史记录，需要单独配置来记录所有 tab 上执行的命令\n# 在 /etc/profile 中添加如下内容 $ tail -2 /etc/profile export HISTORY_FILE=\"/var/log/CMD_all.log\" export PROMPT_COMMAND='{ thisHistID=`history 1|awk \"{print \\\\$1}\"`;lastCommand=`history 1| awk \"{\\\\$1=\\\"\\\" ;print}\"`;user=`id -un`;whoStr=(`who -u am i`);realUser=${whoStr[0]};logMonth=${whoStr[2]};logDay=${whoStr[3]};pid=${whoStr[5]};ip=${whoStr[6]};if [ ${thisHistID}x != ${lastHistID}x ];then echo -E `date \"+%Y/%m/%d %H:%M:%S\"` $user\\($realUser\\)@$ip[Pid:$pid][LoginTime:$logMonth $logDay] ExecuteCommand: $lastCommand;fi; } \u003e\u003e $HISTORY_FILE' # 先生成日志文件，并修改其权限配置 $ sudo touch /var/log/CMD_all.log $ sudo chmod 666 /var/log/CMD_all.log # 重新加载 /etc/profile 文件，使配置生效 $ source /etc/profile # 后续需要查找之前执行的命令，可以直接执行命令 $ cat /var/log/CMD_all.log | grep \u003citem\u003e 软件的安装配置 # 安装配置 virtualbox # 获取当前内核版本 $ mhwd-kernel -li Currently running: 5.15.28-1-MANJARO (linux515) The following kernels are installed in your system: * linux515 # 安装 virtualbox $ sudo pacman -Syu virtualbox linux515-virtualbox-host-modules # 自己下载镜像，在 virtualbox 上安装系统，保存快照，以后就可以基于快照生成虚拟机 # 安装远程工具 日常工作在 manjaro 上，连接其他 windows 主机或 linux 主机，需要用到 vnc 和 rdp 工具\n# 安装 rdp 工具 remmina $ sudo pacman -S remmina # 安装 vnc 工具 $ yay -S realvnc-vnc-viewer # 安装下载工具 日常下载工具，aria2c + uget\n$ sudo pacman -S aria2 uget # 安装笔记工具 日常笔记工具，trilium-bin\n$ yay -S trilium-bin # 安装 chrome 浏览器 不是很习惯使用火狐，下载 google-chrome\n$ yay -S google-chrome 安装 switchomega-proxy 插件，登陆 google 帐号，开启同步功能后，会自动将 chrome 的配置和书签同步过来。\n登陆谷歌帐号需要翻墙，见下面翻墙配置内容\n# 安装配置 albert albert 是一个快速加载工具，开启相应支持后，可以很方便的打开文件、软件、链接等各种内容，功能类似于 windows 上的 everything; 可以简省很多快捷键配置、减少找文件的时间\n# 安装 albert $ yay -S albert-bin 安装完成后，打开 albert 配置界面，设置快捷键、主题、开机自启、及开启各个插件支持，主题选择了spotlight dark # 开发 IDE 日常使用到的有 vscode，pycharm，直接安装就好\n$ yay -S pycharm-community-eap vscode # 安装 pyenv pyenv 可以在多个版本的 python 之间轻松切换，日常使用如果同时要用到 python2 和 python3，安装配置 pyenv 会很方便\n# 下载最新版的 pyenv 到家目录下 $ git clone https://github.com/pyenv/pyenv.git ~/.pyenv # 进入家目录，进行编译 $ cd ~/.pyenv \u0026\u0026 src/configure \u0026\u0026 make -C src # 添加相应的环境变量到 ～/.bashrc中 $ sed -Ei -e '/^([^#]|$)/ {a \\ export PYENV_ROOT=\"$HOME/.pyenv\" a \\ export PATH=\"$PYENV_ROOT/bin:$PATH\" a \\ ' -e ':a' -e '$!{n;ba};}' ~/.profile $ echo 'eval \"$(pyenv init --path)\"' \u003e\u003e~/.profile $ echo 'eval \"$(pyenv init -)\"' \u003e\u003e ~/.bashrc # 下载 virtualenv 插件到 pyenv 的插件目录下 $ git clone https://github.com/pyenv/pyenv-virtualenv.git $(pyenv root)/plugins/pyenv-virtualenv # 添加环境变量到 ~/.bashrc 中 $ echo 'eval \"$(pyenv virtualenv-init -)\"' \u003e\u003e ~/.bashrc # 重启 bash，加载 virtualenv $ exec $SHELL 使用 pyenv 管理多版本 python 时可能用到的一些特殊变量：\n Special environment variables\nYou can set certain environment variables to control pyenv-virtualenv.\n   PYENV_VIRTUALENV_CACHE_PATH, if set, specifies a directory to use for caching downloaded package files.\n  VIRTUALENV_VERSION, if set, forces pyenv-virtualenv to install the desired version of virtualenv. If virtualenv has not been installed, pyenv-virtualenv will try to install the given version of virtualenv.\n  GET_PIP, if set and venv is preferred over virtualenv, use get_pip.py from the specified location.\n  GET_PIP_URL, if set and venv is preferred over virtualenv, download get_pip.py from the specified URL.\n  PIP_VERSION, if set and venv is preferred over virtualenv, install the specified version of pip.\n  PYENV_VIRTUALENV_VERBOSE_ACTIVATE, if set, shows some verbose outputs on activation and deactivation\n安装和配置 virtualenv\n# 安装指定版本的 python $ pyenv install 2.7.15 -v # 在 指定的目录下，使用基于指定 python 版本的 virtualenv # 如下，会在目录 my-virtual-env-2.7.10 下创建一个基于 $(pyenv root)/versions 中 2.7.10 版本 python 的 virtualenv $ pyenv virtualenv 2.7.10 my-virtual-env-2.7.10 # 从指定版本创建 virtualenv $ pyenv virtualenv 2.7.16 py27 # 激活/释放 virtualenv $ pyenv activate \u003cname\u003e $ pyenv deactivate # 删除 virtualenv $ pyenv uninstall my-virtual-env $ pyenv virtualenv-delete my-virtual-env   # 博客使用 日常写博客用的是 hugo，图床用的是阿里云OSS，图片上传到图床的工具用 picgo\n# 安装 hugo $ sudo pacman -S hugo # 安装 picgo $ yay -S picgo markdown 文件中包含了中英文和数字，美观起见，互相之间应该加一个空格。除了在写的时候注意调整，还可以使用 textlint 来检查和修改，如下方式进行配置：\n# 安装 textlint $ npm install textlint --global $ npm install textlint-rule-ja-space-between-half-and-full-width --global $ cd ~ \u0026\u0026 textlint --init # 配置 .textlintrc 配置文件 $ cat .textlintrc { \"filters\": {}, \"rules\": { \"ja-space-between-half-and-full-width\": { \"space\": \"always\" } } } # 使用 textlint 检查 $ textlint *.md # 使用 textlint 修复 $ textlint --fix *.md # 安装 wps marjaro 无法使用 office套装（可能也可以，自己没找到可用的方式），libreoffice 自己用的不习惯，选了 wps 做替代\n# 安装 wps, 建议英文界面下安装 wps-office, 安装 wps-office-zh 后使用过程中碰到过一些报错 $ yay -S wps-office # 安装网易云音乐 日常听歌使用\n$ yay -S netease-cloud-music # 安装街机模拟器 mame 街机游戏\n$ sudo pacman -S mame # 安装 xmind-2020 思维导图使用\n# xmind-2020 需要使用 snap 进行安装，manjaro 系统安装完成后已经有 snap 了; 若没有，则按以下方式进行配置 $ sudo pacman -S snapd $ sudo systemctl enable --now snapd.socket $ sudo ln -s /var/lib/snapd/snap /snap # 安装 xmind-2020 $ sudo snap install xmind xmind-2020 个人使用可以不用激活，感觉没有增强功能也足够使用了\n易用性/界面优化 需要使用到的一些配置文件/工具，已经提前准备好，直接拷贝到机器上。包括有：\n 配置文件  .bashrc：个人用户使用的 bash 配置文件，包括一些配置的别名、环境变量等 .vimrc：个人用户使用的 vim 配置文件，包括缩进、语法高亮、插件、主题等 .tmux.conf：tmux 的配置文件，tmux 的一些配置 shell_init.tar.gz：自己使用的一些终端banner，可以不用管   需要网上找，直接本地备份的一些文件  Trojan-Qt5-Linux.AppImage：trojan-qt5，服务器延迟不稳定但能使用，不是很适合clash，还是用 trojan了 Proxy-SwitchyOmega-Chromium.crx：chrome 的代理插件    # yakuake/tmux/bash/vim 配置 bash/vim 配置很简单，直接将 .bashrc 和 .vimrc 文件拷贝到用户家目录下即可。\n# shell_init.tar.gz是自己使用的一些内容，就不放出来了 $ tar xf ./shell_init.tar.gz $ mv .english* ~/ $ mv ./{.vimrc,.bashrc} ~/ 配置 yakuake 和 tmux\n# yakuake 在 manjaro 安装时已经自带，可以不用安装; # 安装 tmux $ sudo pacman -S tmux 将自己备份的 tmux.conf 文件拷贝到用户家目录下，重命名为 .tmux.conf。拷贝 tmux 配置文件生效后，需要配置 yakuake, 因为 tmux 配置中 Alt + \u003cnum\u003e  的配置占用了yakuake的快捷键，不配置的话无法在 yakuake 中切换 tab。如下所示进行配置（yakuake/config keyboard shortcuts）： 顺带把 yakuake 主题和边框都调整好\n# 调整终端的配置（profile） manjaro 安装完成后，终端默认的配置方案（profile）不是很喜欢，新增配置方案（最初默认的profile修改了不能保存），配置好后将其设置为默认的配置方案\n 新建 profile（konsole/settings/manage profiles/new）  选择配置方案及字体  鼠标选中复制   # 配置翻墙 翻墙软件自己使用的是 trojan-qt5 的 AppImage 版本，这个可以在网上自行搜索下载。不想配置全局代理，还可以安装 provixy\n# 将下载的 appimage 文件放到 /tmp 下 $ mv Trojan-Qt5-Linux.AppImage /tmp $ chmod +x /tmp/Trojan-Qt5-Linux.AppImage # 创建自定义的 AppImage 存储目录 $ mkdir ~/.Applications # 运行 AppImage $ /tmp/Trojan-Qt5-Linux.AppImage # 配置 trojan 开机自启，创建软链接 $ sudo ln -s /home/\u003cusername\u003e/.Applications/Trojan-Qt5-Linux_cb059cf83989c64d7d13dd501bcd6b62.AppImage /usr/bin/trojan # 配置 trojan 开机自启，生成 autostart 文件 $ cat /home/\u003cusername\u003e/.config/autostart/trojan.desktop [Desktop Entry] Exec=/usr/bin/trojan Icon=dialog-scripts Name=trojan Path= Type=Application X-KDE-AutostartScript=true 第一次执行 AppImage 时，会要求确认 applications 存放的位置，设置存储路径到~/.Applications。\n导入gui-config.json文件，配置 trojan（settings/General settings）\n 常规设置  入站设置  出站设置   配置完成后测试延迟，选择一个延迟较低的连接即可\n配置 switchomega-proxy 为socks5 监听端口1080 安装并配置privoxy,启动服务\n# 安装 privoxy $ sudo pacman -S privoxy # 配置配置文件，trojan 监听的是1080端口，转发端口为 8118 $ grep '^forward-socket' /etc/privoxy/config listen-address 127.0.0.1:8118 forward-socks5t / 127.0.0.1:1080 . # 启动 privoxy，并设置开机自启 $ sudo systemctl start privoxy.service \u0026\u0026 sudo systemctl enable privoxy.service 上述内容配置完成后，chrome 开启代理模式，然后登陆 google 帐号，各项配置、插件、书签会自动同步\n# 安装wudao-dict wudao-dict 是一个命令行下查单词的工具，日常看文档、wiki的时候有不清楚的单词，可以很方便的查询\n$ cd ~/Downloads/linux $ git clone https://github.com/chestnutheng/wudao-dict $ cd ./wudao-dict/wudao-dict $ sudo bash setup.sh # 界面优化   配置系统托盘，在上尖点击右键，进入项目可以配置\n  unpin 所有托盘图标\n  # 安装 numix 主题相关 numix 主题安装\n命令行下安装 numix-folders 相关内容，可以调整 numix 默认的棕红色\n$ sudo pacman -S python-dulwich $ pamac build numix-icon-theme-git $ pamac build numix-square-icon-theme-git $ pamac build numix-circle-icon-theme-git $ pamac build numix-folders-git 安装numix，进入终端，开启代理后再打开系统设置，不然可能下载不了 numix 主题，下载界面会一直报错\n$ export http_proxy='http://127.0.0.1:8118' # 打开界面后，进入主题安装，搜索 numix 进行安装 $ /usr/bin/systemsetting 更改 numix 默认的文件夹颜色\n# 打开界面后，自行选择颜色 $ sudo numix-folders splash screen配置\n如下图，选择自己喜欢的安装即可 SDDM 配置\n如下图，选择自己喜欢的安装即可 Plasma style配置\n如下图，选择自己喜欢的进行安装 锁屏配置\n如下图，先安装 wallpaper plugin flipclock\n 入口：桌面空白处右键/configure desktop and wallpaper/wallpaper type/get new plugins\n 如下图，配置锁屏界面\n 入口：system settings/workspace behavior/screen locking/apperance/configure/wallpaper type/flipclock\n # 语言设置 切换默认语言，可以自行设置\n 入口: system settings/regional settings/languages\n  要从中文切换为英文，添加语言选择 American English  调整语言顺序  logout 再登陆，配置生效  # 快捷键配置 设置一些快捷键，方便日常使用\n 入口：system settings/shortcuts/custom shortcuts/Edit/New/Global shortcuts/Commands URLs\n 这边添加的有：google-chrome、kate、virtualbox、dolphin\n其他 参考内容：\n Windows + Linux 双系统时间同步问题解决 manjaro linux 界面优化 pyenv安装 pyenv-virtualenv使用 Get your time/timezone right using Manjaro/Windows dual-boot Markdown 自动添加中英文空格 grub2-theme Linux上安装街机模拟器  ","description":"manjaro 系统安装完成后的配置优化内容","tags":["manjaro","linux","系统安装"],"title":"Manjaro系统初始化","uri":"/tech/miscell/manjaro%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"categories":["tech"],"content":"说明 日常工作内容，或多或少会包含部分运维相关内容，像：\n 自测环境使用完成，需要重装 服务器故障，宕机后无法进入系统定位故障原因 修复操作系统，需要设定硬件服务器下次从光盘启动 ...  如果不具备一些基本条件，可能就需要蹲机房解决这些问题了。\n当硬件服务器的管理口有连接到交换机，并且在办公环境下能正常访问该交换机的话，上述的问题就比较好解决了，可以通过 ipmi 来查看/管理服务器\n什么是IPMI IPMI 的全称是 Intelligent Platform Management Interface，智能平台管理接口的意思。\nIPMI 原本是一种Intel架构的企业系统的周边设备所采用的一种工业标准\nIPMI 是一个开放的免费标准，用户无需支付额外的费用即可使用此标准。\nIPMI 能够横跨不同的操作系统、固件和硬件平台，可以智能的监控、控制和自动上报大量服务器的运作状况，以降低服务器系统成本。\n发展历史   1998年Intel、DELL、HP及NEC共同提出IPMI规格，可以透过网络远程控制温度、电压。\n  2001年IPMI从1.0版改版至1.5版，新增 PCI Management Bus等功能。\n  2004年Intel发表了IPMI 2.0的规格，能够向下兼容IPMI 1.0及1.5的规格。新增了Console Redirection，并可以通过Port、Modem以及Lan远程管理服务器，并加强了安全、VLAN 和刀片服务器的支持性。\n  2014年2月11日，发表了v2.0 revision 1.1, 增加了IPv6的支持。\n  ipmi 的特点  IPMI 独立于操作系统外自行运作，允许管理员在即使缺少操作系统或系统关机但有接电源的情况下，仍能远程管理系统。 IPMI 能在操作系统启动后活动，与系统管理功能一并使用时，还能提供加强功能（linux 的 ipmi 服务）。  ipmi 的结构 IPMI包含了一个以 基板管理控制器(BMC：baseboard management controller) 为主的控制器和其他分布在不同系统模块（被称为“卫星”控制器）的管理控制器。\n同一机箱内的卫星控制器通过称为 智能平台管理总线（IPMB：Intelligent Platform Management Bus/Bridge）的系统接口连接到BMC - 增强的I²C（Inter-Integrated Circuit）的实现。\nBMC通过智能平台管理控制器（IPMC）总线连接到另一个机箱中的卫星控制器或其他BMC。\n它可以使用 远程管理控制协议（RMCP：Remote Management Control Protocol） 进行管理，RMCP是该规范定义的专门电线协议。\nBMC IPMI 的核心是 BMC，BMC 是一种专门的微控制器，该微控制器嵌入了计算机（通常是服务器）主板上。在工作时，所有的 IPMI 功能都是向 BMC 传送命令来完成的，命令使用 IPMI 规范中规定的指令，BMC 接收并在系統事件日志中记录事件信息。\nBMC管理系统管理软件和平台硬件之间的接口。BMC拥有专用的固件和RAM。\n计算机系统中内置的不同类型的传感器向BMC报告温度、冷却风扇速度、电源状态、操作系统（OS）状态等参数。BMC监视传感器，并可以通过网络向系统管理员发送警报，如果任何参数不在预设限制范围内，则表明系统的潜在故障。管理员还可以与BMC进行远程通信，来采取一些纠正措施，例如重置系统以使hang死的系统再次运行。这些能力降低了系统维护的成本。\n符合IPMI版本2.0的系统也可以通过LAN串行进行通信，从而可以在LAN上远程查看串行控制台输出。支持IPMI 2.0的系统通常还包括基于IP的KVM、远程虚拟媒体、嵌入式网络服务器接口功能，尽管严格地说，这些功能都不在IPMI接口标准范围内。\nipmitool 的使用 ipmitool 是一种可用在 linux 系统下的命令行方式的 ipmi 平台管理工具，它支持 ipmi 1.5 规范（最新的规范为 ipmi 2.0），通过它可以实现获取感测器的信息、显示系统日志内容、网路远程开关机等功能。\n本地管理  ipmitool 的安装  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # 安装相应包 $ yum install OpenIPMI OpenIPMI-tools # 启动 ipmi 服务，才能在 linux 上使用 $ systemctl enable ipmi.service; systemctl start ipmi.service # 要能够正常的使用 ipmi 功能，需要加载相应的 ipmi 模块 $ modprobe ipmi_msghandler $ modprobe ipmi_devintf $ modprobe ipmi_si $ modprobe ipmi_poweroff $ modprobe ipmi_watchdog # 获取信道信息（一般是信道1） $ for i in $(seq 1 14); do ipmitool lan print $i 2\u003e/dev/null | grep -q ^Set \u0026\u0026 echo Channel $i; done Channel 1    查看固件版本  1  $ ipmitool mc info    重置 MC（management controller）  1 2  # 两种方式，硬重置/软重置 $ ipmitool mc reset [ warm | cold ]    输出传感器信息（sensor）  1 2 3 4 5  $ ipmitool sdr list # list sensor $ ipmitool sdr type list $ ipmitool sdr type Temperature $ ipmitool sdr type Fan $ ipmitool sdr type 'Power Supply'    chassis 相关命令  1 2 3 4 5 6 7  $ ipmitool chassis status $ ipmitool chassis identify [] # turn on front panel identify light (default 15s)  $ ipmitool [chassis] power soft # initiate a soft-shutdown via acpi  $ ipmitool [chassis] power cycle # issue a hard power off, wait 1s, power on  $ ipmitool [chassis] power off # issue a hard power off  $ ipmitool [chassis] power on # issue a hard power on  $ ipmitool [chassis] power reset # issue a hard reset    修改下一次系统启动的引导设备  1 2 3  $ ipmitool chassis bootdev pxe # via pxe $ ipmitool chassis bootdev cdrom # via cdrom $ ipmitool chassis bootdev bios # into bios setup    日志相关  1 2 3 4  $ ipmitool sel info $ ipmitool sel list # show system event log $ ipmitool sel elist # extended list (see manpage)  $ ipmitool sel clear    用户配置  1 2 3 4 5  # 打印本机用户 $ ipmitool user list 1 $ ipmitool channel setaccess 1 2 callin=true ipmi=on link=on privilege=4 $ ipmitool user set name 2 root $ ipmitool user set password 2 password@123    网络配置  1 2 3 4 5 6 7 8  # 打印信道1上配置的 IP 信息 $ ipmitool lan print 1 # 配置信道1的 IP 相关内容 $ ipmitool lan set 1 ipsrc [ static | dhcp ] $ ipmitool lan set 1 ipaddr {YOUR DESIRED IP} $ ipmitool lan set 1 netmask {YOUR NETMASK} $ ipmitool lan set 1 defgw ipaddr 10.0.1.1 $ ipmitool bmc reset cold   远程管理 若需要使用 ipmi 远程管理其他主机，则需要在 ILO 或 DRAC 卡或 ipmitool 在 OS 上配置用户和网络。\n配置 LAN 设置后，就可以使用 ipmitool 的 lan 接口进行远程连接，管理其他同网段的服务器。\n ipmitool 远端管理  1 2 3 4 5 6 7 8 9 10  # 远程管理机器 $ ipmitool -I lanplus -U \u003cusername\u003e -P \u003cpassword\u003e -H \u003cBMC_IP or Hostname\u003e chassis power \u003cstatus|on|off|cycle|reset\u003e # 重置 BMC $ ipmitool bmc reset cold # 激活 SOL 系统控制台 $ ipmitool -I lanplus -U \u003cusername\u003e -P \u003cpassword\u003e -H \u003cBMC_IP or Hostname\u003e sol activate # 退出 SOL 系统控制台 $ ipmitool -I lanplus -U \u003cusername\u003e -P \u003cpassword\u003e -H \u003cBMC_IP or Hostname\u003e sol activate   共享口和独享口 物理服务器会有一个单独的 BMC 管理口，一般是千兆网口; 进入 BIOS 设置，配置 BMC IP，IP 地址生效的网口就是这个管理口。 这个管理口在 BIOS 中可以配置两种模式：共享模式、独享模式\n共享模式 共享模式可以在 BIOS 中设置，要清楚共享模式的实现，需要先了解 网络控制器边带接口：NC-SI（network controller sideband interface），这一技术是用来实现 BMC 芯片和以太网控制器之间信息传递的，它使得 BMC 芯片能够像使用独立管理网口那样使用主板上的网络接口。\nNC-SI 支持将 BMC(baseboard management controller) 连接到服务器计算机系统中的一个或多个网络接口控制器 (NIC：network interface controllers)，以实现带外系统管理。这使得对应网口除了常规的主机流量外，还可以接受 BMC 的管理网流量。\n简单理解：BMC 其实是一个单片机，它有自己独立的 IO 设备，而独立网口就是其中之一。将BMC芯片和网络控制器之间互联，并通过 NC-SI 技术使得 BMC 芯片能够使用网络控制器上的接口。\n共享模式优势 如下几方面：\n 减少物料成本：可以在物理机系统需要配置千兆网时，节省一根网线 减少交换机投入：独立网口会多占用一个交换机端口，增加交换机采购数量，使用共享模式减少了这部分的支出和额外的交换机运维成本 减少人力成本：如果业务网只需要接一根网线，共享方案可以减少一半的布线人力支出；  共享模式潜在风险 如下：\n 系统千兆网和 BMC 管理网使用的是同一个物理网口，网口故障时，BMC 和 千兆网将同时不可访问，单点故障  共享模式配置 不同型号硬件服务器界面可能不一样，实际的配置内容相同，都是通过 BIOS 或者 BMC WEB界面 将 IPMI 访问方式修改为 share（共享模式）。\n独享模式 独享模式是默认模式，BMC 管理网单独使用一个网口，不和系统共用。\n其他 python接口使用 ipmi 的 python 库是 python-ipmi，具体内容可以参考：python-ipmi\n 使用 pip 安装 1 2  # pip 直接安装 $ pip install python-ipmi    接口调用示例 如下示例，使用 ipmitool 作为网络和串行接口的后端来设置接口和连接。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import pyipmi import pyipmi.interfaces # Supported interface_types for ipmitool are: 'lan' , 'lanplus', and 'serial-terminal' interface = pyipmi.interfaces.create_interface('ipmitool', interface_type='lan') connection = pyipmi.create_connection(interface) connection.target = pyipmi.Target(0x82) connection.target.set_routing([(0x81,0x20,0),(0x20,0x82,7)]) connection.session.set_session_type_rmcp('10.0.0.1', port=623) connection.session.set_auth_type_user('admin', 'admin') connection.session.establish() connection.get_device_id() # 对应的 ipmitool 命令：  # ipmitool -I lan -H 10.0.0.1 -p 623 -U \"admin\" -P \"admin\" -t 0x82 -b 0 -l 0 raw 0x06 0x01     服务器接线 需要使用到 PXE 和 ipmi 的几种常见接线方式：\n 系统 PXE 使用服务器 BMC 管理口，BMC 是共享模式，BMC 和 PXE 流量都要走同一个千兆交换机口 系统 PXE 使用服务器千兆口，BMC 是独享模式，BMC 和 PXE 流量各走千兆交换机一个口 系统 PXE 使用服务器万兆口，BMC 是独享模式，万兆网作为 PXE 口  参考链接 参考内容：\nhttps://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface\nhttps://www.easyatm.com.tw/wiki/ipmitool\nhttps://www.ibm.com/docs/en/power9/0000-FUL?topic=msbui-common-ipmi-commands-2\nhttps://serverfault.com/questions/259792/how-does-ipmi-sideband-share-the-ethernet-port-with-the-host\nhttps://developer.aliyun.com/article/544871\nhttps://github.com/kontron/python-ipmi\n","description":"ipmi的介绍和ipmitool工具的使用","tags":["ops","ipmi","linux"],"title":"ipmi的使用","uri":"/tech/ops/ipmi%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"categories":["tech"],"content":" 工具下载: openssl-toolkit\n 说明 openssl-toolkit 是一个封装好的 openssl 命令行工具(shell 脚本), 可以用来执行证书管理等相关任务.\n工具使用 下载完成后, 上传文件至可执行 shell 脚本的环境\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ## 执行脚本, 查看帮助/说明内容 $ bash openssl-toolkit.sh ____ __________ ______ ____ _ __ / __ \\___ ___ ___ / __/ __/ / ___/_ __/__ ___ / / /__ (_) /_ / /_/ / _ \\/ -_) _ \\_\\ \\_\\ \\/ /_/___// / / _ \\/ _ \\/ / '_// / __/ \\____/ .__/\\__/_//_/___/___/____/ /_/ \\___/\\___/_/_/\\_\\/_/\\__/ /_/ Submenu options: 1. Create certificates 2. Convert certificates 3. Locally verify certificates 4. Externally verify certificates (s_client) 5. Output certificate information q. Quit Selection:   Create certificates(创建证书)   Self-Signed SSL Certificate (key, csr, crt)\n 生成自签名 SSL 证书\n 自签名证书的优点:\n 免费(自己生成) 随时签发 方便(证书过期处理)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  ## 实际使用命令为, 以下 ${pass} 为执行过程中需要手动输入的密码 $ openssl genrsa -passout pass:${pass} -des3 -out server.key 2048 # 1. 生成密钥文件 # genrsa : 生成一个 rsa key 文件, 也即密钥文件, 此处只会生成私钥文件, 不会生成公钥, 因为公钥提取自私钥 # -passout: 对生成的 RSA 秘钥文件施加密码保护, 结合 pass 使用 # pass:${pass} : ${pass} 为交互输入时给定的密码, 这里作用是设置私钥的密码 # -des3: Triple-DES Cipher, 指定加密私钥文件用的算法, 三重数据加密算法的意思, 对私钥加密密码 ${pass}  # 应用三次DES加密算法 # 2048: 指生成多少位的私钥, 还可以为512/1024等 $ openssl req -sha256 -new -key server.key -out server.csr -passin pass:${pass} # 2. 通过 server.key 私钥, 生成 server.csr 文件 # 如果要一个 CA(Certificate Authority) 认证机构颁发 CRT 证书的话, 需要先提供 # 一个 CSR(Certificate Signing Request) 请求文件. # 这个 CSR 请求文件中, 会包含公钥(Public Key), 以及一些申请者信息 (DN Distingusied Name). # DN 信息中最重要的部分是 Common Name (CN), 需要与后续安放 CRT 证书的服务器  # FQDN(Fully Qualified Domain Name) 完全一致才行.  # openssl-toolkit 会在执行过程中要求输入 DN 信息, 请按实际情况填写相应内容. # # req: PKCS#10 X.509 CSR 管理相关 # -new: 生成一个新的 CSR 请求文件 # -key: 指定已有的私钥文件 # -passin: 指定私钥文件的加密密码 $ openssl x509 -req -sha256 -days $certDays -in $csr -signkey $key -out $crt -passin pass:${pass} # 3. 根据已有的密钥文件 ${key} 和请求文件 ${csr} 来产生自签名 CRT(certificate) 证书文件 # -days: 指定生成的证书有效时间 # -in: 指定 CSR 请求文件 # -signkey: 指定私钥文件 # -out: 指定生生成的 CRT 文件 $ openssl rsa -in $key -out nopassword.key -passin pass:${pass} $ cat nopassword.key ${crt} \u003e\u003e server.pem $ rm -f nopassword.key # 4. 生成 server.pem 文件, 保存不加密的私钥和 CRT 证书内容     Private Key \u0026 Certificate Signing Request (key, csr)\n 创建私钥和证书签名请求(CSR)\n 1 2 3 4 5 6 7  ## 实际使用命令为, ${pass} 为执行时手动交互输入 $ openssl genrsa -passout pass:${pass} -des3 -out server.key 2048 # 1. 生成密钥文件 $ openssl req -sha256 -new -key server.key -out server.csr -passin pass:${pass} # 2. 通过 server.key 私钥, 生成 server.csr 文件, 需要交互输入 DN 内容     PEM with key and entire trust chain\n 生成包含整个证书链和 key 的 PEM 文件\n 1 2 3 4 5 6 7  ## 实际使用命令为 # 生成 server.pem 文件, 保存不加密的私钥和 CRT 证书内容 # 证书链有多少级, 则执行多少次如下内容, 注意区分每次的 ${key} 和 ${crt}:  $ openssl rsa -in $key -out nopassword.key -passin pass:${pass} $ cat nopassword.key ${crt} \u003e\u003e server.pem $ rm -f nopassword.key     Convert certificates(格式转换) 不同格式证书说明\n  PEM -\u003e DER\n PEM 转换为 DER\n 1 2 3  ## 实际使用命令为 $ openssl x509 -outform der -in server.pem -out server.der # x509: X.509证书数据管理     PEM -\u003e P7B\n PEM 转换为 P7B\n 1 2 3 4 5 6 7  ## 实际使用命令为 $ openssl crl2pkcs7 -nocrl -certfile server.pem -out server.p7b # crl2pkcs7: CRL to PKCS#7 # -nocrl: 通常 CRL 包含在输出文件中. 使用此选项时, 输出文件中不会包含 CRL, 并且不会从输入文件中读取 CRL. # crl: (Certificate Revocation List)证书吊销列表, 是 PKI 系统中的一个结构化数据文件,  # 该文件包含了证书颁发机构 (CA) 已经吊销的证书的序列号及其吊销日期. CRL 文件中还包含证书颁发机构信息、 # 吊销列表失效时间和下一次更新时间, 以及采用的签名算法等.     PEM -\u003e PFX\n PEM 转换为 PFX\n 1 2 3 4 5 6 7  ## 实际使用命令为 $ openssl pkcs12 -export -out server.pfx -inkey server.pem -in server.pem -certfile server.pem # pkcs12: PKCS#12 数据管理 # 转换为 PFX 格式, 需要交互输入加密密码 # -inkey: 私钥文件, 此处即 server.pem # -in: 指定要解析的 PKCS＃12 文件的文件名, 此处为 server.pem # -certfile: 要从中读取其他证书的文件名, 此处仍是 server.pem     DER -\u003e PEM\n DER 转换为 PEM\n 1 2 3  ## 实际使用命令为 $ openssl x509 -inform der -in server.der -out server.pem # x509: X.509 证书数据管理     P7B -\u003e PEM\n P7B 转换为 PEM\n 1 2 3 4  ## 实际使用命令为 $ openssl pkcs7 -print_certs -in server.p7b -out server.pem # pkcs12: PKCS#7 数据管理 # -print_certs: 打印出文件中包含的任何证书或 CRL.     P7B -\u003e PFX\n P7B 转换为 PFX\n 1 2  ## 实际使用命令为 $ openssl pkcs7 -print_certs -in server.p7b -out server.pfx     PFX -\u003e PEM\n PFX 转换为 PEM\n 1 2 3  ## 实际使用命令为 $ openssl pkcs12 -in server.pfx -out server.pem -nodes # -nodes: 不加密私钥     Verify certificates(证书校验)   CSR is a public key from the private key\n 校验 CSR 是来自私钥的公钥\n 1 2 3 4 5  ## 实际使用命令为 # -noout: 防止输出请求的编码版本. # -modules: 打印出请求中包含的公钥的模值. $ openssl rsa -noout -modulus -in server.key $ openssl req -noout -modulus -in server.csr     Signed certificate is the public key from the private key\n 校验签名证书是来自私钥的公钥\n 1 2 3 4 5  ## 实际使用命令为 # -noout: 防止输出请求的编码版本. # -modules: 打印出请求中包含的公钥的模值. $ openssl x509 -noout -modulus -in server.crt $ openssl rsa -noout -modulus -in server.pem     Chain file applies to the signed certificate (complete ssl chain)\n 校验证书链适用于签​​名证书（包含完整的 ssl 链）\n 1 2 3 4 5  ## 实际使用命令为 # verify: 证书校验 # -purpose: 证书的预期用途. 如果未指定此选项, verify 将不会在链验证期间考虑证书用途. # 当前接受的用途是 sslclient、sslserver、nssslserver、smimesign、smimeencrypt. $ openssl verify -verbose -purpose sslserver -CAfile server.pem server.crt     Check date validity of certificates\n 检查证书的日期有效性\n 1 2 3 4 5  ## 实际使用命令为 # -noout: 防止输出请求的编码版本. # -enddate: 打印出证书的到期日期, 即 notAfter 日期. $ openssl x509 -checkend 7776000 -in server.crt $ openssl x509 -noout -enddate -in server.crt     Test ssl server(测试 ssl 服务器)   SSL Certificate handshake\n SSL 证书能否完成握手连接\n 1 2  ## 实际使用命令为 $ openssl s_client -connect \"$server\":\"$port\"     SSL Server date validity\n 检查 SSL 服务器日期有效性\n 1 2  ## 实际使用命令为 $ openssl s_client -connect \"$server\" 2\u003e\u00261 | openssl x509 -text | grep -i -B1 -A3 validity     Permitted Protocols\n 检查允许的协议\n 1 2 3  ## 实际使用命令为 $ timeout 3 openssl s_client -connect www.baidu.com:443 -no_ssl3 -no_tls1 $ timeout 3 openssl s_client -connect www.baidu.com:443 -cipher NULL,LOW     Output certificate information(输出证书信息)   Output the details from a certifticate sign request\n 从证书签名请求中(CSR)输出详细信息\n 1 2  ## 实际使用命令为 $ openssl req -text -in ${csr}     Output the details from a signed certificate\n 从签名证书中输出详细信息\n 1 2  ## 实际使用命令为 $ openssl x509 -text -in ${crt}     什么是 DN   什么是 DN: Distingusied Name 专有名称 (DN) 是描述证书中的标识信息的术语, 是证书本身的一部分.\n向不同的 CA 申请证书, 对应要求的 DN 信息不一样.\n每个 CA 都有一个策略来确定 CA 需要哪些识别信息来颁发证书. 像电子邮件地址这类需要的信息就很少, 其他的一些公共 CA 可能需要更多的信息, 并在颁发证书之前要严格地证明该识别信息.\n为任一类型的证书提供的 DN 信息包括：\n Certificate owner's common name Organization Organizational unit Locality or city State or province Country or region  一些额外的 DN 信息，包括：\n Version 4 or 6 IP address Fully qualified domain name E-mail address    以下列出一些 DN 首选项\n     DN 信息 描述 示例     CN Common Name 希望被保护的完全限定域名(FQDN) *.wikipedia.org   O Organization Name 通常是公司或实体的法定名称，应包含任何后缀，例如 Ltd. Inc. 或 Corp. Wikimedia Foundation, Inc.   OU Organizational Unit 内部组织部门/部门名称 IT   L Locality 镇、市、村等的名称 ShenZhen   ST State 省、地区、县或州, 不可以缩写 GuangDong   C Country 组织所在国家/地区的两个字母 ISO 代码 CN   EMAIL Email Address 组织联系人，通常是证书管理员或 IT 部门的联系人     CA/ca.crt/单双向认证  这一段是截取 SSL-TLS 双向认证：SSL-TLS 工作原理 中的部分内容, 因为已经讲解的很清楚, 直接粘贴了\n CA 全称为 Certificate Authotiry, 证书授权中心, 又被称为根证书. 它类似于工商管理局, 给公司企业颁发营业执照. CA 有两大主要特性：\n CA 本身是受国际认可, 可以被信任的 CA 需要给信任的对象颁发证书  哪里可以查看证书:\n Chrome 浏览器：设置 -\u003e 高级 -\u003e 管理证书 -\u003e 授权中心 Ubuntu: /etc/ssl/certs  CA 的证书 ca.crt 与 SSL Server 的证书 Server.crt 的关系\n SSL Server 自己生成一个密钥 KEY, 内置包含 Private Key/Public Key, 私钥加密, 公钥解密. Server 利用密钥生成一个请求文件 server.csr, 请求文件中包含有 Server 的一些信息, 如域名/申请者/公钥等. Server 将请求文件 server.csr 递交给 CA, 然后 CA 对其验明正身后, 将用 ca.key 和 server.csr 加密生成 server.crt 证书. 由于 ca.key 和 ca.crt 是一对, 于是以后客户端通过使用 ca.crt 就可以解密认证 server.crt 证书了.  什么是 SSL/TLS 单向认证/双向认证\n 单向认证, 指的是只有一个对象校验对端的证书合法性. 通常都是 client 来校验服务器的合法性. 那么 client 需要一个 ca.crt, 服务器需要 server.crt，server.key. 双向认证, 指的是相互校验, 服务器需要校验每个 client, client 也需要校验服务器. server 需要 server.key,server.crt,ca.crt；client 需要 client.key, client.crt, ca.crt.  本文内容参考自:\n OpenSSL Toolkit Distinguished name Certificate_signing_request SSL-TLS 双向认证：SSL-TLS 工作原理  ","description":"一种openssl 工具集, 满足各种证书生成和转换需求","tags":["openssl","证书","CA"],"title":"Openssl Toolkit使用","uri":"/tech/basics/certificate/openssl-toolkit%E4%BD%BF%E7%94%A8/"},{"categories":["tech"],"content":"说明 PFX 文件是 PKCS#12 格式的证书, 它包含 SSL 证书（公钥）和相应的私钥.\n PKCS#12 是一个容器标准, 它可以保存 X509 客户端证书和相应的私钥, 以及（可选）签署 X509 客户端证书的 CA 的 X509 证书\n 大多数证书颁发机构不会使用私钥颁发证书, 只会以 .cer、.crt 和.p7b格式颁发或共享证书, 在绝大多数情况下, 这些格式的证书是不包含私钥的.\n在有些场景下, 包含了私钥的 .pfx 格式证书才能满足需求, 比如: kubernetes 作为 slave 对接 jenkins\n证书和 PFX 文件的区别  证书名义上是公钥的容器. 证书内容包括公钥,服务器名称,有关服务器的一些额外信息及由证书颁发机构 (CA) 计算的签名. 当服务器将其公钥发送给客户端时, 实际上发送了它的证书和其他一些证书(包含签署其证书的 CA 的公钥的证书, 以及签署 CA 证书的 CA 的证书, 依此类推). 证书本质上是公共对象. .pfx 文件是一个 PKCS#12 存档：一个可以包含许多对象的包, 并且带有可选的密码保护；通常情况下, PKCS#12 存档包含证书（可能带有各种 CA 证书）和相应的私钥.  PFX 的安全性 因为 PFX 包含了私钥, 在创建 PFX 时, 需要确保PFX 文件有设置密码, 避免证书被滥用. 设置的密码应该有一定复杂度, 不然设置了和没设置一样, 很容易被破解.\nPFX 的一些操作   使用 openssl 创建 PFX\ntodo: 在 openssl 中, 必须在单个 PFX (PKCS#12) 文件中使用单独存储的密钥, 如下将密钥加入 PFX：\n1 2  # 两次输入密码后, 将在当前目录中创建 output.pfx 文件 $ openssl pkcs12 -export -in linux_cert+ca.pem -inkey privateky.key -out output.pfx     从 pfx 文件中提取内容\n可以从 pfx 文件中提取出私钥等, 需要知道创建 pfx 文件时设置的密码. 参数说明可以参考: openssl-toolkit使用\n1 2 3 4 5 6 7 8  # 第一步, 提取私钥; 系统会再次提示我们提供新密码来保护正在创建的 .key 文件 $ openssl pkcs12 -in output.pfx -nocerts -out private.key # 第二步, 提取证书 $ openssl pkcs12 -in output.pfx -clcerts -nokeys -out certificate.crt # 第三步, 解密私钥；输入第一步中创建的用于保护私钥文件的密码 $ openssl rsa -in private.key -out decrypted.key     ","description":"PFX 是什么, 我们日常有哪些场景会使用到","tags":["PFX","证书","openssl","CA"],"title":"什么是PFX文件","uri":"/tech/basics/certificate/%E4%BB%80%E4%B9%88%E6%98%AFpfx%E6%96%87%E4%BB%B6/"},{"categories":["tech"],"content":"说明 PEM (Privacy Enhanced Mail的缩写)文件最初是为了确保电子邮件安全而发明的, 现在它是一个互联网安全标准. PEM 文件是 X.509 证书、CSR(certificate signing request) 和加密密钥的最常见格式.\n什么是 PEM 文件 PEM 文件是一个文本文件, 文件中包含一个或多个采用 Base64 ASCII 编码的条目, 每个条目都有纯文本的页眉和页脚\n 例如: --BEGIN CERTIFICATE-- 和 --END CERTIFICATE--\n PEM 是一种容器格式, 可能只包括公共证书, 也可能包括整个证书链, 包括公钥、私钥和根证书.\nPEM可以有多种扩展名\n 例如: .pem、.key、.cer、.cert 等\n 典型的 PEM 文件是：\n key.pem: 包含私有加密密钥 cert.pem: 包含证书信息  PEM 文件格式 页眉和页脚用于标识文件的类型, 但并非所有 PEM 文件都需要它们. 如下说明几种不同类型的PEM文件\n   页眉页脚内容 文件类型     —–BEGIN CERTIFICATE REQUEST—–\n....\n—–END CERTIFICATE REQUEST—– CSR文件   —–BEGIN RSA PRIVATE KEY—–\n....\n—–END RSA PRIVATE KEY—– 私钥文件   —–BEGIN CERTIFICATE—–\n....\n—–END CERTIFICATE—– 证书文件    如果 PEM 文件包含 SSL 证书链, 则格式如下所示:\n1 2 3 4 5 6 7 8 9  —–BEGIN CERTIFICATE—– //end-user —–END CERTIFICATE—– —–BEGIN CERTIFICATE—– //intermediate —–END CERTIFICATE—– —–BEGIN CERTIFICATE—– //root —–END CERTIFICATE—–   文件示例 如下示例是一个私钥 pem 文件:\n1 2 3 4 5 6 7 8 9  —–BEGIN PRIVATE KEY—– MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDBj08sp5++4anG cmQxJjAkBgNVBAoTHVByb2dyZXNzIFNvZnR3YXJlIENvcnBvcmF0aW9uMSAwHgYD VQQDDBcqLmF3cy10ZXN0LnByb2dyZXNzLmNvbTCCASIwDQYJKoZIhvcNAQEBBQAD … bml6YXRpb252YWxzaGEyZzIuY3JsMIGgBggrBgEFBQcBAQSBkzCBkDBNBggrBgEF BQcwAoZBaHR0cDovL3NlY3VyZS5nbG9iYWxzaWduLmNvbS9jYWNlcnQvZ3Nvcmdh z3P668YfhUbKdRF6S42Cg6zn —–END PRIVATE KEY—–   如下是根证书 pem 文件的示例:\n1 2 3 4 5 6 7 8 9 10 11  # Trust chain root certificate —–BEGIN CERTIFICATE—– MIIDdTCCAl2gAwIBAgILBAAAAAABFUtaw5QwDQYJKoZIhvcNAQEFBQAwVzELMAkG YWxTaWduIG52LXNhMRAwDgYDVQQLEwdSb290IENBMRswGQYDVQQDExJHbG9iYWxT aWduIFJvb3QgQ0EwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDaDuaZ … jc6j40+Kfvvxi4Mla+pIH/EqsLmVEQS98GPR4mdmzxzdzxtIK+6NiY6arymAZavp 38NflNUVyRRBnMRddWQVDf9VMOyGj/8N7yy5Y0b2qvzfvGn9LhJIZJrglfCm7ymP HMUfpIBvFSDJ3gyICh3WZlXi/EjJKSZp4A== —–END CERTIFICATE—–   其他   使用 openssl 命令检查 PEM 证书文件\nopenssl 是一个开源命令行工具, 通常用于生成私钥、创建 CSR、安装我们的 SSL/TLS 证书以及识别证书信息.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  ## 命令格式是: openssl x509 -text -in server.pem -noout # 示例:  $ openssl x509 -in /etc/pki/fwupd/LVFS-CA.pem -text -noout Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: CN = LVFS CA, O = Linux Vendor Firmware Project Validity Not Before: Aug 1 00:00:00 2017 GMT Not After : Aug 1 00:00:00 2047 GMT Subject: CN = LVFS CA, O = Linux Vendor Firmware Project Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public-Key: (3072 bit) Modulus: 00:b5:f5:17:1f:73:70:0c:9c:d6:ca:19:0f:c8:f7: ...... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: critical CA:TRUE, pathlen:1 X509v3 Subject Alternative Name: URI:http://www.fwupd.org/, email:sign@fwupd.org X509v3 Extended Key Usage: Code Signing X509v3 Key Usage: critical Certificate Sign, CRL Sign X509v3 Subject Key Identifier: B1:8D:EA:E4:23:A7:7E:09:8E:B5:EE:31:E0:6A:DD:9E:34:37:65:AC X509v3 CRL Distribution Points: Full Name: URI:http://www.fwupd.org/pki/ Signature Algorithm: sha256WithRSAEncryption ......     ssh 使用的 PEM\nPEM 文件也用于 ssh, 如果我们执行过 ssh-keygen 用来配置 ssh 的免密, 则 ~/.ssh/id_rsa 就是一个 PEM 文件, 只是没有扩展名.\n我们可以在 ssh 中使用 -i 标志来指定我们要使用新密钥而不是 id_rsa：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 生成一对新公私钥对 $ ssh-keygen -f ./test_rsa -t rsa -P '' Generating public/private rsa key pair. Your identification has been saved in ./test_rsa Your public key has been saved in ./test_rsa.pub The key fingerprint is: SHA256:r+NkIS+z7wZcjYjsQ1q/mWDkBkbSXjE1W7mS74W69AE liawne@ruiwen The key's randomart image is: +---[RSA 3072]----+ | . ooo .. | |. o .. +. | | + o ..o + | | + * + + . | | . O oE+S. | | . B ++oo. | | o o+B=.. | | .=B+o | | o**. | +----[SHA256]-----+ # 使用新生成的密钥对配置免密 $ ssh-copy-id -i ./test_rsa.pub pi@192.168.8.106 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"./test_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed ...... # 使用对应的私钥连接服务器 $ ssh -i ./test_rsa pi@192.168.8.106 Last login: Tue Mar 22 23:10:35 2022 from 192.168.8.102 ......     ","description":"PEM 是什么, 我们有哪些日常使用的命令和 PEM 相关","tags":["PEM","证书","openssl","CA"],"title":"什么是PEM文件","uri":"/tech/basics/certificate/%E4%BB%80%E4%B9%88%E6%98%AFpem%E6%96%87%E4%BB%B6/"},{"categories":["tech"],"content":"介绍 通常来说, 所有 SSL 证书都被视为 X.509 证书的类型. 这些数字证书具有不同的文件扩展名和格式.\n分类   Base64 (ASCII)\n PEM: 由 RFC 管理, 开源软件优先使用, 因为它是基于文本的, 因此不太容易出现翻译/传输错误. 可以有多种扩展名（.pem、.key、.cer、.cert 等）  .pem .crt .ca-bundle   PKCS#7: Java 使用并受 Windows 支持的开放标准. 不包含私钥内容.  .p7b .p7s .p7c      Binary\n DER: PEM 的父格式, 可以将其视为 base64 编码的 PEM 文件的二进制版本. 在 Windows 之外不经常使用.  .der .cer   PKCS#12: 一种 Microsoft 私有标准, 后被纳入 RFC, 与纯文本 PEM 格式相比, 安全性得到增强. 可以包含私钥和证书链内容. Windows 系统优先使用, 可通过 openssl 自由转换为PEM格式.  .pfx .p12      单独说明  PEM 格式: 查看什么是PEM文件 P7B/PKCS#7 格式: P7B/PKCS#7 格式的证书以 Base64 ASCII 编码进行编码, 它们通常具有 .p7b 或 .p7c 作为文件扩展名. 将 PKCS#7 格式的证书分开的原因在于, 只有证书才能以这种格式存储, 而私钥则不能. 换句话说, 一个 P7B 文件将只包含证书和链证书.  具有 P7B/PKCS#7 格式的证书包含在\"--BEGIN PKCS7--\"和\"--END PKCS7--\"语句之间. Microsoft Windows 和 Java Tomcat 是使用这种格式的 SSL 证书的最常见平台.\n  DER 格式: DER 证书格式代表 distinguished encoding rules, 是 PEM 格式证书的二进制形式. DER 格式可以包含所有类型的证书和私钥, 大多使用 .cer 和 .der 扩展名. DER 证书格式最常用于基于 Java 的平台. PFX/P12/PKCS#12 格式: 是一种受密码保护的容器格式, 包含公共和私有证书对. 和 .pem 文件不同, 这个容器是完全加密的.PFX/P12/PKCS#12 格式 —— 都是指个人信息交换格式 —— 是存储服务器证书的二进制格式. 这些文件通常在 Windows 平台上使用，用来导入和导出证书及私钥.  不同格式的转换 因为以下两个原因, 存在不同编码格式证书的互相转换需求:\n 不同证书颁发机构以不同的格式颁发证书 不同的服务器需要不同格式的证书  不同格式间的转换, 请查看: openssl-toolkit使用\n其他 一些名词的解释:\n SSL: Secure Socket Layer 安全套接字层 TLS: Transport Layer Security 传输层安全协议 CSR: Certificate Signing Request 证书签名请求, 实际格式是 RFC 2986 中定义的 PKCS10, 它包括所请求证书的部分/全部关键细节, 例如subject, organization, state诸如此类, 以及要签署的证书的公钥. 这些由 CA 签名并返回证书, 返回的证书是公共证书（包括公钥但不包括私钥）,返回的证书可以有多种格式. key: 这是一个（通常）PEM 格式的文件, 仅包含特定证书的私钥, 并且只是一个惯用名称, 而不是标准化名称. 安装 apache 相关软件时, 通常可以在 /etc/ssl/private 中找到. 这些文件的权限非常重要, 如果设置错误, 有些程序会拒绝加载这些证书. PKCS: Public-Key Cryptography Standards 公钥密码标准 CRL: certificate revocation list 证书吊销清单, 证书颁发机构生成这些内容作为证书到期前, 取消授权证书的一种方式.  本文内容参考自:\n A SSL Certificate File Extension Explanation: PEM, PKCS7, DER, and PKCS#12  What is a Pem file and how does it differ from other OpenSSL Generated Key File Formats?  ","description":"认识几种不同编码格式的X509证书,及使用openssl相互转换","tags":["X509","CA","证书","加密"],"title":"几种不同的证书编码格式","uri":"/tech/basics/certificate/x509%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E8%AF%81%E4%B9%A6%E7%BC%96%E7%A0%81%E6%A0%BC%E5%BC%8F/"},{"categories":["tech"],"content":"背景 使用 vim 打开 windows 上编辑的 txt 文件, 出现下面的乱码现象 在 manjaro 的 kate 中打开, 可以正常显示 定位 判断出 vim 编辑乱码的原因是因为 vim 的编码方式问题, 需要调整 vim 的相关配置\n对于 vim 的配置文件 ~/.vimrc 或者 /etc/vimrc, 若不清楚配置项的具体作用, 最好不要调整. 建议自行测试配置内容的作用, 确定最合适自己的配置.\n/etc/vimrc 是全局配置, ~/.vimrc 是用户配置, 我们只需要调整~/.vimrc 即可\n先了解一下 vimrc 中涉及到格式编码的几个配置项\n进入 vim 命令行界面, shift + : 进入到 COMMAND mode, 输入 help encoding 查找编码相关的帮助内容 :\n1 2  $ vim :help encoding   配置介绍    配置项 配置说明     encoding vim 内部使用的字符编码方式, 主要包括 buffer, 寄存器, 表达式中的字符, 保存在viminfo中的内容等. 对 MS-windows 来说默认是 UTF-8, 对其他的系统则通过$LANG读取或者是latin1. 默认情况下, encoding 是设置成当前 locale 的值, 如果 encoding 没有设置成 locale 的 $LANG, 则 termencoding 必须设置成 locale 的 $LANG用于转换终端显示的文本内容   fileencoding 设置当前打开文件的 buffer 文件字符编码方式, 默认为空值；当 fileencoding 的设置和 encoding 设置值不一样时, vim 编辑后保存文件时会将文件保存为 fileencoding 设置的字符编码方式；fileencoding为空时, 使用encoding 的编码方式保存文件. 当需要以特定编码方式读取一个文件时, 配置fileencoding不生效, 需要使用++enc 参数来设置, 也有一种特殊情况, 当fileencodings的值是空时, fileencoding的值才会被使用   fileencodings vim设置fileencoding的顺序列表, 默认值为ucs-bom(Byte Order Mark), vim 打开文件时会按照fileencodings 的内容, 依次检测罗列的字符编码方式, 当一项编码解析出现错误时, 会自动使用下一项进行探测. 最终确认一项可用时, 会将fileecoding 设置为该值; 若都失败, fileencoding 则设置为空, 则当前打开的缓冲文件使用默认的 encoding 设置内容进行编码. fileencodings 只对已存在文件生效, 新文件使用的是fileencoding配置值, 也就是说新文件和空文件使用的编码方式可能是不一样的.   termencoding vim 所在的命令行终端的字符编码方式, 键盘打印输出和显示器显示内容的编码, 对 GUI 环境来说, 则只对 键盘产生的数据生效, GUI 使用encoding的配置值; termencoding的默认值是空值.    相关参数罗列完成后, 整理一下 vim 打开文件的过程, 这几项参数在这个过程中的作用\n vim 使用配置文件(/etc/vimrc 或 ~/.vimrc)中 encoding 配置的编码方式打开文件, 设置缓冲区文件, viminfo 文件, 寄存器等内容的编码方式 因为是已经存在的文件, vim 加载fileencodings 内容, 逐项检测配置的编码方式, 若存在无错误的项时, 分配该编码方式的值给fileencoding 对比encoding 和 fileencoding 的值, 若不相同, 则使用fileencoding 的编码方式重新编码缓冲区文件内容, 最终体现为当前终端打开文件的显示内容. 转换的动作是由iconv() 完成的, 或者在COMMAND mode指定 charconvert 进行转换 编辑完文件后保存, 还是对比 encoding 和 fileencoding 的内容, 不一致就将缓存区文件内容以 fileencoding 设置的编码方式更新到文件中   encoding 和 fileencoding的转换可能导致文件内容部分丢失, 当 encoding 是 utf-8 或者其他 Unicode 编码, 转换的内容很大概率还是能够被反解析成相同的内容; 但当 encoding 不是 utf-8时, 一些字符可能在转换的过程丢失\n 修复 先确认当前文件的编码方式:\n1 2  $ chardetect make\\ iso\\ image.txt make iso image.txt: GB2312 with confidence 0.99   配置文件增加相应的编码方式:\n1 2 3 4  ## 编辑 ~/.vimrc, 增加相应的配置项 $ vim ~/.vimrc $ cat ~/.vimrc | egrep 'fileencoding|encoding' set fileencodings=utf-8,ucs-bom,gb2312,cp936   重新打开文件, 显示正常\n","description":"vim 打开 windows 上编辑的 txt 文件格式乱码","tags":["vim","解码"],"title":"vim 打开 txt 文件乱码","uri":"/tech/miscell/vim%E6%89%93%E5%BC%80txt%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/"},{"categories":["tech"],"content":"说明 在服务器上安装 docker , 并启动 docker.service 后会发现, iptables-save 命令的输出增加一些 DOCKER 相关的内容.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  [root@c7u3test1 ~]# iptables-save  # Generated by iptables-save v1.4.21 on Sun Aug 25 05:05:17 2019 *nat :PREROUTING ACCEPT [0:0] :INPUT ACCEPT [0:0] :OUTPUT ACCEPT [1:128] :POSTROUTING ACCEPT [1:128] :DOCKER - [0:0] -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE -A DOCKER -i docker0 -j RETURN COMMIT # Completed on Sun Aug 25 05:05:17 2019 # Generated by iptables-save v1.4.21 on Sun Aug 25 05:05:17 2019 *filter :INPUT ACCEPT [23:1592] :FORWARD DROP [0:0] :OUTPUT ACCEPT [12:1152] :DOCKER - [0:0] :DOCKER-ISOLATION - [0:0] -A FORWARD -j DOCKER-ISOLATION -A FORWARD -o docker0 -j DOCKER -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A FORWARD -i docker0 ! -o docker0 -j ACCEPT -A FORWARD -i docker0 -o docker0 -j ACCEPT -A DOCKER-ISOLATION -j RETURN COMMIT # Completed on Sun Aug 25 05:05:17 2019   当使用-p参数拉起一个容器时, 查看 iptables-save 输出会发现多了一些规则, 其中的 IP 地址就是新拉起容器的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  [root@c7u3test1 ~]# docker run -d -p 5000:5000 busybox sleep 10000 e4d5f73de95ed178fb24b5068ded0478d957d94d88a3906d7a08c89aab79f339 [root@c7u3test1 ~]# docker container ps -q e4d5f73de95e [root@c7u3test1 ~]# iptables-save  # Generated by iptables-save v1.4.21 on Tue Mar 29 11:06:18 2022 *nat ...... -A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 5000 -j MASQUERADE ...... *filter ...... -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 5000 -j ACCEPT ......   iptables的介绍请看这里: iptables 简述\n这篇文章简述iptables 在 docker 中常见的一些功能.\ndasfdsadf ","description":"安装并启动 docker 服务后, 服务器上自动增加 docker 相关的 iptables 规则和链, 他们的作用是什么","tags":["docker","iptables","network"],"title":"docker 使用到的 iptables 内容","uri":"/tech/docker/docker%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84iptables/"},{"categories":["tech"],"content":"github+hexo+next搭建个人博客已经完成,使用一段时间后,发现存在多处编辑提交的需求. 在网上查询相关方案后,决定采取广大网友建议的方式: 将平时需要修改的内容存储在 hexo 分支,hexo 基于更改内容生成的文件提交到 master 分支 下列内容记录在 raspberry 上配置实现 hexo 编辑提交内容的过程\n1.安装基础包 在新机器上安装基础包，当前机器为 raspberry，以该机器为例说明 raspberry 安装系统是\"Raspbian GNU/Linux 10 (buster)\"，基于 debian 的发行，用如下命令安装\n1 2  # 安装nodejs、npm、git sudo apt install nodejs npm git   2.配置git及github 安装好基础包后，要配置 github 上个人资料/settings/SSH and GPG keys/SSH keys,用于提交代码使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # 在raspberry上,使用pi用户生成公私钥对 PI $ ssh-keygen -t rsa -P '' Generating public/private rsa key pair. Enter file in which to save the key (/home/pi/.ssh/id_rsa): Your identification has been saved in /home/pi/.ssh/id_rsa. Your public key has been saved in /home/pi/.ssh/id_rsa.pub. The key fingerprint is: SHA256:5C2iM9maPY/n+2iDwmodQJOjxTq2ZJkwv0xBy4EG68E pi@raspberrypi The keys randomart image is: +---[RSA 2048]----+ |o+o. | |=+Oo | |+E=+ . | |=*= o . | |+=.o . S . | | .o .+ . . | | o=... | | . +*o.+. | | ...o.o*=+. | +----[SHA256]-----+ # pi用户家目录下.ssh文件夹下新生成了id_rsa/id_rsa.pub文件 PI $ ls ~/.ssh -lrt total 16 -rw-r--r-- 1 pi pi 444 Feb 27 21:28 known_hosts -rw------- 1 pi pi 1366 Feb 28 13:06 authorized_keys -rw-r--r-- 1 pi pi 396 Mar 1 21:30 id_rsa.pub -rw------- 1 pi pi 1823 Mar 1 21:30 id_rsa # 复制id_rsa.pub内容,在github上SSH keys界面上点击New SSH key,添加复制的公钥内容并命名 PI $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaCxxxx.....   配置本地 git\n1 2 3  # 配置user.name和user.email PI $ git config --global user.email \"you@example.com\" PI $ git config --global user.name \"Your Name\"   3.npm安装hexo相关包 配置好 github SSH keys后,下载yourname.github.io库到本地\n1 2 3 4 5  # 进入相应的目录,下载hexo分支代码; 此处在家目录下新建了projects目录,进入projects目录进行操作 PI $ mkdir ~/projects \u0026\u0026 cd ~/projects # $yourname填写自己实际的名称 PI $ git clone git@github.com:$yourname/$yourname.github.io.git   下载完成后,进入yourname.github.io目录,安装 npm 相关包\n1 2 3 4 5 6 7 8 9 10 11 12  # 安装hexo PI $ cd $yourname.github.io \u0026\u0026 npm install hexo # 当前目录下已经包含package.json文件,直接安装相关包 PI $ npm install # hexo同步至github需要使用的包 PI $ npm install hexo-deployer-git # 安装完成后,需要将当前目录下node_modules/.bin加入到PATH中 PI $ echo 'export PATH=$PATH:/home/pi/projects/$yourname.github.io/node_modules/.bin' \u003e\u003e ~/.bashrc PI $ source ~/.bashrc   4.测试发布新文章 上述内容配置完成后,在新机器上测试新文章发布\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 新增文章 PI $ hexo n test # 编辑source/_post/test.md内容,可以在typora等markdown写作软件上先完成内容后再粘贴 PI $ vim source/_post/test.md # 生成内容 PI $ hexo g # 测试新文章内容,hexo s后访问localhost:4000查看文章效果 PI $ hexo s # 内容核对完成,发布到github yourname.github.io的master分支上 PI $ hexo d   ","description":"在新设备上准备hexo发布文章的配置过程","tags":["hexo"],"title":"hexo多设备管理","uri":"/tech/miscell/hexo%E5%A4%9A%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/"},{"categories":["tech"],"content":"Devops核心要点及kubernetes架构概述 1, ansible:应用编排工具\n 可以安装,配置应用 可以依照playbook来配置有依赖关系的应用程序  2, docker的编排工具,docker的编排不能再采用传统意义应用的方式来编排,因为接口已经发生了变化\n docker呼唤面向容器的新式编排工具的实现  docker编排三剑客 1,docker compose(主要功能是编排,可以单机,可以资源池 ) 2,docker swarm(跨机执行,能够将多个主机集成为一个资源池,可以算作一个集群管理工具 ) 3,docker machine(新扩入集群的主机,能够将一个主机迅速初始化加入到一个docker swarm集群中)   mesos: IDC的OS,能够将一个IDC所提供的所有硬件资源提供的计算资源统一分配,是一个资源分配工具 1,marathon: 提供面向容器编排的框架 kubernetes,现有占据80%以上的份额  3, 新概念\n MicroServices: 微服务, 应用不再分层,将应用拆解成一个个的微服务,很可能当前使用的一个应用以- 微服务体现的话,需要拆解成上百个的微服务,彼此之间互相写作 CI: continious intergration持续集成 CD: continious delivery持续交付 CD: continious deployment持续部署  4, 容器技术的出现,使得DevOps的落地实现成为了可能\n1 2 3 4 5  trigger(commit, push and so on) --\u003e CI --\u003e CD(交付) --\u003e CD(部署) DevOps progress --------------------------------------------------------------\u003e # DevOps中异构环境的问题,因为容器的出现而可以解决   5, 容器编排的必要性\n 通过微服务的方式来发布应用,一个应用几百个微服务构成,出故障是必然的,每天出现多少次,人为修复是不可能的,所以需要容器编排工具来完成这个工作 因为容器技术的出现,使得DevOps得以落地; 因为DevOps的落地,使得容器编排技术成为一个底层技术 devops是一种文化, 打破dev和ops的隔阂, 使传统手工方式自动化完成  6, openshift\n redhat使用的paas工具是openshift, openshift的核心是kubernetes, kubernetes还没达到paas这个层面; openshift可以理解为kubernetes的发行版(linux的发行版有ubuntu,redhat,debian等) kubernetes实现的东西很底层,如果要具有paas的功能,还需要自行安装很多工具;openshift则提供了一个完整的工具链供客户使用  7,kubernetes是站在borg肩膀上的开源软件\n kubernetes相关功能  自动装箱: 基于资源依赖及其他约束能够自动完成容器的部署而且不影响其可用性 自动修复: 自我修复,自愈能力,容器的轻量,能够在挂掉之后很短的时间内拉起;  容器方式拉起的应用处理逻辑也发生了变化, 一个应用崩掉了, 可以直接kill掉容器进程, 然后重新拉起来 有了k8s这种编排工具之后, 我们关注的更多的是群体, 而不再是个体了   自动实现水平扩展: 在资源足够的情况下,可以自动扩展节点 服务发现和负载均衡:  当在k8s上运行了很多应用程序(微服务)后, 服务可以通过服务发现自动找到依赖到的服务 每一种服务拉起来之后,自动做负载均衡   自动发布和回滚 密钥和配置管理 存储编排: 使存储卷实现动态供给(某一个容器需要用到存储卷时,根据容器自身的需求创建能够满足其需要的存储卷) 批处理执行   kubernetes就是一个集群, 组合多台主机的资源,组合成一个大的资源池,并统一对外提供存储,计算的集群 kubernetes是一个有中心节点架构的集群系统, master-nodes模型  8, kubernetes编排的应用\n 非云原生应用的启动方式: entrypoint中定义一个脚本,脚本能够接受用户传递给容器的参数,脚本将其转化为应用可读取的配置信息;应用再通过配置文件来读取配置 云原声的启动方式: 基于环境变量的方式传递参数, 修改环境变量, 容器应用自动通过读取环境变量实现不同动作  通过kubernetes来编排的应用需要是云原声应用, 非云原声的应用可能会碰到各种各样的问题(比如配置文件保存在哪里等等)    9, kubernetes工作\n 用户在kubernetes上运行一个应用  客户的请求先发给master(启动容器的请求) master当中存在一个调度器,分析各个node现有的可用资源状态 找出一个最佳适配运行客户容器的节点 节点上的容器引擎来运行这个容器(先检查本地是否有镜像,没有镜像则从harbor上拉取镜像)   怎样保证kubernetes实现自愈能力的  kubelet监控节点上应用容器的状态,确保容器应用的状态正常(节点正常的情况下) 控制器确保容器是否正常,如果不正常,控制器上报给master,由master重新调度新的(节点宕机的场景);  kubernetes有一大堆的控制器来监控容器是否正常; 控制器在本地不断的loop,来监控各个容器的状态; 确保处于用户期望的状态,或者说是移向用户期望的状态   控制器有问题了, 在master上有controller-manager,用来监控控制器的状态；控制器有冗余(3个master, 做了高可用, 三个节点中只有一个可用) master是整个集群的大脑, 有三个核心组件:  apiserver: 负责接受并处理请求的 scheduler: 调度容器创建的请求 controller-manager: 确保控制器状态正常(确保容器状态正常的控制器只是众多控制器中的一种)     kubernetes并不直接调度容器,调度的最小对象是pod(可以理解为容器的外壳,给容器做了一层抽象的封装)  kubernetes做了一个逻辑组件叫pod,在pod内用来运行容器  一个pod内可以包含多个容器,共享的namespace有NET,IPC,UTS,另外三个互相隔离(USER,MNT,PID) pod对外像一个虚拟机 同一个pod中的容器共享存储卷; 存储卷可以理解为不属于容器, 而是属于pod     kubernetes上运行的node, 负责运行由master指派的各种任务,最核心的就是一pod形式去运行容器的  10, kubernetes区分\n master:  apiserver scheduler controller manager   node:  kubelet: node的核心组件, 用来同集群交互, 尝试拉起容器等 docker: 容器引擎,不一定是docker,只是docker最流畅 kube-proxy: 随时与apiserver通信, 监控本地相关资源的情况,当发生变化通知到apiserver后,apiserver生成一个通知事件,可以被所有关联的组件接收到  service的创建需要kube-proxy生成相应规则 service的更新,也需要kube-proxy更新相应的规则      kubernetes基础概念 1, pod说明\n pod:  kubernetes的最小调度单元 pod很重要的一个属性: label,众多元数据中的一个,用于区分筛选pod,负责筛选的是label selector   人为分类(官方未做分类):  自主式pod: 由kubelet监控管理,在节点故障时,pod消失,无法再自动创建 控制器管理的pod: 控制器存在多种    2, 控制器\n ReplicationController: 副本控制器 ReplicaSet: Deployment:  HPA: 自动水平扩展功能(horizontal Pod Autoscaler), 通过监控当前CPU或者内存等资源的消耗情况(比如定义不能超过60%), 来自动添加pod, 当负载下降后还可以自动减少,但有一个最少值   StatefulSet: DaemonSet: Job, cronjob  3, Service\n pod时时在变化,在容器时代,不能再按照以前通过写配置文件,固定IP地址或者主机名的方式来访问固定的Pod了; 客户端发送一个请求过来,路由到相应的pod是怎么实现的  在client和目标Pod之间,存在一个中间层,这个中间层就是service service固定IP地址或者端口, 在没有手动删除的情况下, service不会消失 客户端访问service, service将相应的请求路由到后端对应的pod service通过label去匹配pod的 service不是什么应用程序,也不是实体组件,是iptables的DNAT规则(现已修改为ipvs规则) 客户端访问service名称,然后被kubernetes中的dns服务解析,得到service的地址,再由service的DNAT转发到相应的pod(现已修改为ipvs规则); service只是用来调度分配到各个pod上的流量的 创建了service之后,其相应的iptables/ipvs规则会反映在所有的node主机上    4, 云计算平台和kubernetes天生具有良好的兼容性\n 物理机在kubernetes创建服务时,若需要对外提供服务,需要有loadbalance,但已经不属于kubernetes的管理范围 云平台则不一样,aws,阿里云等可以提供lbaas的接口,在kubernetes需要创建对外提供服务的service时,可以通过调用云平台的lbaas接口来创建loadbalance  5, kubernetes涉及的网络\n 三类网络  pod使用的网络(pod网络): 供pod通信使用,各个pod共享同一个network namespace,网络可以互相ping通,类似于一个正常的IP地址 Service使用的网络(集群网络): 和pod的地址是不同网段的,虚拟的网络,只存在于iptables或者ipvs中 各个node的网段(节点网络): 各个节点各自的IP地址   三类通信  同一个pod内的多个容器间通信: 直接是哟你lo就可以 各个pod之间的通信: 与docker之间的网络通信实现方式不同(两层NAT转发实现跨主机的容器网络通信), kubernetes是直接通过pod地址来通信的(各个pod的地址唯一)  使用物理机桥接网络, 但当集群中pod数多起来之后,广播量太大,无法承受 使用overlay network(叠加网络),使得虽然跨主机,但仍像工作在同一个二层网络中;叠加网络可以实现二层广播,也可以实现三层广播(隧道)   pod与service的通信:  service的iptables/ipvs规则是反映在所有的节点上的,当一个容器需要去访问一个service时,容器的请求转发给docker0网桥就可以了     网络功能kubernetes不提供,需要依赖插件来完成  网络插件提供商最少要提供两个功能:节点网络, 集群网络 kubernetes通过CNI插件体系来接入外部的网络服务解决方案  flannel: 支持网络配置,叠加网络实现,相对简单 calico: 既支持网络配置,也支持网络策略,三层网络隧道实现,相对复杂 canel: 这种方式是上面两种方式的折中 各个CNI插件可以作为容器托管在集群上,也可以作为守护进程在各个节点上运行      6, kubernetes使用到的证书\n etcd是整个集群的核心,整个集群的状态信息都在etcd当中存储,故etcd需要做高可用  etcd是restful风格的集群:通过http/https通信,kubernetes使用的是https方式 etcd是一个端口用于集群内部通信,一个端口用于对客户端提供服务   证书使用  etcd集群内部通信,点对点通信https,需要使用一个证书 etcd对客户端(集群中的apiserver)提供服务,使用另外一套证书(一套ca) kubernetes的apiserver需要使用https对外提供服务,一套证书(不要与etcd使用同一套ca来签署) apiserver与kubelet,kube-proxy等通信,每个组件需要单独的证书 手动部署k8s集群,大概需要手动部署5套ca左右(etcd之间,apiserver访问etcd,client访问apiserver,apiserver与内部集群间的通信,还剩一个需要确认)    使用kubeadm安装kubernetes  常用kubernetes安装方式  使用rpm包的方式安装或者源码编译的方式安装: 这种方式很麻烦,为了提高安全性,需要手动提供很多套的ca和证书 使用kubeadm部署  每个节点都需要安装docker和kubelet,并确保两个服务都已经运行起来 选择一个节点初始化为master后, 将controller-manager,api-server,etcd,kube-schedule以pod的方式运行在master节点上 其他node上以pod的方式运行kube-proxy服务 所有的组件pod都是static pod(静态pod)     使用kubeadm安装kubernetes的步骤  master, nodes:安装kubelet, kubeadm, docker 在master节点上执行kubeadm init来完成集群初始化  先决条件预捡 生成证书,私钥,配置文件 生成每一个静态pod的清单文件 完成部署addon   在各个node节点上执行kubeadm join  检查先决条件,看能否满足需求   查看github上kubeadm的designvx_xx.md文档说明即可 解决docker下载kubernetes镜像需要翻墙的问题  在安装完docker之后,修改/usr/lib/systemd/system/docker.service文件, 增加一个Environment=\"HTTPS_PROXY=http://www.ik8s.io:10080\" 在下载完kubernetes相关镜像之后,将上面的内容注释掉,正常使用国内源即可      kubernetes应用快速入门   kubectl就是apiserver的客户端程序\n 通过连接master节点上的apiserver apiserver也是整个kubernetes集群的唯一管理入口,kubectl就是这个管理入口的客户端工具,完成kubernetes上各种对象的增删改查等基本操作    kubectl命令\n run子命令  通过run命令生成一个deployment或者job来管理相应容器 1 2  kubectl run nginx --image=nginx kubectl run nginx-deploy --image=nginx:1.14-alpine --port=80 --replicas=3 --dry-run=true    传递给pod的命令默认方式是后接-- run命令是通过生成deployment或者job,再拉起pod,不是直接直接创建的pod      kubernetes网络分配\n pod可分配网段是10.244.0.0/16,各个节点分配一个24位掩码的子网,比如node2分配到的是10.244.2.0/24 pod的客户端主要有两类: 其他pod,外部访问 使用kubectl expose来创建service(视频是1.11版本的), 指定端口用于转发 - 参考示例: kubectl expose deployment nginx-deploy --name=xxx --port=xxx --target-port=xxx --protocol=xxx - 外部访问转发: --\u003e service_ip:service_port --\u003e pod_ip:pod_port - 参数type: ClusterIP:仅供集群内部使用,是默认的类型 NodePort:可用于将svc暴露给外部使用,默认会自动生成一个随机端口映射至内部各个节点,网关地址,外部访问时,可以随机使用任意一个node的该端口  service给有生命周期的pod提供了一个固定的访问入口  service是iptables或者ipvs规则 访问svc的端口,都会被调度至该svc用Label Selector关联到的各个pod后端      命令使用\n 使用watch方式监控资源变化  kubectl get pods -w   动态扩展pod数(也可以缩减)  kubectl scale --replicas=x TYPE NAME   动态更新容器镜像  kubectl set image TYPE NAME CONTAINER_NAME_1=CONTAINER_IMAGE_1 ... 使用kubectl rollout status TYPE NAME 来查看滚动更新的状态 使用kubectl rollout undo TYPE NAME来回滚更新 kubectl rollout --help可以查看支持的各个命令   k8s支持自动扩缩容,但是需要有监控系统,这个需要单独部署 kubectl run/expose只是一个简单的命令,用于测试学习等场景;因为这些单独的命令无法实现全部功能,无法实现全部定制,实际使用应该基于yaml的配置文件来实现    05-kubernetes资源清单定义入门   kubernetes有一个RESTful风格的API,把各种操作对象都一律当作资源来管理,通过标准的http请求方法(GET,PUT,POST,DELETE)_来完成操作\n 但是通过相应的命令(kubectl run/expose/edit/get),反馈到命令行上    资源实例化之后变成对象\n 工作资源负载型对象(workload): Pod, ReplicaSet, Deployment, StatefulSet, DaemonSet, Job, CronjobSet, Deployment, StatefulSet, DaemonSet, Job, Cronjob 服务发现及服务均衡: Service, Ingress 配置与存储: Volume(有状态的持久存储需求的应用必须要用到的),CSI(存储卷),  configmap:为了配置容器化应用必然会用到的 secret:保存敏感数据   集群级资源:  namespace node role clusterrole rolebinding clusterrolebinding   元数据型资源  HPA Podtemplate LimitRange      资源清单定义\n 运行中的pod为例,说明各个字段的作用  apiVersion定义,有两个部分组成,分别是group名+version(组名+版本号),如果group省略,则表示属于core(核心组)  apiVersion: v1 --\u003e apiVersion: core/v1 组管理的好处:某一组的改动,只改一组就行,不影响其他组的使用; 一个组的多个版本号还可以并存 version一般有3个:alpha(内测版本), beta(公测版本), stable(稳定版本)  不同版本支持的可嵌套字段可能是不一样的\n    kind定义,确定资源类别,用来指明实例化成一个资源对象时使用 metadata,元数据, spec(specification):用来定义接下来需要创建的资源应该具有什么样的特性,或者应该满足什么样的规范;基本是一个资源对象中最重要的字段 status,与spec对应,显示当前的状态,spec是预期值,status是实际值,当实际值与预期值不符时,会向预期值靠拢      apiversion仅接收json格式的资源定义,yaml格式提供配置清单,apiserver可自动将其转为json格式,而后再提交\n  大部分资源的配置清单组成有5部分(一级字段):\n apiversion  pod是最核心的资源,所以属于核心群组vxxxx;deployment,replicaset属于应用程序管理的核心资源,他们属于app/vxxxxx kubectl api-versions即可获取   kind:资源类别 metadata:元数据  name: 在同一类别中,那么必须是唯一的,同一命名空间中 namespace: name需要受限于namespace,是kubernetes的概念,和操作系统的namespace要区分好 labels: 标签 annotations: 资源注解   spec:最重要的一个字段,定义期望状态(desired state)  不同资源类型,spec部分需要嵌套的内容不同   status:当前状态(current state),本字段由kubernetes集群维护,不能人为定义 各个字段的man文档可以使用如下命令查看: kubectl explain KIND.OBJECT.xxx.xxx --\u003e kubectl explain pod.metadata/pod.spec.containers.livenessprobe # explain输出的内容中,设定格式有 # \u003cstring\u003e: 字串 # \u003c[]string\u003e: 字串列表,字串类型的数组 # \u003cObject\u003e: 嵌套类型的三级字段 # \u003cmap[string]string\u003e: 键值组成的映射 # \u003c[]Object\u003e: 对象列表 # -required-: 表示该字段必须存在     每个资源的引用PATH:\n /api/GROUP/VERSION/namespaces/NAMESPACE/TYPE/NAME    一个pod定义的yaml文件示例\npod-demo.yaml: -------------------------------------------------------------- apiVersion: v1 kind: Pod metadata: name: pod-demo namespace: default labels: ---\u003e labels字段是属于map(kv字典), 这里也可以写成labels: {\"app:myapp\", \"tire:frontend\"} app: myapp tire: frontend ---\u003e labels字段可以有多个label map spec: containers: ---\u003e containers是对象列表格式 - name: myapp image: ikubernetes/myapp:v1 - name: busybox ---\u003e 多个容器存在于一个pod中, 用于辅助主容器工作, 这种方式称为边车模型 image: busybox:latest command: ---\u003e command字段属于列表, 这里也可以写成command: [\"/bin/sh\", \"-c\", \"sleep 3600\"]; command用于覆盖容器的默认命令 - \"/bin/sh\" - \"-c\" - \"sleep 3600\" --------------------------------------------------------------  基于这个yaml文件可对资源进行管理  kubectl create -f pod-demo.yaml: 根据这个文件内容,创建相应的资源 kubectl delete -f pod-demo.yaml: 根据yaml文件内容,删除相应的资源 kubectl apply -f pod-demo.yaml: 根据yaml修改内容,滚动更新相应的资源   问题:  使用pod-demo.yaml文件定义的pod,没有控制器被创建,都是我们自己去控制了,这种形式的pod称之为\u003c自主式Pod资源\u003e  有控制器的pod,一删除会被自动创建 我们这里创建的这个pod,一删除就被删除了        在定义pod资源时, spec字段常用的字段有哪些\n spec.containers: \u003c[]object\u003e  name:  image:  imagePullPolicy: ,有Always,Never,IfNotPresent这几个值可选择;  如果镜像标签选择了latest,则使用的是Always 其他策略时默认为IfNotPresent; 该字段不能更改 各个策略的优缺点:  always(好处是可以一直拿到最新的镜像,确保拿到最新的发布镜像;缺点是会占用带宽,而且拉起时间长); never: 可以节省带宽和时间,但可能本地就有的基础镜像是被修改过的,有问题的,也无法被更新 ifnotpresent: 折中的一种方式,当不可用的时候才去拿镜像     ports: \u003c[]object\u003e,informational功能,只是提供信息而已,和docker中的暴露端口不一样  containerPort可以有多个 containerPort以列表的方式展示   command/args: \u003c[]string\u003e  args:entrypoint arguments;  当这个参数没有提供时,容器镜像的默认ENTRYPOINT会被使用 变量引用的格式是$(variable_name),需要特别注意;若自己需要使用命令替换方式,则格式为$$(variable_name),作为逃逸   command:entrypoint array;  当这儿参数没有被使用时,容器镜像的默认CMD会被使用 给定的内容不会在shell中执行,所以若需要在shell中执行内容,需要自己在内容中增加'/bin/sh', '-c', 'contents' 变量引用的格式是$(variable_name),需要特别注意;若自己需要使用命令替换方式,则格式为$$(variable_name),作为逃逸   docker中entrypoint/cmd和k8s中command/args的结合使用 ------------------------------------------------------------------------------------------------------------------------ | 描述 | Docker filed name | Kubernetes field name | ------------------------------------------------------------------------------------------------------------------------ | The command run by the container | Entrypoint | command | ------------------------------------------------------------------------------------------------------------------------ | The arguements passwd to the command | Cmd | args | ------------------------------------------------------------------------------------------------------------------------ # 资源清单中没有给容器提供command和args,则容器镜像的默认entrypoint和cmd生效 # 资源清单中给容器提供了command但没有args时,则仅仅command生效,容器镜像默认的entrypoint和cmd被忽略 # 资源清单中给容器提供了args但没有command时,则容器镜像的Entrypoint使用给定的args # 资源清单中给容器提供了command和args,则command使用给定的args生效      有些字段是可以被修改,而且改完之后能即时生效的;有些字段不能修改 docker中如果同时存在entrypoint和cmd时,cmd将作为参数被传递给entrypoint    使用kubectl管理资源有三种用法\n 命令式用法: kubectl run/expose/edit xxxx 配置清单式用法: 本章讲解的内容(命令式资源清单) 也是使用命令清单,但用法不同(声明式资源清单)    kubernetes Pod控制器应用进(一)   label是kubernetes上很有特色的一个功能\n 提升资源管理效率,在同一套集群中,k8s的资源量上去后,需要被管理的资源通过label可以被快速识别 当给资源配置了label之后,还可以通过label来查看,删除等管理操作 所谓的label就是附加在对象上的一个键值对 一个资源上可以存在多个label,每个label都可以被标签选择器进行匹配度检查,从而完成资源挑选 标签可以在资源创建时配置,也可以在资源创建之后配置 key=value,键值对的长度都不能超过63个字符 # key:字母,数字,_,-,. # value:可以为空,只能字母或数字开头及结尾  直接给资源打标签 # kubectl label pods pod-demo release=canary # kubectl label pods pod-demo release=stable --overwrite     标签选择器的类型\n 等值关系的标签选择器,可以使用'=','==','!=' kubectl get pods -l release=canary kubectl get pods -l release=stable kubectl get pods -l release!=stable(没有相应的键同样包含在条件内) kubectl get pods -l release=stable,app=myapp  集合关系的标签选择器 # KEY in (VALUE1,VALUE2,...) kubectl get pods -l \"release in (canary,alpha,beta)\" # KEY notin (VALUE1,VALUE2,...) kubectl get pods -l \"release notin (canary,alpha,beta)\" # KEY(存在某个键) # !KEY(不存在某个键)     deployment,service等资源通常支持通过以下字段来匹配相应的标签\n# matchLabels: 直接给定键值 # matchExpression: 基于给定的表达式来定义使用标签选择器 # # 方式为:{key: \"KEY\", operator:\"OPERATOR\", values:[VAL1,VAL2,...]} # 操作符常用的有: # In, Notin: values字段的值必须为非空列表 # Exists, NotExists: value字段的值必须为空列表   node也可以打标签\n 创建pod时,有一个字段叫做nodeSelector\u003cmap[string]string\u003e(节点标签选择器),可以用来选择在哪些标签节点上运行  - spec: containers: - xxx - xxx 选择节点可以有以下方式: ---------------- nodeSelector: disktype: ssd ---------------- nodeName: node02     annotation:\n 与labels的区别在于,他不能用于挑选资源对象,仅用于为对象提供\"元数据\";  这些\"元数据\"在某些时候可能被某些程序用到,并且很重要 annotation中键值的大小可大可小,不再受字符的限制 查看annotations可以通过describe来查看      pod的生命周期:\n 如下图:   -------------------------------------------------------------------- | Pod | -------------------------------------------------------------------- a--\u003e| -------- | | |init c| | | -------- | | -------- | | |init c| | | -------- | | -------- | | |init c| | | -------- | | | ----------------- | | |liveness probe | | | ----------------- | | ----------------- | | |readiness probe| | | ----------------- | | ------------ ---------- | | |post start| |pre stop| | | ------------ ---------- | b | |\u003c--------------------------\u003e| -------------------------------- | | | main container | | | -------------------------------- | |\u003c--------------------------------- | | c | |  各个阶段说明   1,a是pod中创建容器前的初始化动作(entrypoint中定义的初始化动作内容),这里需要一点时间,时间可能比较短,可以忽略 2,在主容器启动前,可能需要做一些环境设定和配置,此处有一系列的init container,专门用于给主容器做环境初始化动作(初始化容器是需要串行执行的) 3,等所有的初始化容器完成之后,拉起主容器 4,主容器退出,pod的生命周期结束 5,在主容器的启停前后,可以存在两个分别称为post start和pre stop的 - post start:在启动完执行一次后自动退出 - pre stop: 在结束前执行一次的动作 - 钩子触发,用于开始前的预设,结束前的清理 6,还可以做health check,一般来说,在post start执行完成之后,可以做两类检测(k8s支持两类) - liveness probe : 存活状态检测,检测主进程是否还在运行(避免已经进入死循环还不退出的情况),主容器是否处于运行状态 - readiness probe: 就绪状态检测,容器中的主进程是否已经准备就绪并可以对外提供服务 - 两种probe都支持三种探测行为: a,执行自定义命令 b,向指定的套接字发请求(向指定端口发请求) c,向指定的http发请求(向指定url发送GET请求) - kubernetes和docker的探测差别:docker不需要探测liveness,因为只有一个容器,kubernetes需要,因为一个pod中可能有多个容器存在  pod的各种状态:  pending:挂起,启动条件没满足,调度未完成(比如已经创建,但没有适合运行的节点,即没有符合nodeselector或者nodename的节点) running:运行中 failed:失败 succeed:成功,存在时间很短 unknown:所有信息的获取都是apiserver和各个节点上的kubelet交互获取的,如果kubelet出故障了,就有可能出现unknown的状态   用户创建pod时会经历哪些阶段:  用户创建pod时,发送请求给到apiserver apiserveri将创建请求的目标状态保存到etcd中 apiserver请求schedule,进行调度,并将调度的结果保存到etcd中(运行在哪个节点上) etcd状态信息更新后,调度节点上的kubelet通过与apiserver通信,获取到有一些任务给到自己了 此时此kubelet通过apiserver拿到此前用户提交的创建清单,根据清单在当前节点上运行这个pod 启动后,pod有一个当前状态,再将当前pod状态发回给apiserver apiserver再次将该信息存入etcd中   pod生命周期中的重要行为:  初始化容器 容器探测  liveness probe readiness probe   pod在kubernetes上代表的是运行的程序或者进程,给用户提供服务的主要单位,当pod发生故障时,需要让其平滑终止,才能确保数据不会丢失  在给pod发送delete请求时,pod给各个容器发送TERM信号,容器自己停止(给予一个宽限期) 超过宽限期后,发送kill信号,杀掉进程     restartPolicy:  Always: 总是重启 OnFailure: 只有状态为错误时才重启 Never: 从不重启 一旦一个pod被调度到某个节点以后,只要这个节点在,这个pod就不会被重新调度了;pod里面的容器只会被重启,如果容器不满足启动条件,则容器会一直在那不断重启(取决于策略定义)      kubernetes Pod控制器应用进阶(二)   探针(kubectl explain pods.spec.containers.livenessProbe)\n# a, ExecAction # b, TCPSocketAction # c, HTTPGetAction ------------------------------------------------------------------------ Exec: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: liveness-probe-pod namespace: default spec: containers: - name: liveness-probe-container image: busybox:latest imagePullPolicy: IfNotPresent command: [\"/bin/sh\", \"-c\", \"touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 3600\"] livenessProbe: exec: command: [\"test\", \"-e\", \"/tmp/healthy\"] initialDelaySeconds: 1 periodSeconds: 3 ------------------------------------------------------------------------ TCPSocket: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: liveness-httpget-pod namespace: default spec: containers: - name: liveness-httpget-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3   就绪性探测使用的场景\n pod提供的服务是通过war来展开的  war包很大,容器运行之后,war包展开还需要10s钟时间 容器运行之后,service作为服务入口,通过标签选择器已经关联到该pod了(请求可以调度到该pod了) 新分配到这个pod的请求因还未准备好,所以会出现请求失败的情况      使用pod提供服务,必须要用到liveness probe和readiness probe\n# readiness probe ------------------------------------------------------------------------ TCPSocket: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: readiness-probe-pod namespace: default containers: - name: readiness-probe-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 readinessProbe: httpGet: port: http path: /index.html indexDelaySeconds: 1 periodSeconds: 3   lifecycle(postStart,preStop)字段,启动停止钩子函数\n# a, ExecAction # b, TCPSocketAction # c, HTTPGetAction ------------------------------------------------------------------------ postStart: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: poststart-pod namespace: default spec: containers: - name: poststart-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent lifecycle: postStart: exec: command: [\"/bin/sh\", \"-c\", \"sed -i 's/MyApp/Home_Page/' /usr/share/nginx/html/index.html\"] command: [\"nginx\"] args: [\"-g\", \"daemon off\", \"-c\", \"/etc/nginx/nginx.conf\"] -----------\u003e注意不要和lifecycle的command有强依赖   ","description":"k8s学习笔记记录","tags":["cloud","docker","云原生","kubernetes"],"title":"Kubernetes学习笔记","uri":"/tech/cloud/kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["tech"],"content":"#. 容器是什么 1, LXC(linux container): linux容器\n2, 虚拟化类型:\n 主机级虚拟化: Type-I: 直接在硬件上安装一个hypervisor,再在hypervisor上使用虚拟机 Type-II: virtualbox,vmware workstation,kvm等;先存在一个宿主机,安装好host os,在host os上再安装vmm(virtual machine manager),vmm上再启动虚拟机,还需要自己安装操作系统 容器级虚拟化: 所有的用户空间不再分属于不同内核,从属于同一内核  主机级虚拟化可以在创建时就天然限制资源(CPU,MEM) CPU资源属于可压缩资源,MEM不属于,当进程申请MEM时没有,则会触发OOM 内核级必须实现一种功能,来限制用户空间中每一个进程所有可用资源总量  可以实现在整体资源上按比例分配,也可以在单一用户空间上,实现做核心绑定,通过CGrouop(control group)来实现      3, 内核和用户空间\n 能够有产出的都是用户空间的应用程序,像部署一个nginx服务,http服务,再对外提供服务 内核是协调资源的作用,出于通用目的而设计的资源管理平台 现代软件基本都是对内核的系统调用和库调用,应用程序依赖着内核和操作系统  4, kvm等虚拟化\n 资源需要经过两层调度,虚拟机操作系统层面是一层,宿主机层面又是一层,浪费,存在额外的开销,效率低 优点是资源隔离彻底,某台虚拟机出现问题,不要影响到其他的虚拟机 提高效率的方式: 减少中间层  5, 容器最早出现的形式是freebsd里面的jail,迁移到linux中后,变成了vserver(chroot)\n6, 用户空间的隔离类型,都是在内核级别实现的\n UTS: CLONE_NEWUTS,2.6.19之后支持;主机名和域名,在内核当中以名称命名,并且单独隔离开;可以分别各自使用,而不影响主的,真正的命名空间 Mount: CLONE_NEWNS,2.4.19之后支持;文件系统 IPC: CLONE_NEWIPC,2.6.19之后支持;信号量,消息队列和共享内存,进程间通信 PID: CLONE_NEWPID,2.6.24之后支持;进程号 User: CLONE_NEWUSER,3.8之后支持;用户(组)等相关信息也要做隔离,以root用户说明,只在容器内部是root用户,在宿主机上实际是普通用户 Net:CLONE_NEWNET,2.6.29之后支持;网络设备,网络栈,端口等,有自己专有的TCP/IP协议栈  7, 一个操作系统运行存在两棵树: 进程树,文件系统树\n 进程管理从来都是白发人送黑发人,父进程只有把所有子进程,子进程的子进程...都送完才能放心离开 每个用户空间都有一个init进程(docker中自己定义),当init进程结束时,docker容器实例也停止 一个docker容器中可以存在多个进程,但需要是由同一个最原始的init进程生成  8, linux现已在内核中原生支持名称空间(namespaces),并且通过系统调用向外输出\n clone() setns(): 进程创建完成后放到某个命名空间中去 unshare(): 将进程从某个命名空间中拿出来  9, 要想使用容器,得靠用于支撑用户空间的内核级的内核资源的名称空间隔离来实现\n10, CGroup(control group)控制组: 把系统资源分为多个组,然后把每个组的资源指派或者分配到特定的用户空间的进程上去,分类如下:\n blkio: 块设备IO cpu: CPU cpuacct: CPU资源使用报告 cpuset: 多处理器平台上的CPU集合 devices: 设备访问 freezer: 挂起或恢复任务 memory: 内存使用量及报告 perf_event: 对cgroup中的任务进行统一性能测试 net_cls: cgroup中的任务创建的数据报文的类别标识符  11, 可以给一个系统上所有运行的进程分门别类的进行分类,每个类就是一个组,叫做控制组\n 每个控制组内部还可以继续进行划分,分配完成后,每个子组当中的进程自动拥有该控制组分配的资源,除非进一步对子组进行分类  12, 容器级虚拟化相对主机级虚拟化,安全隔离相差很多,相应的为了防止利用漏洞使用其他用户空间的资源,docker也相应的做了一些加固\n 结合selinux使用  13, 容器实现的三个核心技术:\n chroot namespaces cgroups  14, 一个容器只运行一个主进程,相应的优缺点\n 缺点:  空间占用更多 工具不能共用了,如果需要调试工具,需要在容器中安装 不方便运维,需要专门的编排,不然使用容器部署应用比单独安装服务更麻烦   优点:  方便研发,一次打包,到处运行    15, docker分层构建,联合挂载\n 每一个镜像都是只读的,多层联合挂载后提供的视图就是当前使用的镜像 每一个容器有一个自己的可写层,在联合挂载的最顶层附加一个新层,能读能写,容器专有的  如果要删除一个文件,且刚好属于上一层镜像中的文件,实现方式为标记为不可见 需要修改一个文件,该文件属于上一层或多层的文件,则通过写时复制的方式实现   持久化使用的数据,通过在容器外部挂载一个共享存储(ceph,glusterfs,iscsi等)实现  16, 在docker的基础之上,能够把这些应用程序之间的依赖关系,从属关系,隶属关系等等反映在启动,关闭时的次序和管理逻辑中,这种功能叫做容器编排\n docker-compose(单机),docker-swarm(多机集群),docker-machine mesos+marathon kubernetes --\u003e k8s  17, docker后面研发libcontainer,替换了lxc,后面libcontainer进化为runc(run container)\n lxc(linux container) --\u003e libcontainer --\u003e runc 为了标准化容器相关(容器引擎,容器底层镜像格式) runc,容器运行时的环境标准 容器镜像格式标准OCF(open container format),事实上的工业标准  18, iaas, paas, saas 的差别\n------------------ S | Application | | ------------------ | | Data | | ------------------ P | | Runtime | | | ------------------ | | | Middleware | | | ------------------ | | | OS | | | ------------------ I | | | Virtualization | | | | ------------------ | | | | Servers | | | | ------------------ | | | | Storage | | | | ------------------ | | | | Networking | | | | ------------------ #. docker基础用法 1, 相关名词\n OCI(open container initiative),开放容器协会,主要目的是围绕容器格式和运行时制定一个开放的工业化标准,由两部分组成:  runtime-spec(The Runtime Specification): 运行时标准 image-spec(The Image Specification): 镜像格式标准   OCF(open container format),开放容器镜像格式 runC是一个cli工具,依照OCI标准来运行容器  容器以runC子程序的方式启动,可以被集成到各种不同的操作系统,而且可以不需要守护进程存在 runC是从libcontainer发展而来的    2, docker架构,由一下几部分组成\ndocker可以认为是一个C/S的架构,无论时server端还是client端,都是由一个docker程序来提供,这个docker程序有很多子程序\n docker client  docker pull docker build docker run   docker host  docker daemon: docker众多子程序中的一个,运行为daemon,即守护进程  mysql接入用户请求一般有两种方式,分别是: a,标准的TCP/IP协议,IP+端口的方式 b,使用socket文件,在本机接入 类似于mysql监听,docker也监听在套接字上,为了安全起见,默认时只监听本机,支持三种套接字 a,ipv4套接字(ipv4地址+端口) b,ipv6套接字(ipv6地址+端口) c,unix socket file,监听在本机的一个文件上,上面两个没有放开的话,就会只监听本机(127.0.0.1)   docker containers  启动容器时,就是基于镜像来启动,在已有的镜像之上,为一个容器启动一个专用的可写层   docker images  不确定要用哪些,具体要用的时候再下载 要用的时候就必须要加载到本地     docker registry(docker镜像仓库,默认就是dockerhub)  支持http/https,默认必须使用https,为了安全 要使用http,必须在配置文件中明确定义,才能正常使用 registry而不是repository,因为registry有三个功能  repository: 存储镜像的仓库 auth: 用于认证 catalog: 提供已有镜像的索引,即仓库名(nginx) + tag(1.10)      3, docker支持restful风格的调用,docker中的资源对象\n images和containers的关系可以类比与程序(software)和进程(process),镜像是静态的,容器是动态的,存在生命周期 restful风格的资源对象都是可以增删改查的  images containers networks volumes plugins other objects    4, docker的安装使用\n 为了能够正常使用docker,要求环境的内核版本必须要在3.10以上(user namespace是在3.8之后才支持的) 红帽在2.6.32之后可以安装docker,打了补丁补进去了(但还有很多不确定与因素,建议不要跑在centos6上) 建议不要使用Centos-Base.repo这个源中的docker,因为版本较老,有很多软件要求使用新版本docker的特性,但也不要使用最新的docker版本(k8s不支持最新版),使用docker-ce.repo中stable版 当前docker的配置文件是/etc/docker/daemon.json  使用images时,建议使用加速器(docker cn/阿里云)   需要查看当前docker的详细信息,可以使用docker version来查看  docker info输出中的Storage Drive这项很重要 a,docker镜像需要使用到多层构建,联合挂载,这两项要求必须使用特殊的文件系统才能实现,专用的文件驱动 b,一般包含overlay2和aufs;centos7.4之前没有使用可能和内核版本有关系,之前的还不支持 c,centos7之前还有使用到dm(弱爆了),就是lvm的实现,使用dm的方式,docker的性能很差,而且还不稳定    5, docker镜像及容器\n alpine: 专门用于构建非常小的镜像文件的一个微型发行版,能够给程序提供运行环境,但体积非常小(缺少相应的调试工具) 停掉一个容器的方式有:  stop: 相当于sigterm kill: 相当于sitkill   启动一个容器时,不能让其跑在后台,不然启动就会停止(一个容器就是为了一个进程,如果跑后台,终端没有任何程序,那docker就认为已经结束了)  #. docker镜像管理基础 1, docker镜像含有启动容器所需要的文件系统及其内容,容器镜像用于创建并启动docker容器\n 采用分层构建的机制,最底层为bootfs,其次为rootfs  bootfs: 用于系统引导的文件系统,包括bootloader和kernel,容器启动完成后会被卸载以节约内存资源  bootfs只在容器启动的时候存在,当容器已经挂载了rootfs后,bootfs层将会被卸载(不是被删除) 存在一个问题,如果存在bootfs这一层,那是否拉起的容器可以支持宿主机内核不支持的特性?   rootfs: 位于bootfs之上,表现为docker容器的根文件系统  传统模式中,系统启动时,内核挂载rootfs时会首先将其挂载为只读模式,完整性自检完成后将其重新挂载为读写模式 docker中,rootfs由内核挂载为'只读'模式,而后通过联合挂载技术而外挂载成一个'可写'层   最上层为'可读写'层,其下的均为'只读'层  容器启动后,所有的写操作都是在最上一层的'可读写'层完成的,当删除一个容器时,可读写层一并被释放      2, 联合挂载文件系统分类\n aufs(advanced multi-layered unification filesystem): 高级多层统一文件系统  用于为linux文件系统实现'联合挂载' aufs是之前的UnionFS的重新实现,但未能整合到linux内核中(据说是代码很烂),所以如果需要使用,需要给内核打补丁(redhat系不支持,因为不允许) docker最初使用aufs作为容器文件系统层,目前仍作为存储后端之一来支持   aufs的竞争产品为overlay,从3.18版本开始被合并到linux内核中 docker的分层镜像,除了aufs,docker还支持btrfs,devicemapper和vfs等  在ubuntu系统下,docker默认ubuntu的aufs 在centos7上,用的时devicemapper(性能差还不稳定)   目前推荐使用overlay2  overlay是抽象文件系统,属于二级文件系统,需要先有一层文件系统(xfs,ext...)    3,docker registry分类\n registry 用于保存docker镜像,包括镜像的层次结构和元数据 用户可以自建registry,也可以使用官方的dockerhub 分类:  sponsor registry: 第三方registry,供客户和docker社区使用 mirror registry: 第三方registry,供客户使用 vendor registry : 由发布docker镜像的供应商提供的registry private registry: 通过设有防火墙和额外的安全层的私有实体提供的registry   docker registry中的镜像通常由开发人员制作,而后推送至'公共'或'私有'registry上保存 获取镜像的标准格式: docker pull :[:port]/[/]/:  4,云原生的解释\n 面向云环境中去运行这个程序而调云系统本身自有的功能而开发的应用程序,就是为了云环境运行而生的 docker容器本身如果通过修改配置文件的方式来改配置,相对麻烦,故想了一种方式,通过运行时传入环境变量的方式来运行(早期的解决方式)  5,docker hub的使用 docker hub主要提供如下的功能特性:\n image repository: 镜像仓库 automated builds: 自动构建 dockerfile(change/push) --\u003e github --\u003e build image --\u003e docker hub webhooks: 当dockerfile提交成功时,自动触发钩子构建镜像  6,镜像的生成途径\n Dockerfile 基于容器制作  基于先有容器制作镜像时,建议先暂停该镜像,再commit,防止文件数据的缺失 1 2 3 4 5  # 命令为: docker commit -p \u003ccontainer\u003e [repository[:tag]] # 替换原有镜像的CMD或者其它参数 docker commit -p \u003ccontainer\u003e -c \"CMD ['/bin/httpd', '-f', '-h', '/data/html']\" [repository[:tag]]      Docker Hub automated build(也是基于Dockerfile)  7,不通过registry,直接导入导出镜像文件\n docker save -o  docker load -i   #. 容器虚拟化网络 1,网络名称空间主要是实现网络设备(网卡,协议栈)的隔离\n 当网络设备不够用时,可以通过命令生成虚拟网络设备,linux内核支持实现生成两种网络设备:  二层网络设备  成对出现,类似一根网线两头,一根接入网络命名空间,一头接入虚拟交换机(虚拟网桥),就可以模拟一台主机连接到一台交换机的场景   三层网络设备   linux内核原生支持二层网桥虚拟设备(软件构建交换机),虚拟化网络 linux上实现路由的方式,可以通过直接增加一个netns实现,将相应网桥的网卡接入该netns,然后在netns中配置路由规则即可  桥接不安全,跨机容易出现风暴    2,virtualbox/vmware桥接模式的实现\n 将物理网卡当作交换机来使用,虚拟机的流量都是通过物理网卡转发过去的,对于物理机本身的流量,是通过对本机增加一个虚拟网卡,物理网卡流量转到该网卡实现的  3,overlay network(叠加网络)\n 叠加网络(隧道实现),用于实现跨机同网段通信  C1(container)在H1(host)上,C1 IP 172.17.0.11 C2(container)在H2(host)上,C2 IP 172.17.0.22 通过隧道实现直接通信,省去了两次NAT的动作(先SNAT,再DNAT),类似12inN中的vxlan实现(报文两次三层封装)    4,容器类型,及容器类型\n bridged container(bridge): 桥接容器,默认模式,每起一个容器,新增一对veth peer,一个接在容器中,一个接入docker0 open container(host): 开放式容器,共享宿主机的协议栈,网卡,主机名,进程见通信(UTC,IPC,NET) closed container(none): 封闭式容器,拉起的容器只有lo,不需要网络 joined container: 联盟式容器,几个容器共享网络名称空间(UTC,IPC,NET名称空间是共享的)  5,可以使用inspect命令查看任何一个docker对象的情况\n docker network inspect  docker container inspect  docker volume inspect   #. 容器网络 1,容器间可以共享IPC,UTC,NET命名空间\n2,可以手动操作网络名称空间,因为由ip命令\n 想模拟容器的网络名称空间,只靠ip命令就能完成  3,容器启动时可以指定的一些参数\n -h指定hostname --dns指定dns服务器(/etc/resolv.conf文件会记录) --add-host直接外部注入host解析内容  4,opening inbound communication(如何开放nat桥桥接式服务到宿主机外部提供服务,可以使用-p参数来实现)\n 使用-p来实现,有以下@sh几种方式: 1 2 3 4 5 6 7 8 9 10 11  # -p \u003ccontainerPort\u003e: 将指定的容器端口映射至主机所有地址的一个动态端口 docker run --name myweb --rm -p 80 mageedu/httpd:v0.2 # -p \u003chostPort\u003e:\u003ccontainerPort\u003e: 将容器端口映射至指定的主机端口 docker run --name myweb --rm -p 172.20.0.67::80 mageedu/httpd:v0.2 # -p \u003cip\u003e::\u003ccontainerPort\u003e: 将指定的容器端口映射至主机指定\u003cip\u003e的动态端口 docker run --name myweb --rm -p 80:80 mageedu/httpd:v0.2 # -p \u003cip\u003e:\u003chostPort\u003e:\u003ccontainerPort\u003e:将指定的容器端口映射至主机指定\u003cip\u003e的端口\u003chostPort\u003e docker run --name myweb --rm -p 172.20.0.67:8080:80 mageedu/httpd:v0.2 # 动态端口指的是随机端口,具体的映射结果可以使用docker port命令查看 ## 使用-P时,可以不用指定端口,默认会将容器监听的端口暴露出去     5,joined containers(联盟式容器)\n 联盟式容器是指使用某个已存在容器的网络接口的容器,接口被联盟内的各容器共享使用; 因此联盟式容器间完全无隔离 1 2 3 4 5 6 7 8  # 创建一个监听2222端口的http服务容器 docker run -d -it --rm -p 2222 busybox:latest /bin/httpd -p 2222 -f # 创建一个联盟式容器,并查看其监听的端口 docker run -it --rm --net container:web --name joined busybox:latest netstat -tan ## another example docker run --name b1 -it --rm busybox docker run --name b2 --network container:b1 -it --rm busybox    联盟式容器彼此间虽然共享一个网络名称空间,但其他名称空间如User,Mount等还是隔离的 联盟式容器彼此间存在端口冲突的可能性,因此通常只会在多个容器上的程序需要程序loopback接口互相通信,或对某已存的容器的网络属性进行监控时才使用此种模式的网络模型  6,可以自定义docker的一些配置(修改/etc/docker/daemon.json)\n 定义docker0网桥的IP段及其他相关配置 1 2 3 4 5 6 7 8  ## docker0使用的网段,会自动识别出所属的网段 \"bip\": \"192.168.1.5/25\" ## mtu \"mtu\": 1500 ## 如果想让容器不获取宿主机的dns,获取指定的dns,可以如下配置 \"dns\": [\"10.20.1.2\", \"10.20.1.3\"] ## 设定容器的默认网关 \"default-gateway\": \"10.20.1.1\"     7,docker默认只支持在本机使用,通过/var/run/docker.sock通信\n -H可以指定指向的docker服务器 可以放开选项,在daemon.json文件中放开 1 2  ## 增加本机2375端口的监听 \"hosts\": [\"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\"]     8,自定义创建docker桥接桥\n 示例如下: 1 2 3 4 5 6  ## 新增mybr0桥 docker network create -d bridge --subnet \"172.26.0.0/16\" --gateway \"172.26.0.1\" mybr0 ## 新起一个容器,网络设置为mybr0 docker run -it --name t1 --net mybr0 busybox:latest ## 默认加入docker0网桥的命令是(default,不加默认就是) docker run -it --name t2 --net bridge busybox:latest     #. 容器存储 1,为什么要使用data volume\n docker镜像由多个只读层叠加而成,启动容器时,docker会加载只读镜像层并在镜像栈顶添加一个读写层 如果运行中的容器修改了现有的一个已经存在的文件,那该文件将会从读写层下面的只读层复制到读写层,该文件的只读版本仍然存在,之时已经被读写层中该文件的副本所隐藏,此即\"写时复制(COW)\"机制 经过多层联合挂载,IO性能肯定不高,对于一些IO要求比较高的应用,这种联合挂载的方式肯定不满足条件  2,使用容器的可读写层完成相关读写\n 缺点:  删除容器时,所有内容都被删除了 实现数据存取时,效率比较低   若想绕故上述的限制,可以通过存储卷的方式来实现  可以理解为在特权名称空间中(宿主机),在宿主机本地找一个文件系统上的目录(或者文件)与容器内的某一文件系统目录(或文件)建立绑定关系 绑定的实现是通过mount的bind参数实现的,绑定之后,容器写入相应的目录就是写到了宿主机上对应目录下 使得容器内的进程在数据保存时,能跳过或绕过容器文件系统的限制,从而与宿主机的文件系统建立关联关系,使得可以在容器内与宿主机共享数据或者内容(宿主机可以直接访问容器内内容,宿主机可以给容器直接提供内容)   使用了volume的docker容器,run时加--rm参数,实现就类似进程了  进程是程序的实例(类比容器是镜像的实例) 进程执行过程,生成的数据保存在文件系统,停止后,数据仍然还在(类比docker单独挂载了volume保存数据后,容器停止,数据已经保存在volume中)    3,容器启动时,参数会比较多,当需要完全复现一个容器时,可能不记得当时的启动参数了,这个功能可以通过容器编排工具提供\n4,有状态应用和无状态应用\n 有状态应用是当前这次连接请求是和之前有关联关系的,大多数有状态应用需要持久化数据的 无状态应用是当前请求和之前没有关联关系  5,docker的存储卷默认情况下是使用其所在的宿主机之上的本地文件系统目录的\n 存储卷是关联到宿主机上的一个目录而已,要单独挂载磁盘,需要先在宿主机上完成才行  6,为什么使用数据卷\n 关闭并重启容器,其数据不受影响;但删除容器,则其更改将会全部丢失 存在的问题:  存储于联合文件系统中,不利于宿主机访问 容器间共享数据不便 删除容器其数据会丢失   解决方案: 卷(volum)  卷是容器上一个或多个'目录',此类目录可以绕过联合文件系统,与宿主机上的某个目录绑定    7,卷提供了几项有用的特性以支持持久化存储或共享存储\n volume在容器创建之初就会创建,由base image提供的卷中的数据会于此期间完成复制  存储卷可以在容器之间复用 对卷中的数据更改实时生效 对卷中的数据更改不影响容器镜像的更新 容器删除后,卷中的数据仍然存在   volume的初衷是独立于容器的生命周期实现数据持久化,因此删除容器既不会删除卷,也不会对那些未被应用的卷做垃圾回收操作  8,卷为docker提供了独立于容器的数据管理机制\n 可以把镜像想象成静态文件,例如程序,把卷类比于动态内容,例如数据,于是,镜像可以重用,而卷可以共享 卷实现了'程序(镜像)'和'数据(卷)'的分离,以及'程序(镜像)'和'制作镜像的主机'分离,用户制作镜像时无需再考虑镜像运行的容器所在的主机的环境  9,卷的类型,docker有两种类型的卷,每种类型的卷都在容器中存在一个挂载点,但其在宿主机上的位置有所不同\n bind mount volume(绑定挂载卷): 在宿主机上需要指定挂载路径,在容器中也要指定挂载路径,两个已知路径建立关联关系  指定的宿主机路径不存在,默认情况下,会自动创建出来 1 2  docker run -it -v HOSTDIR:VOLUMEDIR --name bbox2 busybox:latest docker inspect -f {% raw %}{{.Mounts}}{% endraw %} bbox2      docker-managed volume(docker管理卷):只需要指定容器中的挂载路径,宿主机路径不指定,由docker自动指定一个空目录,与挂载目录建立关联关系 1 2  docker run -it -v /data --name bbox1 busybox:latest docker inspect -f {% raw %}{{.Mounts}}{% endraw %} bbox1    使用其他容器的卷 1  docker run -it --name bbox1 --volume-from bbox2 busybox:latest     10,使用docker inspect去查看容器的相关信息时,可以使用go模板(go template),类似与ansible的jinja2模板\n docker inspect -f {% raw %}{{.Mounts}}{% endraw %} b2 docker inspect -f {% raw %}{{.NetworkSettings.IPAddress}}{% endraw %} b2  11,joined-container使用共享卷,实现nmt(nginx+mysql+tomcat)\n 可以先启动一个基础支撑容器(互联网上有专门的这种容器),先提供一个卷,给后面的容器使用 nmt三个容器共用一个存储卷,共用(net,uts,ipc)名称空间 只有nginx对外暴露端口,tomcat和mysql监听在lo上 1 2 3 4  docker run -it --name infracon -it -v /data/infracron/volume/:/data/web/html/ busybox docker run -it --name nginx --network container:infracon --volume-from infracon nginx:latest docker run -it --name tomcat --network container:infracon --volume-from infracon tomcat:latest docker run -it --name mysql --network container:infracon --volume-from infracon mysql:latest    对于这种需求,可以使用docker-compose来实现,主要功能是单击编排(还可以做镜像,镜像现做,容器现启动)  #. Dockerfile详解(一) 1,生产环境下使用nginx场景,修改配置生效的几种方式\n docker exec CONTAINER vi, reload进入容器修改配置文件,再reload服务 挂载存储卷,配置文件在存储卷中,但修改之后还是需要reload操作 自己制作镜像  2,制作镜像的两种方式\n 基于已有镜像制作,修改完成后,提交可读写层  日常运维修改很频繁,相应的提交也就很频繁 版本管理混乱,后续想制作同样的镜像很难   Dockerfile  Dockerfile仅仅就是构建docker镜像的源代码 Dockerfile的内容就是一个用户可以在命令行下操作,用来装配好docker镜像的指令集合 docker可以通过读取Dockerfile的内容,自动构建docker镜像    3,Dockerfile的组成\n 格式:  INSTRUCTION其实并不区分大小写,但是为了规范且和参数区别,一般大写 docker是按照顺序执行Dockerfile中的INSTRUCTION的 Dockerfile的第一行必须是FROM开头,用来指定需要构建的镜像的基础镜像是哪个 Dockerfile中可以执行很多shell命令,但是这个命令是docker容器中的命令,不是宿主机上的命令 1 2  # CommentINSTRUCTION arguements     构建规范和逻辑  要有单独的工作路径(目录) 工作目录中,要有Dockerfile文件 需要使用到的文件,需要存放在工作目录下,Dockerfile中引用的路径都是以当前工作目录为起始路径 对于子目录中不需要拷贝的文件,可以使用.dockerignore文件来罗列(文件排除列表)  一行一个文件 支持通配符     环境变量替换  环境变量(以ENV开头的部分)同样能被Dockerfile解析 环境变量在Dockerfile中引用的格式时$variable_name或者${variable_name} ${variable_name}同样支持少量的shell变量替换操作  ${variable_name:-word}:变量为空或者变量未设置时,引用的值就是word,变量有值的时候,则使用变量的值 ${variable_name:+word}:变量有值则显示为word,没值就什么都没有      4,Dockerfile中的指令\n FROM  FROM指令是最重要的一个,且必须是Dockerfile文件开篇的第一个非注释行,用于为影响文件构建过程指定基准镜像,后续的指令基于此基准镜像提供的运行环境 基准镜像可以使用任何镜像文件,默认情况下,docker build会在docker主机上查找指定的镜像文件,在其不存在时,则会从docker hub registry上拉取所需要的镜像文件(如果找不到指定的镜像文件,则返回报错) 语法: 1 2 3 4  FROM\u003crepository\u003e:\u003ctag\u003e## 或者FROM\u003crepository\u003e@\u003cdigest\u003e## digest是镜像的哈西码,为的是避免同名镜像被替换     MAINTANIER(depreacted已废弃)  用于让镜像制作者提供本人信息 Docker并不限制MAINTANIER出现的位置,建议放在FROM后面 语法: 1  MAINTANIER \u003cauthor's details\u003e     LABEL  LABEL指令用于给镜像增加元数据 一个镜像可以有多个LABEL 可以在一行中指定多个label(键值对) 语法: 1 2  LABEL \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e## MAINTANIER可以作为LABEL中的一个键值数据存在     COPY  用于从Docker主机复制文件至创建的新映像文件 语法如下: 1 2 3 4 5  COPY \u003csrc\u003e...\u003cdest\u003e或者COPY [\"\u003csrc\u003e\",...\"\u003cdest\u003e\"] # \u003csrc\u003e:要复制的源文件或者目录,支持使用通配符 # \u003cdest\u003e:目标路径,即正在创建的image的文件系统路径;建议为\u003cdest\u003e使用绝对路径,否则,COPY指定则以WORKDIR为其起始路径 # 注意: 在路径中有空白字符时,通常使用第二种格式   文件复制准则:  必须是build上下文中的路径,不能是父目录中的文件 如果是目录,则其内部文件或子目录会被递归复制,但目录自身不会被复制 如果指定了多个,或在中使用了通配符,则必须是一个目录,且必须以/结尾 如果事先不存在,他将会被自动创建,这包括岐阜目录路径     ADD  类似于COPY指令,ADD支持使用TAR文件和URL路径 语法如下: 1 2  ADD \u003csrc\u003e...\u003cdest\u003e或者ADD [\"\u003csrc\u003e\",...\"\u003cdest\u003e\"]   文件复制准则:  同COPY指令 如果为URL且不以/结尾,则指定的文件将被下载并直接被创建为;如果以/结尾,则文件名URL指定的文件将被下载下来并保存为/ 如果是一个本地文件系统上的压缩格式的tar文件,它将被展开为一个目录,其行为类似于'tar -x'命令;然而,通过URL获取到的tar文件将不会自动展开 如果有多个,或其间接或直接使用了通配符,则必须是一个以/结尾的目录路径;如果不以/结尾,则其被视作一个普通文件,的内容将被直接写入到     WORKDIR  用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 语法如下: 1 2 3 4 5 6  WORKDIR\u003cdirpath\u003e # 在Dockerfile文件中,WORKDIR指令可以出现多次,其路径也可以为相对路径,不过,其是相对此前一个WORKDIR指令指定的路径 # 另外,WORKDIR也可调用由ENV指定定义的变量# 示例:WORKDIR/var/logWORKDIR$STATEPATH     VOLUME  用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上卷 语法如下: 1 2  VOLUME\u003cmountpoint\u003e或者VOLUME [\"\u003cmountpoint\u003e\"]   如果挂载点目录下此前在文件存在,docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 与run命令使用的volume不同,Dockerfile中指定VOLUME只能指定docker挂载目录   EXPOSE  用于为容器打开指定要监听的端口以实现与外部通信 语法如下: 1 2 3 4 5 6 7 8 9  EXPOSE\u003cport\u003e[/\u003cprotocol\u003e][\u003cport\u003e[/\u003cprotocol\u003e]...] # \u003cprotocol\u003e用于指定传输层协议,可为tcp或者udp二者之一,默认为TCP协议 # 注意:写在Dockerfile中的端口暴露,只是提示可以暴露,而不是以该镜像启动的容器就暴露端口 # 在需要暴露时,docker run指定-P选项,会读取到哪些端口需要暴露,并将其暴露出去 # 示例:(构建惊险的Dockerfile中已经存在EXPOSE 80/tcp) # docker run --name tinyweb1 --rm tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html # docker port tinyweb1 --\u003e none # docker run --name tinyweb1 --rm -P tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html # docker port tinyweb1 --\u003e 80/tcp -\u003e 0.0.0.0:32768   EXPOSE可以一次指定多个端口,如:  EXPOSE 11211/udp 11211/tcp   写在镜像中的端口,在运行容器时没有指定则被称为待暴露端口,而不会真正暴露,除非在运行容器时加上-P(默认暴露端口)选项   ENV  用于为镜像定义所需的环境变量,并可以被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY)所调用 语法如下: 1 2 3 4 5  ENV \u003ckey\u003e \u003cvalue\u003e 或者ENV \u003ckey\u003e=\u003cvalue\u003e...# 第一种格式中,\u003ckey\u003e之后的所有内容均会被视作其\u003cvalue\u003e的组成部分,因此,一次只能设置一个变量# 第二种格式可以用于一次设置多个变量,每个变量为一个\"\u003ckey\u003e=\u003cvalue\u003e\"的键值对,如果\u003cvalue\u003e中包含空格,可以以反斜线(\\)进行转意,亦可通过对\u003cvalue\u003e加引号进行标识;另外,反斜线也可用于续行.# 定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能   在Dockerfile中ENV定义的变量,可以在依照其构建出的镜像启动的容器中直接使用    5,Dockerfile中请惜字如金,因为每一条指令都会生成一个新的层\n#. Dockerfile详解(二) 1,在docker的上下文当中,有一个重要的特点,一个容器只是为了运行单个程序或者单个应用\n2,在命令行下通过\u0026符放后台执行的程序都是当前shell的子进程,当退出当前shell时,该shell的子进程会被杀掉,相应的该shell下的后台进程也被关闭\n 如果要实现退出shell时,仍然可以正常运行,需要增加nuhup command \u0026,剥离command与当前shell的关系,相当于把启动这个进程的父进程安排给了init 在一个用户空间中,不是以shell的子进程去启动一个程序,很多的经验和参数则不能使用 1 2 3  ls /var/* # --\u003e 不在shell下执行的话,*无法被内核解析 # 变量替换 --\u003e 同样不能被解析 # 管道,输入输出重定向等 --\u003e 无法识别     3,Dockerfile中的指令\n CMD  在docker容器中,需要让容器运行的进程变为pid为1的进程   在容器当中,希望以shell的方式启动一个主进程\n 先在用户空间中启动一个shell(pid为1),在shell中以剥离终端的方式启动需要启动的主进程;解决主进程pid不为一的方式为,在shell中exec command --\u003e exec顶替shell的pid=1,取代shell进程,shell退出,command成为pid=1的进程\n   在docker容器中,可以不基于shell,直接启动进程;也可以基于shell,通过shell启动进程,但要基于shell启动,并且不违背这个主进程id为1的原则,需要通过exec来实现\n   CMD是定义一个容器启动时,默认需要执行的程序  类似于RUN指令,CMD指令也可用与运行任何命令或应用程序,不过二者的运行时间点不同  RUN指令运行于映像文件构建过程中,而CMD指令运行于基于Dockerfile构建出的新镜像文件启动为一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序,且其运行结束后,容器也将终止;不过CMD指定的命令可以被docker run的命令行选项所覆盖 在Dockerfile中,可以存在多个CMD指令,但仅有最后一个会生效     语法: 1 2 3 4 5  CMD \u003ccommand\u003eCMD [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]CMD [\"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 前两种语法格式的意义同RUN# 第三种则用于为ENTRYPOINT指令提供默认参数     RUN  用于指定docker build过程中运行的程序,其可以是任何命令 语法: 1 2 3 4 5  RUN \u003ccommand\u003eRUN [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 第一种格式中,\u003ccommand\u003e通常是一个shell命令,且以'/bin/sh -c'来运行它,这意味着此进程在容器中的PID不为1,不能接收Unix信号,因此,当使用docker stop \u003ccontainer\u003e命令停止容器时,此进程接收不到SIGTERM信号RUN ['/bin/bash', '-c', '\u003cexecutable\u003e', '\u003cparam1\u003e']# 第二种格式中的参数是一个JSON格式的数组,其中\u003cexecutable\u003e为要运行的命令,后面的\u003cparamN\u003e为传递给命令的选项或者参数;然而,此种格式指定的命令不会以'/bin/sh -c'来发起,因此常见的shell操作如变量替换以及通配符(?,*等)替换将不会进行;不过,如果要运行的命令依赖于此shell特性的话,可以将其替换为类似下面的格式   示例用法: 1 2 3 4  ENV WEB_DOC_ROOT='/data/web/html/'CMD /bin/httpd -f -h ${WEB_DOC_ROOT} # ---\u003e 可用CMD [\"/bin/httpd\", \"-f\", \"-h ${WEB_DOC_ROOT}\"] # ---\u003e 不可用,如上b所述,该写法不是在shell中执行,不能解析${WEB_DOC_ROOT}CMD [\"/bin/sh\", \"-c\", \"/bin/httpd\", \"-f\", \"-h ${WEB_DOC_ROOT}\"] # ---\u003e 可用     ENTRYPOINT  类似CMD指令的功能,用于为容器指定默认运行程序,从而使得容器像是一个单独的可执行程序 与CMD不同的是,由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖,而且,这些命令行参数会被当作参数传递给ENTRYPOINT指定的程序  docker run命令的--entrypoint选项的参数可以覆盖ENTRYPOINT指令指定的程序   语法: 1 2 3 4 5 6  ENTRYPOINT \u003ccommand\u003eENTRYPOINT [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 示例:ENTRYPOINT /bin/sh -c # --\u003e inspect image会发现存在两层/bin/sh -c,因为默认这种格式就是/bin/sh -cENTRYPOINT ['/bin/sh', '-c'] # --\u003e inspect image正常   docker run命令传入的命令参数会覆盖CMD指令的内容并附加到ENTRYPOINT命令最后,作为其参数使用 ENTRYPOINT在Dockerfile中也可以存在多个,但仅有最后一个会生效   USER  用于指定运行image时的或运行Dockerfile中任何RUN,CMD或ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下,container的运行身份为root用户 语法: 1 2  USER\u003cUID\u003e|\u003cUserName\u003e# 需要注意的是,\u003cUID\u003e可以为任意数字,但实践中必须要为/etc/passwd中某用户的有效UID,否则,docker run命令将运行失败     HEALTHCHECK  HEALTHCHECK指令是通过给定内容给docker,令其检查容器是否还在正常运行,检查主进程工作状态健康与否 语法: 1 2 3 4 5 6 7 8 9 10 11 12 13  HEALTHCHECK [OPTION] CMD command # --\u003e 通过在容器中运行command来检测容器是否运行正常 - 可在CMD前指定的option --interval=DURATION(default: 30s) --timeout=DURATION(default: 30s) --start-period=DURATION(default: 0s) --\u003e等待多长时间(docker run容器起来后,可能还需要初始化动作,这个时候不应该算到检测内容中) --retries=N(default: 3) - command执行的返回值反映了容器的健康状态,可能的value包括如下: 0:success --\u003e 容器健康且能提供服务 1:unhealthy --\u003e 容器未能正常运行 2:reserved --\u003e 不使用该返回值(预留的,没什么意义) # 示例内容: HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1HEALTHCHECK NON禁用任何从容器尽享中继承的healthcheck     STOPSIGNAL  STOPSIGNAL指令用于指定发送给容器,用于停掉的容器的system call signal 语法: 1  STOPSIGNALsingal     ARG  定义变量,但只能在docker build过程中使用  ARG后定义的变量可以在docker build过程中被替换,这种场景适用于一个Dockerfile可以接收不同参数,构建不同镜像的   语法: 1 2  ARG \u003ckey\u003e=\u003cvalue\u003e# 使用了之后,可以在构建镜像时使用--build-arg \u003ckey\u003e=\u003cvalue2\u003e替换     ONBUILD  在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile用作FROM指令的参数,并以之构建新的镜像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时,将会触发创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 语法: 1  ONBUILD \u003cINSTRUCTION\u003e   尽管任何指令够可注册成为触发器指令,但ONBUILD不能自我嵌套,且不会触发FROM和ENTRYPOINT指令 使用ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签,例如ruby:2.0-onbuild 在ONBUILD指令中使用ADD或者COPY指令应该格外小心,因为新构建过程的上下文缺少指定的源文件时会报错    4,nginx Dockerfile示例\n 内容如下: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  FROMnginx:1.14:alpineLABLE maintainer=\"MageEdu \u003cmage@magedu.com\u003e\"ENV NGX_DOC_ROOT='/data/web/html/'ADD entrypoint.sh /bin/CMD ['/usr/sbin/nginx', '-g', 'daemon off;']ENTRYPOINT ['/bin/entrypoint.sh']##################################cat entrypint.sh#!/bin/bash#cat \u003e /etc/nginx/conf.d/www.conf \u003c\u003cEOFserver { server_name $HOSTNAME; listen ${IP:-0.0.0.0}:${PORT:-80}; root ${NGX_DOC_ROOT:-/usr/share/nginx/html};}exec \"$@\"EOF    5,在写Dockerfile时,注意json传入时必须要写双引号,单引号会报错\n#. Docker私有registry 1,registry用于保存docker镜像,包括镜像的层次结构和元数据\n2,启动registry有几种方式\n docker run -d xxxx registry yum install docker-registry(在epel源中,实际名称为docker-distribution)  实际上时一个python开发的web自运行程序 数据保存目录在/var/lib/docker下,配置文件在/etc下,可以通过更改/etc下配置文件修改镜像保存位置和监听端口    3,建议使用harbor来管理镜像,搭建harbor需要使用到docker-compose\n harbor有两种安装方式,离线和在线  离线版安装需要下载tgz文件,文件较大,需要下载一段时间 在线版是在更改完配置文件后,执行安装脚本,安装过程中下载相应镜像 不管离线还是在线安装,需要先完成harbor.cfg文件的配置,而后才能进行部署   harbor是一个多容器服务,需要使用到各种容器镜像,编排内容在docker-compose.yml中定义  一般执行docker-compose命令,会在docker-compose.yml文件所在目录执行 根据docker-compose.yml文件启动相应服务 --\u003e docker-compose start 根据docker-compose.yml文件关闭相应服务 --\u003e docker-compose stop 查看docker-compose的帮助命令 --\u003e docker-compose help    4,harbor的一些特性:\n 多租户登录和验证 安全和风险验证 日志监控 RBA(role-base control) 实例间镜像拷贝 扩展API和web UI界面  #. Docker的资源限制 1,默认情况下,容器是没有资源限制的,可以使用完宿主机上内核分配给该容器的所有资源\n2,docker提供了一个途径,可以用来控制容器可以使用多少CPU,memory,块设备IO(限制有限);可以通过设置运行时(runtime)配置\n 内存是不可压缩资源,当容器需要使用的内存分配不到时,可能触发容器内的oom CPU的分配可以通过少分配来实现  3,这些资源限制功能的实现依赖于内核是否支持来实现\n4,在linux主机上,如果内核探测到但前内存无法满足重要系统功能实现时,会抛出OOME(out of memory exception),并开始杀掉进程来释放空间\n 一旦发生oome,任何进程都有可能被杀死,包括docker daemon 为此docker特地调整了docker daemon的OOM优先级,以免被内核杀掉,但容器内的优先级并未被调整 每个进程有一个oom_adj,用来计算oom权重(优先级)  5,限制一个容器可以使用的内存\n -m或者--memory:最少为4M --memory-swap:不使用--memory时,不能使用该项  ------------------------------------------------------------------------------------------------ | --memory-swp | --memory | 功能 ------------------------------------------------------------------------------------------------ | 正数S | 正数M | 容器可用总内存为S,其中ram为M,swap为(S-M),若S=M,则无可用swap资源 ------------------------------------------------------------------------------------------------ | 0 | 正数M | 相当于未设置swap(unset) ------------------------------------------------------------------------------------------------ | unset | 正数M | 若主机(Docker Host)启用了swap,则容器的可用swap为2M ------------------------------------------------------------------------------------------------ | -1 | 正数M | 若主机(Docker Host)启用了swap,则容器的可用swap可使用到主机上所有swap ------------------------------------------------------------------------------------------------ # 注意:在容器内部使用free命令可以看到的swap空间并不具有其所展现出的空间指示意义  --memory-swappiness --memory-reservation --kernel-memory --oom-kill-disable  6,限制一个容器可以使用的CPU\n 默认情况下,每个容器可以使用的CPU时间片是不受限制的 可以通过多种方式来限制容器可以使用的CPU资源 大多数用户通过CFS(completely fair scheduler)来调度 在1.13之后版本的docker上,还可以使用realtime调度器 --cpus= 限定一个容器最多能够使用几核 --cpu-period= --cpu-quota= --cpuset-cpus 限制在哪些核上 -- cpu-shares 配置为共享方式(各个容器共享宿主机CPU)  7,下载压测镜像,可以在dockerhub上搜索stress\n","description":"介绍容器的实现,讲解docker常用命令和Dockerfile的使用","tags":["云原生","docker","cloud"],"title":"docker学习","uri":"/tech/cloud/docker%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"learning ansible 本文内容参考自朱双印ansible笔记\n配置主机清单 主机清单配置有两种方式\n# ini方式 1 2 3 4 5 6 7 8 9 10 11  # 1,如下示例: [ctl] 10.168.0.2 10.168.0.3 10.168.0.4 [nova:children] ctl [nova-compute:children] nova   # yaml方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 1,如下示例:all:children:k8s:hosts:master:ansible_host:192.168.110.11ansible_port:22ansible_user:rootansible_pass:'123.com'node2:ansible_host:192.168.110.22ansible_port:22ansible_user:rootansible_pass:'123.com'node3:ansible_host:192.168.110.33ansible_port:22ansible_user:rootansible_pass:'123.com'  常用模块 # 文件类操作 1,copy: 将ansible主机上的文件拷贝至远端主机\n 同fetch类似,不过操作动作相反,fetch是从远端主机拿文件到ansible主机 可使用content直接代替src 可备份远端重名文件 可设定拷贝文件的权限  2,file: 完成一些对文件的基本操作,包括创建,删除,修改文件和目录的权限等\n path是必须项,需要和state结合使用 state参数是核心,对不同类型的文件对应的动作不相同,path如果是文件(touch),是目录(directory); absent时不用管path是什么(目录或者文件)  3,blockinfile: 在文件中插入一段文本,这段文本是被标记过的,方便我们后面对标记内容的操作(删除,修改等)\n 对文件中块的操作,文件位置定位使用insertbefore,insertafter 使用block/content制定块内容 使用该模块marker会在插入内容前后增加marker内容 可使用regex,匹配文件中内容进行操作 包含backup相关内容  4,lineinfile: 确保某一行文本存在于文件中,或不存在与文本中,可使用regex进行替换\n line指定行内容 包含regex参数,使用regex来匹配相应的行,当替换文本时，如果有多行文本都能被匹配，则只有最后面被匹配到的那行文本才会被替换，当删除文本时，如果有多行文本都能被匹配，这么这些行都会被删除 backrefs参数：默认情况下，当根据正则替换文本时，即使regexp参数中的正则存在分组，在line参数中也不能对正则中的分组进行引用，除非将backrefs参数的值设置为yes 插入内容为insertbefore,insertafter, 包含backup相关内容  5,find: 类似find命令,可在远端机器中找到相应文件\n 使用方式ansible-doc -s find查看  6,replace: replace模块可以根据我们指定的正则表达式替换文件中的字符串，文件中所有被正则匹配到的字符串都会被替换\n 使用方式ansible-doc -s replace查看  # 命令类操作 1,command: 在远端主机上执行命令\n 使用command模块在远程主机中执行命令时，不会经过远程主机的shell处理，在使用command模块时，如果需要执行的命令中含有重定向、管道符等操作时，这些符号也会失效，比如”\u003c“, “\u003e”, “|”, “;” 和 “\u0026” 这些符号，如果你需要这些功能，需要使用shell模块 具体使用方式,参考ansible-doc -s command  2,shell: 在远端主机上执行命令,与command不同的是,shell模块在远端执行命令时,会经过远端主机的/bin/sh程序处理\n 具体使用方式,参考ansible-doc -s shell  3,scripts: 在远端主机上执行ansible主机上的脚本,脚本在ansible主机上,不需要拷贝到远端主机\n 具体使用方式,参考ansible-doc -s scripts  # 系统类操作 1,cron: 管理远端主机上的定时任务,功能同crontab\n 具体使用方式,参考ansible-doc -s cron  2,service: 管理远端主机上的服务\n 具体使用方式,参考ansible-doc -s service  3,user: 管理远端主机上的用户,类似命令usermod\n 还可以管理用户的ssh密钥 具体使用方式,参考ansible-doc -s user  4,groupo: 管理远端主机上的组,类似命令groupmod\n 具体使用方式,参考ansible-doc -s group  # 包管理类操作 1,yum_repository: 管理远端主机上的yum仓库\n 具体使用方式,参考ansible-doc -s yum_repository  1,yum: 通过远端主机上的yum管理软件包\n 具体使用方式,参考ansible-doc -s yum  #认识ansible-playbook 1,ansible-playbook的使用,可以理解为ansible -m \u003cmodule_name\u003e -a 'xxxx'的转换,将命令行使用模块操作的内容写成脚本内容,按照脚本内容完成相关操作\n2,上述脚本在ansible-playbook中称作为'playbook',即剧本\n 每个playbook(剧本)又多个play(桥段)组成,每个剧本是由多个桥段组成的,每个桥段包含有人物,场景,故事 每个play在执行时,都会执行一个默认任务('Gathering Facts),任务会收集当前当前play对应的目标主机的相关信息(IP,hostname,硬件版本,系统版本等),收集完成后才会完成我们定义的相关任务  3,ansible有个重要特性:幂等性\n 在ansible调用模块或者ansible-playbook执行相应play时,输出内容会有颜色区分,黄色表示有修改,绿色表示么有修改;区别是远端的内容是否满足我们的预期 ansible是”以结果为导向的”，我们指定了一个”目标状态”，ansible会自动判断，”当前状态”是否与”目标状态”一致，如果一致，则不进行任何操作，如果不一致，那么就将”当前状态”变成”目标状态”，这就是”幂等性”，”幂等性”可以保证我们重复的执行同一项操作时，得到的结果是一样的  #使用handlers 1,handlers的使用场景:\n 有个任务需要修改nginx的配置文件,将listen端口由8080改为8088,使用handler可以在nginx配置文件有修改的环境上重启nginx,没有修改的不会出发重启nginx handlers可以理解为另一种tasks,handlers是另一种'任务列表',handlers中的任务会被tasks中的任务调用; handlers被调用并不一定会执行,只有当tasks中的任务真正被执行后(真正的进行了实际操作,造成了实际变化),handlers中的任务才会真正执行 如果tasks中的任务并没有作出任何实际的操作,那么handlers中的任务即使被调用,也不会执行 handlers和tasks是平级的,所以缩进相同  2,handlers的调用:\n handlers需要被关键字notify调用 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:allremote_user:roottasks:- name:change nginx configurationlineinfile:path=/etc/nginx/conf.d/test.confregexp=\"listen(.*) 8080(.*)\"line=\"listen\\1 8088\\2\"backrefs=yesbackup=yesnotify:restart nginxhandlers:- name:restart nginxservice:name=nginxstate=restarted   3,handlers中可以有多个任务,被tasks中不同的任务调用\n handler执行的顺序与handler在playbook中定义的顺序相同,与handler被notify的顺序无关(下述内容ht1先触发,ht2后触发),如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ---- hosts:allremote_user:roottasks:- name:make testfile1file:path=/testdir/testfile1state=directorynotify:ht2- name:make testfile2file:path=/testdir/testfile2state=directorynotify:ht1handlers:- name:ht1file:path=/testdir/ht1state=touch- name:ht2file:path=/testdir/ht2state=touch   默认情况下,所有tasks执行完成后,才会执行各个handlers 当存在多个同名的handler时,只会执行一个handler  4,若要在执行完某个task后立即执行其对应的handler,需要使用meta模块\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  ---- hosts:allremote_user:roottasks:- name:task1file:path=/testdir/testfilestate=touchnotify:handler1- name:task2file:path=/testdir/testfile2state=touchnotify:handler2- meta:flush handlers- name:task3file:path=/testdir/testfile3state=touchnotify:handler3handlers:- name:handler1file:path=/testdir/hd1state=touch- name:handler2file:path=/testdir/hd2state=touch- name:handler3file:path=/testdir/hd3state=touch   meta可以理解为tasks下一个特殊任务,使用的是meta模块 meta: flush_handlers指的是立即执行之前的task对应的handlers,上述例子中flush_handlers之前有两个task,在执行了这两个task之后立即执行他们对应的handler 使用meta配合task和handler,可以让任务调用更加灵活  5,如果需要一次性notify多个handler,需要使用到listen\n 可以把'listen'理解为'组名',可以把多个handler分成'组',当我们需要一次性notify多个handler时,只要将多个handler分成一组,使用相同的组名即可 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:allremote_user:roottasks:- name:task1file:path=/testdir/testfilestate=touchnotify:handler group1handlers:- name:handler1listen:'handler group1'shell:'echo handler1'- name:handler2listen:'handler group1'shell:'echo handler2'  #使用tags 1,写了一个很长的playbook,在调试时只想跑其中很少的一部分,tag在这种场景下可以使用,指定执行哪些任务,不执行哪些任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:allremote_user:roottasks:- name:test 1file:path=/testdir/testfilestate=touchtags:t1- name:test 2file:path=/testdir/testfile2state=touchtags:t2- name:test 3file:path=/testdir/testfile3state=touchtags:t3$ ansible-playbook --tags=t2 test.yaml$ ansible-playbook --skip-tags=t2 test.yaml   --tags=t2,只执行tag为t2部分的task,--skip-tags=t2,跳过tag=t2的tag tag相关使用命令:  1 2 3 4  # 指定多个tag时,使用命令为 $ ansible-playbook -t tag1,tag2,tag3 test.yaml # 执行play前,查看当前有哪些tag $ ansible-playbook --list-tags test.yaml    ansible预置了几个特殊tag:  # always: 如果任务的tags包含always,则该task一定会被执行,除非指定--skip-tags always(该情况也不合理,可能其他任务也包含always,这样其他task也不会执行) # never: 永远不执行,与always刚好相反 ## 下列只在调用标签时生效 # tagged: ansible-playbook --tags tagged test.yaml --\u003e 只执行有标签的task,没有标签的task不会被执行 # untagged: ansible-playbook --tags untagged test.yaml --\u003e 只执行没有tag的task,有tag的不会被执行 # all: 默认使用,所有都会被执行  可以为task指定多个tag,如下:  1 2 3 4 5 6 7 8  # method onetags:- testing- t1# method twotags:testing, t1# method threetags:['testing','t1']  2,play也可以指定tags,当一个play之指定了tags,这个play下的所有task都包含该tag,若该play下的task还有自己的tags,则该task的实际tags为'play tags' + 'task tags'\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:test70remote_user:roottags:httpdtasks:- name:install httpd packagetags:['package']yum:name=httpdstate=latest- name:start up httpd servicetags:- serviceservice:name:httpdstate:started  #使用变量(一) 1,怎么定义变量\n 变量由数字,字母,下划线组成,要以字母开头 ansible的关键字不能作为变量名  2,变量的定义及引用\n 变量定义可以使用vars,和tasks同级,如下(普通定义方式):  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ---- hosts:allremote_user:rootvars:testvar1:testfiletestvar2:testfile2# 或者使用yaml写法vars:- testvar1:testfile- testvar2:testfile2tasks:- name:task1file:path:/testdir/{{testvar1}}state:touch   使用属性的方式定义  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  - hosts:allremote_user:rootvars:nginx:conf80:/etc/nginx/conf.d/80.confconf8080:/etc/nginx/conf.d/8080.conftasks:- name:task1file:path:\"{{nginx.conf80}}\"# 或者path: \"{{nginx['conf80']}}\"state:touch- name:task2file:path:\"{{nginx.conf8080}}\"# 或者path: \"{{nginx['conf8080']}}\"state:touch# 使用=给模块参数赋值时,可以不考虑变量是否加引号# - name: task2# file:# path={{nginx.conf8080}}# # 或者path={{nginx['conf8080']}}# state=touch   注意: 上面列举的两个例子有些差别,第一个例子中变量没有加引号,第二个有加引号,因为第一个变量不是'开头'位置,第二个是'开头'位置 但实际上也有例外,给模块参数赋值时,可以选择':',也可以选择'=',当使用'='时,可以不用考虑引号的问题\n 3,在文件中定义变量给playbook使用\n 将变量在单独的文件中定义的好处是,可以做到变量文件分离,不给看到变量的值 在文件中定义变量时,不用使用vars关键字,直接定义变量即可,如下集中语法:  1 2 3 4 5 6 7 8 9 10  # method onetestvar1:testfiletestvar2:testfile2# method two- testvar1:testfile- testvar2:testfile2# method threenginx:conf80:/etc/nginx/conf.d/80.confconf8080:/etc/nginx/conf.d/8080.conf   在文件中定义完变量,在playbook中使用变量,需要使用vars_files,被导入的文件以'-'开头(可以引入多个变量文件),以yaml中块序列的方式导入  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:allremote_user:rootvars_files:- /testdir/ansible/nginx_vars.ymltasks:- name:task1file:path:\"{{nginx.conf80}}\"state:touch- name:task2file:path:\"{{nginx['conf8080']}}\"state:touch  #使用变量(二) 1,在playbook执行前,有一个Gathering Facts的动作,调用的是setup模块; 这些信息会保存在对应的变量中，我们在playbook中可以使用这些变量,我们可以称这些信息为facts信息\n setupa模块的返回值是json格式的,方便返回时内容展示 setup模块可以获取远端主机很详尽的信息,若需要过滤相关信息,可以使用setup的filter参数(支持通配符)  1 2 3 4  # 显示内存相关信息 ansible all -m setup -a 'filter=ansible_memory_mb' # 不确定信息相关信息,使用通配符来获取 ansible all -m setup -a 'filter=*mb*'    setup模块获取的信息都保存在相应的变量中,我们可以通过引用变量获取到这些值  2,setup模块支持获取自定义内容\n 要求:自定义内容存在于目标主机的/etc/ansible/facts.d/下以.fact结尾的文件; 这些文件需要以json或者ini格式保存变量信息  1 2 3 4  $ cat /etc/ansible/facts.d/test.fact [testmsg] msg1='test message 1' msg2='test message 2'    这些自定义的变量称为'local facts',可以在setup获取时通过filter=ansible_local获取  3,另一个模块debug,可用于playbook的调试使用,把调试信息打印到控制台上,方便我们查看和定位问题\n debug模块常用的两个参数分别是var和msg,var用于测试变量,msg用于打印输出是否符合预期  # 连接到主机,但是并没有做任何事情,debug引用的是testvar,测试testvar是否能用 ---yaml - hosts: all remote_user: root vars: testvar: value of testvar tasks: - name: test debug debug: var: testvar #使用变量(三) 1,变量注册\n ansible模块在执行之后都会有一些返回值,默认情况下,这些返回值不会显示而已;我们可以把这些返回值写入到某个变量中,我们可以通过引用相应的变量获取到这些返回值,将模块的返回值写入到变量中,这种方式称为'注册变量'; 如下为变量注册的的一个范例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:allremote_user:roottasks:- name:test registershell:\"echo test \u003e /tmp/testfile\"register:testvar- name:shell module return valuesdebug:var:testvar# 执行完成后,在控制台中看到名为”[shell module return values]”的任务中已经显示了第一个任务的返回值的信息，返回信息:TASK [shell module return values] ************************************ok:[master] =\u003e { \"testvar\": {\"changed\": true,\"cmd\": \"echo test \u003e /tmp/testfile\",\"delta\": \"0:00:00.010963\",\"end\": \"2021-03-30 09:26:47.432571\",\"failed\": false,\"rc\": 0,\"start\": \"2021-03-30 09:26:47.421608\",\"stderr\": \"\",\"stderr_lines\": [],\"stdout\": \"\",\"stdout_lines\": []}}# register的变量testvar其实是一个json格式的返回值,可以通过引用testvar的不同属性获取相应的值  2,变量的传入方式,ansible支持多种变量传入的方式,包括:交互式传入,命令行传入,文件传入\n 交互式传入,需要使用到var_prompt关键字,属于vars的一种,当出现该关键字时,会让你在命令行下输入  普通使用,以下输入内容不会在控制台显示(默认情况下private: yes)    1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:allremote_user:rootvars_prompt:- name:'your_name'prompt:\"What is your name?\"# private: no- name:'your_age'prompt:\"What is your age?\"# private: notasks:- name:output varsdebug:msg:your name is {{your_name}}, your age is {{your_age}}  - 普通使用,可以做到提供选项供选择 - 特殊使用,例如增加用户,设定密码  1 2 3 4 5 6 7 8 9 10 11 12 13  # 需要使用到vars_prompt下encrypt,指定加密方式,而且该方式需要passlib库,么有的话需要安装---- hosts:test70remote_user:rootvars_prompt:- name:\"hash_string\"prompt:\"Enter something\"private:noencrypt:\"sha512_crypt\"tasks:- name:Output the string after hashdebug:msg:\"{{hash_string}}\"   命令行传入,直接在ansible-playbook执行时增加-e 'key=value'即可,可有多个,变量赋值有多种方式,还可以是json格式 文件传入,类似命令行-e \"@变量文件绝对路径\"  #使用变量(四),register,set_fact 1,配置主机清单时,可以配置主机或主机组变量,但只对配置的主机或主机组生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  ## 主机配置,配置/etc/ansible/hosts如下# method onenode2 ansible_host=192.168.110.22 testhostvar=node2_host_var# method twoall:hosts:node2:ansible_host:192.168.110.22ansible_port:22testhostvar:node2_host_vartesthostvar2:node2_host_var2testhostvar3:thv31:3.1thv32:3.2$ ansible node2 -m shell -a 'echo {{testhostvar}}$ ansible node2 -m shell -a 'echo {{testhostvar3.thv31}}' or '{{testhostvar3['thv32']}}'## 主机组配置,配置/etc/ansible/hosts如下# method one[testB]node2 ansible_host=192.168.110.22node3 anisble_host=192.168.110.33[testB:vars]test_group_var1='group var test'test_group_var2='group var test2'# method twoall:children:testB:hosts:node2:ansible_host:192.168.110.22ansible_port:22node3:ansible_host:192.168.110.33ansible_port:22vars:test_group_var1:'group var test1'test_group_var2:'group var test2'$ ansible testB -m shell -a 'echo {{test_group_var1}}'  2,通过set_fact定义变量,set_fact是一个模块,可以通过set_fact模块在task中定义变量\n 普通使用,直接与task同级定义一个变量  1 2 3 4 5 6 7 8  ---- hosts:node2remote_user:roottasks:- set_fact:testvar:\"testtest\"- debug:msg:\"{{testvar}}\"   普通使用,将一个变量的值赋给另一个变量  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:node2remote_user:rootvars:testvar1:test1_stringtasks:- shell:\"echo test2_string\"register:shellreturn- set_fact:testsf1:\"{{testvar1}}\"testsf2:\"{{shellreturn.stdout}}\"- debug:msg:\"{{testsf1}} {{testsf2}}\"   通过set_fact模块创建的变量还有一个特殊性，通过set_fact创建的变量就像主机上的facts信息一样，可以在之后的play中被引用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:node2remote_user:rootvars:testvar1:tv1tasks:- set_fact:testvar2:tv2- debug:msg:\"{{testvar1}} ----- {{testvar2}}\"- hosts:node2remote_user:roottasks:- name:other play get testvar2debug:msg:\"{{testvar2}}\"- name:other play get testvar1debug:msg:\"{{testvar1}}\"# 这两个变量在第一个play中都可以正常的输出.但是在第二个play中，testvar2可以被正常输出了，testvar1却不能被正常输出，会出现未定义testvar1的错误   如果想要在tasks中给变量自定义信息，并且在之后的play操作同一个主机时能够使用到之前在tasks中定义的变量时，则可以使用set_facts定义对应的变量  #使用变量(五),内置变量,host_vars 1,ansible有一些内置变量可供使用,这些变量被ansible保留,我们定义变量时不能使用\n ansible_version  1  $ ansible node2 -m debug -a 'msg={{ansible_version}}'   2,hostvars可以在我们操作当前主机时获取到其他主机中的信息\n 如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---# 第一个什么也没做,只是获取node3的facts内容,这一步是需要的,只有收集过的facts才能被后面的play使用# 如果没有收到对应主机的facts信息,即使使用hostvars内置变量,也无法获取到对应主机的facts内容- name:\"play 1: gather facts of node3\"hosts:node3remote_user:root# 下面的gather_facts默认是yes# gater_facts: yes- name:\"play 2: gathter facts of node3 when operating on node2\"hosts:node2remote_user:roottasks:- debug:msg:\"{{hostvars['node3'].ansible_enp0s3.ipv4}}\"# 下面两种也可以#msg: \"{{hostvars.node3.ansible_enp0s3.ipv4}}\"#msg: \"{{hostvars['node3']['ansible_enp0s3']['ipv4']}}\"   hostvars除了获取到其他主机的facts内容,还可以获取到其他类型的一些变量信息,如其他主机的注册变量,主机变量,组变量等;如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---# 1,通过hostvars内置变量可以直接获取到其他主机中的注册变量# 2,注册变量并不用像facts信息那样需要事先收集，即可直接通过hostvars跨主机被引用到# 3,如果你在清单中为node3主机配置了主机变量，或者为node3主机所在的组配置了组变量，也是可以通过hostvars直接跨主机引用- hosts:node3remote_user:rootgather_facts:notasks:- shell:\"echo register_var_in_play1\"register:shellreturn- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.shellreturn.stdout}}\"   通过vars关键字定义的变量使用上例中的hostvars方法是无法被跨主机引用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  # 下列内容会报错,变量需要注册才行,直接使用vars定义的变量无法传递---- hosts:node3remote_user:rootgather_facts:novars:testvar:testvar_in_3tasks:- debug:msg:\"{{testvar}}\"- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.testvar}}\"# 通过set_fact将vars定义的内容注册,则可以---- hosts:node3remote_user:rootgather_facts:notasks:- set_fact:testvar:testvar_in_3- debug:msg:\"{{testvar}}\"- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.testvar}}\"   通过”set_fact”结合”hostvars”的方式，可以实现跨play获取其他主机中的变量信息  3,内置变量inventory_hostname,获取到被操作的当前主机的主机名称\n 主机名称并不是linux系统的主机名，而是对应主机在清单中配置的名称,清单中配置的名称即是  4,内置变量inventory_hostname_short,获取到被操作的当前主机的主机名称,简版\n 无论是IP还是别名，如果清单的主机名称中包含”.”，inventory_hostname_short都会取得主机名中第一个”.”之前的字符作为主机的简短名称  5,内置变量play_hosts,获取到当前play所操作的所有主机的主机名列表\n 如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:node2,node3remote_user:rootgather_facts:notasks:- debug:msg:\"{{play_hosts}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": [\"node2\",\"node3\"]}ok:[node3] =\u003e {\"msg\": [\"node2\",\"node3\"]}  6,内置变量groups,可以获取到清单中”所有分组”的”分组信息”\n 同inventory_hostname,但能获取到分组的信息  1 2  $ ansible all -m debug -a 'msg={{groups}}' $ ansible all -m debug -a 'msg={{groups.k8s}}'   7,内置变量group_names,获取到当前主机所在分组的组名\n 如下示例:  1 2 3 4 5 6 7  # ansible node2 -m debug -a \"msg={{group_names}}\" node2 | SUCCESS =\u003e { \"changed\": false, \"msg\": [ \"k8s\" ] }   8,内置变量inventory_dir,获取到ansible主机中清单文件的存放路径,默认是/etc/ansible,但也可以自定义\n 如下示例:  1 2 3 4 5  # ansible node2 -m debug -a \"msg={{inventory_dir}}\" node2 | SUCCESS =\u003e { \"changed\": false, \"msg\": \"/etc/ansible\" }   9,除了直接在hosts文件中定义主机变量和组变量，还有另外一种方法也可以定义主机变量和组变量，我们可以在清单文件的同级目录中创建两个目录，这两个目录的名字分别为”group_vars”和”host_vars”，我们可以将组变量文件放在”group_vars”目录中，将主机变量文件放在”host_vars”目录中，这样ansible就能获取到对应组变量和主机变量\n#使用循环(一),with_items的使用 1,使用with_items处理循环的内容\n 普通示例:  1 2 3 4 5 6 7 8 9 10 11  # \"with_items\"关键字会把返回的列表信息自动处理，将每一条信息单独放在一个名为\"item\"的变量中，只要获取到名为\"item\"变量的变量值，即可循环的获取到列表中的每一条信息# 下列debug被循环3次,每次单独输出相应循环的debug输出内容---- hosts:node2remote_user:rootgather_facts:notasks:- name:test with_itemsdebug:msg:\"{{item}}\"with_items:\"{{groups.k8s}}\"  2,with_items可以自定义\n 列表  1 2 3 4 5 6 7  # method onewith_items:- 1- 2- 3# method twowith_items:[1,2,3]   相对复杂的列表  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item.test1}}\"with_items:- {test1: a, test2:b}- {test1: c, test2:d}  3,result的使用\n 当使用了循环以后，每次shell模块执行的返回值放入名为”results”的序列中，”results”也是一个返回值，当模块中使用循环时，模块每次执行的返回值都会追加存放到”results”这个返回值中,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # 两次debug循环,输出的内容都保存在results序列中,属于results---- hosts:node2gather_facts:notasks:- shell:\"{{item}}\"with_items:- \"ls /opt\"- \"ls /home\"register:returnvalue- debug:var:returnvalue# 可以使用如下方式,避免所有结果在最后的results中去获取---- hosts:node2gather_facts:notasks:- shell:\"{{item}}\"with_items:- \"ls /opt\"- \"ls /home\"register:returnvalue- debug:msg:\"{{item.stdout}}' with_items: \"{{returnvalue.results}}\"# 先使用循环重复的调用了shell模块，然后将shell模块每次执行后的返回值注册到了变量”returnvalue”中，之后，在使用debug模块时，通过返回值”results”获取到了之前每次执行shell模块的返回值（shell每次执行后的返回值已经被放入到item变量中），最后又通过返回值”stdout”获取到了每次shell模块执行后的标准输出  #使用循环(二),对列表循环的操作 1,对序列循环有几个关键字\n with_items: 当循环的序列元素也是列表时,展开与预期的有差异,会将所有的列表展开 with_list: 其他动作与with_items相同,只有在嵌套列表循环时有差异,子列表将会作为元素使用 with_flattened: 与with_items相同 with_together: 列对齐,”对齐合并”功能  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_together:- [1,2,3]- [a, b, c ]# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=[1, u'a']) =\u003e {\"changed\": false,\"item\": [1,\"a\"],\"msg\": [1,\"a\"]}ok:[node2] =\u003e (item=[2, u'b']) =\u003e {\"changed\": false,\"item\": [2,\"b\"],\"msg\": [2,\"b\"]}ok:[node2] =\u003e (item=[3, u'c']) =\u003e {\"changed\": false,\"item\": [3,\"c\"],\"msg\": [3,\"c\"]}  #使用循环(三),嵌套循环 1,with_cartesian和with_nested\n 当我们需要两个列表嵌套循环时,可以使用with_cartesian或者with_nested,将每个小列表中的元素按照”笛卡尔的方式”组合后，循环的处理每个组合,如下示例  1 2 3 4 5 6 7 8 9 10 11 12  # 下面的例子会在node2下创建6个目录---- hosts:node2remote_user:rootgather_facts:notasks:- file:state:directorypath:\"/testdir/testdir/{{ item.0 }}/{{ item.1 }}\"with_cartesian:- [a, b, c ]- [test1, test2 ]  #使用循环(四),序列索引循环 1,使用到with_indexed_items,在处理列表中的每一项时，按照顺序为每一项添加了编号,如下示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_indexed_items:- test1- test2- test3# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=(0, u'test1')) =\u003e {\"changed\": false,\"item\": [0,\"test1\"],\"msg\": [0,\"test1\"]}ok:[node2] =\u003e (item=(1, u'test2')) =\u003e {\"changed\": false,\"item\": [1,\"test2\"],\"msg\": [1,\"test2\"]}ok:[node2] =\u003e (item=(2, u'test3')) =\u003e {\"changed\": false,\"item\": [2,\"test3\"],\"msg\": [2,\"test3\"]}   ”with_indexed_items”会将嵌套的两层列表”拉平”，”拉平”后按照顺序为每一项编号 当多加了一层嵌套以后，”with_indexed_items”并不能像”with_flattened”一样将嵌套的列表”完全拉平”，第二层列表中的项如果仍然是一个列表，”with_indexed_items”则不会拉平这个列表，而是将其当做一个整体进行编号  #使用循环(五),with_sequence,with_random_choice 1,with_sequence\n 使用with_sequence生成序列,with_sequence可以按照顺序生成数字序列,如下示例:  1 2 3 4 5 6 7 8 9 10 11  # debug模块被循环调用了5次，msg的值从1一直输出到了5，值的大小每次增加1---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_sequence:start=1 end=5 stride=1# 下列写法结果一致# with_sequence: count=5   使用with_sequence还可以格式化输出  1 2 3 4 5 6 7 8  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_sequence:start=2 end=6 stride=2 format=\"number is %0.2f\"  2,with_random_choice,使用with_random_choice可以从列表的多个值中随机返回一个值\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_random_choice:- 1- 2- 3- 4- 5  #使用循环(六),with_dict,with_subelements,with_file 1,with_dict,循环遍历字典元素,如下示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item}}\"with_dict:\"{{users}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item={'value': {u'gender': u'male', u'name': u'Bob Bananarama', u'telephone': u'987-654-3210'}, 'key': u'bob'}) =\u003e {\"changed\": false,\"item\": {\"key\": \"bob\",\"value\": {\"gender\": \"male\",\"name\": \"Bob Bananarama\",\"telephone\": \"987-654-3210\"}},\"msg\": {\"key\": \"bob\",\"value\": {\"gender\": \"male\",\"name\": \"Bob Bananarama\",\"telephone\": \"987-654-3210\"}}}ok:[node2] =\u003e (item={'value': {u'gender': u'female', u'name': u'Alice Appleworth', u'telephone': u'123-456-7890'}, 'key': u'alice'}) =\u003e {\"changed\": false,\"item\": {\"key\": \"alice\",\"value\": {\"gender\": \"female\",\"name\": \"Alice Appleworth\",\"telephone\": \"123-456-7890\"}},\"msg\": {\"key\": \"alice\",\"value\": {\"gender\": \"female\",\"name\": \"Alice Appleworth\",\"telephone\": \"123-456-7890\"}}}  2,with_subelements:\n with_subelements会将hobby子元素列表中的每一项作为一个整体，将其他子元素作为一个整体，然后组合在一起  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  # 如下示例:---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{ item }}\"with_subelements:- \"{{users}}\"- hobby# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=({u'gender': u'male', u'name': u'bob'}, u'Skateboard')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"male\",\"name\": \"bob\"},\"Skateboard\"],\"msg\": [{\"gender\": \"male\",\"name\": \"bob\"},\"Skateboard\"]}ok:[node2] =\u003e (item=({u'gender': u'male', u'name': u'bob'}, u'VideoGame')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"male\",\"name\": \"bob\"},\"VideoGame\"],\"msg\": [{\"gender\": \"male\",\"name\": \"bob\"},\"VideoGame\"]}ok:[node2] =\u003e (item=({u'gender': u'female', u'name': u'alice'}, u'Music')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"female\",\"name\": \"alice\"},\"Music\"],\"msg\": [{\"gender\": \"female\",\"name\": \"alice\"},\"Music\"]}   由于item由两个整体组成，所以，我们通过item.0获取到第一个小整体，即gender和name属性，然后通过item.1获取到第二个小整体，即hobby列表中的每一项  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{ item.0.name }} 's hobby is {{ item.1 }}\"with_subelements:- \"{{users}}\"- hobby# msg内容如下:\"msg\": \"bob 's hobby is Skateboard\"\"msg\": \"bob 's hobby is VideoGame\"\"msg\": \"alice 's hobby is Music\"  #使用循环(七) with_file, with_fileglob 1, ansible主机中有几个文件,若需要获取到这些文件的内容，可以使用with_file关键字，循环的获取到这些文件的内容\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11  # 无论目标主机是谁，都可以通过with_file关键字获取到ansible主机中的文件内容---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_file:- /testdir/testdir/a.log- /opt/testfile  2,可以通过with_fileglob关键字，在指定的目录中匹配符合模式的文件名，with_file与with_fileglob相同的地方，它们都是针对ansible主机的文件进行操作，而不是目标主机\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_fileglob:- /testdir/(此处为星号,删除防止下面格式错乱)# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=/testdir/testfile) =\u003e {\"changed\": false,\"item\": \"/testdir/testfile\",\"msg\": \"/testdir/testfile\"}ok:[node2] =\u003e (item=/testdir/test.sh) =\u003e {\"changed\": false,\"item\": \"/testdir/test.sh\",\"msg\": \"/testdir/test.sh\"}# 需要注意的是，with_fileglob只会匹配指定目录中的文件，而不会匹配指定目录中的目录  #条件判断(六),with_dict,with_subelements,with_file 1,绝大多数语言中，都使用if作为条件判断的关键字，而在ansible中，条件判断的关键字是when\n 如下示例:  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:roottasks:- name:test whendebug:msg:\"System is centos\"# 如果需要获取到facts中的key的值，都是通过引用变量的方式获取的，即\"{{ key }}\"# 在when关键字中引用变量时，变量名不需要加\"{{ }}\"when:ansible_distribution == \"CentOS\"  2,使用when关键字为任务指定条件，条件成立，则执行任务，条件不成立，则不执行任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_items:- 1- 2- 3when:item \u003e 1  3,在ansible中，使用如下比较运算符.\n 如下所示:  == :比较两个对象是否相等，相等为真 != :比较两个对象是否不等，不等为真 \u003e :比较两个值的大小，如果左边的值大于右边的值，则为真 \u003c :比较两个值的大小，如果左边的值小于右边的值，则为真 \u003e= :比较两个值的大小，如果左边的值大于右边的值或左右相等，则为真 \u003c= :比较两个值的大小，如果左边的值小于右边的值或左右相等，则为真 上述总结的这些运算符其实都是jinja2的运算符，ansible使用jinja2模板引擎，在ansible中也可以直接使用jinja2的这些运算符 上述为比较运算符，再来说说逻辑运算符，可用的逻辑运算符如下: and :逻辑与，当左边与右边同时为真，则返回真 or :逻辑或，当左边与右边有任意一个为真，则返回真 not :取反，对一个操作体取反 ( ) :组合，将一组操作体包装在一起，形成一个较大的操作体  如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # 示例1:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is centos7\"when:# 使用列表,列表中的每一项都是一个条件，列表中的所有条件同时成立时，对应的任务才会执行- ansible_distribution == \"CentOS\"- ansible_distribution_major_version == \"7\"# 示例2:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is centos6 or centos7\"# 比较运算符和逻辑运算符结合使用作为条件判断when:ansible_distribution == \"CentOS\" and(ansible_distribution_major_version == \"6\" or ansible_distribution_major_version == \"7\")# 示例3:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is not centos\"# 逻辑取反when:not ansible_distribution == \"CentOS\"# 示例4:---- hosts:node2remote_user:roottasks:- name:task1shell:\"ls /testabc\"register:returnmsg- name:task2debug:msg:\"Command execution successful\"# 通过shell指令的返回值判断是否执行when:returnmsg.rc == 0- name:task3debug:msg:\"Command execution failed\"when:returnmsg.rc != 0  3,结合ignore_errors和when来限定playbook的执行\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:node2remote_user:roottasks:- name:task1shell:\"ls /testabc\"register:returnmsg# 此处增加了ignore_errors,在不存在/testabc目录的节点就不会报错,playbook不会退出,task2,task3通过rc值来确定是否要执行ignore_errors:true- name:task2debug:msg:\"Command execution successful\"when:returnmsg.rc == 0- name:task3debug:msg:\"Command execution failed\"when:returnmsg.rc != 0  #条件判断与tests 1,在ansible中也有类似bash中test的用法,不过是借助jinja2的tests，借助tests，可以进行一些判断操作，tests会将判断后的布尔值返回，如果条件成立，返回true，否则返回false，通常在条件判断时使用到tests\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:megather_facts:noremote_user:rootvars:testpath:/testdirtasks:- name:test testsdebug:msg:\"test dir exist\"# \"is exists\"中的\"exists\"就是tests的一种，它与\"test -e\"命令的作用是相同的，通过\"exists\"可以判断ansible主机中的对应路径是否存在# \"is not exists\"表示对应路径不存在时返回真# 上述内容都是在ansible主机中判断的,和远端目标主机无关when:testpath is exists  2,判断变量的一些tests\n defined: 判断变量是否已经定义，已经定义则返回真 undefined: 判断变量是否已经定义，未定义则返回真 none: 判断变量值是否为空，如果变量已经定义，但是变量值为空，则返回真 上述内容,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:meremote_user:rootgather_facts:novars:testvar:\"test\"testvar1:tasks:- debug:msg:\"Variable is defined\"when:testvar is defined- debug:msg:\"Variable is undefined\"when:testvar2 is undefined- debug:msg:\"The variable is defined, but there is no value\"when:testvar1 is none  3,判断执行结果的一些tests\n success或者succeeded: 通过任务的返回信息判断任务的返回状态,任务执行成功则返回真 failure或者failed: 通过任务的返回信息判断任务的返回状态,任务执行失败则返回真 change后者changed: 通过任务的返回信息判断任务的返回状态,任务执行状态为changed则返回真 skip或者skipped: 通过任务的返回信息判断任务的返回状态,当任务没有满足执行条件,而被跳过执行时,则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  ---- hosts:meremote_user:liawnegather_facts:novars:doshell:\"yes\"tasks:- name:executeshell:cat /testdir/testwhen:doshell == \"yes\"register:retmsgignore_errors:true- debug:msg:\"task success\"when:retmsg is success- debug:msg:\"task failed\"when:retmsg is failed- debug:msg:\"task skipped\"when:retmsg is skip- debug:msg:\"task changed\"when:retmsg is changed  4,判断路径的一些tests\n 注:如下tests的判断均针对于ansible主机中的路径,与目标主机无关 file : 判断路径是否是一个文件,如果路径是一个文件则返回真 directory :判断路径是否是一个目录,如果路径是一个目录则返回真 link :判断路径是否是一个软链接,如果路径是一个软链接则返回真 mount:判断路径是否是一个挂载点,如果路径是一个挂载点则返回真 exists:判断路径是否存在,如果路径存在则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  ---- hosts:meremote_user:liawnegather_facts:novars:testpath1:\"/testdir/test\"testpath2:\"/testdir/\"testpath3:\"/testdir/testsoftlink\"testpath4:\"/testdir/testhardlink\"testpath5:\"/boot\"tasks:- debug:msg:\"file\"when:testpath1 is file- debug:msg:\"directory\"when:testpath2 is directory- debug:msg:\"link\"when:testpath3 is link- debug:msg:\"link\"when:testpath4 is link- debug:msg:\"mount\"when:testpath5 is mount- debug:msg:\"exists\"when:testpath1 is exists  5,判断字符串的一些tests\n lower:判断包含字母的字符串中的字母是否是纯小写,字符串中的字母全部为小写则返回真 upper:判断包含字母的字符串中的字母是否是纯大写,字符串中的字母全部为大写则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:meremote_user:liawnegather_facts:novars:str1:\"abc\"str2:\"ABC\"tasks:- debug:msg:\"This string is all lowercase\"when:str1 is lower- debug:msg:\"This string is all uppercase\"when:str2 is upper  6,判断整除的一些tests\n even :判断数值是否是偶数,是偶数则返回真 odd :判断数值是否是奇数,是奇数则返回真 divisibleby(num) :判断是否可以整除指定的数值,如果除以指定的值以后余数为0，则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ---- hosts:meremote_user:liawnegather_facts:novars:num1:4num2:7num3:64tasks:- debug:msg:\"An even number\"when:num1 is even- debug:msg:\"An odd number\"when:num2 is odd- debug:msg:\"Can be divided exactly by\"when:num3 is divisibleby(8)  7,其他一些tests\n version:可以用于对比两个版本号的大小,或者与指定的版本号进行对比，使用语法为 version(‘版本号', ‘比较操作符')  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ---- hosts:meremote_user:liawnevars:ver:7.4.1708ver1:7.4.1707tasks:- debug:msg:\"This message can be displayed when the ver is greater than ver1\"when:ver is version(ver1,\"\u003e\")- debug:msg:\"system version {{ansible_distribution_version}} greater than 7.3\"when:ansible_distribution_version is version(\"7.3\",\"gt\")# ”\u003e”与”gt”都表示”大于”,当使用version时，支持多种风格的比较操作符，你可以根据自己的使用习惯进行选择，version支持的比较操作符如下# 大于:\u003e, gt# 大于等于:\u003e=, ge# 小于:\u003c, lt# 小于等于:\u003c=, le# 等于: ==, =, eq# 不等于:!=, \u003c\u003e, ne   subset:判断一个list是不是另一个list的子集,是另一个list的子集时返回真 superset : 判断一个list是不是另一个list的父集,是另一个list的父集时返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:meremote_user:liawnegather_facts:novars:a:- 2- 5b:[1,2,3,4,5]tasks:- debug:msg:\"A is a subset of B\"when:a is subset(b)- debug:msg:\"B is the parent set of A\"when:b is superset(a)# 注:2.5版本中上述两个tests从issubset和issuperset更名为subset和superset   string:判断对象是否是一个字符串,是字符串则返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:meremote_user:liawnegather_facts:novars:testvar1:1testvar2:\"1\"testvar3:atasks:- debug:msg:\"This variable is a string\"when:testvar1 is string- debug:msg:\"This variable is a string\"when:testvar2 is string- debug:msg:\"This variable is a string\"when:testvar3 is string# 上例playbook中只有testvar2和testvar3会被判断成字符串,testvar1不会   number:判断对象是否是一个数字,是数字则返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:meremote_user:liawnegather_facts:novars:testvar1:1testvar2:\"1\"testvar3:00.20tasks:- debug:msg:\"This variable is number\"when:testvar1 is number- debug:msg:\"This variable is a number\"when:testvar2 is number- debug:msg:\"This variable is a number\"when:testvar3 is number# 上例playbook中只有testvar1和testvar3会被判断成数字,testvar2不会  #条件判断与block 1,在ansible中,可以使用\"block\"关键字将多个任务整合成一个\"块\",这个\"块\"将被当做一个整体,我们可以对这个\"块\"添加判断条件,当条件成立时,则执行这个块中的所有任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:meremote_user:roottasks:- debug:msg:\"task1 not in block\"- block:- debug:msg:\"task2 in block1\"- debug:msg:\"task3 in block1\"when:2\u003e 1  2,block用在错误处理的场景下\n 之前的方式如下:  1 2 3 4 5 6 7 8 9 10 11  ---- hosts:meremote_user:roottasks:- shell:'ls /ooo'register:return_valueignore_errors:true# 通过注册变量,且忽略错误(ignore_errors)来做分支判断- debug:msg:\"I cought an error\"when:return_value is failed   使用block+rescue的方式  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:meremote_user:roottasks:- block:- shell:'ls /ooo'# rescue直接承接上面的block,当block中的内容出现错误时,执行rescue中的内容# rescue关键字与block关键字对齐,rescue的字面意思为\"救援\",表示当block中的任务执行失败时,会执行rescue中的任务进行补救# rescue中的内容由自己定义rescue:- debug:msg:'I caught an error'   block的优势,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:meremote_user:roottasks:- block:# block可以接多个任务,任何一个任务出错,都会执行rescue中的任务,所以通常使用block和rescue结合,完成\"错误捕捉,报出异常\"的功能# 不仅block中可以有多个任务,rescue中也可以定义多个任务,当block中的任何一个任务出错时,会按照顺序执行rescue中的任务.- shell:'ls /opt'- shell:'ls /testdir'- shell:'ls /c'rescue:- debug:msg:'I caught an error'   block+rescue+always的使用示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 还能再加入always关键字,加入always关键字以后,无论block中的任务执行成功还是失败,always中的任务都会被执行---- hosts:meremote_user:roottasks:- block:- debug:msg:'I execute normally'- command:/bin/false- debug:msg:'I never execute, due to the above task failing'rescue:- debug:msg:'I caught an error'- command:/bin/false- debug:msg:'I also never execute'always:- debug:msg:\"This always executes\"# 如上例所示,block中有多个任务,rescue中也有多个任务,上例中故意执行\"/bin/false\"命令,模拟任务出错的情况,当block中的'/bin/false'执行后,其后的debug任务将不会被执行,因为'/bin/false'模拟出错,出错后直接执行rescue中的任务,在执行rescue中的任务时,会先输出 ‘I caught an error',然后又在rescue中使用'/bin/false'模拟出错的情况,出错后之后的debug任务不会被执行,直接执行always中的任务,always中的任务一定会被执行,无论block中的任务是否出错  #条件判断与错误处理 1,使用fail模块来处理出错\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ---- hosts:meremote_user:roottasks:- shell:\"echo 'This is a string for testing--error'\"register:return_value- fail:msg:\"Conditions established,Interrupt running playbook\"when:\"'error' in return_value.stdout\"- debug:msg:\"I never execute,Because the playbook has stopped\"# a, 当使用\"in\"或者\"not in\"进行条件判断时,整个条件需要用引号引起,并且,需要判断的字符串也需要使用引号引起,所以,使用'in'或者'not in'进行条件判断时,如下两种语法是正确的:# when: ' \"successful\" not in return_value.stdout '# when: \" 'successful' not in return_value.stdout \"# b,fail可以单独使用,不加msg和when,效果是直接报错  2,使用failed_when\n 'failed_when'的作用就是,当对应的条件成立时,将对应任务的执行状态设置为失败  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:meremote_user:roottasks:- debug:msg:\"I execute normally\"- shell:\"echo 'This is a string for testing error'\"register:return_valuefailed_when:' \"error\" in return_value.stdout'- debug:msg:\"I never execute,Because the playbook has stopped\"# 'failed_when'关键字与shell关键字对齐,表示其对应的条件是针对shell模块的,'failed_when'对应的条件是 ‘ “error\" in return_value.stdout',表示\"error\"字符串如果存在于shell模块执行后的标准输出中,则条件成立,# 当条件成立后,shell模块的执行状态将会被设置为失败,由于shell模块的执行状态被设置为失败,所以playbook会终止运行,于是,最后的debug模块并不会被执行# 'failed_when'虽然会将任务的执行状态设置为失败,但并不代表任务真的失败了,以上例来说,shell模块的确是完全正常的执行了,只不过在执行之后,' failed_when'对应的条件成立了,' failed_when'将shell模块的执行状态设置为失败而已  3,使用changed_when\n ‘changed_when'关键字的作用是在条件成立时,将对应任务的执行状态设置为changed  1 2 3 4 5 6 7 8  ---- hosts:meremote_user:roottasks:- debug:msg:\"test message\"changed_when:2\u003e 1# debug模块在正常执行的情况下只能是\"ok\"状态,上例中,我们使用'changed_when'关键字将debug模块的执行后的状态定义为了\"changed\"   与handler结合使用  1 2 3 4 5 6 7 8 9 10  # 只有任务作出了实际的操作时（执行后状态为changed）,才会真正的执行对应的handlers# 而在某些时候,如果想要通过任务执行后的返回值将任务的最终执行状态判定为changed,则可以使用'changed_when'关键字,以便条件成立时,可以执行对应的handlers,# 'changed_when'除了能够在条件成立时将任务的执行状态设置为\"changed\",还能让对应的任务永远不能是changed状态,示例如下:---- hosts:meremote_user:roottasks:- shell:\"ls /opt\"changed_when:false# 当将'changed_when'直接设置为false时,对应任务的状态将不会被设置为'changed',如果任务原本的执行状态为'changed',最终则会被设置为'ok',所以,上例playbook执行后,shell模块的执行状态最终为'ok'  #过滤器 1,过滤器是一种能够帮助我们处理数据的工具,其实,ansible中的过滤器功能来自于jinja2模板引擎\n2,过滤器有些是jinja2内置的,有些是ansible特有的,如果这些过滤器都不能满足你的需求,jinja2也支持自定义过滤器\n3,一些常见的过滤器\n 字符串相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  ---- hosts:meremote_user:rootvars:testvar:\"abc123ABC 666\"testvar1:\" abc \"testvar2:'123456789'testvar3:\"1a2b,@#$%^\u0026\"tasks:- debug:#将字符串转换成纯大写msg:\"{{ testvar | upper }}\"- debug:#将字符串转换成纯小写msg:\"{{ testvar | lower }}\"- debug:#将字符串变成首字母大写,之后所有字母纯小写msg:\"{{ testvar | capitalize }}\"- debug:#将字符串反转msg:\"{{ testvar | reverse }}\"- debug:#返回字符串的第一个字符msg:\"{{ testvar | first }}\"- debug:#返回字符串的最后一个字符msg:\"{{ testvar | last }}\"- debug:#将字符串开头和结尾的空格去除msg:\"{{ testvar1 | trim }}\"- debug:#将字符串放在中间,并且设置字符串的长度为30,字符串两边用空格补齐30位长msg:\"{{ testvar1 | center(width=30) }}\"- debug:#返回字符串长度,length与count等效,可以写为countmsg:\"{{ testvar2 | length }}\"- debug:#将字符串转换成列表,每个字符作为一个元素msg:\"{{ testvar3 | list }}\"- debug:#将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序#shuffle的字面意思为洗牌msg:\"{{ testvar3 | shuffle }}\"- debug:#将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序#在随机打乱顺序时,将ansible_date_time.epoch的值设置为随机种子#也可以使用其他值作为随机种子,ansible_date_time.epoch是facts信息msg:\"{{ testvar3 | shuffle(seed=(ansible_date_time.epoch)) }}\"   数字相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  ---- hosts:meremote_user:rootvars:testvar4:-1tasks:- debug:#将对应的值转换成int类型#ansible中,字符串和整形不能直接计算,比如{{ 8+'8' }}会报错#所以,我们可以把一个值为数字的字符串转换成整形后再做计算msg:\"{{ 8+('8' | int) }}\"- debug:#将对应的值转换成int类型,如果无法转换,默认返回0#使用int(default=6)或者int(6)时,如果无法转换则返回指定值6msg:\"{{ 'a' | int(default=6) }}\"- debug:#将对应的值转换成浮点型,如果无法转换,默认返回'0.0'msg:\"{{ '8' | float }}\"- debug:#当对应的值无法被转换成浮点型时,则返回指定值'8.8‘msg:\"{{ 'a' | float(8.88) }}\"- debug:#获取对应数值的绝对值msg:\"{{ testvar4 | abs }}\"- debug:#四舍五入msg:\"{{ 12.5 | round }}\"- debug:#取小数点后五位msg:\"{{ 3.1415926 | round(5) }}\"- debug:#从0到100中随机返回一个随机数msg:\"{{ 100 | random }}\"- debug:#从5到10中随机返回一个随机数msg:\"{{ 10 | random(start=5) }}\"- debug:#从5到15中随机返回一个随机数,步长为3#步长为3的意思是返回的随机数只有可能是5、8、11、14中的一个msg:\"{{ 15 | random(start=5,step=3) }}\"- debug:#从0到15中随机返回一个随机数,这个随机数是5的倍数msg:\"{{ 15 | random(step=5) }}\"- debug:#从0到15中随机返回一个随机数,并将ansible_date_time.epoch的值设置为随机种子#也可以使用其他值作为随机种子,ansible_date_time.epoch是facts信息#seed参数从ansible2.3版本开始可用msg:\"{{ 15 | random(seed=(ansible_date_time.epoch)) }}\"   列表相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  ---- hosts:meremote_user:rootvars:testvar7:[22,18,5,33,27,30]testvar8:[1,[7,2,[15,9]],3,5]testvar9:[1,'b',5]testvar10:[1,'A','b',['QQ','wechat'],'CdEf']testvar11:['abc',1,3,'a',3,'1','abc']testvar12:['abc',2,'a','b','a']tasks:- debug:#返回列表长度,length与count等效,可以写为countmsg:\"{{ testvar7 | length }}\"- debug:#返回列表中的第一个值msg:\"{{ testvar7 | first }}\"- debug:#返回列表中的最后一个值msg:\"{{ testvar7 | last }}\"- debug:#返回列表中最小的值msg:\"{{ testvar7 | min }}\"- debug:#返回列表中最大的值msg:\"{{ testvar7 | max }}\"- debug:#将列表升序排序输出msg:\"{{ testvar7 | sort }}\"- debug:#将列表降序排序输出msg:\"{{ testvar7 | sort(reverse=true) }}\"- debug:#返回纯数字非嵌套列表中所有数字的和msg:\"{{ testvar7 | sum }}\"- debug:#如果列表中包含列表,那么使用flatten可以'拉平'嵌套的列表#2.5版本中可用,执行如下示例后查看效果msg:\"{{ testvar8 | flatten }}\"- debug:#如果列表中嵌套了列表,那么将第1层的嵌套列表‘拉平'#2.5版本中可用,执行如下示例后查看效果msg:\"{{ testvar8 | flatten(levels=1) }}\"- debug:#过滤器都是可以自由结合使用的,就好像linux命令中的管道符一样#如下,取出嵌套列表中的最大值msg:\"{{ testvar8 | flatten | max }}\"- debug:#将列表中的元素合并成一个字符串msg:\"{{ testvar9 | join }}\"- debug:#将列表中的元素合并成一个字符串,每个元素之间用指定的字符隔开msg:\"{{ testvar9 | join(' , ') }}\"- debug:#从列表中随机返回一个元素#对列表使用random过滤器时,不能使用start和step参数msg:\"{{ testvar9 | random }}\"- debug:#从列表中随机返回一个元素,并将ansible_date_time.epoch的值设置为随机种子#seed参数从ansible2.3版本开始可用msg:\"{{ testvar9 | random(seed=(ansible_date_time.epoch)) }}\"- debug:#随机打乱顺序列表中元素的顺序#shuffle的字面意思为洗牌msg:\"{{ testvar9 | shuffle }}\"- debug:#随机打乱顺序列表中元素的顺序#在随机打乱顺序时,将ansible_date_time.epoch的值设置为随机种子#seed参数从ansible2.3版本开始可用msg:\"{{ testvar9 | shuffle(seed=(ansible_date_time.epoch)) }}\"- debug:#将列表中的每个元素变成纯大写msg:\"{{ testvar10 | upper }}\"- debug:#将列表中的每个元素变成纯小写msg:\"{{ testvar10 | lower }}\"- debug:#去掉列表中重复的元素,重复的元素只留下一个msg:\"{{ testvar11 | unique }}\"- debug:#将两个列表合并,重复的元素只留下一个#也就是求两个列表的并集msg:\"{{ testvar11 | union(testvar12) }}\"- debug:#取出两个列表的交集,重复的元素只留下一个msg:\"{{ testvar11 | intersect(testvar12) }}\"- debug:#取出存在于testvar11列表中,但是不存在于testvar12列表中的元素#去重后重复的元素只留下一个#换句话说就是:两个列表的交集在列表1中的补集msg:\"{{ testvar11 | difference(testvar12) }}\"- debug:#取出两个列表中各自独有的元素,重复的元素只留下一个#即去除两个列表的交集,剩余的元素msg:\"{{ testvar11 | symmetric_difference(testvar12) }}\"   变量未定义时相关操作的过滤器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ---- hosts:meremote_user:rootgather_facts:novars:testvar6:''tasks:- debug:#如果变量没有定义,则临时返回一个指定的默认值#注:如果定义了变量,变量值为空字符串,则会输出空字符#default过滤器的别名是dmsg:\"{{ testvar5 | default('zsythink') }}\"- debug:#如果变量的值是一个空字符串或者变量没有定义,则临时返回一个指定的默认值msg:\"{{ testvar6 | default('zsythink',boolean=true) }}\"- debug:#如果对应的变量未定义,则报出“Mandatory variable not defined.\"错误,而不是报出默认错误msg:\"{{ testvar5 | mandatory }}\"  4,上述使用到的default参数,default过滤器,还有一个很方便的用法,default过滤器不仅能在变量未定义时返回指定的值,还能够让模块的参数变得\"可有可无\"\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # method one,循环了两次- hosts:meremote_user:rootgather_facts:novars:paths:- path:/tmp/testmode:'0444'- path:/tmp/foo- path:/tmp/bartasks:- file:dest={{item.path}} state=touch mode={{item.mode}}with_items:\"{{ paths }}\"when:item.mode is defined- file:dest={{item.path}} state=touchwith_items:\"{{ paths }}\"when:item.mode is undefined# method two- hosts:meremote_user:rootgather_facts:novars:paths:- path:/tmp/testmode:'0444'- path:/tmp/foo- path:/tmp/bartasks:- file:dest={{item.path}} state=touch mode={{item.mode | default(omit)}}with_items:\"{{ paths }}\"# 没有对文件是否有mode属性进行判断,而是直接调用了file模块的mode参数,将mode参数的值设定为了\"{{item.mode | default(omit)}}\",这是什么意思呢？它的意思是,如果item有mode属性,就把file模块的mode参数的值设置为item的mode属性的值,如果item没有mode属性,file模块就直接省略mode参数,'omit'的字面意思就是\"省略\",换成大白话说就是:[有就用,没有就不用,可以有,也可以没有]  #变量(六)include_vars 1,通过'vars_files'可以将文件中的变量引入playbook,以便在task中使用,但是vars_files加载时是静态的引入变量,即后续在vars_files中新增的变量,无法被引用\n vars_files变量文件在ansible控制节点中,与目标主机无关 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---# 为了更加方便的操作变量文件进行测试,此处将目标主机设置为me,主机me为ansible控制主机- hosts:meremote_user:rootgather_facts:novars_files:- /testdir/ansible/testfile# /testdir/ansible/testfile内容为:# testvar1: aaa# testvar2: bbbtasks:- debug:msg:\"{{testvar1}},{{testvar2}}\"- lineinfile:path:\"/testdir/ansible/testfile\"line:\"testvar3: ccc\"- debug:msg:\"{{testvar1}},{{testvar2}},{{testvar3}}\"# 上述执行出错,因为在playbook载入vars_files对应的变量文件时,文件中只有两个变量,在执行第三个任务执行,并没有重新载入对应的变量文件  2,include_vars可以在任务执行过程中,随时的引入变量文件,以便动态的获取到最新的变量文件内容\n 接上例,调整内容如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ---# 为了更加方便的操作变量文件进行测试,此处将目标主机设置为me,主机me为ansible控制主机- hosts:meremote_user:rootgather_facts:novars_files:- /testdir/ansible/testfiletasks:- debug:msg:\"{{testvar3}}\"- lineinfile:path:\"/testdir/ansible/testfile\"line:\"testvar4: ddd\"- include_vars:\"/testdir/ansible/testfile\"- debug:msg:\"{{testvar4}}\"   include_vars还有一种使用场景,有些时候,变量文件可能并没有位于ansible主机中,而是位于远程主机中,所以需要先把变量文件从远程主机中拉取到ansible主机中,当通过前面的task拉取到变量文件以后,也可以使用'include_vars'模块加载刚才拉取到的变量文件,以便后面的task可以使用变量文件中的变量.  3,include_vars的一些常用参数\n file,如下示例:  1 2 3 4 5 6 7 8 9 10 11  ---- hosts:node2remote_user:rootgather_facts:notasks:- include_vars:file:/testdir/ansible/testfile# 等效于:# - include_vars: \"/testdir/ansible/testfile\"- debug:msg:\"{{testvar4}}\"   'include_vars'可以把变量文件中的变量全部赋值给另外一个变量,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:node2remote_user:rootgather_facts:notasks:- include_vars:file:/testdir/ansible/testfilename:trans_var- debug:msg:\"{{trans_var}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[test70] =\u003e {\"msg\": {\"testvar1\": \"aaa\",\"testvar2\": \"bbb\",\"testvar3\": \"ccc\",\"testvar4\": \"ddd\"}}# 'trans_var'变量的值就是变量文件中的所有变量,可以使用name参数指定一个变量,然后将文件中的所有变量都赋值给这个指定的变量# 当使用name参数时,要获取到文件中的某一个变量的值,可以使用如下方法tasks:- include_vars:file:/testdir/ansible/testfilename:trans_var- debug:msg:\"{{trans_var.testvar4}}\"   ‘include_vars'不仅能够加载指定的变量文件,还能够一次性将指定目录下的所有变量文件中的变量加载,使用dir参数即可指定对应的目录  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  ---- hosts:node2gather_facts:noremote_user:roottasks:- include_vars:dir:/testdir/ansible/test/name:trans_var- debug:msg:\"{{trans_var}}\"# 上例中,使用dir参数指定了\"/testdir/ansible/test/\"目录,此目录中的所有变量文件都会被加载,但是在使用dir参数时,需要注意如下三点# 第一:指定目录中的所有文件的文件后缀必须是 ‘.yaml' 、'.yml' 、'.json'中的一种,默认只有这三种后缀是合法后缀,如果目录中存在非合法后缀的文件,执行playbook时则会报错.# 第二:如果此目录中的子目录中包含变量文件,子目录中的变量文件也会被递归的加载,而且子目录中的文件也必须遵守上述第一条规则.# 第三:dir参数与file参数不能同时使用.# 第一点与第二点都是默认设置,可以通过其他选项修改# 当使用dir参数时,指定目录中的所有文件必须以 ‘.yaml' 、'.yml' 、'.json' 作为文件的后缀,如果想要手动指定合法的文件后缀名,则可以使用extensions参数指定哪些后缀是合法的文件后缀,extensions参数的值需要是一个列表tasks:- include_vars:dir:/testdir/ansible/test/extensions:[yaml,yml,json,varfile]name:trans_var- debug:msg:\"{{trans_var}}\"# 上例中extensions参数的值为 “[yaml,yml,json,varfile]\",这表示指定目录中的合法文件后缀名为yaml、yml、json和varfile.# 当使用dir参数时,默认情况下会递归的加载指定目录及其子目录中的所有变量文件,如果想要控制递归的深度,则可以借助depth参数,示例如下tasks:- include_vars:dir:/testdir/ansible/test/depth:1name:trans_var- debug:msg:\"{{trans_var}}\"# 上例表示,加载\"/testdir/ansible/test/\"目录中的变量文件,但是其子目录中的变量文件将不会被加载,depth的值为1表示递归深度为1,默认值为0,表示递归到最底层的子目录.# 在使用dir参数时,我们还可以借助正则表达式,匹配那些我们想要加载的变量文件,比如,我们只想加载指定目录中以\"var_\"开头的变量文件,则可以使用如下方法tasks:- include_vars:dir:/testdir/ansible/test/files_matching:\"^var_.*\"name:trans_var- debug:msg:\"{{trans_var}}\"# 如上例所示,使用'files_matching'参数可以指定正则表达式,当指定目录中的文件名称符合正则时,则可以被加载# 还可以明确指定,哪些变量文件不能被加载,使用'ignore_files'参数可以明确指定需要忽略的变量文件名称,'ignore_files'参数的值是需要是一个列表tasks:- include_vars:dir:/testdir/ansible/test/ignore_files:[\"^var_.*\",varintest.yaml]name:trans_var- debug:msg:\"{{trans_var}}\"# 加载 /testdir/ansible/test/目录中的变量文件,但是所有以\"var_\"开头的变量文件和varintest.yaml变量文件将不会被加载, ‘files_matching'参数和'ignore_files'参数能够同时使用,当它们同时出现时,会先找出正则匹配到的文件,然后从中排除那些需要忽略的文件  3, 在2.4版本以后的ansible中,当执行了include_vars模块以后,include_vars模块会将载入的变量文件列表写入到自己的返回值中,这个返回值的关键字为'ansible_included_var_files',所以,如果我们想要知道本次任务引入了哪些变量文件,则可以使用如下方法\n 如下示例:  1 2 3 4 5 6  tasks:- include_vars:dir:/testdir/ansible/test/register:return_val- debug:msg:\"{{return_val.ansible_included_var_files}}\"  #过滤器(二) json_query 1,ansible可以通过include_vars加载日志文件,debug格式化输出json/yaml内容,方便查看\n json是yaml的子集,yaml是json的超集,yaml格式的数据和json格式的数据是可以互相转换的 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  ---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/wsCdnLogList\"name:testvar- debug:msg:\"{{ testvar }}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": {\"logs\": [{\"domainName\": \"asia1.cdn.test.com\",\"files\": [{\"dateFrom\": \"2018-09-05-0000\",\"dateTo\": \"2018-09-05-2359\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-0000-2330_asia1.cdn.test.com.all.log.gz\",\"fileSize\": 254,\"logUrl\": \"http://log.testcd.com/log/zsy/asia1.cdn.test.com/2018-09-05-0000-2330_asia1.cdn.test.com.all.log.gz?wskey=XXXXX5a\"}]},{\"domainName\": \"image1.cdn.test.com\",\"files\": [{\"dateFrom\": \"2018-09-05-2200\",\"dateTo\": \"2018-09-05-2259\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-2200-2230_image1.cdn.test.com.cn.log.gz\",\"fileSize\": 10509,\"logUrl\": \"http://log.testcd.com/log/zsy/image1.cdn.test.com/2018-09-05-2200-2230_image1.cdn.test.com.cn.log.gz?wskey=XXXXX1c\"},{\"dateFrom\": \"2018-09-05-2300\",\"dateTo\": \"2018-09-05-2359\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-2300-2330_image1.cdn.test.com.cn.log.gz\",\"fileSize\": 5637,\"logUrl\": \"http://log.testcd.com/log/zsy/image1.cdn.test.com/2018-09-05-2300-2330_image1.cdn.test.com.cn.log.gz?wskey=XXXXXfe\"}]}]}}# 变量文件的格式可以是yaml格式的,也可以是json格式的,上例就是将json格式的数据文件当做变量文件使用的# 对于ansible来说,当我们把上例中的json数据文件当做变量文件引入时,就好像引入了一个我们定义好的yaml格式的变量文件一样,对于ansible来说是没有区别的   当需要从上例中获取到logUrl时,可以使用如下方式获取:  1 2 3 4 5 6 7 8 9  tasks:- include_vars:file:\"/testdir/ansible/wsCdnLogList\"name:testvar- debug:msg:\"{{ item.1.logUrl }}\"with_subelements:- \"{{testvar.logs}}\"- files  2,上述例子中除with_subelements外,还可以使用json_query来获取\n json_query的使用方式:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 假设testvarfile中内容如下{\"users\": [{\"name\": \"tom\",\"age\": 18},{\"name\": \"jerry\",\"age\": 20}]}# 如果要获取到所有user的name---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/testvarfile\"name:testvar- debug:msg:\"{{ testvar | json_query('users[*].name') }}\"# 这段数据当做变量赋值给了testvar变量,使用json_query过滤器对这个变量进行了处理,json_query('users[*].name')表示找到users列表中所有元素的name属性,输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[test70] =\u003e {\"msg\": [\"tom\",\"jerry\"]}   更进一步  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  # 假设testvarfile中内容如下---test:users:- name:tomage:18hobby:- Skateboard- VideoGame- name:jerryage:20hobby:- Music# 要获取到所有的爱好---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query('test.users[*].hobby[*]') }}\"# 当数据结构中存在列表时,我们可以使用”列表名[*]”获取到列表下面的所有项,输出结果如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": [[\"Skateboard\",\"VideoGame\"],[\"Music\"]]}# 想要根据条件获取到某个用户的某些信息# method onetasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:# 此处使用了反引号,因为已经使用了'和\",使用`用作区分msg:\"{{ testvar | json_query('test.users[?name==`tom`].hobby[*]') }}\"# method twotasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query(querystring) }}\"vars:querystring:\"test.users[?name=='tom'].age\"# 在debug任务中使用vars关键字定义了一个只有当前debug任务能够使用的变量,从而避免了多层引号嵌套时所产生的冲突问题.# 同时获取到用户的姓名、年龄两个属性的值,当需要同时获取多个属性值时,需要通过键值对的方式调用属性tasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query('test.users[*].{uname:name,uage:age}') }}\"# 输出内容如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": [{\"uage\": 18,\"uname\": \"tom\"},{\"uage\": 20,\"uname\": \"jerry\"}]}   回到第一个示例,获取logUrl的方式如下:  1 2 3 4 5 6 7 8 9 10  ---- hosts:meremote_user:liawnegather_facts:novars_files:- /testdir/ansible/wsCdnLogListtasks:- debug:msg:\"{{item}}\"with_items:\"{{ logs | json_query('[*].files[*].logUrl') }}\"  #过滤器(三) 其他过滤器 1,其他一些常用的过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172  ---- hosts:meremote_user:liawnegather_facts:notasks:#######################################################################在调用shell模块时,如果引用某些变量时需要添加引号,则可以使用quote过滤器代替引号#示例如下,先看示例,后面会有注解- shell:\"echo {{teststr | quote}} \u003e /testdir/testfile\"vars:teststr:\"a\\nb\\nc\"#上例中shell模块的写法与如下写法完全等效#shell: \"echo '{{teststr}}' \u003e /testdir/testfile\"#没错,如你所见,quote过滤器能够代替引号#上例中,如果不对{{teststr}}添加引号,则会报错,因为teststr变量中包含\"\\n\"转义符#######################################################################ternary过滤器可以实现三元运算的效果 示例如下#如下示例表示如果name变量的值是John,那么对应的值则为Mr,否则则为Ms#简便的实现类似if else对变量赋值的效果- debug:msg:\"{{ (name == 'John') | ternary('Mr','Ms') }}\"vars:name:\"John\"#######################################################################basename过滤器可以获取到一个路径字符串中的文件名- debug:msg:\"{{teststr | basename}}\"vars:teststr:\"/testdir/ansible/testfile\"#######################################################################获取到一个windows路径字符串中的文件名,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_basename}}\"vars:teststr:'D:\\study\\zsythink'#######################################################################dirname过滤器可以获取到一个路径字符串中的路径名- debug:msg:\"{{teststr | dirname}}\"vars:teststr:\"/testdir/ansible/testfile\"#######################################################################获取到一个windows路径字符串中的文件名,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_dirname}}\"vars:teststr:'D:\\study\\zsythink'#######################################################################将一个windows路径字符串中的盘符和路径分开,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_splitdrive}}\"vars:teststr:'D:\\study\\zsythink'#可以配合之前总结的过滤器一起使用,比如只获取到盘符,示例如下#msg: \"{{teststr | win_splitdrive | first}}\"#可以配合之前总结的过滤器一起使用,比如只获取到路径,示例如下#msg: \"{{teststr | win_splitdrive | last}}\"#######################################################################realpath过滤器可以获取软链接文件所指向的真正文件- debug:msg:\"{{ path | realpath }}\"vars:path:\"/testdir/ansible/testsoft\"#######################################################################relpath过滤器可以获取到path对于“指定路径”来说的“相对路径”- debug:msg:\"{{ path | relpath('/testdir/testdir') }}\"vars:path:\"/testdir/ansible\"#######################################################################splitext过滤器可以将带有文件名后缀的路径从“.后缀”部分分开- debug:msg:\"{{ path | splitext }}\"vars:path:\"/etc/nginx/conf.d/test.conf\"#可以配置之前总结的过滤器,获取到文件后缀#msg: \"{{ path | splitext | last}}\"#可以配置之前总结的过滤器,获取到文件前缀名#msg: \"{{ path | splitext | first | basename}}\"#######################################################################to_uuid过滤器能够为对应的字符串生成uuid- debug:msg:\"{{ teststr | to_uuid }}\"vars:teststr:\"This is a test statement\"#######################################################################bool过滤器可以根据字符串的内容返回bool值true或者false#字符串的内容为yes、1、True、true则返回布尔值true,字符串内容为其他内容则返回false- debug:msg:\"{{ teststr | bool }}\"vars:teststr:\"1\"#当和用户交互时,有可能需要用户从两个选项中选择一个,比如是否继续,#这时,将用户输入的字符串通过bool过滤器处理后得出布尔值,从而进行判断,比如如下用法#- debug:# msg: \"output when bool is true\"# when: some_string_user_input | bool#######################################################################map过滤器可以从列表中获取到每个元素所共有的某个属性的值,并将这些值组成一个列表#当列表中嵌套了列表,不能越级获取属性的值,也就是说只能获取直接子元素的共有属性值.- vars:users:- name:tomage:18hobby:- Skateboard- VideoGame- name:jerryage:20hobby:- Musicdebug:msg:\"{{ users | map(attribute='name') | list }}\"#也可以组成一个字符串,用指定的字符隔开,比如分号#msg: \"{{ users | map(attribute='name') | join(';') }}\"#######################################################################与python中的用法相同,两个日期类型相减能够算出两个日期间的时间差#下例中,我们使用to_datatime过滤器将字符串类型转换成了日期了类型,并且算出了时间差- debug:msg:'{{ (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 19:00:00\" | to_datetime) }}'#默认情况下,to_datatime转换的字符串的格式必须是“%Y-%m-%d %H:%M:%S”#如果对应的字符串不是这种格式,则需要在to_datetime中指定与字符串相同的时间格式,才能正确的转换为时间类型- debug:msg:'{{ (\"20160814\"| to_datetime(\"%Y%m%d\")) - (\"2012-12-25 19:00:00\" | to_datetime) }}'#如下方法可以获取到两个日期之间一共相差多少秒- debug:msg:'{{ ( (\"20160814\"| to_datetime(\"%Y%m%d\")) - (\"20121225\" | to_datetime(\"%Y%m%d\")) ).total_seconds() }}'#如下方法可以获取到两个日期“时间位”相差多少秒,注意:日期位不会纳入对比计算范围#也就是说,下例中的2016-08-14和2012-12-25不会纳入计算范围#只是计算20:00:12与08:30:00相差多少秒#如果想要算出连带日期的秒数差则使用total_seconds()- debug:msg:'{{ ( (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 08:30:00\" | to_datetime) ).seconds }}'#如下方法可以获取到两个日期“日期位”相差多少天,注意:时间位不会纳入对比计算范围- debug:msg:'{{ ( (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 08:30:00\" | to_datetime) ).days }}'#######################################################################使用base64编码方式对字符串进行编码- debug:msg:\"{{ 'hello' | b64encode }}\"#使用base64编码方式对字符串进行解码- debug:msg:\"{{ 'aGVsbG8=' | b64decode }}\"########################################################################使用sha1算法对字符串进行哈希- debug:msg:\"{{ '123456' | hash('sha1') }}\"#使用md5算法对字符串进行哈希- debug:msg:\"{{ '123456' | hash('md5') }}\"#获取到字符串的校验和,与md5哈希值一致- debug:msg:\"{{ '123456' | checksum }}\"#使用blowfish算法对字符串进行哈希,注:部分系统支持- debug:msg:\"{{ '123456' | hash('blowfish') }}\"#使用sha256算法对字符串进行哈希,哈希过程中会生成随机\"盐\",以便无法直接对比出原值- debug:msg:\"{{ '123456' | password_hash('sha256') }}\"#使用sha256算法对字符串进行哈希,并使用指定的字符串作为\"盐\"- debug:msg:\"{{ '123456' | password_hash('sha256','mysalt') }}\"#使用sha512算法对字符串进行哈希,哈希过程中会生成随机\"盐\",以便无法直接对比出原值- debug:msg:\"{{ '123123' | password_hash('sha512') }}\"#使用sha512算法对字符串进行哈希,并使用指定的字符串作为\"盐\"- debug:msg:\"{{ '123123' | password_hash('sha512','ebzL.U5cjaHe55KK') }}\"#如下方法可以幂等的为每个主机的密码生成对应哈希串#有了之前总结的过滤器用法作为基础,你一定已经看懂了- debug:msg:\"{{ '123123' | password_hash('sha512', 65534|random(seed=inventory_hostname)|string) }}\"  #lookup插件 1,ansible中有很多种类的插件,比如之前总结的”tests”,也是插件的一种,ansible官网总结了各个插件的作用,并且将这些插件按照功能进行了分类\n https://docs.ansible.com/ansible/latest/plugins/plugins.html  2,前文总结的”循环”在本质上也是一种插件,这种插件叫做”lookup插件”,先回忆一些”循环”的使用方法,以便能够更好的描述”循环”和”lookup插件”之间的关系\n 列表示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"index is {{item.0}} , value is {{item.1}}\"with_indexed_items:['a','b','c']# 等价于---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"index is {{item.0}} , value is {{item.1}}\"loop:\"{{ lookup('indexed_items',['a','b','c']) }}\"# 第一个示例使用”with_indexed_items关键字”处理列表# 第二个示例使用”loop关键字”配合”lookup插件”处理列表# 上例中,”lookup(‘indexed_items',[‘a','b','c'])” 这段代码就是在使用lookup插件,含义是,使用名为'indexed_items'的lookup插件处理[‘a','b','c']这个列表,'indexed_items'就是一个lookup插件   字典示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"with_dict:\"{{ users }}\"# 等价于---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ lookup('dict',users) }}\"# 第一个示例使用”with_dict关键字”处理users字典变量# 第二个示例使用”loop关键字”配合”lookup插件”处理users字典变量# 上例中,”lookup(‘dict',users)”表示使用名为'dict'的lookup插件处理users字典变量,'dict'也是一个lookup插件  3,lookup插件的用法\n lookup(‘插件名',被处理数据或参数) 以”with_”开头的循环实际上就是”with_”和”lookup()”的组合,lookup插件可以作为循环的数据源  4,查看插件的帮助命令\n 查看有哪些lookup插件可以使用: ansible-doc -t lookup -l(”-t”选项用于指定插件类型,”-l”选项表示列出列表) 单独查看某个插件的使用方法,比如dict插件的使用方法: ansible-doc -t lookup dict file插件可以获取到指定文件的文件内容（注:文件位于ansible主机中）,示例如下  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ lookup('file','/testdir/testfile') }}\"# 如果想要获取多个文件中的内容,则可以传入多个文件路径,示例如下msg:\"{{ lookup('file','/testdir/testfile','/testdir/testfile1') }}\"# file插件获得多个文件中的内容时,会将多个文件中的内容放置在一个字符串中,并用”逗号”隔开每个文件中的内容# 想要获得一个字符串列表,将每个文件的内容当做列表中的一个独立的字符串msg:\"{{ lookup('file','/testdir/testfile','/testdir/testfile1',wantlist=true) }}\"  5,其他lookup插件用法示例\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  ---- hosts:node2remote_user:rootgather_facts:notasks:#file插件可以获取ansible主机中指定文件的内容- debug:msg:\"{{ lookup('file','/testdir/testfile') }}\"#env插件可以获取ansible主机中指定变量的值- debug:msg:\"{{ lookup('env','PATH') }}\"#first_found插件可以获取列表中第一个找到的文件#按照列表顺序在ansible主机中查找- debug:msg:\"{{ lookup('first_found',looklist) }}\"vars:looklist:- /testdir- /tmp/staging#当使用with_first_found时,可以在列表的最后添加- skip: true#表示如果列表中的所有文件都没有找到,则跳过当前任务,不会报错#当不确定有文件能够被匹配到时,推荐这种方式- debug:msg:\"{{item}}\"with_first_found:- /testdir1- /tmp/staging- skip:true#ini插件可以在ansible主机中的ini文件中查找对应key的值#如下示例表示从test.ini文件中的testA段落中查找testa1对应的值#测试文件/testdir/test.ini的内容如下(不包含注释符#号)#[testA]#testa1=Andy#testa2=Armand##[testB]#testb1=Ben- debug:msg:\"{{ lookup('ini','testa1 section=testA file=/testdir/test.ini') }}\"#当未找到对应key时,默认返回空字符串,如果想要指定返回值,可以使用default选项,如下#msg: \"{{ lookup('ini','test666 section=testA file=/testdir/test.ini default=notfound') }}\"#可以使用正则表达式匹配对应的键名,需要设置re=true,表示开启正则支持,如下#msg: \"{{ lookup('ini','testa[12] section=testA file=/testdir/test.ini re=true') }}\"#ini插件除了可以从ini类型的文件中查找对应key,也可以从properties类型的文件中查找key#默认在操作的文件类型为ini,可以使用type指定properties类型,如下例所示#如下示例中,application.properties文件内容如下(不包含注释符#号)#http.port=8080#redis.no=0#imageCode = 1,2,3- debug:msg:\"{{ lookup('ini','http.port type=properties file=/testdir/application.properties') }}\"#dig插件可以获取指定域名的IP地址#此插件依赖dnspython库,可使用pip安装pip install dnspython#如果域名使用了CDN,可能返回多个地址- debug:msg:\"{{ lookup('dig','www.baidu.com',wantlist=true) }}\"#password插件可以生成随机的密码并保存在指定文件中- debug:msg:\"{{ lookup('password','/tmp/testpasswdfile') }}\"#以上插件还有一些参数我们没有涉及到,而且也还有很多插件没有总结,等到用到对应的插件时,再行介绍吧#你也可以访问官网的lookup插件列表页面,查看各个插件的用法#https://docs.ansible.com/ansible/latest/plugins/lookup.html  #循环(八) 1,在新版本的ansible中,官方推荐的循环的使用方式不同,在2.6推荐的方式为loop加lookup和loop加filter\n loop的简单使用方式:  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"loop:- teststr1- teststr2   loop加lookup插件替换with_X  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ lookup('dict',users) }}\"  2,在2.6版本开始,官方开始推荐使用\"loop加filter\"的方式来替代\"loop加lookup\"的方式\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ users | dict2items }}\"# users是一个字典格式的变量,它的结构是这样的# users:# alice: female# bob: male# 当users字典被dict2items转换处理以后,会变成如下模样# users:# - key: alice# value: female# - key: bob# value: male  3,无论是\"with_X\"、\"loop加lookup\"还是\"loop加filter\",都是使用不同的方式,实现相同的功能而已\n4,替换方式\n with_list  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #loop可以替代with_list,当处理嵌套的列表时,列表不会被拉平---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist}}\"   with_flattened  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #flatten过滤器可以替代with_flattened,当处理多层嵌套的列表时,列表中所有的嵌套层级都会被拉平#示例如下,flatten过滤器的用法在前文中已经总结过,此处不再赘述---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist | flatten}}\"   with_items  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #flatten过滤器（加参数）可以替代with_items,当处理多层嵌套的列表时,只有列表中的第一层会被拉平---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist | flatten(levels=1)}}\"   with_indexed_items  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #flatten过滤器（加参数）,再配合loop_control关键字,可以替代with_indexed_items#当处理多层嵌套的列表时,只有列表中的第一层会被拉平,flatten过滤器的bug暂且忽略#示例如下,之后会对示例进行解释---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{index}}--{{item}}\"loop:\"{{testlist | flatten(levels=1)}}\"loop_control:index_var:index# \"loop_control\"关键字可以用于控制循环的行为,比如在循环时获取到元素的索引.# \"index_var\"是\"loop_control\"的一个设置选项,\"index_var\"的作用是让我们指定一个变量,\"loop_control\"会将列表元素的索引值存放到这个指定的变量中,比如如下配置loop_control:index_var:my_idx# 上述设置表示,在遍历列表时,当前被遍历元素的索引会被放置到\"my_idx\"变量中,也就是说,当进行循环操作时,只要获取到\"my_idx\"变量的值,就能获取到当前元素的索引值# loop_control还有其他的选项可以使用,当前暂时不列举   with_together  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #zip_longest过滤器配合list过滤器,可以替代with_together---- hosts:node2remote_user:rootgather_facts:novars:testlist1:[a, b ]testlist2:[1,2,3]testlist3:[A, B, C, D ]tasks:- debug:msg:\"{{ item.0 }} - {{ item.1 }} - {{item.2}}\"with_together:- \"{{testlist1}}\"- \"{{testlist2}}\"- \"{{testlist3}}\"- debug:msg:\"{{ item.0 }} - {{ item.1 }} - {{item.2}}\"loop:\"{{ testlist1 | zip_longest(testlist2,testlist3) | list }}\"   with_nested/with_cartesian  1 2 3 4 5 6 7 8 9 10 11 12 13  #product过滤器配合list过滤器,可以替代with_nested和with_cartesian#如果你忘了with_nested和with_cartesian的用法,可以回顾前文---- hosts:node2remote_user:rootgather_facts:novars:testlist1:[a, b, c ]testlist2:[1,2,3,4]tasks:- debug:msg:\"{{ item.0 }}--{{ item.1 }}\"loop:\"{{ testlist1 | product(testlist2) | list }}\"   with_sequence  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #range过滤器配合list过滤器可以代替with_sequence#你可以先回顾一下with_sequence的用法,然后再测试如下示例---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"loop:\"{{ range(0, 6, 2) | list }}\"# 需要格式化功能时:- debug:msg:\"{{ 'number is %0.2f' | format(item) }}\"loop:\"{{ range(2, 7, 2) | list }}\"   with_random_choice  1 2 3 4 5 6 7 8 9 10  #使用random函数可以替代with_random_choice,由于random函数是随机取出列表中的一个值,并不涉及循环操作,所以并不用使用loop关键字.---- hosts:node2remote_user:rootgather_facts:novars:testlist:[a, b, c ]tasks:- debug:msg:\"{{ testlist | random }}\"   with_dict  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #除了上文总结的dict2items过滤器,dictsort过滤器也可以替代with_dict---- hosts:node2remote_user:rootgather_facts:novars:users:d:daisyc:carola:aliceb:bobe:ellatasks:- debug:msg:\"{{item.key}} -- {{item.value}}\"loop:\"{{ users | dict2items }}\"- debug:msg:\"{{item.0}} -- {{item.1}}\"loop:\"{{ users | dictsort }}\"   with_subelements  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #subelements过滤器可以替代with_subelements---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{item.0.name}}'s hobby is {{item.1}}\"with_subelements:- \"{{users}}\"- hobby- debug:msg:\"{{item.0.name}}'s hobby is {{item.1}}\"loop:\"{{users | subelements('hobby')}}\"  5,loop_control的其他参数使用\n pause选项  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"loop:- 1- 2- 3loop_control:pause:10# 上例表示每次循环之间间隔10秒   label  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item.key}}\"loop:\"{{users | dict2items}}\"# 此处输出内容太多,对于需要查找的内容较难找到# label选项的作用,它可以在循环输出信息时,简化输出item的信息---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item.key}}\"loop:\"{{users | dict2items}}\"loop_control:label:\"{{item.key}}\"  #include 1,ansible中有类似编程语言中类似函数调用的功能,就是include,通过include,可以在一个playbook中包含另一个文件\n include模块可以指定一个文件,这个文件中的内容是一个任务列表（一个或多个任务）,使用include模块引用对应的文件时,文件中的任务会在被引用处执行,就像写在被引用处一样  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # cat lamp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:httpdstate:present# cat lnmp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:nginxstate:present# cat install_MysqlAndPhp.yml- yum:name:mysqlstate:present- yum:name:php-fpmstate:present  2,在handlers关键字中,也可以使用include,handlers也是一种任务,只是这种任务有相应的触发条件而已\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # cat test_include.yml---- hosts:node2remote_user:rootgather_facts:notasks:- file:path:/opt/tttstate:touchnotify:test include handlershandlers:- name:test include handlersinclude:include_handler.yml# cat include_handler.yml- debug:msg:\"task1 of handlers\"- debug:msg:\"task2 of handlers\"- debug:msg:\"task3 of handlers\"  3,\"include\"不仅能够引用任务列表,还能够引用playbook,比如,在一个playbook中引用另一个playbook\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13  # cat lamp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:httpdstate:present- include:lnmp.yml# 在lamp.yml的结尾引入了lnmp.yml,当我们在执行lamp.yml时,会先执行lamp相关的任务,然后再执行lnmp.yml中的任务.  4,include还可以接受一些参数\n 如下所示  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in.ymltest_var1=hellotest_var2=test# cat in.yml- debug:msg:\"{{ test_var1 }}\"- debug:msg:\"{{ test_var2 }}\"   还能够使用vars关键字,以key: value变量的方式传入参数变量  1 2 3 4 5  tasks:- include:in.ymlvars:test_var1:hellotest_var2:test   通过vars关键字也能够传入结构稍微复杂的变量数据,以便在包含的文件中使用,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in.ymlvars:users:bob:gender:malelucy:gender:female# cat in.yml- debug:msg:\"{{ item.key}} is {{ item.value.gender }}\"loop:\"{{ users | dict2items }}\"  5,可以针对某个include去打标签\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in1.ymltags:t1- include:in2.ymltags:t2# cat in1.yml- debug:msg:\"task1 in in1.yml\"- debug:msg:\"task2 in in1.yml\"# cat in2.yml- debug:msg:\"task1 in in2.yml\"- debug:msg:\"task2 in in2.yml\"   可以对include添加条件判断,还可以对include进行循环操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in3.ymlwhen:2\u003e 1- include:in3.ymlloop:- 1- 2- 3# cat in3.yml- debug:msg:\"task1 in in3.yml\"- debug:msg:\"task2 in in3.yml\"# 循环的调用多个任务,可以使用上例中的方法,将需要循环调用的多个任务写入到一个yml文件中,然后使用include调用这个yml文件,再配合loop进行循环即可  6,loop_control中loop_var的使用\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat A.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:B.ymlloop:- 1- 2# cat B.yml- debug:msg:\"{{item}}--task in B.yml\"loop:- a- b- c# B.yml中循环调用了debug模块,而在A.yml中,又循环的调用了B.yml,当出现这种\"双层循环\"的情况时,B文件中的item信息只打印B中的列表内容   若要获取上例中外层item的值,可以使用loop_control中loop_var选项  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat A.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:B.ymlloop:- 1- 2loop_control:loop_var:outer_item# cat B.yml- debug:msg:\"{{outer_item}}--{{item}}--task in B.yml\"loop:- a- b- c# 将loop_var选项的值设置为\"outer_item\",这表示,我们将外层循环的item值存放在了\"outer_item\"变量中,在B文件中的debug任务中,同时输出了\"outer_item\"变量和\"item\"变量的值  #include(二) 1,\"include\"的某些原始用法在之后的版本中可能会被弃用,在之后的版本中,会使用一些新的关键字代替这些原始用法\n2,include_task模块\n include模块可以用来包含一个任务列表,include_tasks模块的作用也是用来包含一个任务列表,在之后的版本中,如果我们想要包含一个任务列表,那么就可以使用\"include_tasks\"关键字代替\"include\"关键字,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat intest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task1\"- include_tasks:in.yml- debug:msg:\"test task2\"# cat in.yml- debug:msg:\"task1 in in.yml\"- debug:msg:\"task2 in in.yml\"# 当我们使用\"include_tasks\"时,\"include_tasks\"本身会被当做一个\"task\",这个\"task\"会把被include的文件的路径输出在控制台中# \"include\"是透明的,\"include_tasks\"是可见的,\"include_tasks\"更像是一个任务,这个任务包含了其他的一些任务  3,在2.7版本之后,include_tasks模块加入了file和apply参数\n file参数  1 2 3 4  - include_tasks:file:in.yml- include_tasks:in.yml# 两种方式其实完全相同,只不过一个使用了\"file\"参数的方式,另一个使用了\"free_form\"的方式,虽然语法上不同,但是本质上没有区别   apply参数  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # cat intest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task1\"- include_tasks:file:in.ymltags:t1- debug:msg:\"test task2\"# \"include_tasks\"这个任务本身被调用了,而\"include_tasks\"对应文件中的任务却没有被调用# \"include_tasks\"与\"include\"并不相同,标签只会对\"include_tasks\"任务本身生效,而不会对其中包含的任务生效# 如果想要tags对\"include_tasks\"中包含的所有任务都生效,需要使用到\"include_tasks\"模块的apply参数---- hosts:node2remote_user:rootgather_facts:notasks:- include_tasks:file:in.ymlapply:tags:- t1# 但如上写法并未按预期执行,连include_tasks都没有执行,需要完成预期内容,需要如下配置---- hosts:node2remote_user:rootgather_facts:notasks:- include_tasks:file:in.ymlapply:tags:- t1tags:always# 在使用\"include_tasks\"时,不仅使用apply参数指定了tags,同时还使用tags关键字,对\"include_tasks\"本身添加了always标签  4,import_tasks\n 如果想要包含引用一个任务列表,也可以使用\"import_tasks\"关键字  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat intest1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task\"- import_tasks:in.yml# cat in.yml- debug:msg:\"task1 in in.yml\"- debug:msg:\"task2 in in.yml\"# \"import_tasks\"模块并不会像\"include_tasks\"模块那样,在控制台中输出相关的任务信息,\"import_tasks\"是相对透明的   \"import_tasks\"是静态的,\"include_tasks\"是动态的  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # \"静态\"的意思就是被include的文件在playbook被加载时就展开了（是预处理的）.# \"动态\"的意思就是被include的文件在playbook运行时才会被展开（是实时处理的）.# 由于\"include_tasks\"是动态的,所以,被include的文件的文件名可以使用任何变量替换.# 由于\"import_tasks\"是静态的,所以,被include的文件的文件名不能使用动态的变量替换.# cat intest3.yml---- hosts:node2remote_user:rootgather_facts:novars:file_name:in.ymltasks:- import_tasks:\"{{file_name}}\"- include_tasks:\"{{file_name}}\"# 上述内容可以正常执行# cat intest3.yml---- hosts:node2remote_user:rootgather_facts:notasks:- set_fact:file_name:in.yml- import_tasks:\"{{file_name}}\"- include_tasks:\"{{file_name}}\"# 上述内容执行报错# 当使用静态的import时,请确保文件名中使用到的变量被定义在vars中、vars_files中、或者extra-vars中,静态的import不支持其他方式传入的变量   如果想要对包含的任务列表进行循环操作,则只能使用\"include_tasks\"关键字,不能使用\"import_tasks\"关键字,\"import_tasks\"并不支持循环操作,使用\"loop\"关键字或\"with_items\"关键字对include文件进行循环操作时,只能配合\"include_tasks\"才能正常运行 使用when做条件判断执行include_tasks和import_tasks时,区别很大  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  # 当对\"include_tasks\"使用when进行条件判断时,when对应的条件只会应用于\"include_tasks\"任务本身,当执行被包含的任务时,不会对这些被包含的任务重新进行条件判断.# 当对\"import_tasks\"使用when进行条件判断时,when对应的条件会应用于被include的文件中的每一个任务,当执行被包含的任务时,会对每一个被包含的任务进行同样的条件判断.# cat intest4.yml---- hosts:node2remote_user:rootgather_facts:notasks:- name:'----------set testvar to 0'set_fact:testnum:0- debug:msg:'-----include_tasks-----enter the in1.yml-----'- include_tasks:in1.ymlwhen:testnum == 0- name:'----------set testvar to 0'set_fact:testnum:0- debug:msg:'-----import_tasks-----enter the in1.yml-----'- import_tasks:in1.ymlwhen:testnum == 0# cat in1.yml- set_fact:testnum:1- debug:msg:\"task1 in in1.yml\"# 输出内容如下:PLAY [node2] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxTASK [----------set testvar to 0] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"-----include_tasks-----enter the in1.yml-----\"}TASK [include_tasks] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxincluded:/testdir/ansible/in1.yml for node2TASK [set_fact] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"task1 in in1.yml\"}TASK [----------set testvar to 0] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"-----import_tasks-----enter the in1.yml-----\"}TASK [set_fact] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxskipping:[node2]PLAY RECAP xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxnode2 :ok=8 changed=0 unreachable=0 failed=0   tags的使用,与\"include_tasks\"不同,当为\"import_tasks\"添加标签时,tags是针对被包含文件中的所有任务生效的,与\"include\"关键字的效果相同. \"include_tasks\"与\"import_tasks\"都可以在handlers中使用,并没有什么不同 5,import_playbook  使用\"include\"关键字除了能够引用任务列表,还能够引用整个playbook,在之后的版本中,如果想要引入整个playbook,则需要使用\"import_playbook\"模块代替\"include\"模块,因为在2.8版本以后,使用\"include\"关键字引用整个playbook的特性将会被弃用 示例如下:    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat intest6.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task in intest6.yml\"- import_playbook:intest7.yml# cat intest7.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task in intest7.yml\"  #jinja2模板(一) 1,对远端机器进行操作时,很多场景下都需要根据主机信息进行配置,这个时候可以使用template模块来完成相应的目的\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat temptest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- yum:name:redisstate:present- template:src:/testdir/ansible/redis.confdest:/etc/redis.conf# cat /testdir/ansible/redis.conf,下列的ansible_host是host alias,需要注意......bind {{ansible_host}}......   template还有其他的选项  # owner,group,mode(mode=0644,mode=u+x) # force参数: 当远程主机的目标路径中已经存在同名文件,并且与最终生成的文件内容不同时,是否强制覆盖,可选值有yes和no,默认值为yes,表示覆盖,如果设置为no,则不会执行覆盖拷贝操作,远程主机中的文件保持不变 # backup参数: 当远程主机的目标路径中已经存在同名文件,并且与最终生成的文件内容不同时,是否对远程主机的文件进行备份,可选值有yes和no,当设置为yes时,会先备份远程主机中的文件,然后再将最终生成的文件拷贝到远程主机 2,上述例子中使用的template模块渲染,使用的都是jinja2模板引擎\n - \\{\\{ \\}\\} :用来装载表达式,比如变量、运算表达式、比较表达式等. - \\{\\% \\%\\} :用来装载控制语句,比如 if 控制结构,for循环控制结构. - \\{\\# \\#\\} :用来装载注释,模板文件被渲染后,注释不会包含在最终生成的文件中. 3,双花括号的使用\n 变量的引用,如下示例:  1 2 3 4 5 6 7 8 9 10  # ansible node2 -m template -e \"testvar1=teststr\" -a \"src=test.j2 dest=/opt/test\" # cat test.j2 test jinja2 variable test {{ testvar1 }} test # 输出内容如下: # cat test test jinja2 variable test teststr tesT # \"{{ }}\"中包含的就是一个变量,当模板被渲染后,变量的值被替换到了最终的配置文件中    包含表达式,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119  ## 比较表达式: # cat test.j2 jinja2 test {{ 1 == 1 }} {{ 2 != 2 }} {{ 2 \u003e 1 }} {{ 2 \u003e= 1 }} 生成文件内容如下: # cat test jinja2 test True False True True ## 逻辑运算: # cat test.j2 jinja2 test {{ (2 \u003e 1) or (1 \u003e 2) }} {{ (2 \u003e 1) and (1 \u003e 2) }} {{ not true }} {{ not True }} # cat test jinja2 test True False False False ## 算数运算: # cat test.j2 jinja2 test {{ 3 + 2 }} {{ 3 - 4 }} {{ 3 * 5 }} {{ 2 ** 3 }} {{ 7 / 5 }} {{ 7 // 5 }} {{ 17 % 5 }} # cat test jinja2 test 5 -1 15 8 1.4 1 2 ## 成员运算: # cat test.j2 jinja2 test {{ 1 in [1,2,3,4] }} {{ 1 not in [1,2,3,4] }} # cat test jinja2 test True False ## 一些基础的数据类型,都可以包含在\"{{ }}\"中,jinja2本身就是基于python的模板引擎,所以,python的基础数据类型都可以包含在\"{{ }}\"中 # cat test.j2 jinja2 test ## \\#str {{ 'testString' }} {{ \"testString\" }} ## \\#num {{ 15 }} {{ 18.8 }} ## \\#list {{ ['Aa','Bb','Cc','Dd'] }} {{ ['Aa','Bb','Cc','Dd'].1 }} {{ ['Aa','Bb','Cc','Dd'][1] }} ## \\#tuple {{ ('Aa','Bb','Cc','Dd') }} {{ ('Aa','Bb','Cc','Dd').0 }} {{ ('Aa','Bb','Cc','Dd')[0] }} ## \\#dic {{ {'name':'bob','age':18} }} {{ {'name':'bob','age':18}.name }} {{ {'name':'bob','age':18}['name'] }} ## \\#Boolean {{ True }} {{ true }} {{ False }} {{ false }} 生成文件内容如下: # cat test jinja2 test ## \\#str testString testString ## \\#num 15 18.8 ## \\#list ['Aa', 'Bb', 'Cc', 'Dd'] Bb Bb ## \\#tuple ('Aa', 'Bb', 'Cc', 'Dd') Aa Aa ## \\#dic {'age': 18, 'name': 'bob'} bob bob ## \\#Boolean True True False False    过滤器也可以在双花括号中使用  1 2 3 4 5 6 7 8 9  # cat test.j2 jinja2 test {{ 'abc' | upper }} 生成文件内容 # cat test jinja2 test ABC    jinja2的tests自然也能够在\"双花括号\"中使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # cat test.j2 jinja2 test {{ testvar1 is defined }} {{ testvar1 is undefined }} {{ '/opt' is exists }} {{ '/opt' is file }} {{ '/opt' is directory }} # ansible node2 -m template -e \"testvar1=1 testvar2=2\" -a \"src=test.j2 dest=/opt/test\" 生成文件内容 # cat test jinja2 test True False True False True    lookup插件在双花括号中的使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # cat /testdir/ansible/test.j2 jinja2 test {{ lookup('file','/testdir/testfile') }} {{ lookup('env','PATH') }} test jinja2 # ansible主机中的testfile内容如下 # cat /testdir/testfile testfile in ansible These are for testing purposes only # 生成文件内容如下 # cat test jinja2 test testfile in ansible These are for testing purposes only /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin test jinja2   3,{# #}的使用\n 同编程语言中注释方式的使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # cat test.j2 jinja2 test {#这是一行注释信息#} jinja2 test {# 这是多行注释信息, 模板被渲染以后, 最终的文件中不会包含这些信息 #} jinja2 test 生成文件内容如下: # cat test jinja2 test jinja2 test jinja2 test   #jinja2模板(二) 1,结合if的使用\n 通用结构  1 2 3 4 5 6 7  {% if 条件一 %}...{% elif 条件N %}...{% else %}...{% endif %}   三元运算  1 2 3 4 5 6 7  # cat test.j2 jinja2 test {{ 'a' if 2\u003e1 else 'b' }} # 输出内容如下: # cat /opt/test jinja2 test a   2,使用set\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat test.j2 jinja2 test {% set teststr='abc' %} {{ teststr }} # 在jinja2中,使用set关键字定义变量,执行如下ad-hoc命令渲染模板 ansible node2 -m template -a \"src=test.j2 dest=/opt/test\" # 输出内容如下: # cat /opt/test jinja2 test abc   3,结合for的使用\n 通用结构  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  {% for 迭代变量 in 可迭代对象 %} {{ 迭代变量 }} {% endfor %} # 注: jinja2的控制语句大多都会遵循这个规则,即\"XXX\"控制语句需要使用\"endXXX\"作为结尾 ## 默认换行方式: # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] %} {{ i }} {% endfor %} # ansible node2 -m template -a \"src=test.j2 dest=/opt/test\" # cat /opt/test jinja2 test 3 1 7 8 2 ## 不换行方式: # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i }} {%- endfor %} # 在for的结束控制符\"%}\"之前添加了减号\"-\" # 在endfor的开始控制符\"{%\"之后添加到了减号\"-\" # cat test jinja2 test 31782 ## 不换行,但有间隔方式 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i }}{{ ' ' }} {%- endfor %} # 在循环每一项时,在每一项后面加入了一个空格字符串 # cat test jinja2 test 3 1 7 8 2 ## 不换行,但有间隔方式二 # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i~' ' }} {%- endfor %} # 在jinja2中,波浪符\"~\"就是字符串连接符,它会把所有的操作数转换为字符串,并且连接它们   4,结合for使用,循环字典\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat test.j2 jinja2 test {% for key,val in {'name':'bob','age':18}.iteritems() %} {{ key ~ ':' ~ val }} {% endfor %} # cat test jinja2 test age:18 name:bob   5,在使用for循环时,有一些内置的特殊变量可以使用\n 当前循环操作为整个循环的第几次操作,则可以借助\"loop.index\"特殊变量  1 2 3 4 5 6 7 8 9 10 11 12  # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] %}{{ i ~ '----' ~ loop.index }}{% endfor %}# cat test jinja2 test 3----1 1----2 7----3 8----4 2----5    其他的一些循环变量  1 2 3 4 5 6 7 8 9 10  # loop.index 当前循环操作为整个循环的第几次循环,序号从1开始 # loop.index0 当前循环操作为整个循环的第几次循环,序号从0开始 # loop.revindex 当前循环操作距离整个循环结束还有几次,序号到1结束 # loop.revindex0 当前循环操作距离整个循环结束还有几次,序号到0结束 # loop.first 当操作可迭代对象中的第一个元素时,此变量的值为true # loop.last 当操作可迭代对象中的最后一个元素时,此变量的值为true # loop.length 可迭代对象的长度 # loop.depth 当使用递归的循环时,当前迭代所在的递归中的层级,层级序号从1开始 # loop.depth0 当使用递归的循环时,当前迭代所在的递归中的层级,层级序号从0开始 # loop.cycle() 这是一个辅助函数,通过这个函数我们可以在指定的一些值中进行轮询取值,具体参考之后的示例    对一段内容循环的生成指定的次数,则可以借助range函数完成  1 2 3 4  {% for i in range(3) %}something ... {% endfor %}  6,for的一些其他操作\n 当for循环中没有使用if内联表达式时,也可以使用else块  1 2 3 4 5 6  {% for u in userlist %}{{ u.name }}{%else%}no one {% endfor %}# 只有userlist列表为空时,才会渲染else块后的内容    for支持递归操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  {% set dictionary={ 'name':'bob','son':{ 'name':'tom','son':{ 'name':'jerry' } } } %}{% for key,value in dictionary.iteritems() recursive %}{% if key == 'name' %}{% set fathername=value %}{% endif %}{% if key == 'son' %}{{ fathername ~\"'s son is \"~ value.name}}{{ loop( value.iteritems() ) }}{% endif %}{% endfor %}# 使用了iteritems函数,在for循环的末尾,添加了recursive 修饰符,当for循环中有recursive时,表示这个循环是一个递归的循环,当需要在for循环中进行递归时,只要在需要进行递归的地方调用loop函数即可,上例中的\"loop( value.iteritems() )\"即为调用递归的部分,由于value也是一个字典,所以需要使用iteritems函数进行处理 bob's son is tom tom's son is jerry   #jinja2模板(三) 1,jinja2模板文件中需要使用特殊字符\n 最简单的方法就是直接在\"双花括号\"中使用引号将这类符号引起,当做纯粹的字符串进行处理  1 2 3 4 5 6 7 8 9 10 11 12  # cat test.j2 {{ '{{' }}{{ '}}' }}{{ '{{ test string }}' }}{{ '{% test string %}' }}{{ '{# test string #}' }}# cat test {{ }}{{ test string }}{% test string %}{# test string #}   如果有较大的段落时,可以借助raw块,来实现需求  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat test.j2 {% raw %} {{ test }} {% test %} {# test #} {% if %} {% for %} {% endraw %}# \"{% raw %}\"与\"{% endraw %}\"之间的所有\"{{ }}\"、\"{% %}\"或者\"{# #}\"都不会被jinja2解析,上例模板被渲染后,raw块中的符号都会保持原样 # cat test {{ test }}{% test %}{# test #}{% if %}{% for %}  2,在调用模板引擎时,手动的指定一些符号,这些符号可以替换默认的区块\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat test.j2 {% set test='abc' %}(( test )) {{ test }}{{ test1 }}{{ 'test' }}{{ 'test1' }}# 使用variable_start_string参数指定一个符号,这个符号用于替换\"{{ }}\"中的\"{{“,同时,可以使用variable_end_string参数指定一个符号,这个符号用于替换\"{{ }}\"中的\"}}\" # ansible node2 -m template -a \"src=test.j2 dest=/opt/test variable_start_string='((' variable_end_string='))'\" # cat test abc {{ test }}{{ test1 }}{{ 'test' }}{{ 'test1' }}# 可以使用block_start_string参数指定一个符号, 这个符号用于替换\"{% %}\"中的\"{% \",可以使用block_end_string参数指定一个符号,这个符号用于替换\"{% %}\"中的\"%}\"   3,jinja2中也有类似函数的东西,名字叫做宏\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 最简单的宏 # cat test.j2 {% macro testfunc() %}test string {% endmacro %}{{ testfunc() }}# 指定参数的宏,包含默认值 {% macro testfunc(tv1=111) %}test string {{tv1}}{% endmacro %}{{ testfunc( ) }}{{ testfunc(666) }}  #ansible中的role 1,ansible官方定义的规范\n role的标准目录结构  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  $ tree role role ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── tasks │ └── main.yml ├── templates └── vars └── main.yml # tasks目录:角色需要执行的主任务文件放置在此目录中,默认的主任务文件名为main.yml,当调用角色时,默认会执行main.yml文件中的任务,也可以将其他需要执行的任务文件通过include的方式包含在tasks/main.yml文件中. # handlers目录:当角色需要调用handlers时,默认会在此目录中的main.yml文件中查找对应的handler # defaults目录:角色会使用到的变量可以写入到此目录中的main.yml文件中,通常,defaults/main.yml文件中的变量都用于设置默认值,以便在你没有设置对应变量值时,变量有默认的值可以使用,定义在defaults/main.yml文件中的变量的优先级是最低的. # vars目录:角色会使用到的变量可以写入到此目录中的main.yml文件中,看到这里你肯定会有疑问,vars/main.yml文件和defaults/main.yml文件的区别在哪里呢？区别就是,defaults/main.yml文件中的变量的优先级是最低的,而vars/main.yml文件中的变量的优先级非常高,如果你只是想提供一个默认的配置,那么你可以把对应的变量定义在defaults/main.yml中,如果你想要确保别人在调用角色时,使用的值就是你指定的值,则可以将变量定义在vars/main.yml中,因为定义在vars/main.yml文件中的变量的优先级非常高,所以其值比较难以覆盖. # meta目录:如果你想要赋予这个角色一些元数据,则可以将元数据写入到meta/main.yml文件中,这些元数据用于描述角色的相关属性,比如 作者信息、角色主要作用等等,你也可以在meta/main.yml文件中定义这个角色依赖于哪些其他角色,或者改变角色的默认调用设定,在之后会有一些实际的示例,此处不用纠结. # templates目录: 角色相关的模板文件可以放置在此目录中,当使用角色相关的模板时,如果没有指定路径,会默认从此目录中查找对应名称的模板文件. # files目录:角色可能会用到的一些其他文件可以放置在此目录中,比如,当你定义nginx角色时,需要配置https,那么相关的证书文件即可放置在此目录中. # 当然,上述目录并不全是必须的,也就是说,如果你的角色并没有相关的模板文件,那么角色目录中并不用包含templates目录,同理,其他目录也一样,一般情况下,都至少会有一个tasks目录.   2,调用role的方式\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # ls testrole test.yml # cat test.yml - hosts: node2 roles: - testrole # ansible-playbook test.yml ## 调用testrole角色时,test.yml会从同级目录中查找与testrole角色同名的目录 ## 还有其他位置也可以被调用: ## 1,当前系统用户的家目录中的.ansible/roles目录,即 ~/.ansible/roles目录中 ## 2,同级目录中的roles目录中 ## 3,修改ansible的配置文件,编辑/etc/ansible/ansible.cfg配置文件,设置roles_path选项 roles_path = /etc/ansible/roles:/opt:/testdir ## 或者在playbook中,直接接上role的绝对路径   3,一些role使用的问题\n 在默认情况下,角色中的变量是全局可访问的,可以将变量的访问域变成角色所私有的,如果想要将变量变成角色私有的,则需要设置/etc/ansible/ansible.cfg文件,将private_role_vars的值设置为yes,默认情况下,\"private_role_vars = yes\"是被注释掉的,将前面的注释符去掉皆可 默认情况下,无法多次调用同一个角色,也就是说,如下playbook只会调用一次testrole角色:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # cat test.yml - hosts: node2 roles: - role: testrole - role: testrole # 如果想要多次调用同一个角色,有两种方法,如下: # 方法一:设置角色的allow_duplicates属性 ,让其支持重复的调用. # 方法二:调用角色时,传入的参数值不同. # 方法一需要为角色设置allow_duplicates属性,而此属性需要设置在meta/main.yml文件中,所以我们需要在testrole中创建meta/main.yml文件,写入如下内容: # cat testrole/meta/main.yml allow_duplicates: true # 方法二 # cat test.yml # cat test.yml - hosts: node2 roles: - role: testrole vars: testvar: \"zsythink\" - role: testrole vars: testvar: \"zsythink.net\"   4,除了使用\"-e\"传入的变量的优先级,其他变量（包括主机变量）的优先级均低于vars/main.yml中变量的优先级\n5,调试handler方法\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat testrole/tasks/main.yml - debug: msg: \"hello testrole!\" changed_when: true notify: test_handler # cat testrole/handlers/main.yml - name: test_handler debug: msg: \"this is a test handler\"   #常用技巧(一) 1,技巧一,在ansible中使用python字符串的一些特性\n ansible基于python实现,当我们在ansible中处理字符串时,能够借助一些python的字符串特性,比如,在python中可以使用中括号(方括号)截取字符串中的一部分,在ansible中也可以利用这一特性  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat test.yml - hosts: me gather_facts: no vars: a: \"vaA12345\" tasks: - debug: msg: \"{{a[2]}}\" # 使用a[2:5]获取到a字符串的第3到第5个字符（不包含第6个字符） # 使用a[:5]获取到a字符串的第6个字符之前的所有字符（不包含第6个字符） # 使用a[5:]获取到a字符串的第6个字符之后的所有字符（包含第6个字符） ## 之前成员运算符\"in\"和\"not in\",也是python的字符串运算符 - hosts: me gather_facts: no vars: a: \"vaA12345\" tasks: - debug: msg: \"true\" when: \"'va' in a\"    运算符处理字符  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 使用加号\"+\"连接两个字符串- hosts:megather_facts:novars:a:\"vaA12345\"b:\"vbB67890\"tasks:- debug:msg:\"{{a+b}}\"# 使用乘号\"*\"连续的重复输出字符串- hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"{{a*3}}\"   使用find查找字符串中字符位置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  - hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"{{a.find('A1')}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": \"2\"}# 用作条件判断- hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"not found\"when:a.find('A2') == -1  2,指定任务在某个节点上运行\n 通过\"delegate_to\"关键字,可以指定某个任务在特定的主机上执行,这个特定的主机可以是目标主机中的某一个,也可以不是目标主机中的任何一个  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  - hosts:node2,megather_facts:notasks:- file:path:\"/tmp/ttt\"state:touch- file:path:\"/tmp/delegate\"state:touchdelegate_to:node3- file:path:\"/tmp/ttt1\"state:touch  3,让某个人物在ansible主机上执行,不在目标主机上执行\n 有两种方式,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ## delegate_to- hosts:node2,node3gather_facts:notasks:- file:path:\"/tmp/inAnsible\"state:touchdelegate_to:local- file:path:\"/tmp/test\"state:touch## connection: local- hosts:node2,node3gather_facts:notasks:- file:path:\"/tmp/inAnsible\"state:touchconnection:local- file:path:\"/tmp/test\"state:touch  4,只跑一次的任务\n 从网站上下载包,但目标主机共有5台  1 2 3 4 5 6 7 8 9 10 11 12 13  - hosts:A,B,C,D,Egather_facts:notasks:- get_url:url:\"http://nexus.zsythink.net/repository/testraw/testfile/test.tar\"dest:/tmp/# 结合本机执行一起使用connection:localrun_once:true- copy:src:\"/tmp/test.tar\"dest:\"/tmp\"  #常用技巧(二) 1,向列表中追加项\n 如下内容:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  - hosts:megather_facts:novars:l1:- 1- 2l2:- a- b- 2tasks:- set_fact:l3:\"{{ l1 + l2 }}\"- debug:var:l3# 直接列表相加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{{ tlist + ['a'] }}\"- debug:var:tlist# jinja2的语法,完成上述追加元素的过程- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{% set tlist = tlist + ['a'] %}{{tlist}}\"- debug:var:tlist# 使用extend()追加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{% set tlist = tlist + ['a'] %}{{tlist}}\"- debug:var:tlist# append追加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{{ tlist.append('a') }}{{tlist}}\"- debug:var:tlist  2, 在列表中插入项\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  # 使用insert()- hosts:megather_facts:novars:tlist:- 11- 2- 11tasks:- set_fact:tlist:\"{{ tlist.insert(1,'a') }}{{tlist}}\"- debug:var:tlist  3, 在列表中删除项\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # 使用pop- hosts:megather_facts:novars:tlist:- 11- 2- 'a'- 'b'- 3tasks:- debug:msg:\"{{tlist.pop(2)}}\"# 使用remove()- hosts:megather_facts:novars:tlist:- 11- 'b'- 'a'- 'b'- 3tasks:- set_fact:tlist:\"{{ tlist.remove('b') }}{{tlist}}\"- debug:var:tlist# for循环匹配删除- hosts:megather_facts:novars:tlist:- 11- 'b'- 'a'- 'b'- 11- 'a11'- '1a'- '11'tasks:- set_fact:tlist:\"{%for i in tlist%}{% if 11 in tlist%}{{tlist.remove(11)}}{%endif%}{%endfor%}{{tlist}}\"- debug:var:tlist  ","description":"讲解ansible及ansible-playbook的使用","tags":["ansible","ops"],"title":"ansible及ansible-playbook的使用","uri":"/tech/ops/ansible%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"变量及操作符 #1. 特殊字符使用 # --\u003e 注释(不包括#!) --\u003e 变量替换使用 echo ${PATH#*:} ; --\u003e 命令分隔符,用于连接多个命令 ;; --\u003e 用于终止一个case语句 . --\u003e 等同于source命令 --\u003e 可作为隐藏文件的文件名开头 --\u003e 相对路径的表示,当前路径和父目录路径 --\u003e 匹配单个字符 '' --\u003e 忽略所有特殊字符,全部引用 \"\" --\u003e 忽略除去`,$,\\外所有的特殊字符,部分引用 , --\u003e 连接一串运算,只返回最后一个的结果 let \"t2 = ((a = 9, 15 / 3))\" ## set \"a=9\" and \"t2 = 15 / 3\" --\u003e for file in /{,usr/}bin/*calc ## 与{}一起使用,用作选择的一种,简略代码 --\u003e 变量替换中的大小写替换 echo ${var,} --\u003e 第一个字符小写 echo ${var,,} --\u003e 所有字符小写 echo ${var^} --\u003e 第一个字符大写 echo ${var^^} --\u003e 所有字符大写 \\ --\u003e 脱意符,除去特殊字符的含义,\\X等效与'X' ` --\u003e 运算符,将命令的输出结果作为内容传递给变量 : --\u003e 空命令,no op,执行结果返回值为0 --\u003e 在if/then记过中作为占位符使用 if condition;then :;else action;done --\u003e 为需要二进制文件存在的场合提供占位符 : ${username=`whoami`} | : ${1?\"Usage: $0 ARGUMENT\"} --\u003e 作为切片使用,同python中的切片 ${var:1} ${var:3:3} --\u003e 同重定向一同使用,用于清空一个文件而不更改其权限,如果文件不存在,则创建该文件 : \u003e /tmp/testfile --\u003e 可以用作注释符使用,但与#不同,:仍然会检查注释内容中命令是否正确 --\u003e 用作/etc/passwd文件和$PATH的分隔符 ! --\u003e 更改命令返回值,反转test命令的含义 --\u003e ${!variable},获取变量$variable的变量值 --\u003e 调用历史命令,在脚本中无法使用 * --\u003e 通配符,用以指代在给定的目录下的任何文件 --\u003e 在正则表达式中,表示任意数量的(包括0)xxx --\u003e 运算符,**便是乘方 ? --\u003e 在双括号结构中,可以用做判断 (( var0 = var1\u003c98?9:21 )) --\u003e 变量替换,当parameter不存在是,打印err_msg内容,返回值为1,两种形式的差别仅当parameter被声明且为空值时有差别 ${parameter?err_msg}, ${parameter:?err_msg} --\u003e 通配符,给定目录中的单字符文件名,在扩展正则表达式中代表单个字符 $ --\u003e 变量替换 --\u003e 锚定符,代表行尾 ${} --\u003e 参数替换 $* --\u003e 位置参数 $@ --\u003e 位置参数 $? --\u003e 命令返回值 $$ --\u003e 进程ID () --\u003e 小括号中的一组命令开启一个子shell,在脚本当中,其他部分无法读取括号中定义的变量 --\u003e 用于数组的初始化 Array=(e1 e2 e3) {} --\u003e 大括号展开 echo {file1,file2}\\ :{\\ A,\" B\",' C'} --\u003e 扩展大括号展开 echo {a..e} echo {1..10..2} 显示10以内的奇数，步长为2 --\u003e 代码块,内联组(inline group), anonymous function, the variate in the inline group \\ can be seen in the scripts anywhere { read line1 read line2 } \u003c /tmp/passwd line1和line2可以直接读取passwd中的文件内容 在{}中的代码块,一般情况下不会开启一个新的子shell --\u003e {}可以用在非标准的for循环当中 for ((n=1; n\u003c=10; n++)); { echo -n \"* $n *\"; } --\u003e many commands can be used in a {} section, just like a function, return the outcome --\u003e 占位符, use with xargs; 'ls . | xargs -i -t cp ./{} $1' {} \\; --\u003e 该结构用在find架构当中,不作为shell的关键字存在 The \";\" ends the -exec option of a find command sequence. It needs to be escaped to protect it from interpretation by the shell. [] --\u003e test命令,[是test命令的内置指令(test的同义字),并不是test的链接 --\u003e 数组元素,用于展开各个序号的数组元素 --\u003e 正则表达式中使用,用于表示一个序列 \"[B-Pk-y]\" $[] --\u003e 运算符,等效与(()) echo $[$a+$b] $[...] --\u003e 整数扩展符, 可用于整数的计算; 'echo $[3*5]' (())--\u003e 运算符 (( a = 23 )); (( a++ )) \u003c\u003e --\u003e 重定向,包含\u003e,\u0026\u003e,\u003e\u0026,\u003e\u003e,\u003c,\u003c\u003e --\u003e \u0026\u003e 把标准输出和标准错误都重定向 --\u003e \u003e\u00262重定向到标准错误 --\u003e \u003e\u003e 追加 --\u003e [i]\u003c\u003efilename 打开文件filename读写,分配文件描述符i给文件,若i不存在,则默认使用stdin ---------------------------------------------------------------- #!/bin/bash ## example 1-1 lock_file=/tmp/$(basename $0).lock exec 300\u003c\u003e$lock_file if ! flock -x -n 300; then echo \"already running\" else echo \"starting...\" sleep 30 fi ---------------------------------------------------------------- --\u003e (command)\u003e 进程替换, 暂且记下,后续有具体讲解 --\u003e \u003c\u003c here document --\u003e \u003c\u003c\u003c here string --\u003e askii 比较,对比文本字符顺序 \\\u003e --\u003e 单词边界,同时还有\\\u003c grep '\\\u003cthe\\\u003e' textfile [[]]--\u003e test,比[]更灵活 | --\u003e 管道,将命令的输出作为输入传递给下一个命令 echo ls -l | sh ## 可以作为一种方式执行命令 --\u003e 管道运行在子shell当中,所以不能在管道中定义变量 variable=\"initial_value\";echo \"new_value\" | read variable;echo \"variable = $variable\" # variable = initial_value \u003e| --\u003e 强制重定向,强制清空文件内容,即使已经设置了noclobber属性已经设置了 || --\u003e 或逻辑运算符,在test结构中使用 \u0026 --\u003e 在后台运行任务,在脚本中,命令甚至是循环结构可以运行在后台中 for i in {1..10};do echo -n \"$i\"; done \u0026 脚本中包含后台运行的命令可能会导致脚本hang死,可以设置补救措施; a,在后台命令后面增加一个wait命令可以解决该问题 b,在将结果重定向至/dev/null或者一个文件也可 ls -l \u0026; ehco \"Done.\"; wait \u0026\u0026 --\u003e 逻辑和运算符,用于test结构中 - --\u003e 选项前缀, ls -l --\u003e 从stdin重定向输入或从stdout重定向输入 1, (cd /source/directory \u0026\u0026 tar cf - . ) | (cd /dest/directory \u0026\u0026 tar xpvf -) 2, bunzip2 -c linux-2.6.16.tar.bz2 | tar xvf - 3, grep Linux file1 | diff file2 - --\u003e 前一个工作目录,由$OLDPWD变量保存 --\u003e 减号,用作逻辑运算符 -- --\u003e 命令长格式选项前缀 ls --all --\u003e 与set结合使用,设置位置参数 ---------------------------------------------------------------- variable=\"one two three four five\" set -- $variable; first_param=$1 second_param=$2 shift; shift echo \"first parameter = $first_param\" # one echo \"second parameter = $second_param\" # two ---------------------------------------------------------------- = --\u003e 赋值运算符;a=28 + --\u003e 逻辑运算符,相加 --\u003e 正则表达式,1各或者多个 --\u003e 特定命令的参数前缀,+为开启,-为关闭,如set命令 % --\u003e 逻辑运算符,余 ~ --\u003e 家目录,由$HOME保存 ~+ --\u003e 当前工作目录,由$PWD保存 ~- --\u003e 上一个工作目录,由$OLDPWD保存 =~ --\u003e 正则表达式中匹配 variable=\"This is a fine mess.\" if [[ \"$variable\" =~ T.........fin*es* ]] ^ --\u003e 行开头 --\u003e 参数替换中,大写替换 ^^ --\u003e 参数替换中,大写替换 ' ' --\u003e 空格,用作命令或者是变量的分隔 #2. 变量及参数 1, 变量名是变量值的占位符,获取变量值的操作称之为变量替换 2, 变量裸露的情况(没有前缀'$'符) --\u003e 变量声明或者是赋值的时候 --\u003e 取消变量unset --\u003e 被export --\u003e 逻辑运算表达式(())中 3, 变量的赋值可以在如下结构中 --\u003e '='中 --\u003e read结构 --\u003e 类似for var in xx的循环结构中 4, 变量引用中 --\u003e 使用$a,不用\"\"括起来,移除变量中的tab和newline --\u003e 使用\"$a\",保存whitespace(空白) 5, 使用$(...)替换`...`来进行变量赋值 6, shell变量没有类型 7, 特殊类型的变量 --\u003e 本地变量: 只在代码块或者是函数中可见 --\u003e 环境变量: 影响shell动作的变量,如PATH或者是PS1等 --\u003e 位置参数: $0,$1这些,$0表示脚本;$*和$@代表所有的位置参数 8, 每次新建shell,在shell中会创建相应的环境变量 9, 使用export命令来将本地变量变成环境变量 --\u003e 脚本中,变量只能export给子子进程,也即在脚本中声明的变量无法作用于脚本之外 10,shift命令的作用是重新赋值位置参数,每执行一次,位置参数向左偏移一位 --\u003e 默认可调用10个 --\u003e $0不参与 --\u003e 被重新赋值的变量是move,不是copy(只有两个位置参数,shift后,$2不存在) --\u003e shift可接受数字,表示每次偏移多少 --\u003e 如下示例: ---------------------------------------------------------------- # 脚本名称不变,使用软链接给创建多个脚本名称,调用不同的名称,执行不同的功能 ln -s /usr/local/bin/wh /usr/local/bin/wh-ripe ln -s /usr/local/bin/wh /usr/local/bin/wh-apnic ln -s /usr/local/bin/wh /usr/local/bin/wh-tucows E_NOARGS=75 if [ -z \"$1\" ]; then echo \"Usage: `basename $0` [domain-name]\" exit $E_NOARGS fi case `basenam $0` in # Or: case ${0##*/} in \"wh\" ) whois $1@whois.tucows.com;; \"wh-ripe\" ) whois $1@whois.ripe.net;; \"wh-apnic\" ) whois $1@whois.apnic.net;; \"wh-cw\" ) whois $1@whois.cw.net;; * ) echo \"Usage: `basename $0` [domain-name]\";; esac ----------------------------------------------------------------  #3. 引用 1, grep '[Ff]irst' *.txt;在''中的特殊情况,这里并不会去除[]的作用,而是作为被保护的内容传递给grep 2, \"\"保护除过$,\\,`的其他符号 3, 可以引用\\n quote=$'\\116' echo -e '\\'${quote,} 4, $'...'可以将8进制或者16进制数转换成ascii字符保存到变量中 quote=$'\\042' 5, echo -e用于转换特殊含义字符  #4. 测试 测试结构: 1, if/then/elif/else结构,结合if后面的返回值确定执行顺序 --\u003e if结构不仅仅只能判断[]结构,后面可借命令 --\u003e if和then都是关键字参数,关键字开启代码块,在同一行开启一行新语句,就语句必须终结 2, []结构,等效于test 3, [[]]关键字结构,类比于test 4, ((...))和let ...结构,运算结果为非零时,返回值为0;运算结果为零时,返回值为非零 5, test是bash的内建命令,因此在一个脚本中使用test,使用的并不是/usr/bin/test二进制文件 --\u003e 在脚本中需要使用/usr/bin/test命令,需要写全路径 6, 使用[[]]替换[]做测试结构可以防止很多脚本中的逻辑错误 --\u003e \u0026\u0026, ||, \u003c, \u003e可以用在[[]]中,但无法在[]中使用 --\u003e 8进制,10进制,16进制可在[[]]中进行比较,[]会报错 7, (())也可用于测试,展开并对括号中的变量进行运算;当运算结果非零或为0或者'true';当运算结果为零时返回1或者'false' 8, 文件测试,如下不同场景返回true --\u003e -e 文件存在 --\u003e -f 是普通文件,不是目录或设备文件 --\u003e -s 大小不为零 --\u003e -d 是个目录 --\u003e -b 块设备 --\u003e -c 字符设备 --\u003e -p 管道文件 ---------------------------------------------------------------- # 示例内容: function show_input_type() { [ -p /dev/fd/0 ] \u0026\u0026 echo PIPE || echo STDIN } show_input_type \"Input\" # STDIN echo \"Input\" | show_input_type # PIPE ---------------------------------------------------------------- --\u003e -h 符号链接 --\u003e -L 符号链接 --\u003e -S socket文件 --\u003e -t 文件绑定一个终端设备 [ -t 0 ]用来测试脚本执行是不是在终端上 --\u003e -r/w/x/g/u/k 检测文件是否具有相应的权限 --\u003e -O/G你是文件所属者(组) --\u003e f1 -nt f2 文件f1比f2新 --\u003e f1 -ot f2 文件f1比f2旧 --\u003e f1 -ef f2 文件f1和f2是指向同一个文件的硬链接 --\u003e ! 非  #5. 操作符 --\u003e bash不明白浮点数的运算,会将浮点数当作字符处理;需要处理浮点数的运算,可以使用bc操作 --\u003e 逻辑运算符: 1, \u0026\u0026 和/与 --\u003e if [ $condition1 ] \u0026\u0026 [ $condition2 ] Same as: if [ $condition1 -a $condition2 ] 2, ! 非 --\u003e if [ ! -f $file ] 3, || 或 --\u003e if [ $condition1 ] || [ $condition2 ] Same as: if [ $condition1 -o $condition2 ] 4, \u0026\u0026/||在判断结构中的使用 --\u003e if [[ $a -eq 24 \u0026\u0026 $b -eq 24 ]] works. --\u003e if [ \"$a\" -eq 24 \u0026\u0026 \"$b\" -eq 47 ] error 5, 进制换算 --\u003e 可以使用$((...))结构对各个进制数进行换算 echo $((0x9abc)) --\u003e 在shell中,默认使用10进制,当把8进制或者16进制数使用let赋值存储在变量中,打印后变为10进制 let 'hex = 0x32';echo $hex --\u003e 不限制进制数格式,可以使用let进行换算,可以使用10 digits + 26 lowercase characters + 26 uppercase characters + @ + _ echo $((36#zz)) $((2#10101010)) $((16#AF16)) $((53#1aA)) # 1295 170 44822 3375 --\u003e 双括号结构: 同let,(())结构允许逻辑展开和运算 1, (( a = 23 )) 赋值,等号左右两侧都要有空格 2, (( --a ))和(( a-- ))都可以进行运算 3, (( t = a\u003c45?7:11 )) echo \"if a \u003c 45;then t = 7;else t = 11;fi\" # a = 23 echo \"t = $t \" # t = 7 --\u003e 运算符优先顺序: if [ \"$v1\" -gt \"$v2\" -o \"$v1\" -lt \"$v2\" -a -e \"$filename\" ] # Unclear what's going on here...,不能有超过三个的叠加存在(-a/-o) if [[ \"$v1\" -gt \"$v2\" ]] || [[ \"$v1\" -lt \"$v2\" ]] \u0026\u0026 [[ -e \"$filename\" ]] # Much better -- the condition tests are grouped in logical sections.  #6. 其他变量视角 内部变量\n1, $BASHPID(返回当前shell),不同于$$(返回父shell),虽然大部分时候两个值相同 echo $BASHPID;(echo $BASHPID) ## output different echo $$;(echo $$)\t## output same 2, $DIRSTACK,在目录栈中的第一个值,被pushd和popd影响 内置变量响应dirs命令,dirs会显示栈中所有的信息 3, $EDITOR,默认被脚本引用的编辑器,一般是vi或者emacs,nano 4, $EUID,有效UID 5, $FUNCNAME,在函数中,显示当前函数的名字 6, $GROUPS,当前用户所属用户组,是一个数组 echo ${GROUPS[1]} 7, $HOSTTYPE,检查当前系统的硬件类型 echo $HOSTTYPE # i686 8, $IFS,内部边界分隔符;这个变量决定bash怎样判断词组,字符串的边界 --\u003e 默认为空白符(空格,tab,新行) --\u003e 这个值可以被更改 bash -c 'set w x y z; IFS=\":-;\"; echo \"$*\"' ## w:x:y:z --\u003e 在设置IFS时需要注意,IFS对待空格和其他字符不一样 var=\" a b c \"使用for循环打印出来时,会变成三行,而不是和','一样,变为多行(超过三行) 对于使用在awk中的FS也存在同样的问题 9, $PATH,二进制文件路径 10,$PIPESTATUS,保存上一条命令的执行返回值 11,$PPID,父进程的PID号 12,$PROMPT_COMMAND,保存将要被执行的命令(是否为该含义待查) 13,$PS1,主提示符,命令行界面显示 14,$PS2,备提示符,在需要输入额外输入是显示,显示为'\u003e' 15,$PS3,select loop中使用 16,$PS4,set -x后界面显示的提示符'+' 17,$PWD,pwd命令显示结果 18,$REPLY,当且仅当上一条read命令无变量时,保存read的变量值 19,$SECONDS,当前脚本运行了多长时间 while [ \"$SECONDS\" -le \"$TIME_LIMIT\" ] 20,$SHELLOPTS,保存set -o的options项 21,$TMOUT,设置为一个非零值之后,超时会自动登出 --\u003e 可以在脚本中设置超时,在一定时间内未输入,则退出 ---------------------------------------------------------------- TMOUT=3 # Prompt times out at three seconds. echo \"What is your favorite song?\" echo \"Quickly now, you only have $TMOUT seconds to answer!\" read song if [ -z \"$song\" ] then song=\"(no answer)\" # Default response. fi ----------------------------------------------------------------  位置参数\n1, $0,$1,$2...,位置参数,从命令行传递给脚本,函数;或者使用set进行设置 2, $#,位置参数或者命令行参数的数目 3, $*,所有的位置参数,视为一个word,需要使用\"\"外加 4, $@,同$*,但每个参数单独使用\"\"括起来,同样也需要使用\"\"括起来 --\u003e 使用IFS和$@,$*时需要注意 --\u003e $@和$*仅在使用双引号引用的时候有差别 5, $!,上一个跑在后台的job的进程号 --\u003e 可用于任务控制 { sleep ${TIMEOUT}; eval 'kill -9 $!' \u0026\u003e /dev/null; } --\u003e 另一种方式 ---------------------------------------------------------------- TIMEOUT=30 count=0 possibly_hanging_job \u0026 { while ((count \u003c TIMEOUT )); do eval '[ ! -d \"/proc/$!\" ] \u0026\u0026 ((count = TIMEOUT))' # /proc is where information about running processes is found. # \"-d\" tests whether it exists (whether directory exists). # So, we're waiting for the job in question to show up. ((count++)) sleep 1 done eval '[ -d \"/proc/$!\" ] \u0026\u0026 kill -15 $!' # If the hanging job is running, kill it. } ---------------------------------------------------------------- 6, $_,映射为执行的上一个命令最后一项内容 --\u003e du \u003e /dev/null;echo $_ # du --\u003e ls -al \u003e /dev/null;echo $_ # -al 7, $?,命令,函数或者是脚本的执行状态返回值 8, $$,脚本自己的pid号,常用于创建惟一的temp文件,相较于mktemp使用更简单  变量归类\n1, 使用declare/typeset完成变量定义 2, declare/typeset属于内建命令 3, -r,设置只读变量 --\u003e declare -r var1=xx 等效于 readonly var1=xx 4, -i,设置为整数变量 --\u003e 设置为整数变量,允许直接进行运算,不需要expr结构 ---------------------------------------------------------------- n=6/3 echo \"n = $n\" declare -i n echo \"n = $n\" # n = 6/3 # n = 2 ---------------------------------------------------------------- 5, -a,设置为数组变量 6, -f,显示函数 --\u003e declare -f后未接任何参数,显示所有的函数;可以用在ssh远程连接,传递函数使用 --\u003e declare -f func_name仅显示func_name函数内容 7, -x,等效于export 8, 使用declare声明一个变量会限制其scope 9, 使用declare可以非常方便的辨别变量,尤其是在辨认数组时 --\u003e declare | grep HOME --\u003e Colors=([0]=\"purple\" [1]=\"reddish-orange\" [2]=\"light green\");declare |grep Colors  变量操作\n--\u003e bash允许大量字符串操作,部分属于变量替换操作,部分属于UNIX的expr功能 1, 字符串长度 --\u003e ${井号string},显示变量string的长度 --\u003e expr length $string,使用expr功能显示字符串长度 --\u003e expr \"$string\" : '.*',同样是显示变量string中字符串的长度值 2, substring从string开头匹配的字符数,substring是正则表达式 --\u003e expr match \"$string\" '$substring' stringZ=abcABC123ABCabc --\u003e expr \"$string\" : '$substring' echo `expr match \"$stringZ\" 'abc[A-Z]*.2'` # 8 echo `expr \"$stringZ\" : 'abc[A-Z]*.2'` # 8 3, substring在string中第一次匹配的下标号 --\u003e expr index $string $substring echo `expr index \"$stringZ\" 1c` # 'c' (in #3 position) matches before '1'.  变量取出\n\t1, 切片用法 --\u003e ${string:position} # 从position处开始抽取string,此处的position和length都可以是变量 --\u003e ${string:position:length} # 从position处抽取length个string字符 ---------------------------------------------------------------- stringZ=abcABC123ABCabc echo ${stringZ:7} # 23ABCabc echo ${stringZ:7:3} # 23A echo ${stringZ:(-4)} # Cabc 区别于${stringZ:-4},这种形式等效于${string:-default} ---------------------------------------------------------------- --\u003e ${*:position} # 从position处开始取位置参数 --\u003e ${@:position} # 同上一条 --\u003e ${*:position:length} # 同string 的用法,换成位置参数 --\u003e expr substr $string $position $length # expr用法,切片用法 --\u003e expr match \"$string\" '\\($substring\\)'\t# 获取第一次匹配的substring内容,substring为正则表达式 --\u003e expr \"$string\" : '\\($substring\\)'\t# 同上 ---------------------------------------------------------------- echo `expr match \"$stringZ\" '\\(.[b-c]*[A-Z]..[0-9]\\)'`\t# abcABC1 echo `expr \"$stringZ\" : '\\(.[b-c]*[A-Z]..[0-9]\\)'` # abcABC1 echo `expr \"$stringZ\" : '\\(.......\\)'` # abcABC1 ---------------------------------------------------------------- --\u003e expr match \"$string\" '.*\\($substring\\)' # 获取尾部第一次匹配的substring内容,substring为正则表达式 --\u003e expr \"$string\" : '.*\\($substring\\)' # 同上 echo `expr match \"$stringZ\" '.*\\([A-C][A-C][A-C][a-c]*\\)'` # ABCabc echo `expr \"$stringZ\" : '.*\\(......\\)'`\t# ABCabc  变量置换\n file=/dir1/dir2/dir3/my.file.txt --\u003e ${file#*/} # 拿掉第一条/及其左边的字串：dir1/dir2/dir3/my.file.txt --\u003e ${file##*/} # 拿掉最后一条/及其左边的字串：my.file.txt --\u003e ${file#*.} # 拿掉第一个.及其左边的字串：file.txt --\u003e ${file##*.} # 拿掉最后一个.及其左边的字串：txt --\u003e ${file%/*} # 拿掉最后一条/及其右边的字串：/dir1/dir2/dir3 --\u003e ${file%%/*} # 拿掉第一条/及其右边的字串：（空值） --\u003e ${file%.*} # 拿掉最后一个.及其右边的字串：/dir1/dir2/dir3/my.file --\u003e ${file%%.*} # 拿掉第一个.及其右边的字串：/dir1/dir2/dir3/my mv $filename ${filename%$1}$2 # 可以用作重命名 --\u003e ${file:0:5} # 提取最左边的5个字节：/dir1 --\u003e ${file:5:5} # 提取第5个字节右边的连续5个字节：/dir2 --\u003e ${file-my.file.txt} # 假如$file没有设定，则使用my.file.txt作传回值。（空值及非空值时不作处理） --\u003e ${file:-my.file.txt} # 假如$file没有设定或为空值，则使用my.file.txt作传回值。（非空值时不作处理） ${username-`whoami`} # when username has not been set, return the value of result of whoami filename=${1:-DEFAULT_FILENAME} --\u003e ${file+my.file.txt} # 假如$file设为空值或非空值，均使用my.file.txt作传回值。（没设定时不作处理） --\u003e ${file:+my.file.txt} # 若$file为非空值，则使用my.file.txt作传回值。（没设定及空值时不作处理） --\u003e ${file=my.file.txt} # 若$file没设定，则使用my.file.txt作传回值，同时将$file赋值为my.file.txt。\\ （空值及非空值时不作处理） --\u003e ${file:=my.file.txt} # 若$file没设定或为空值，则使用my.file.txt作传回值，同时将$file赋值为my.file.txt。\\ （非空值时不作处理） --\u003e ${file?my.file.txt} # 若$file没设定，则将my.file.txt输出至STDERR,用于变量报错设置（空值及非空值时不作处理） --\u003e ${file:?my.file.txt} # 若$file没设定或为空值，则将my.file.txt输出至STDERR。（非空值时不作处理） --\u003e 要分清楚unset与null及non-null这三种赋值状态。一般而言，: 与null有关，若不带 : 的话，null不受影响，若带 : 则连null \\ 也受影响。 --\u003e ${var,,} # 更改var的大小写,将$var中的大写字符转换成小写 --\u003e ${井号var} # get the length of the variate of var  变量替换\n stringZ=abcABC123ABCabc --\u003e echo ${stringZ/abc/xyz} # xyzABC123ABCabc,将开头的abc替换成xyz --\u003e echo ${stringZ//abc/xyz} # xyzABC123ABCxyz,将字符串中的所有abc替换成xyz abc和xyz都可以使用变量替换 --\u003e echo ${stringZ/abc} # ABC123ABCabc,不包含replacement时,则是直接删除第一处匹配内容 --\u003e echo ${stringZ//abc} # ABC123ABC,同上,删除所有的匹配内容 --\u003e echo ${stringZ/#abc/XYZ} # XYZABC123ABCabc,匹配前端的第一个,进行替换 --\u003e echo ${stringZ/%abc/XYZ} # abcABC123ABCXYZ,匹配后端的最后一个,进行替换 --\u003e echo ${!varprefix*} # 匹配所有已声明已xyz开头的变量 --\u003e echo ${!varprefix@} # 匹配所有已声明已xyz开头的变量 abc23=something_else b=${!abc*} echo \"b = $b\" # b = abc23 c=${!b} # Now, the more familiar type of indirect reference. echo $c awk的使用,等效变量替换 String=23skidoo1 # 012345678 Bash 变量替换中bash的下标计算方式 # 123456789 awk 变量替换中awk的下标计算方式 --\u003e echo | awk '{ print substr(\"'\"${String}\"'\",3,4) }' # skid 前面使用空echo的作用是,所谓伪输入,不需要填写输入文件  #7. 循环和分支结构 for循环\nfor arg in [list]; do command;done --\u003e for循环和set结合使用,会很方便,以下是例子 -------------------------------------------------------------------------------- set `uname -a`; for item in $(seq $#); do echo ${!item}; done for planet in \"Mercury 36\" \"Venus 67\" \"Earth 93\" \"Mars 142\" \"Jupiter 483\"; do set -- $planet echo \"$1 $2,000,000 miles from the sun\" done -------------------------------------------------------------------------------- --\u003e set中使用的--,避免难预测的bug,当后面的变量为空或者是以'-'开头 --\u003e [list]可以是一个变量,保存了多个值,用于for循环使用 --\u003e [list]也可以使用*通配符 --\u003e 无[list]项也可,循环使用的内容为位置参数 for a; do echo -n \"$a \"; done # 写入脚本后,执行脚本时,后接参数或者不接参数,得出结果不同 --\u003e [list]内容同样可为命令替换后的结果 for name in $(awk 'BEGIN{FS=\":\"}{print $1}' \u003c \"$PASSWORD_FILE\" ) # 系统上所有用户 for word in $(generate_list) # 函数运行结果 --\u003e for loop结束后,在done后面可直接使用管道进行操作,例如排序等 for file in \"$( find $directory -type l )\";do echo \"$file\"; done | sort # 对循环执行后的结果进行排序 --\u003e C风格的for循环,需要用到(()); LIMIT=10; for ((a=1; a \u003c= LIMIT ; a++)); do echo $a; done for ((a=1, b=1; a \u003c= LIMIT ; a++, b++)); do echo -n \"$a-$b \"; done --\u003e 一般情况下,do和done分割for循环的结构,但在特定情况下,省略do和done ---------------------------------------------------------------- for((n=1; n\u003c=10; n++)) { # No do echo -n \"* $n *\" } # No done! for n in 1 2 3 { echo -n \"$n \"; } # 在经典的for结构中,花括号中需要包含;,用于结尾 ---------------------------------------------------------------- --\u003e E_NOARGS=65 --\u003e The standards of variate naming, exit-because-no-arguments --\u003e read command read reads a line every time, in the function 'while read i j', i stands for the first word, j stands for the rest of this line --\u003e the difference between return and exit 若在script里，用exit RV来指定其值，若没指定，在结束时以最后一道命令之RV为值。 若在function里，则用return RV来代替exit RV即可。 若在loop里，则用break  while循环\n相对于for循环,while循环更适合用于不确定condition情况下进行的循环 while [condition]; do command(s); done --\u003e 在while循环中可能存在多个条件,但只有最后一个条件决定什么时候终止循环 ---------------------------------------------------------------- while echo \"previous-variable = $previous\" echo previous=$var1 [ \"$var1\" != end ]; do ... ---------------------------------------------------------------- --\u003e 同for循环一样,while可以接收C风格的条件格式 ---------------------------------------------------------------- while (( a \u003c= LIMIT )) do echo -n \"$a\" ((a += 1)) # let \"a+=1\" done ---------------------------------------------------------------- --\u003e while的条件可以直接接函数 ---------------------------------------------------------------- condition(){ ((t++)) if [ $t -lt 5 ]; then return 0 # true else return 1 # false fi } while condition ---------------------------------------------------------------- --\u003e 与read一起结合使用,得到while read结构 cat file | while read line # 同时是以管道作为输入内容 --\u003e while可以在done后使用'\u003c'来作为内容输入  until循环\n循环体在顶部,直到条件正确,才退出执行循环结构中的内容;与while循环相反 until [ condition-is-true ]; do command(s); done until循环结构格式类同于for循环 --\u003e 条件为真才退出 ---------------------------------------------------------------- END_CONDITION=end until [ \"$var1\" = \"$END_CONDITION\" ] # Tests condition here, at top of loop. do echo \"Input variable #1 \" echo \"($END_CONDITION to exit)\" read var1 echo \"variable #1 = $var1\" echo done ---------------------------------------------------------------- --\u003e until同样接受C风格的判断条件,使用双括号的格式(()) until (( var \u003e LIMIT ))  嵌套循环\n一个循环结构属于另一个循环结构的构成部分,称为嵌套循环  循环控制\n影响循环行为的命令 break;continue --\u003e break的作用为终止当前循环 --\u003e continue的作用为跳过当前这次的循环,在该分支中,跳过该分支后面需要执行的命令和操作 ---------------------------------------------------------------- while [ $a -le \"$LIMIT\" ]; do a=$(($a+1)) if [ \"$a\" -eq 3 ] || [ \"$a\" -eq 11 ]; then # Excludes 3 and 11. continue\t# Skip rest of this particular loop iteration. fi echo -n \"$a\"\t# This will not execute for 3 and 11. done while [ \"$a\" -le \"$LIMIT\" ]; do a=$(($a+1)) if [ \"$a\" -gt 2 ]; then break # Skip entire rest of loop. fi echo -n \"$a\" done ---------------------------------------------------------------- --\u003e break可以后接参数,单个的break表示终止当前循环;break N表示终止几层循环 --\u003e continue也可以接参数,单个的continue表示此次循环,continue N会终止当前层级的循环,开始下一次的循环,从N层开始  测试和分支\ncase和select结构不属于循环结构,但他们通过条件判断引导程序流向 --\u003e case对标的是C/C++中的switch结构;case可以说是简化版的if/elif/elif/.../else结构,case可以用于设置程序接口 ---------------------------------------------------------------- case \"$variable\" in \"$condition1\") command... ;; \"$condition2\")\tcommand... ;; esac ---------------------------------------------------------------- --\u003e 判断后接参数 ---------------------------------------------------------------- E_PARAM=1 case \"$1\" in \"\") echo \"Usage: ${0##*/} \u003cfilename\u003e\"; exit $E_PARAM;; # 提示信息,精简化 -*) FILENAME=./$1;; # 如果后面所接参数包含破折号,将其替换为./$1,这样后面的命令嗯就不会把其当做$1 * ) FILENAME=$1;; esac ---------------------------------------------------------------- --\u003e while和case一起使用: ---------------------------------------------------------------- while [ $# -gt 0 ]; do case \"$1\" in -d|--debug) DEBUG=1 ;; -c|--conf) CONFFILE=\"$2\" shift if [ ! -f $CONFFILE ]; then echo \"Error: Supplied file doesn't exist!\" exit $E_CONFFILE fi ;; esac shift done ---------------------------------------------------------------- --\u003e 做匹配函数: ---------------------------------------------------------------- match_string (){ MATCH=0 E_NOMATCH=90 PARAMS=2 E_BAD_PARAMS=91 [ $# -eq $PARAMS ] || return $E_BAD_PARAMS case \"$1\" in \"$2\") return $MATCH;; * ) return $E_NOMATCH;; esac } ---------------------------------------------------------------- --\u003e select继承自ksh,同样是一个可用于构建入口的工具 ---------------------------------------------------------------- select variable [in list] do command... break done ---------------------------------------------------------------- --\u003e select结构提示用户输入给定的选项之一,默认情况下使用环境变量PS3作为提示符,但这个可以被改变 ---------------------------------------------------------------- PS3='Choose your favorite vegetable: ' # Sets the prompt string. # Otherwise it defaults to #? . select vegetable in \"beans\" \"carrots\" \"potatoes\" \"onions\" \"rutabagas\" do echo echo \"Your favorite veggie is $vegetable.\" echo \"Yuck!\" echo break # What happens if there is no 'break' here? done ---------------------------------------------------------------- --\u003e 如果结构中list不存在,select会使用传递给脚本或包含select结构的函数的位置参数$@;可类比for variable [in list] ---------------------------------------------------------------- PS3='Choose your favorite vegetable: ' choice_of(){ select vegetable\t# [in list] omitted, so 'select' uses arguments passed to function. do echo echo \"Your favorite veggie is $vegetable.\" echo \"Yuck!\" echo break done } choice_of beans rice carrots radishes rutabaga spinach ----------------------------------------------------------------  #8. 命令替换 命令替换重新单个甚至多个命令的输出结果,逐字的将输出内容传递给另一个上下文 --\u003e 命令的输出结果可以是传递给其他命令的参数,可以是设置变量,甚至生成for循环需要使用的内容参数 --\u003e 命令替换有两种形式:`commands`,$(commands),两种方式等效 --\u003e 命令替换生成一个子shell --\u003e 命令替换可能把输出结果分片 ---------------------------------------------------------------- COMMAND `echo a b` # 2 args: a and b COMMAND \"`echo a b`\"\t# 1 arg: \"a b\" note: 有时命令替换会出现不期望的结果 mkdir 'dir with trailing newline ' cd \"`pwd`\" # error inform cd \"$PWD\" # works fine ---------------------------------------------------------------- --\u003e 使用echo输出命令替换厚的未括变量,echo会将换行符去除 --\u003e 命令替换允许使用重定向或者cat来获取文件内容作为变量内容 echo ` \u003c$0` # 输出脚本内容 --\u003e 不要将一个长文本内容作为值赋给一个变量，也不要将二进制文件内容作为变量的值 --\u003e 没有缓冲溢出的情况出现，这是翻译性语言的特性，相较编译语言提供更多的保护 --\u003e 变量声明甚至可以通过一个循环结构来赋值 ---------------------------------------------------------------- variable1=`for i in 1 2 3 4 5 do echo -n \"$i\" done` ---------------------------------------------------------------- --\u003e 命令替换使用$()替换掉反引号的使用 允许这种形式：content=$(\u003c$File2) --\u003e $()的形式允许多重嵌套  #9. 运算展开 算数展开提供了一个强大的工具，用于在脚本中进行算数运算；常用的有反引号、双括号、let 变种： --\u003e 使用反引号的算数运算，常常和expr结合使用 z=`expr $z + 3` --\u003e 算数展开使用双括号和let，反引号的结构已经被(())，$(())和let替换 z=$(($z+3))或者z=$((z+3))也可以 (( n += 1 ))是正确的；(( $n += 1 ))是错误的 let z=z+3是正确的；let \"z += 3\"也可以  linux命令 #1. 内部命令和内部指令 ​ 内建指令是指包含在bash工具集内部的命令；内建命令的作用一方面是为了提升性能，常用于需要fork新进程的命令，另一方面是出于某些命令需要直接访问shell内部\n--\u003e 父进程获取到子进程的pid后，可以传递参数给子进程，反过来则不行；这个需要注意，出现这种问题时，一般难以排查 ---------------------------------------------------------------- PIDS=$(pidof sh $0) # Process IDs of the various instances of this script. P_array=( $PIDS ) echo $PIDS let \"instances = ${井号P_array[*]} - 1\" echo \"$instances instance(s) of this script running.\" echo \"[Hit Ctl-C to exit.]\"; echo sleep 1 sh $0 exit 0 ---------------------------------------------------------------- --\u003e 一般来说，bash内建指令不会自动fork新的进程，外部命令或者管道过滤时会fork新进程 --\u003e 内建指令可能和系统命令有同样的名字，但bash会使用内建命令，echo和/bin/echo并不一样 ---------------------------------------------------------------- echo \"This line uses the \\\"echo\\\" builtin.\" /bin/echo \"This line uses the /bin/echo system command.\" ---------------------------------------------------------------- --\u003e 关键字是预留字、符号，或者是操作符；关键字对shell来说具有特殊的含义，是shell的语句块的构成部分；关键字属于bash的硬编码部分，不同于内建指令，关键字是命令的子单元  #2. IO命令 echo：打印表达式或者变量到标准输出 --\u003e 和-e使用，用来打印脱意符 --\u003e 默认情况下，每个echo会打印一个终端换行符，当与-n一起使用时，会将换行符省略掉 --\u003e echo `command`的形式会删除所有由command生成的换行符 变量$IFS默认情况下降'\\n'作为分隔符之一，bash将换行符后面的内容作为参数传递给echo，echo将这些参数打印出来，使用空格分隔 printf：格式化打印，增强型的echo，是一个C语言中printf()函数的限制型变体，部分内容与原函数使用不同 printf format-string... parameter... --\u003e 格式化输出 ---------------------------------------------------------------- declare -r PI=3.14159265358979 printf \"Pi to 2 decimal places = %1.2f\" $PI printf \"Pi to 9 decimal places = %1.9f\" $PI ---------------------------------------------------------------- --\u003e 格式化输出错误内容很实用 ---------------------------------------------------------------- # 注意$'strings...'的格式，在此处与%s的使用 error() { printf \"$@\" \u003e\u00262 # Formats positional params passed, and sends them to stderr. echo exit $E_BADDIR } cd $var || error $\"Can't cd to %s.\" \"$var\" ---------------------------------------------------------------- read：通过标准输入读取变量值，动态的通过键盘获取值，与-a选项一起使用时可获取数组变量 --\u003e read通常情况下，'\\'会去除换行的含义，当与-r参数一同使用时，'\\'按照原意进行输出 --\u003e -s：不显示输入内容到屏幕上 --\u003e -n：设置仅接收多少字符，-n同样能接受特殊按键，但需要清楚特殊按键对应的字符，但不能获取到回车的字符 ---------------------------------------------------------------- arrowup='\\[A' arrowdown='\\[B' arrowrt='\\[C' arrowleft='\\[D' insert='\\[2' delete='\\[3' ---------------------------------------------------------------- --\u003e -p：在接收输入内容前，打印后续内容到屏幕上，作为提示用 --\u003e -t：用在设置超时时间的场景下 --\u003e -u：获取目标文件的文件描述符 --\u003e read命令同样可以通过重定向到标准输入的文件来读取变量，如果文件内容超过一行，则只有第一行内容会被用于变量读取； --\u003e 当read后接的参数多余一个时，默认会以空格（或者连续空格）作为分隔符来读取变量，此行为可通过更改环境变量$IFS来改变 ---------------------------------------------------------------- read var1 \u003c /tmp/file1 read var1 var2 \u003c /tmp/file1 while read line; do echo $line; done \u003c /tmp/file1 ----------------------------------------------------------------  #3. 文件系统命令 cd：切换路径命令 --\u003e 使用-P参数，忽略链接文件 --\u003e cd -,切换到上一个目录，$OLDPWD变量保存的内容 --\u003e 使用两个斜杠时，cd命令会出现我们不期望的情况 ---------------------------------------------------------------- # 以下的问题在命令行和脚本中都存在，需要注意 $ cd // $ pwd // ---------------------------------------------------------------- pwd：显示当前工作目录路径 --\u003e使用该命令的效果同$PWD完全相同 pushd,popd,dirs：这个命令集合是一个工作目录书签工具，用于在工作目录中有序的来回切换；后进先出的堆栈方式处理工作目录组，允许对这个堆栈进行各种不同的操作 --\u003e pushd dir-name把目录dir-name放入到到堆栈中（栈顶），同时切换当前目录到dir-name中去 --\u003e popd 将目录栈顶的目录从栈中移除，同时将工作目录切换至此时的栈顶目录中去 --\u003e dirs 列出栈中的目录列表，popd和pushd会引用到dirs 在脚本中需要切换多个目录工作时，使用这个命令集可以方便的进行管理，$DIRSTACK数组包含有目录的列表栈内容  #4. 变量操作命令 let：let命令执行对变量的算数运算操作，在很多种情况下，let相当于简化版的expr命令 ---------------------------------------------------------------- let a=11; let a=a+5 let \"a \u003c\u003c= 3\" let \"a += 5\" let a++(++a) let \"t = a\u003c7?7:11\" ---------------------------------------------------------------- --\u003e 使用let命令，在特定情况下，命令返回值和通常情况不同 ---------------------------------------------------------------- $ var=0 $ echo $? 0 $ let var++ $ echo $? 1 ---------------------------------------------------------------- eval： eval arg1 [arg2] ... [argN] 结合一个表达式或者一列表达式中的参数，是这些参数联合；所有在表达式中的变量都会被展开，得出的字符串被转换为命令 ---------------------------------------------------------------- $ command_string=\"ps ax\" $ eval \"$command_string\" ---------------------------------------------------------------- --\u003e 每次调用eval都会强制重新评估其参数 ---------------------------------------------------------------- $ a=\"$b\" $ b=\"$c\" $ c=d $ echo $a $ eval echo $a $ eval eval echo $a ---------------------------------------------------------------- ---------------------------------------------------------------- params=$# param=1 while [ \"$param\" -le \"$params\" ] do echo -n \"Command-line parameter \" echo -n \\$$param echo -n \" = \" eval echo \\$$param (( param ++ )) done ---------------------------------------------------------------- --\u003e 使用eval命令有一定的风险，如果存在替换的方案，尽量使用替换方案来实现目的；像是eval $COMMANDS，在命令的返回结果中可能存在危险的内容如rm -rf *等 set： set命令可用于更改脚本内部的变量值或者脚本选项，用法之一是可以设置option flags来更改脚本执行的动作；另一个用法是可以是将命令的输出结果设置为位置参数。 ---------------------------------------------------------------- set `uname -a` ---------------------------------------------------------------- --\u003e 当单独使用set命令时，终端显示所有的环境变量以及已经设置的变量 --\u003e set后接--,表示将一个变量的内容设置为位置参数,当--后没有任何参数时,表示取消所有的位置参数 ---------------------------------------------------------------- variable=\"one two three four five\" set -- $variable first_param=$1 second_param=$2 shift; shift remaining_params=\"$*\" echo \"first parameter = $first_param\" # one echo \"second parameter = $second_param\" # two echo \"remaining parameters = $remaining_params\" # three four five set -- first_param=$1 second_param=$2 echo \"first parameter = $first_param\" # (null value) echo \"second parameter = $second_param\" # (null value) ---------------------------------------------------------------- unset: unset命令删除一个shell变量,将变量的值设置为null,改命令不影响位置参数 --\u003e 大多数情况下,使用unset设置过的变量和undeclare设置过的变量是等效的;但对于${parameter:-default}还是有区分的 export: export命令将变量的值声明至所有由脚本生成的子shell或者是shell,令其都可使用;在开机启动脚本中使用是export一个重要使用场景,有初始化环境的作用,让后启用的脚本能够继承环境变量 --\u003e 父进程是没有办法获取到子进程的变量的 --\u003e 大部分情况下,export var=xxx和var=xxx;export var是等效的,但在某些情况下有差别 ---------------------------------------------------------------- bash$ export var=(a b); echo ${var[0]} (a b) bash$ var=(a b); export var; echo ${var[0]} a ---------------------------------------------------------------- declare/typeset: 这两个命令用来设定或者限制变量的属性 readonly: 等效于declare -r,将一个变量设置为只读,或者实际效用为设置成一个常量,这个命令类似于C中的const getopsts: 这个强大的命令解析命令行参数,传递给脚本使用,这个命令类似于C中的外部命令getopt,getopt库函数;命令允许传递和连接多个选项,并且为脚本联合多个参数,如下所示: ---------------------------------------------------------------- scriptname -abc -e /usr/local ---------------------------------------------------------------- --\u003e getopts使用两个默认的变量: $OPTIND(OPTion INDex)是参数指针 $OPTARG(OPTion ARGument)是参数指定一个选项 选项名声明时后接冒号表明这个选项有一个指定的参数 --\u003e getopts结构一般会同while循环使用,每次处理一个选项和参数,然后变量$OPTIND指针指向下一个值 命令行传递给脚本的参数前面必须接'-',存在'-'的前缀,让getopts识别命令行参数为选项;实际上,没有'-'时,getopts不会去处理这些参数,直接当作缺失选项处理 getopts模板与while循环有些许差别 getopts结构是外部命令getopt命令的替换 ---------------------------------------------------------------- while getopts \":abcde:fg\" Option # Initial declaration. # a, b, c, d, e, f, and g are the options (flags) expected. # The : after option 'e' shows it will have an argument passed with it. do case $Option in a ) # Do something with variable 'a'. b ) # Do something with variable 'b'. ... e) # Do something with 'e', and also with $OPTARG, # which is the associated argument passed with option 'e'. ... g ) # Do something with variable 'g'. esac done shift $(($OPTIND - 1)) # Move argument pointer to next. # All this is not nearly as complicated as it looks \u003cgrin\u003e. ---------------------------------------------------------------- ---------------------------------------------------------------- NO_ARGS=0 E_OPTERROR=85 if [ $# -eq \"$NO_ARGS\" ]\t# Script invoked with no command-line args? then echo \"Usage: `basename $0` options (-mnopqrs)\" exit $E_OPTERROR # Exit and explain usage. # Usage: scriptname -options # Note: dash (-) necessary fi while getopts \":mnopq:rs\" Option do case $Option in m) echo \"Scenario #1: option -m- [OPTIND=${OPTIND}]\";; n | o ) echo \"Scenario #2: option -$Option- [OPTIND=${OPTIND}]\";; p) echo \"Scenario #3: option -p- [OPTIND=${OPTIND}]\";; q) echo \"Scenario #4: option -q- with argument \\\"$OPTARG\\\" [OPTIND=${OPTIND}]\";; r | s ) echo \"Scenario #5: option -$Option-\";; *) echo \"Unimplemented option chosen.\";; # Default. esac done shift $(($OPTIND - 1)) exit $? ----------------------------------------------------------------  #5. 脚本行为命令 source/. (点命令) 这个命令,当在脚本外使用时,作用为调用一个脚本; 在脚本内部使用,source file-name的作用为加载file-name的内容; --\u003e source一个文件,将该文件的代码加载进入当前脚本(作用内容于C里面的#include作用) --\u003e 最终结果是,一个被source过的文件,代码就像在当前脚本物理上包含了被source过的文件的代码内容;当多个脚本使用同一个数据文件时,这种方式很有用 --\u003e 如果被source的文件本身是一个可执行脚本,当source后,脚本会执行,然后将控制权交回调用其的脚本;一个可执行的source文件可以使用return来实现目的 --\u003e 参数(可选)可以传递给被source的文件作为位置参数 ---------------------------------------------------------------- source $filename $args1 $args2 ---------------------------------------------------------------- --\u003e 脚本甚至可以在执行时source自己,随然可能没有什么实际的应用场景 ---------------------------------------------------------------- #!/bin/bash MAXPASSCNT=100 echo -n \"$pass_count \" let \"pass_count += 1\" while [ \"$pass_count\" -le $MAXPASSCNT ]; do . $0 done echo exit 0 ---------------------------------------------------------------- exit 无条件的终止一个脚本;exit命令可以选择性的后接一个整数参数,用作脚本的exit返回状态 --\u003e 最简单的方式是直接使用exit 0, 指明此次运行成功 --\u003e 如果一个脚本以未接参数的exit作为结尾,那么脚本的返回值则为最后一条命令的返回值,等效于exit $? --\u003e 一个exit命令也可以用于终止一个子shell exec 这个shell内建命令替换当前进程为一个指定的命令 --\u003e 通常情况下,当shell遇到一个命令时,会fork一个子进程来执行该命令,当使用exec命令时,shell不再fork子进程,并且exec调用的命令替换了shell --\u003e 当exec在脚本中使用时,当exec调用的命令结束时,会强制退出脚本 ---------------------------------------------------------------- #!/bin/bash exec echo \"Exiting \\\"$0\\\" at line $LINENO.\" # Exit from script here. # $LINENO is an internal Bash variable set to the line number it's on. # The following lines never execute. echo \"This echo fails to echo.\" exit 99 ---------------------------------------------------------------- ---------------------------------------------------------------- #!/bin/bash # self-exec.sh # Note: Set permissions on this script to 555 or 755, #\tthen call it with ./self-exec.sh or sh ./self-exec.sh. echo echo \"This line appears ONCE in the script, yet it keeps echoing.\" echo \"The PID of this instance of the script is still $$.\" # Demonstrates that a subshell is not forked off. echo \"==================== Hit Ctl-C to exit ====================\" sleep 1 exec $0 # Spawns another instance of this same script #+ that replaces the previous one. echo \"This line will never echo!\"\t# Why not? exit 99\t# Will not exit here! # Exit code will not be 99! ---------------------------------------------------------------- --\u003e exec同时还具有重新声明文件描述符的功能,例如:exec \u003czzz-file用文件zzz-file内容替换标准输入 --\u003e 在find命令中使用的-exec选项和shell内建命令exec不同,需要注意 shopt 这个命令允许在运行的过程中更改shell选项,通常出现在bash启动文件中,同样在脚本中可以使用,需要version 2以上版本的bash ---------------------------------------------------------------- shopt -s cdspell # Allows minor misspelling of directory names with 'cd' # Option -s sets, -u unsets. cd /hpme # Oops! Mistyped '/home'. pwd # /home # The shell corrected the misspelling. ---------------------------------------------------------------- caller 在一个函数中放置一个caller命令,会打印出是在第几行调用这个函数,不再函数中使用没有作用 ---------------------------------------------------------------- #!/bin/bash function1 () { caller 0\t# Tell me about it. } function1 ---------------------------------------------------------------- --\u003e caller命令在被source后,同样能够打印出在被source文件中的位置,类似于一个函数,这个被称作为子程序 --\u003e caller在debug中比较有用  #6 常用命令 true 一个返回成功(0)的退出状态码命令,不做任何其他动作 常用与无限循环结构中: while true false 一个返回失败(非0)退出状态码命令,不做任何其他动作 常用场景同样为无限循环结构: while false type[cmd] 类似于which的外部命令,type命名用于鉴定cmd命令; --\u003e 不同于which,type是一个内建命令 --\u003e type使用-a参数时,用于鉴定关键字和内建命令,同样定位命令在系统上的唯一名称 ---------------------------------------------------------------- bash$ type '[' [ is a shell builtin bash$ type -a '[' [ is a shell builtin [ is /usr/bin/[ bash$ type type type is a shell builtin ---------------------------------------------------------------- --\u003e 在测试一个命令是否存在时,type命令非常有用,可以在判断结构中使用 ---------------------------------------------------------------- bash$ type bogus_command \u0026\u003e/dev/null bash$ echo $? 1 ---------------------------------------------------------------- hash [cmds] 记录指定命令的path名--在shell的哈希表中--因此shell或者脚本不需要逐次的查找$PATH变量目录来调用这些命令 --\u003e 当hash命令后不接参数时,则仅仅将已经hash的命令列出来 --\u003e 使用-r参数是清空hash表操作 bind 内建命令bind显示或者修改readline关键子绑定 readline:The readline library is what Bash uses for reading input in an interactive shell. help 获取简短的shell内建命令帮助信息,这个命令whatis的副本,但是是一个内建命令 help命令在bash v4后显示的信息详尽很多  #7. job控制命令 该部分内容的部分命令需要后接任务鉴定符作为参数 jobs 列出当前在后台运行的所有job,给出job数字,没有ps有用 --\u003e job和process的概念很容易混淆;一些特定的内建命令,像kill,disown,wait后接job号或者进程号作为参数;但fg,bg和jobs命令则仅接收任务号(job号)作为参数 ---------------------------------------------------------------- bash$ sleep 100 \u0026 [1] 1384 bash $ jobs [1]+ Running\tsleep 100 \u0026 ---------------------------------------------------------------- 上面的命令及其输出中,数字1是任务号(由当前shell获取的job号),1384是进程号(由系统获取),杀掉job/process,使用kill %1或者kill 1384 disown 移除shell中table内正在运行的job ---------------------------------------------------------------- $ jobs [1] Running sleep 1000 \u0026 [2] Running sleep 1000 \u0026 [3]- Running sleep 1000 \u0026 [4]+ Running sleep 1000 \u0026 $ disown $ jobs [1] Running sleep 1000 \u0026 [2]- Running sleep 1000 \u0026 [3]+ Running sleep 1000 \u0026 ---------------------------------------------------------------- fg,bg fg命令将一个运行在后台的任务切换至前台. bg命令重新启动一个挂起的任务,并在后台执行 --\u003e 如果没有指定任务号,则默认fg和bg会作用与当前正在running状态的任务 wait 暂时挂起脚本的执行过程,直到所有的后台运行任务已经结束,或者是作为参数的任务号/进程号已经终止,返回wait后接命令的返回状态码 --\u003e 使用wait的场景通常为:指定的后台任务已完成,再继续执行脚本后续内容 ---------------------------------------------------------------- #!/bin/bash ROOT_UID=0\t# Only users with $UID 0 have root privileges. E_NOTROOT=65 E_NOPARAMS=66 if [ \"$UID\" -ne \"$ROOT_UID\" ]; then echo \"Must be root to run this script.\"\t# \"Run along kid, it's past your bedtime.\" exit $E_NOTROOT fi if [ -z \"$1\" ]; then echo \"Usage: `basename $0` find-string\" exit $E_NOPARAMS fi echo \"Updating 'locate' database...\" echo \"This may take a while.\" updatedb /usr \u0026\t# Must be run as root. wait # Don't run the rest of the script until 'updatedb' finished. # You want the the database updated before looking up the file name. locate $1 # Without the 'wait' command, in the worse case scenario, #+ the script would exit while 'updatedb' was still running, #+ leaving it as an orphan process. exit 0 ---------------------------------------------------------------- --\u003e wait也可以后接一个任务识别号作为参数,例如: wait %1或者wait $PPID --\u003e 在一个脚本中,使用\u0026符号让命令在后台执行可能会导致脚本hang死直到按下enter键,这种情况主要出现在需要输出到标准输出的命令,这种情况的出现比较让人烦;在这种命令后接wait ---------------------------------------------------------------- #!/bin/bash # test.sh\tls -l \u0026 echo \"Done.\" wait bash$ ./test.sh Done. [bozo@localhost test-scripts]$ total 1 -rwxr-xr-x 1 bozo bozo 34 Oct 11 15:09 test.sh ---------------------------------------------------------------- 将命令输出写入到文件或者/dev/null中也可以解决这个问题 suspend 改命令与ctrl+Z有相似的效果,但是这个命令是挂起shell(shell的父进程应该在合适的时候恢复该shell的运行) logout 退出一个登录shell,后面可借参数n,指定登出shell的状态返回码 times 显示进程执行用时数据,区别于time命令;得出的信息价值有限,对于profile和基础shell脚本并不通用 kill 强制终止一个进程,通过传递合适的终止信号 ---------------------------------------------------------------- #!/bin/bash # self-destruct.sh kill $$\t# Script kills its own process here. # Recall that \"$$\" is the script's PID. echo \"This line will not echo.\" # Instead, the shell sends a \"Terminated\" message to stdout. exit 0\t# Normal exit? No! # After this script terminates prematurely, #+ what exit status does it return? # # sh self-destruct.sh # echo $? # 143 # # 143 = 128 + 15 #\tTERM signal ---------------------------------------------------------------- --\u003e kill -l列出所有支持的信号列表(包含在文件/usr/include/asm/signal.h) --\u003e kill -9是一个确认杀死,通常使用在单独使用kill命令无法杀死的场景下,有时,kill -15也能生效 --\u003e 僵尸进程是一个子进程已经终止,但父进程还没有被kill,无法被一个loged-on用户杀死--你无法杀死一个已经死的物件--但是init迟早会清理这些进程 killall killall命令通过名字杀死一个运行进程,而不是通过pid --\u003e 如果同时存在多个命令运行实例,则执行killall命令会将所有的这些实例全部杀死 --\u003e 此处的killall是指在/usr/bin/下的命令,而不是/etc/rc.d/init.d下的killall脚本 command command命令禁用接在其后的命令的alias和function --\u003e 这个命令是三个影响脚本命令执行的指令之一,其他两个分别是builtin和enable builtin 使用命令builtin BUILTIN_COMMAND将命令BUILTIN_COMMAND当作一个shell内建命令来执行;临时禁用与调用命令同名的functions或者是系统外部命令 enable 改命令能够启用或者禁用一个shell内建命令 例如: 命令enable -n kill禁用了shell内建命令kill,当bash继续调用kill时,调用的是外部命令kill --\u003e enable的-a选项列出所有的shell内建命令,指示这些命令是否被enable --\u003e -f filename选项让enable加载一个内建命令作为一个共享库模块从一个正确编译的二进制文件  #8. 任务识别符    内容 含义     %N 任务号   %S 引用以S开头的job   %?S 引用包含S的job   %% 当前job(最后一个在前台停止的任务或者是最后一个在后台启动的任务)   %+ 当前job(最后一个在前台停止的任务或者是最后一个在后台启动的任务)   %- 上一个job   $! 上一个后台任务    #9. 外部过滤器,程序及命令 标准的UNIX命令让shell脚本更加灵活,shell脚本的能力通过多个系统命令和shell指令的整合来实现\n#10. 基础命令 ls 基础文件罗列命令.很容易理解这个命令的低调; 用-R参数是递归的罗列出当前目录下的内容 用-S参数是按照文件的大小来排序 用-t参数是按照文件的修改时间来排序 用-v参数是文件名逆序罗列(依照数值顺序) 用-b参数是显示脱意字符 用-i参数是显示inode信息 --\u003e ls返回一个非零返回值,当目标文件不存在时 cat/tac cat是concatenate的缩写,获取一个文件的内容,显示到标准输出,当与重定向符(\u003e或者\u003e\u003e)一同使用时,一般用来连接文件 --\u003e -n参数是在文件的前面加上行号 --\u003e -b参数是只显示非空行内容 --\u003e -v参数是显示不可打印字符 --\u003e -s参数是将多行空行显示为一行空行 --\u003e 在一个管道中,直接使用重定向会比cat的效率更高 ---------------------------------------------------------------- cat filename | tr a-z A-Z tr a-z A-Z \u003c filename ---------------------------------------------------------------- --\u003e tac是cat的反向命令,反向输出一个文件的内容(最后一行变为第一行,依次向上) rev 将文件的每一行内容反向输出到标准输出,注意这个通tac功能是不一样的 cp 文件复制命令 cp file1 file2 --\u003e 将file1复制到文件file2,如果file2存在,则覆盖文件file2内容 --\u003e 尤其注意-a(archive)参数的使用,可以用于将一个目录完整复制 --\u003e -u(update)参数避免覆盖 --\u003e -r/-R 递归的复制 move 文件移动命令 命令等效与cp和rm的结合体,用来将多个文件移动到一个文件夹中,或者重命名文件夹; --\u003e 当mv用在一个非交互的脚本中时,mv会使用-f(force)参数来忽略用户的输入内容 --\u003e 当把一个目录mv为另一个已经存在目录名称时,该目录会变成已存在目录的子目录 rm 删除文件命令 --\u003e -f(force)参数用于强制删除文件,即使该文件为只读,在脚本中使用,用来绕开用户输入非常有用 --\u003e 当一个文件以'-'开头时,使用rm删除会失败;rm将以'-'的内容作为参数使用 a.解决方式之一是在要删除文件的前面加上'--'(选项结束标识符) b.另一种方式是,在文件名前加上./,表示是在当前目录下的文件 ---------------------------------------------------------------- rm -- -badname rm ./-badname ---------------------------------------------------------------- --\u003e 当使用-r参数时,表示从当前指定目录递归删除 a.使用路径名称中包含变量的时候,尤其小心,当变量不存在时,有可能就变成了rm -rf / b.使用rm -rf *时需要注意;若命令执行时,当前工作路径不对,改命令结束后,效果将等同如rm -rf / rmdir 删除文件夹命令 当使用这个命令删除文件夹时,目录必须为空(包括.文件--隐藏文件) --\u003e 特定场景下使用这个命令来替代rm -rf dirname,防止误删错误文件夹 mkdir 创建文件夹命令 创建一个新的文件夹,如: mkdir -p project/programs/December; -p参数会自动创建任何必需的父目录 chmod 更改已存在文件或者文件夹的属性命令 --\u003e 数字方式 chmod 755 /dirname --\u003e 字符方式 chmod u+rwx /filename chattr 更改文件属性命令,这个命令与chmod的功能类似,但是使用不同的选项和语法方式,(仅在ext文件系统上使用?) --\u003e chattr的一个特殊的参数'i'(immutable),当一个文件具有了i属性,表示这个文件是不可更改的,不能被修改,删除,链接(root也不行) --\u003e 当一个文件具有了's'(secure)属性时,文件被删除后,之前文件占用的块将被二进制0填充 --\u003e 当一个文件具有了'u'(undelete)属性时,文件被删除后,文件内容仍能够获取到(状态为undeleted) --\u003e 当一个文件具有了'c'(compress)属性时,当文件被写时,自动压缩到磁盘文件,当文件被读时,自动从磁盘解压读取 --\u003e chattr包含的文件属性不同使用ls -l显示出来 ln 为存在的文件创建链接,链接是一个文件的映射,文件的别名 --\u003e ln命令允许被链接的文件包含不止一个映射名 --\u003e ln命令还可以用作别名来使用,在脚本中充作别名(abs-p38) --\u003e ln只创建文件的映射,指向文件的指针大小只有几个字节大小 --\u003e ln命令最常与-s选项一同使用(符号链接或者称为软链接);软链接的优势之一是可以跨越文件系统创建 ln -s oldfile newfile将oldfile链接一个新的文件名称newfile --\u003e 更改文件被链接文件的内容时,软链接和硬链接同时能够体现更改的文件内容;不同点是 a.删除或者重命名被链接文件后,硬链接不受影响,源文件的存储块内容并没有发生变化;但对于指向源文件名称的软链接来说,旧文件名称已经不存在,软链接将失效 b.软链接的优点是可以跨越文件系统进行链接,并且,不同于硬链接,软链接还可以指向文件夹,硬链接则不行 --\u003e 链接的存在可以让脚本(或其他任何可执行的文件)通过不同的名称来调用(eg:/sbin/iptables -\u003e xtables-multi),通过名称来限定脚本执行哪部分功能 ---------------------------------------------------------------- #!/bin/bash # hello.sh ln -s hello.sh goodbye HELLO_CALL=65 GOODBYE_CALL=66 if [ $0 = \"./goodbye\" ]; then echo \"Good-bye!\"\t# Some other goodbye-type commands, as appropriate. exit $GOODBYE_CALL fi echo \"Hello!\" exit $HELLO_CALL ---------------------------------------------------------------- man/info 获取帮助文档,info文档一般描述信息会比man文档更详尽 --\u003e man文档的书写可以通过脚本来优化(abs-709)  #11. 高级命令 find 命令形式: -exec COMMAND \\; 为每一行find匹配的内容执行COMMAND命令,命令序列是以';'结尾 --\u003e 此处使用的-exec与shell自带命令exec别混淆了 --\u003e 注意此处不是命令分隔使用到的';',find命令序列中';'是脱意的,为了确保shell将';'按照字面意思传递给find --\u003e 如果COMMAND中包含有{},则find将find匹配的路径或者文件名通过{}来替换; ---------------------------------------------------------------- find ~/ -name 'core*' -exec rm {} \\; find /etc -exec grep '[0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*' {} \\; find /home -type f -atime +5 -exec rm {} \\; ---------------------------------------------------------------- --\u003e 时间匹配: find可以通过文件的时间戳进行查找匹配 mtime = last modification time of the target file ctime = last status change time (via 'chmod' or otherwise) atime = last access time (-mtime -1表示前一天被修改过的文件) --\u003e 文件匹配: find可以通过文件类型进行查找匹配 f = regular file d = directory l = symbolic link, etc. ---------------------------------------------------------------- ## 删除当前目录下包含特殊字符的文件 find . -name '*[+{;\"\\\\=?~()\u003c\u003e\u0026*|$ ]*' -maxdepth 0 -exec rm -f '{}' \\; ## 通过inum删除文件 inum=`ls -i | grep \"$1\" | awk '{print $1}'` find . -inum $inum -exec rm {} \\; ---------------------------------------------------------------- xargs 一个用来传递参数给命令的过滤器,同样也是一个集合命令的工具 --\u003e xargs将数据流打散成足够小的块,用来给命令或者进程处理,可以将这个命令想成更加强大的后向引用 --\u003e 在有些场景下,命令替换报too many arguements时,用xargs却可以使用 --\u003e 一般场景下,xargs通过管道或者标准输入读取数据,但也可以通过一个文件的内容来获取 --\u003e 默认传递给xargs的命令是echo,这表示当输入管道给到xargs时,换行符和一些其他空白字符会被跳过 ---------------------------------------------------------------- bash$ ls -l | xargs total 0 -rw-rw-r-- 1 bozo bozo 0 Jan 29 23:58 file1 -rw-rw-r-- 1 bozo bozo 0 Jan... ---------------------------------------------------------------- --\u003e 命令ls | xargs -p -l gzip 将当前目录下的每个文件用gzip打包,每次一个,每进行一次会提示一次 --\u003e xargs依次序处理传递给其的参数,一次一项 --\u003e -n NN形式;限制每次传递给命令的参数数目,ls | xargs -n 3 echo -- 每次打印三个名字 --\u003e 另外一个有用的参数是-0,通常和find -print0或者grep -lZ一同使用;这个场景下允许处理的参数中包含空白字符或者引用 ---------------------------------------------------------------- find / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f grep -rliwZ GUI / | xargs -0 rm -f ---------------------------------------------------------------- --\u003e -P选项允许并行执行命令,在多核机器中能够提高执行速度 ---------------------------------------------------------------- ls *gif | xargs -t -n1 -P2 gif2png # Converts all the gif images in current directory to png. # Options: # ======= # -t Print command to stderr. # -n1 At most 1 argument per command line. # -P2 Run up to 2 processes simultaneously. ---------------------------------------------------------------- --\u003e 在find中使用,一对花括号的作用是作为占位符使用的 ---------------------------------------------------------------- ls . | xargs -i -t cp ./{} $1 # -t is \"verbose\" (output command-line to stderr) option. # -i is \"replace strings\" option. # {} is a placeholder for output text. # This is similar to the use of a curly-bracket pair in \"find.\" ---------------------------------------------------------------- expr 通用表达式求值运算命令 连接并对给出的命令选项和参数进行求值操作(各个参数之间必须用空格隔开) --\u003e 可进行的操作包括有: 算数运算,比较,字符或者逻辑运算 ---------------------------------------------------------------- expr 3 + 5 expr 5 % 3 expr 1 / 0 expr 5 \\* 3 # 乘法运算,在expr表达式中,乘号需要脱意 y=`expr $y + 1` # 变量自增,等效于 let y=y+1 and y=$(($y+1)) z=`expr substr $string $position $length` # 获取变量string中position位置length长度的字符 ---------------------------------------------------------------- --\u003e ':'运算符可以用来替代match;命令 b=`expr $a : [0-9]*`等效于 b=`expr match $a [0-9]*`  #12. 时间/日期命令 date 打印当前时间和日期信息到标准输出,这个命令的格式化输出和解析选项很有用 --\u003e -u选项显示UTC时间 --\u003e date可以用来计算不同时间之间的时间间隔 --\u003e date有大量的输出选项可供选择;比如%N是给出当前时间的纳秒格式,这个形式可以用来获取随机数 ---------------------------------------------------------------- date +%N | sed -e 's/000$//' -e 's/^0//' date --date='6 days ago' date --date='1 year ago' ---------------------------------------------------------------- zdump 时区dump:打印指定时区的时间 ---------------------------------------------------------------- bash$ zdump EST EST Tue Sep 18 22:09:22 2001 EST ---------------------------------------------------------------- time 显示执行一个命令的准确时间 --\u003e time不同于命令times,注意 ---------------------------------------------------------------- bash$ time ls -l / real 0m0.004s user 0m0.004s sys 0m0.001s ---------------------------------------------------------------- touch 更新文件的访问/修改时间为系统/指定时间,同时具有新建一个文件的功能 --\u003e 当文件zzz不存在时,touch zzz会创建一个大小为0的文件zzz;这种方式用来存储日期/时间戳很有用 --\u003e touch命令等效于:\u003e\u003e newfile或者\u003e\u003e newfile(普通文件) --\u003e 可以结合cp -a一起使用,使用touch更新不想被覆盖的文件时间戳,再用cp -u at at任务控制命令在指定的时间执行一系列指定的命令;命令类似于cron,at命令很适合只执行一次的命令 --\u003e 使用-f选项或者\u003c输入重定向,at充文件中读取命令;文件应该是一个可执行的shell脚本,同时是非交互式脚本 --\u003e 需要执行较多内容时,可以结合run-parts命令来实现 ---------------------------------------------------------------- bash$ at 2:30 am Friday \u003c at-jobs.list job 2 at 2000-10-27 02:30 ---------------------------------------------------------------- batch batch命令类似于at命令,但要求在系统负载低于0.8时执行;类似于at,可以接-f选项 cal 打印简化版的日历到标准输出,可接不同选项,显示不同年份和月份的日历 sleep 这个是shell形势下的wait循环;命令暂停指定秒数的时间,什么都不做 --\u003e 对于后台运行的命令或者定时进程很有用,定时检查事件 --\u003e sleep命令默认情况下是使用秒,但也可以用分钟,小时或者天来定时 --\u003e watch命令比sleep命令更适合周期性检查命令执行情况 usleep 类似与sleep,但默认时间为微秒,用在对时间更加精准或查询更加频繁的场景下 hwclock/clock 命令hwclock获取或者调整机器的硬件时间,某些选项需要root权限才能使用 --\u003e 在rhel6中,启动时,/etc/rc.d/rc.sysinit启动文件通过hwclock获取硬件时间来设置系统时间 --\u003e clock是hwclock的同义词  #13. 文本处理命令 sort 文件归类工具,通常用在管道后过滤使用 --\u003e 命令用来正序,逆序或者指定位置关键字/字符位置来处理文本流或者文件 --\u003e 使用-m选项,合入预处理过的文件 --\u003e 可以查看info文档来获取sort的使用场景 tsort 拓扑排序,读取以空格分隔的字符串对，并根据输入模式进行排序;通常情况下tsort命令排序的结果与sort排序结果有较大差别 uniq 该命令移除文件中重复出现的行,通常会结合sort和管道一同使用 ---------------------------------------------------------------- cat list-1 list-2 list-3 | sort | uniq \u003e final.list ---------------------------------------------------------------- --\u003e 使用-c选项,在输出结果中显示重复出现的次数 --\u003e sort INPUTFILE | uniq -c | sort -nr　命令打印出在INPUTFILE中出现的频次信息,使用场景为分析log文件或者字典列表等 ---------------------------------------------------------------- sed -e 's/\\.//g' -e 's/\\,//g' -e 's/ //g' \"$1\" | tr 'A-Z' 'a-z' | sort | uniq -c | sort -nr ---------------------------------------------------------------- expand/unexpand 命令expand用来将tab展开为空格,通常与管道结合使用 命令unexpand将空格转换为tab,是expand的反转命令 cut 展开文件指定区域的命令.命令类似于在awk结构中的print $N,但相比较之下,限制更多.在脚本中使用cut命令会比使用awk更简单.cut重要的选项-f和-d ---------------------------------------------------------------- # 使用cut来获取挂载文件系统列表 cut -d ' ' -f1,2 /etc/mtab # 使用cut列出OS和内核版本 uname -a | cut -d\" \" -f1,3,11,12 # 使用cut来解析email信息头部 bash$ grep '^Subject:' read-messages | cut -c10-80 Re: Linux suitable for mission-critical apps? MAKE MILLIONS WORKING AT HOME!!! Spam complaint Re: Spam complaint ---------------------------------------------------------------- --\u003e 甚至可以指定换行符作为分隔符 ---------------------------------------------------------------- bash$ cut -d' ' -f3,7,19 testfile This is line 3 of testfile. This is line 7 of testfile. This is line 19 of testfile. ---------------------------------------------------------------- --\u003e cut -d ' ' -f2,3 filename的结果等效于awk -F'[ ]' '{ print $2, $3 }' filename paste 用于将多个文件合成为一个文件,将合成的结果输出到标准输出 join 这是一个特殊形式的paste命令;这个强大的程序允许按照一定的关联关系来合并两个文件内容,这实际上已经是一个简化版的关系数据库形式了 --\u003e join命令只对两个文件进行操作，但只粘贴那些带有公共标记字段（通常是数字标签）的行，并将结果写入stdout --\u003e 要加入的文件应根据标记字段进行排序，以使匹配正常工作 ---------------------------------------------------------------- File: 1.data 100200300Shoes Laces Socks File: 2.data 100200300$40.00 $1.00 $2.00 bash$ join 1.data 2.data File: 1.data 2.data 100 Shoes $40.00 200 Laces $1.00 300 Socks $2.00 # 标识字段只出现一次 ---------------------------------------------------------------- head 打印一个文件的启示内容到标准输出,默认行数是10,但允许设置不同数字 --\u003e head有多个不同的参数可以使用,如-c(字符数),-n(行数) tail 打印一个文件的尾部到标准输出,默认行数是10,但该数字可以通过接-n选项更改;通常用来追踪一个文件内容的变化 --\u003e tail -f等效于tailf,动态实时的显示文件内容 --\u003e 显示某个文件的指定行内容,其中一种方式: head -n 8 database.txt | tail -n 1 l --\u003e 使用新的 tail -n $LINES filename 代替旧有形式tail -$LINES filename grep 一个多功能的搜索工具,可以使用正则表达式;命令形式grep pattern [file...] --\u003e -i选项,忽略大小写 --\u003e -w选项,仅匹配整个单词 --\u003e -l选项,仅显示匹配相关内容的文件名 --\u003e -r选项,递归搜索 --\u003e -n选项,显示匹配到的内容所在行,并将行数显示在匹配内容的前面 --\u003e -v选项,不显示匹配到的内容 --\u003e -c选项,显示匹配到的次数 --\u003e --color选项,将匹配到的内容上色显示 --\u003e -o选项,仅打印匹配到的内容,不显示一整行 --\u003e -q选项,不打印任何内容,在判断结构中使用很方便 --\u003e 当仅搜索一个文件时,在输出结果中要将文件名一同打印,可以后接/dev/null作为第二个文件名 ---------------------------------------------------------------- bash$ grep Linux osinfo.txt /dev/null ---------------------------------------------------------------- --\u003e grep匹配到相关内容后,返回值为0,这样可以结合判断结构来使用 --\u003e 使用sed命令可以仿真grep的行为: sed -n /\"$1\"/p $file --\u003e 怎样让grep匹配两个不同的匹配模式,可以使用方式grep pattern1 | grep pattern2来实现 --\u003e egrep等效于grep -E,允许使用扩展正则表达式来进行匹配,形式更加灵活 --\u003e fgrep等效于grep -F,逐字匹配(不使用正则表达式),速度会更快一些 --\u003e agrep(近似匹配/模糊匹配),扩展grep的能力,使其能够进行模糊匹配 --\u003e 匹配压缩文件内容时,使用zgrep/zegrep/zfgrep,这些命令同样能用在普通文件,虽然速度慢一些,但对于包含多种文件类型(普通文件/压缩文件)的场景下操作则更方便 --\u003e 匹配bzip文件时使用bzgrep命令 look look命令工作形式类似于grep,但是是基于字典(一个已排序的单词列表)进行查询;默认情况下,look在/usr/dict/words下进行匹配,但可以指定进行匹配的字典 ---------------------------------------------------------------- file=words.database # Data file from which to read words to test. while [ \"$word\" != end ]; do # Last word in data file. read word look $word \u003e /dev/null lookup=$? if [ \"$lookup\" -eq 0 ]; then echo \"\\\"$word\\\" is valid.\" else echo \"\\\"$word\\\" is invalid.\" fi done \u003c\"$file\" ---------------------------------------------------------------- sed/awk 脚本语言,非常适合用来处理文本文件和标准输出的内容 sed 非交互式的流编辑器,在batch(不需要用户介入的情况下运行一组命令)模式下允许使用很多ex命令,在脚本中使用很广泛 awk 可编程式文件内容提取及格式化程序,适合用来操作或展开格式化的文本文件的列,语法格式类似于C语言 wc 计数程序 --\u003e -w:单词数;-l:行数;-c:字节数;-m:字符数;-L:给出最长行的长度 tr 字符转化过滤器 --\u003e 视情况决定是否需要使用引用或者括号,引号引用可以防止shell将属于tr的特殊字符先行处理了,括号必须被引起来,防止直接被展开 ---------------------------------------------------------------- tr \"A-Z\" \"*\" \u003cfilename tr A-Z \\* \u003cfilename ---------------------------------------------------------------- --\u003e 接上-d选项,用于删除一系列的指定字符 --\u003e --squeeze-repeats(-s)选项用来删除连续的字符(保留第一个),这个选项用来移除多余的空白字符很有用 --\u003e -c(补足)选项将未匹配的内容用指定的字符替代 ---------------------------------------------------------------- bash$ echo \"acfdeb123\" | tr -c b-d + +c+d+b++++ bash$ echo \"abcd2ef1\" | tr '[:alpha:]' - ----2--1 ---------------------------------------------------------------- fold 将输入的行折叠成指定宽度的过滤器 --\u003e 使用-s选项用来以空格作为隔断符,防止直接截断字符 ---------------------------------------------------------------- b=`ls /usr/local/bin` $ echo $b | fold - -s -w 40 cnpm compile cops-cli gitbook pacvim ptyping qr-filetransfer runenpass sle study s-tui t termtosvg tget tiv # 等效于echo $b | fmt -w $WIDTH ---------------------------------------------------------------- fmt 简单的格式化工具,用于将长行分割为多行 column 列格式化工具,将列类型的文本输出转换成格式友好的打印形式,在合适的位置插入tab --\u003e 对于文件中存在多列内容,但未对齐的格式,使用column -t处理会很方便 colrm 列删除处理器,该命令删除文件中的列内容并直接写该文件 --\u003e colrm 2 4 \u003cfilename 删除文件中的第二到第四列内容 --\u003e 上列命令使用时,若文件中包含有tab之类的不可打印字符,则可能导致无法预估的结果,考虑使用expand/unexpand命令处理之后再管道传输给colrm nl 打印文件内容并附上行号 --\u003e 打印的是非空行内容 --\u003e nl的操作非常类似于cat -b,同样是不打印非空行 cpio 这个特定的归档复制命令已经很少用了,基本已经被tar/gzip取代;但在某些场景下,还是能够使用 --\u003e 指定块大小进行复制,速度会比tar更快 find \"$source\" -depth | cpio -admvp \"$destination\" rpm2cpio 这个命令从rpm包中解压一个cpio文件出来 gzip 结合-c选项使用时,将gzip的输出写入到标准输出,结合管道使用非常有用 zcat/bzcat 可以用来查看gzip/bzip文件中的内容,相当与bzip/gzip文件下的cat readlink 获取符号链接指向的文件 strings 用来获取二进制文件或其他数据文件中的可打印字符 diff 逐行打印两个对比文件的不同内容 --\u003e 使用--side-by-side选项,每个文件内容显示一列,相较原来的形式更方便对比查看 --\u003e 使用-c和-u选项可以让输出结果更适合查看 --\u003e 可以在判断结构中使用diff命令,当比较的两个文件同一的时候,命令返回值为0,当比较的两个文件不一样时,返回值非零 patch 一个非常灵活的版本记录命令,结合diff使用比较常见,可以给出一个由diff命令创建的差异文件 diff3 diff命令的升级版命令,可以一次比较三个文件,正常执行后命令返回值为0,但改命令不会打印文件差异内容出来 split/csplit 用于将一个文件切片为小块的工具,使用场景一般为文件太大,需要切片后邮件发送或者拷贝到移动磁盘 csplit命令通过文件内容来进行分片 sum,cksum,md5sum,sha1sum 以上命令是用于创建校验和的工具,校验和是通过对一个文件内容进行数学计算得出的字符串,用于检查文件的完整性 openssl 可以用于加密使用,结合tar一同使用,可以方便的加密相关目录和文件 shred 用随机字符多次重写文件,可用在安全要求高的场景下 mktemp 创建一个拥有唯一名称的临时文件,不使用其他参数是,在/tmp目录下创建一个大小为0的文件 --\u003e tempfile=`mktemp $PREFIX.XXXXXX` 指定创建的新文件包含有多少个随机字符 ptx ptx[targetfile]命令输出目标文件的排列索引（交叉引用列表）。如有必要，可以在管道中进一步过滤和格式化。 ipcalc 用于换算和查看ip相关的内容 traceroute 通过发送的包追踪路由 sx,rx 命令集通过xmodem协议与远端服务器传输文件 sz,rz 命令集通过zmodem协议与远端服务器传输文件,zmodem的速度相对xmodem更快 ssh --\u003e 在循环中使用ssh时,可能出现不可预期的情况,可以后接-f或者-n选项来避免 tput --\u003e 初始化终端和/或从terminfo数据中获取有关它的信息。各种选项允许某些终端操作：tput clear等于clear；tput reset等于reset。 --\u003e tput可以用来对终端进行操作,更改字符显示方式等 reset 重置终端参数并且清屏 script 记录键盘敲击记录,执行该命令后,会在当前目录下生成一个文件,用于记录后面敲击的键盘记录 factor 后接一个数字,将该数字的各个因数打印出来 bc bash无法进行浮点数计算,且缺少一些重要的运算功能,bc可以满足部分需求 --\u003e bc可以用在脚本中,用来对变量进行计算获值variable=$(echo \"OPTIONS; OPERATIONS\" | bc) --\u003e 另外一种形式是结合here document的方式来作为输入 ---------------------------------------------------------------- \u003c\u003c EOF 18.33 * 19.78 EOF ---------------------------------------------------------------- awk 另外一种进行浮点数运算的方式是使用awk命令 ---------------------------------------------------------------- AWKSCRIPT=' { printf( \"%3.7f\\n\", sqrt($1*$1 + $2*$2) ) } ' # command(s) / parameters passed to awk # Now, pipe the parameters to awk. echo -n \"Hypotenuse of $1 and $2 = \" echo $1 $2 | awk \"$AWKSCRIPT\" ---------------------------------------------------------------- jot,seq 生成一个整数序列,用户可以自定义步长和分隔符 --\u003e seq -s : 5 指定分隔符为:,默认情况下是换行符 --\u003e jot和seq都可以用在for循环中 run-parts run-parts命令会执行目标目录下的所有脚本,默认依照ascii字母顺序执行,当然,脚本需要有执行权限 yes yes默认的动作为返回y及换行符到标准输出,需要使用ctrl+C来终止 --\u003e 使用yes string,则后面会不断重复出现string --\u003e 使用场景: yes | rm -r dirname tee 类似与重定向,但与重定向不同 (redirection) |----\u003e to file | ==========================|==================== command ---\u003e command ---\u003e |tee ---\u003e command ---\u003e ---\u003e output of pipe =============================================== mkfifo 命令创建一个命名管道,一个临时的first-in-first-out用于在不同的进程之间传递数据,一般情况下,一个进程向FIFO中写数据,另一个进程则从FIFO中读取数据 ---------------------------------------------------------------- (cut -d' ' -f1 | tr \"a-z\" \"A-Z\") \u003epipe2 \u003cpipe1 \u0026 ls -l | tr -s ' ' | cut -d' ' -f3,9- | tee pipe1 | cut -d' ' -f2 | paste - pipe2 rm -f pipe1 rm -f pipe2 ----------------------------------------------------------------  #14. 其他命令 groups 显示当前用户属于哪些组 lid 命令将显示给出的用户名所属的groups列表 logname 显示登录当前终端登录系统的用户名称,即使su之后,改命令仍显示为源用户 ac 显示用户登录的时长 newgrp 更改当前用户的组id而不需要登出系统 tty 显示当前终端所在的文件名称 stty 显示或者是更改终端的设置,改命令较复杂,在脚本中使用时,可以控制终端的行为以及其输出内容的形式 setterm 设置指定的终端属性,这条命令会更改输出到标准输出结果的显示情况 getty/agetty 使用getty/agetty来初始化终端进程,这些命令不能在脚本中使用,脚本中可使用的是stty lastcomm 显示上一条执行命令的一些相关信息,内容是存储在/var/accounut/pacct文件中的 strace(system trace) 用于诊断和debug系统调用的工具,该命令和ltrace可用来查找一个程序运行失败的原因 itrace(library trace) 用于诊断和debug库调用的工具 nc(netcat) nc工具集是一个用来连接和监听TCP/UDP端口的工具 dmesg 打印所有的系统启动日志信息到标准输出 size size /path/to/binary 会给出一个二进制文件的各个段大小,对于程序员来说,需要使用 logger 追加用户自定义的内容到/var/log/messages中去,普通用户也可以使用 --\u003e 该命令可以用来在脚本中增加debug信息到日志中 logrotate 该工具用于管理系统的日志文件,轮转,压缩,删除或者email发送等,一般是结合cron一起使用来实现日志管理的 fuser 获取当前正在访问给定文件,文件集,或者目录的进程(通过进程号显示) --\u003e 同-k选项一同使用时,杀掉这些进程,在插拔可移动设备的场景下使用较多 --\u003e 同-n选项一同使用时,获取到当前在访问指定端口的进程,与nmap一同搭配使用非常有用 ---------------------------------------------------------------- # nmap localhost PORT STATE SERVICE 25/tcp open smtp # fuser -un tcp 25 25/tcp: 2095(root) ---------------------------------------------------------------- nmap network mapper and port scanner,网络映射和端口扫描,查看指定主机开放的端口 sync 执行命令后,强制当前环境下,将buffer中的数据写入到磁盘中 losetup 创建或者配置loop设备 mkswap 创建一个swap分区或者文件,swap区域启动需要使用swapon命令 swapon/swapoff 启用/关闭swap设备 dumpe2fs 打印显示详细的文件系统相关信息,必须由root用户调用 hdparm 显示/更改磁盘参数,必须由root用户使用,错误使用很危险 badblocks 检查一个存储设备的坏块,在一个刚格式化后的设备或者备份文件时使用 lsusb,usbmodules 显示所有的usb设备信息 lspci 列出当前使用到的pci总线 chroot 顾名思义,更改当前的根目录位置 lockfile 属于procmail包的一部分,他创建一个lock 文件,用于作为一个标记文件存在,控制文件,设备或者资源的可获取性 flock 命令给文件设置一个锁信息的公告,当命令执行完成之后,其他命令或者进程才能操作刚才的文件 ---------------------------------------------------------------- flock $0 cat $0 \u003e lockfile__$0 # Set a lock on the script the above line appears in, #+ while listing the script to stdout. ---------------------------------------------------------------- --\u003e 与lockfile命令不同的是,flock命令不会自动创建一个lock文件 mknod 创建一个块设备或者字符设备(当在系统上新增了一个新的设备之后可能有必要这样做),MAKEDEV工具比mknod更容易使用,且具备相应的功能 MAKEDEV 用于创建设备文件的命令,必须由root用户来执行,文件保存在/dev下,是高级版的mknod tmpwatch 自动删除有一段时间没有被访问过的文件,通常结合cron一同使用,用于删除log文件 dump/restore dump命令是设计用于备份文件系统的命令,命令读取磁盘分区的裸数据并写一个二进制文件 ulimit 设置一个更高的系统使用极值 quota 显示用户或者组的磁盘配额信息 setquota 设置用户或者组的磁盘配额 depmod 生成模块依赖文件,通常会被启动脚本调用 ldd 显示一个可执行文件需要使用到的共享库依赖 watch 以特定间隔运行一个命令  特殊内容 #1. here document \u003c\u003c 可以结合vi一同使用,如下所示: ---------------------------------------------------------------- # Insert 2 lines in file, then save. #--------Begin here document-----------# vi $TARGETFILE \u003c\u003cx23LimitStringx23 i This is line 1 of the example file. This is line 2 of the example file. ^[ ZZ x23LimitStringx23 #----------End here document-----------# ---------------------------------------------------------------- 可以使用vi +n的形式指定文件打开后在第几行  ","description":"通过advanced-bash-scripting学习bash的笔记内容","tags":["bash","linux","基础知识"],"title":"learning bash via abs","uri":"/tech/basics/notes/bash%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"用户管理 ## 2017-11-12 ##\n redhat 禁止空密码用户登录 pwck 检查用户帐号完整性，依据 /etc/passwd useradd/groupadd -r 添加一个系统帐号/组，uid/gid 小于 500/1000，系统用户/组默认不存在家目录 newgrp 临时更改用户的初始组(登录到一个新组)，用户属于切换组时不需要密码，需要退出时使用 exit(newgrp 为登录属性)命令即可 用户在/etc/passwd 文件中保存的注释信息顺序-c，name,office,office-phone,home-phone 新增一个用户可完全使用手动添加的方式，涉及 4 个文件，/etc/{passwd,shadow,group,skel/*}，skel 目录下的文件全部复制后需要修改文件权限和属组;  权限管理 ## 2017-11-12 ##\n  普通权限\nr--\u003e 文本文件 cat,more,less; 目录文件 ls,不能使用 cd,ls -l; w--\u003e 文本文件 可写，可编辑，可删除; 目录文件 可在该目录下新建文件; x--\u003e 文本文件 判断运行方式，新启动一个进程; 目录文件，可在该目录下 ls -l,cd 进入，获取目录下文件的详细信息;   目录文件的执行权限不同于普通文件，具备了执行权限之后，才允许用户获取目录下的文件详情\nThe execute bit on a directory allows you to access items that are inside the directory, even if you cannot list the directories contents.\n   可使用 openssl 生成密码\n# 生成后的字符串可放入 /etc/shadow 文件中 $ openssl passwd -1 -salt '123456'   shell 类型\n登录式 shell: 正常通过某终端登录，su - USERNAME，su -l USERNAME; 非登录式 shell: su USERNAME，图形终端下打开的命令窗口，自动执行的shell脚本;   环境变量保存文件：\nprofile类文件: 设定环境变量，运行脚本或命令; bashrc类文件: 设定本地变量，定义命令别名;   重定向 ## 2017-11-16 ##\n 系统设定 默认输出设备：标准输出，STDOUT 1 默认输入设备：标准输入，STDIN 0 标准错误输出：STDERR，2  标准输入：键盘,标准输出：显示器 set -C 可以关闭重定向清空非空文件，set +C 关闭该功能；在-C 指定时\u003e|可强制清空 并无 \u0026\u003e\u003e 的追加重定向 cat 与重定向结合使用 cat \u003c\u003c END --\u003e Here Document cat \u003c\u003c END \u003e\u003e/\u003e 追加/创建文件  管道：把前一个命令的输出当作下一个命令的输入 tee ：ls /etc | tee /tmp/tmp.out  正则表达式 ## 2017-11-16 ##\n 元字符 .：匹配任意单个字符 []：匹配指定范围内的任意字符 [^]：匹配指定范围外的任意字符 字符集合：[:digit:],[:upper:],[:punct:],[:space:],[:alpha:],[:alnum:]  匹配次数 - *:匹配其前面的字符任意次 ?:匹配其前面的字符0次或1次 \\{m,n\\}:匹配其前面的字符至少m次,至多n次  位置锚定 ^:锚定行首,此字符后出现的任意字符必须出现在行首 $:锚定行尾,此字符前出现的任意字符必须出现在行尾 ^$:空白行 \\\u003c或\\b:锚定词首,其后面的任意字符必须作为单词的首部出现 \\\u003e或\\b:锚定词尾,其后面的任意字符必须作为单词的尾部出现 eg: egrep \"^(root|hadoop)\\b\" /etc/passwd  分组 \\(\\):括号中的内容作为一个整体,主要是作为后向引用. \\1:引用第一个左括号以及与之对应的右括号所包括的所有内容 \\2: \\3: eg: 1-\u003e grep \\(ab\\)* /tmp/tmpfile 2-\u003e he love his lover grep '\\(l..e\\).*\\1r' /tmp/tmpfile  默认情况下,正则表达式工作在贪婪模式下,尽可能多的匹配 grep/egrep -o 的使用（主要是正则表达式的使用） $ echo aaabbbccabababcaccaccacbabcbabbacbcacabcba | egrep -o '[abc]{1,3}' aaa bbb cca bab abc acc acc acb abc bab bac bca cab cba # 抓取出来的结果是在[]中三个字母的任意组合   扩展正则表达式 ## 2017-11-21 ##\n grep: 使用基本正则表达式定义的模式来过滤文本的命令； -A -B -C  扩展正则表达式:  字符匹配同基本正则表达式 次数匹配: *: ?: +:匹配其前面的字符至少一次 {m,n} 位置锚定同基本正则表达式 分组: ():分组 \\1,\\2,\\3,..... 或者: | 分组示例: grep -E '(C|c)at' test6.txt 匹配0-255之间的数字: \\\u003c([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\u003e  fgrep:不支持正则表达式,可快速搜索  bash scripts 1 ## 2017-11-21 ##\n shell 编程: 编译器,解释器 编程语言: 机器语言,汇编语言,高级语言 静态语言:编译型语言 强类型(变量) 实现转换成可执行程序 C,C++,JAVA,C# 动态语言:解释型语言 on the fly 弱类型 边解释边执行 PHP,SHELL,python,perl 面向对象 面行过程  变量:内存空间,被命名的内存空间 内存:编址的存储单元 变量类型:事先确定数据的存储格式和长度 字符 数值 整形 浮点型 bull类型:逻辑运算,与,或,非,抑或 与:只要一个为假,结果一定为假 或:只要一个为真,结果一定为真  shell:弱类型编程语言 强类型:变量在使用前,必须事先声明,甚至还需要初始化. 弱类型:变量用时声明.甚至不区分类型. 变量赋值:VAR_NAME=VALUE  bash 变量: 环境变量:作用与为当前shell及其子进程,export NAME=xxx 本地变量:整个bash进程 局部变量:作用域为当前代码块 位置变量: 特殊变量(系统变量): $?:上一个命令的执行状态返回值 程序执行,可能有两类返回值: 程序执行结果 程序状态返回代码(0-255) 0:正确执行 1-255:错误执行,1,2,127系统预留  脚本在执行时会启动一个子 shell 进程\n命令行中启动的脚本会继承当前 shell 环境变量;\n系统自动执行的脚本(非命令行启动)就需要自我定义各种环境变量; /dev/null --\u003e bit bucket 软件设备 撤销变量:用于回收资源,内存空间,unset VAR_NAME 默认情况下,bash 将所有变量均识别为字符串 脚本:命令的堆砌,按照实际需求,结合命令流程控制机制实现的源程序  bash scripts 2 ## 2017-11-21 ##\n bash 中如何实现条件判断 条件测试类型: 整数测试: 字符测试: 文件测试: 条件测试的表达式: [ expression ] [[ expression ]] test expression  整数测试: -eq:测试两个整数是否相等 -ne:测试两个整数是否不等,不等,为真;相等,为假; -le: -ge: -lt: -gt:  命令间的逻辑关系: 逻辑与: \u0026\u0026 第一个条件为假时,第二个条件不用再判断,最终结果已有; 第一个条件为真时,第二个条件必须得判断; 逻辑非: ||   软件包管理 rpm 1 ## 2017-11-21 ##\n1,应用程序\n程序,architecture 源代码--\u003e编译--\u003e链接--\u003e运行 程序: 库 静态 动态 静态链接 动态链接 共享库  2,程序组成部分:\n二进制文件 库 配置文件 帮助文件/usr/share/man /etc,/bin /sbin,/lib --\u003e 均不可使用单独分区,必须在根文件系统分区上,系统启动就需要使用的程序 /usr/ --\u003e 操作系统核心功能,可以单独分区(可以单独格式化根分区,在挂载/usr可使用) bin sbin lib /usr/local bin sbin lib etc man  3,/proc,/sys 不能单独分区,默认为空;\nproc接口,sys硬件接口  4,/dev:设备,不能单独分区\nudev:能够利用内核识别到的硬件信息,动态的创建设备名;内核识别设备是通过驱动程序来实现的;  5,/boot:内核,initrd(initramfs)\n内核: POST--\u003eBIOS(HD)--\u003e(MBR)bootloader(文件系统结构,ext2,ext3,xfs)--\u003e内核 /boot分区其实是先被访问后,启动内核再被挂载起来的 lvm是属于内核中的功能,所以尽量不要将boot分区与根目录放在一个分区上  5,程序=指令+数据\n指令:芯片 CPU:普通指令,特权指令 指令集:  6,软件包管理器:\na,打包成一文件:二进制文件,库文件,配置文件,帮助文件 b,生成数据库,追踪所安装的每一个文件  7,软件包管理器的核心功能:\na,制作软件包 b,安装,卸载,升级,查询,校验 c,RedHat,SUSE,Debian RedHat SUSE RedHat Package Manager RPM is Package Manager Debian:dpt  8,前端工具:yum(yellowdog update modifier),apt-get\n后端工具:RPM,dpt  软件包管理 rpm 2 ## 2017-11-27 ##\n1,rpm 命令:\nrpm: 数据库/var/lib/rpm rpmbuild:  2,安装,卸载,升级,查询,校验,数据库的重建,验证数据包等工作\n3,rpm 命名:\n包:组成部分 主包: bind-9.7.1-1.i586.el5.rpm 子包: bind-libs-9.7.1-1.i586.el5.rpm 包名格式: name-version-release.arch.rpm bind-major.minor.release-release.arch.rpm 主版本号:重大改进 次版本号:某个子功能发生重大变化 发行版:修正了部分bug,调整了一点功能 release1:开发者 release2:制作者  4,rpm 安装\n-h:显示安装进度,以#显示,每个#表示2%的进度 -v:表示详细过程 -vv:更详细的过程 --nodeps:忽略依赖关系 --replacepkgs:重新安装,替换原有安装 --oldpackage:使用就的软件包替换新的软件包 --force:强制安装,可以实现重装或降级  5,rpm 查询--\u003e rpm -q PKGS_NAME\n-qa:查询所有安装的软件包 -qi:查询指定软件包的说明信息 -ql:查询指定包安装后生成的文件列表 -qf:查询指定的文件是由哪个rpm包安装后生成的 -qc:查询指定的包安装的配置文件 -qd:查询指定包安装的帮助文件 -q --scripts:查询指定包中包含的脚本 -qp*:查询尚未安装的软件包的相关内容,承接已安装的软件包的查询内容  6,rpm 升级\n-Uvh: 如果装有老版本的,则升级;否则,则安装; -Fvh: 如果装有老版本的,则升级;否则,则退出; --oldpackage:降级  7,rpm 卸载\n-e:若有依赖关系,则不允许卸载  8,rpm 校验\nrpm -V PKG_NAME --\u003e检查文件在安装后是否被改动过  9,重建数据库\nrpm --rebuilddb:重建数据库(不管有没有都重建,一定会重新建立) rpm --initdb:初始化数据库(没有才建立,有就不重建)  10,检验来源合法性,及软件完整性\n加密类型: 对称:加密解密使用同一个密钥 公钥:一对密钥,公钥,私钥:公钥隐含于私钥中,可以提取出来,并公开出去; rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release rpm -K PKG_NAME dsa,gpg:验证来源合法性,也即验证签名;--nosignature略过 sha1,md5:验证包完整性;使用--nodigist略过 单向:  11，在 rescue 模式下安装 rpm 软件包\nrpm --ivh --replacepkgs --root /mnt/sysimage bash-××××  软件包管理 yum 1 ## 2017-11-28 ##\n1,yum\ncreaterepo --\u003e 创建元数据 XML:eXtended mark language xml,json:半结构化的数据  2,yum 仓库中的元数据文件:\nprimary.xml.gz a,包含所有rpm包的列表 b,依赖关系 c,每个rpm生成的文件列表 filelists.xml.gz a,当前仓库中所有rpm包的所有文件列表; other.xml.gz a,额外信息 repomd.xml a,记录的是上面三个文件的时间戳和校验和 comps*.xml.gz a,rpm包分组信息 更改了镜像中的包后，此文件需要重新生成  3,*.repo 文件\n[Repo_ID] name=Description baseurl= ftp:// http:// file:/// enabled={1|0} gpgcheck={1|0} gpgkey= ftp:// http:// file:///  4,yum 命令\nlist:列表 all:所有(默认) available:可用的 installed:已安装的 updates:可用的升级 clean:清理缓存 all: packages: headers: metadata: dbcache: install:安装 --nogpgcheck -y update:升级 update-to:升级至指定版本  5,createrepo\n-g comps*.xml /path  软件包管理 yum 2 ## 2017-11-28 ##\n1,rpm 安装:\n二进制格式: 源程序--\u003e编译--\u003e二进制格式 有些特性是编译选定的,如果编译未选定此特性,将无法使用 rpm包的版本会落后于源码包,甚至落后很多  2,rpm 包定制:手动编译安装\n前提:准备需要的环境编译环境,开发环境,开发库,开发工具 安装:\"development tools\"和\"Development libraries\" C,C++:静态语言,linux上最流行的开发环境 gcc:GNU C Complier,C g++: make:项目管理工具 makefile:定义了make(gcc,g++)按照何种次序去编译这些源程序文件中的源程序 automake --\u003e makefile.in(半成品) --\u003e makefile autoconf --\u003e configure(100个可选择特性,用户自定义哪些加入)  3,编译安装的三个步骤:\n# tar # cd # ./configure --help --prefix=/path/to/somewhere --sysconfdir=/path/to/conffile_path # make # make install 若指定了安装路径: 1,修改PATH环境变量,以能够识别此程序的二进制文件路径; a,修改/etc/profile文件 b,在/etc/profile.d/目录下建立一个以.sh为名称后缀的文件 2,默认情况下,系统搜索库文件的路径/lib,/usr/lib;要增添额外搜寻路径; 在/etc/ld.so.conf.d/中创建以.conf为后缀名的文件,而后把要增添的路径直接写至此文件中 a,默认情况下需要重启才能生效 b,可使用如下方式即时生效,ldconfig 通知系统重新搜寻库文件(-v显示重新搜寻库的过程) 3,头文件(#include):输出给系统 a,默认:/usr/include b,增添头文件搜寻路径,使用链接进行: ln -s /usr/local/tengine/include/* /usr/include/ 或者 ln -s /usr/local/tengine/include /usr/include/tengine 4,帮助文档路径:默认安装在--prefix指定的目录下的man目录 a,man -M /PATH/TO/MAN_DIR COMMAND b,在/etc/man.config中添加一条MANPATH c,可直接在man后接上准备需要查看相关帮助的文件的绝对路径 man /etc/passwd  4,netstat 命令\n-r:显示路由表 -a:监听和不监听的端口都显示出来 -n:不解析主机名 -t:显示tcp连接 -u:显示udp连接 -l:显示监听状态的连接 -p:显示监听指定的套接字的进程的进程号和服务名  磁盘管理 1 ## 2017-11-30##\n1,机械式硬盘：U 盘，光盘，软盘，硬盘，磁带\n2,文件名字并不保存在该文件的 inode 中，而是保存在文件夹的 block 中\na,文件系统是内核中的功能，可以说是一个软件  3,文件的 inode 保存内容有：block 号，属组，属者，权限，大小，时间戳\n4,找文件的步骤：\n 内核找到根目录的保存块（自引用）--\u003e 读取内容（权限） --\u003e 找到根目录中名为var的目录对应的inode号 --\u003e var目录inode号找到var目录保存块 --\u003e 读取内容（权限） --\u003e 找到var目录中名为log的目录对应的inode号 --\u003e log目录中找到名为messages的文件的保存块 --\u003e 读取内容 --\u003e 核对权限 --\u003e 读取文件\n 5,目录中存储的内容为：文件名和对应的 inode 号码（dentry 目录项）\n6,块位图（bitmap）：用来标记硬盘中块是否被使用（0 和 1 来表示）\n7,inode 位图（bitmap）：用来标记 inode 是否被使用（0 和 1 来表示，所以 8 个标记才记录为 1 字节）\n8,在系统中创建文件/backup/test.txt（文件大小 10k，文件系统块大小为 2k）：\na，扫描inode位图，分配一个空闲inode b，查看backup目录inode中权限情况，核查是否有权限增加文件 c，修改backup目录保存块的内容，增加一行 --\u003e test.txt与新分配inode号的条目 d，扫描块位图，分配8（假设）个块（多余的两个块用于后续的文件增长，防止文件增长后，保存块不连续的情况）  9,在系统中删除文件/backup/test.txt（文件大小 10k，文件系统块大小为 2k）：\na，找到文件保存目录所在的区块 b，删除目录区块中test.txt与相应分配inode号的条目 c，在inode位图中将文件的inode标记为未使用 d，inode找到文件对应的区块，在块位图中将相应的块标记为未使用  10,复制文件与剪切文件（同一个分区）速度相差比较大，原因为复制文件相当于新建文件;剪切文件仅更改文件名\n11,文件系统情况：\na，super block保存文件系统所有block group信息 b，block group保存块位图，inode位图，inode，block信息  12,（特殊文件）指向同一个 inode 的不同路径，称为硬链接，信息保存在目录文件中;ls -l 第二列显示的数字为硬链接的个数\n13,（特殊文件）一个指向另一个的路径（保存的是路径字符串），称为软链接，文件大小由字符个数决定，\n软链接权限为777,完全不影响源文件的权限  磁盘管理 2 ## 2017-11-30## 1,设备\n字符设备：按字符为单位，线性设备; 块设备：按块为单位，随机访问的设备;  2,/dev（特殊文件）\n主设备号（major number）：标识设备类型 次设备号（minor number）：同一种类型下的不同设备  3,创建设备文件（mknod）：连接入口，访问入口\nmknod OPTION NAME TYPE major minor -m：指定  4,格式化：\na，低级格式化：创建磁道 b，高级格式化：创建文件系统  5,文件系统：\na，FAT32在linux下称为vfat b，vfs（同文件系统一样，也是内核的功能）：virtual filesystem --\u003e linux下的虚拟文件系统，作用为提供统一的封装， 使得同样的命令能够在不同的文件系统上使用（例子：mkfs） 文件系统（软件）自己提供相应的调用（不同的文件系统，不同的调用;例如在ext2上是open1,在ext3可能就是open） 为了使软件能够专用于核心功能的实现，vfs把一些基础的调用封装起来 c，/var，/usr等单独分区，目录仍是存在于/目录下的，只是作为了一个入口，指向了第二分区。。。 d，挂在用目录独立于挂载分区存在，/var目录挂载分区sda2,但/var目录只存在于sda1  磁盘管理 3 ## 2017-11-30 ##\n1,用户模式：用户空间\n2,内核模式：内核空间\n3,文件在 linux 上存储，分为元数据和数据，元数据保存文件的属性，目录是完成文件路径的映射的\n4,cpu（intel，amd）分为四个环，内核在 ring0（特权指令）上运行，普通进程运行在 ring3（ring1,ring2 不使用，历史原因）\n5,文件系统上 block size：1024,2048,4096\n6,软链接，设备文件，管道文件，套接字文件其实都没有大小，占据的都是 inode 的空间\n7,超级块：用来存储文件系统中块组的信息，有多少个块组，块大小，已用块多少，可用块多少，空闲 inode，已用 inode\n8,一个块组能够有多少个块，取决于块的大小（块位图占用空间为 1 个块），一般一个块组的数量为一个块存储的位数（1×1024×8）;创建块组的原因为，在一个很大的文件系统上，就算有块位图，去寻找也会很麻烦，所以再切割，减小找寻时间\n9,块组描述符：用于存储 superblock 无法存储下的各块组信息，含有备份\n10,任何一个分区的第一个块不能被使用，名字为 boot block，在多引导的情况下需要被使用到\n11,mbr（master boot recoder 程序）不属于任何分区，是盘的第一个扇区（sector）\n12,分区的构成为：boot block + n 个 block group\n13,每个 block group 组成为 super-block+GDT+block-bitmap+inode-bitmap+inode-table+data-block\n14,每个 block group 均有一个 super block 太浪费空间，后更改为少量的备份，比如 1,5,7,当第一个损坏后，会自动寻找下一个\n15,GDT（group description table）块组描述符表，记录边界信息等\n16,占据块空间的文件主要是目录文件和普通文件\n17,ext3（日志文件系统）：相对于 ext2 文件系统来说，除去元数据和数据区，多出一个日志区（功能为在存储数据时突然断电，开机后能够直接发现文件所在位置，减少文件系统修复的时间），在存储文件时，inode 先放在日志区而不是在元数据区，存储完成后才被移到元数据区去;基于以上的情况，在写操作时 ext2 的速度会快过 ext3（很小）,读操作时无影响。\n18,位图索引，oracle 使用，备注\n磁盘管理 4 ## 2017-12-05 ##\nrhel6与rhel5有差异，在执行命令时，先确认命令使用\n1,重新创建文件系统会损坏文件\n2,创建文件系统完成后，使用 cat /proc/partitions 用于查看是否已经被内核识别，若为识别，使用 partprobe 命令\n3,使用 cat /proc/filesystems 查看当前内核支持哪些操作系统\n4,mkfs 完成系统分区后，在输出的提示信息中能看到，系统会预留 5%的空间给超级用户，用于当系统空间使用完后，仍保留部分空间给 root 用户进行修复工作（这个可以调整） 5,mkfs -t ext2 = mkfs.ext2;mkfs 为一个统一调用格式化命令的接口\n6,专门管理 ext 系列文件系统：mke2fs，直接创建文件系统;\n-j 创建ext3文件系统 -b 创建指定块大小 -L 指定分区卷标 -m 指定预留给超级用户的块百分比 -i 用于指定为多少字节的空间创建一个inode，默认为8192;给出的数值应为块大小的2××n倍 -N 指定要创建的inode的个数  7,查询或查看磁盘设备的相关属性：blkid\nUUID TYPE LABEL  8,用于查看或定义卷标：e2label\n9,调整文件系统的相关属性：tune2fs\n-j 不损坏文件的情况下，将ext2升级为ext3 -L 用于设定卷标 -m 调整预留百分比 -r 指定预留块数 -o 设定默认挂载选项 -c 指定挂载次数达到#后进行自检，0或-1表示关闭此功能 -i 指定挂载多少天后进行自检，0或-1表示关闭此功能 -l 查看super block中的信息  10,显示文件系统相关信息：dumpe2fs\n-h 仅显示super block中的信息 dumpe2fs和tune2fs无法对包含在lvm中的设备进行查看，可以查看lv的 可以显示详细的信息内容  11,检查并修复 linux 文件系统 fsck\n-t # 指定文件系统格式 -a 自动进行修复，不需要交互的模式下进行  12,专门用于检查修复 ext2/3 文件系统：e2fsck\n-f 强制检查 -p 自动修复  13,挂载：将新的文件系统关联至当前根文件系统\n卸载：将某文件系统取消与当前根文件系统的关联 mount：设备 挂载点 设备文件： /dev/sd× UUID：uuid=“” LABEL：label=“” 挂载点： 1,此目录未被其他进程使用  14,mount 使用\n-a 挂载/etc/fstab文件中定义的所有文件系统 -n 默认情况下，mount命令每挂载一个设备，都会把挂载的设备信息保存至/etc/mtab文件中;使用-n选项意味着挂载设备时， 不把信息写入该文件中 mount -n 的效果类似于cat /proc/mounts -t 指定挂载的文件系统格式，省略时，mount会从blkid命令读取 -o 指定额外的选项 async 默认选项，异步写入，可提高读写性能 atime 每访问一次文件，都将访问时间更新一下，繁忙的服务器不建议使用该选项 _netdev 指若为网络共享设备，当开机时无网络，可跳过 remount 重新挂载 loop 挂载本地回环设备，光盘镜像 --bind --move  磁盘管理 5 ## 2017-12-05 ##\nrhel6与rhel5有差异，在执行命令时，先确认命令使用\n1,page out：内存中数据移到 swap 空间中\npage in ：swap空间中的数据移到内存中 swap out：对应page in swap in ：对应page out  2,buffer 与 cache：\nbuffer缓冲--\u003e 蓄水池，照顾吞吐量小/慢的设备;保存元数据--\u003e 查找/var/log/messages，查找中用到的数据 cache：缓存--\u003e 保存数据，用于重复读取，加快读取性能;保存数据--\u003e 块内保存的数据  3,fdisk 分区后，注意必须调整分区类型，不然错乱后，可能会导致后期管理的混乱\n4,swap：交换分区\nmount -t swap /dea/sda8 swapon /dev/sda8 -a 启用所有定义在/etc/fstab下的设备文件 swapoff /dev/sda8  5,回环设备：loop\n使用软件来模拟实现硬件  6,复制和转换文件：dd\nif=数据来源 of=数据存储文件 dd if=/etc/inittab of=/root/inittab dd复制的为底层的数据流，底层的10...,直接操作的是底层的存储设备 cp复制为文件复制，是基于操作系统之上才能使用的 dd if=/dev/zero of=/tmp/swapfile bs=1M count=1024 seek=1023 创建的文件大小问1M，但在系统识别为1G，使用du能看占用的磁盘空间大小 seek=# 表示创建文件时，跳过多大空间  7,/etc/fstab\n设备 挂载点 文件系统类型 挂载选项（默认为defaults） 转储频率（每多少次做一次完全备份） 文件系统检测顺序（只有根可以为1）  8,设备被占用而无法卸载时，可以使用 fuser -v 来查看被谁占用，命令是什么，进程号是多少\n9,fuser：验证进程正在使用的文件或套接字\n-v：显示占用 -k：中止占用的进程 -m：对挂载点和目录使用 fuser -mk /directory  lvm管理 1 ## 2017-12-05 ## rhel6与rhel5有差异，在执行命令时，先确认命令使用\n1,MD，DM\nDM：device mapper将多个硬件设备映射为逻辑设备 LVM2 快照 多路径 可实现动态增减  2,LVM2：\nPE：physical extend;物理卷只有加入卷组之后才有PE LE：logical extend;  3,fdisk 可支持 15 个分区，不知道在 6 当中有没有提升 2\nlvm管理 2 ## 2017-12-07 ##\n逻辑边界包含在物理边界内\n1,扩展逻辑卷\nlvextend -L [+]# /PATH/TO/LV resize2fs -p /PATH/TO/LV --\u003e 能有多大就扩展到多大  2,缩减逻辑卷\n注意： a，缩减逻辑卷的风险很大，不要随便进行该操作 b，不能在线缩减，请先卸载 c，确保缩减后的空间大小依然能够存储原有的所有数据 d，在缩减之前应该先强行检查文件系统，以确保文件系统处于一致状态; df -lh --\u003e umount --\u003e e2fsck -f --\u003e resize2fs /PATH/TO/LV --\u003e lvreduce -L [-]# /PATH/TO/LV  3,快照卷\n1,生命周期为整个数据时长：在这段时间内，数据的增长量不能超出快照卷大小; 2,快照卷应该为只读 3,快照卷必须与备份卷在同一个卷组中 4，快照卷也是一个lv，注意，它可以被挂载 5，生命周期结束，lvremove /PATH/TO/LV lvcreate -L 50M -n S_NAME -s -p r /PATH/TO/LV lvcreate -s：创建 -p：r|w 权限，只读  mdadm管理 1 ## 2017-12-07 ##\n1,颜色设置：\necho -e \"\\033[1;37;41mHello\\033[0m world!\" -e：启用脱意符 \\033：表示ctrl \\033[31m：red \\033[32m：绿色 \\033[33m：yellow \\033[34m：blue [x,y,zm：x为1-9,表示为不同的显示方式，粗体、斜体等;yz为不同颜色的代号（y表示前景色,z表示背景色） [0m：表示显示结束 read -p -e \"\\033[1;37;41mYour choice :\\033[0m\"  2,计算机的核心主件：\na，cpu b，内存 c，输入/出设备  3,设备接口转换，光电转换器，网卡等\na，集成在主板上的叫做controller（控制器） b，需要外接进来的叫做adapter（适配器）  4,计算机中发出的 01 信号，指定在各不同位代表的含义，称之为协议\na，双方都遵循的方式  5,IDE 和 SATA 接口（1MB=8Mb）\nIDE：133Mbps 理论值 并行 a，一个IDE控制器上能够连接2个IDE盘 SATA（1-3）：300Mbps，600Mbps，6Gbps 串行 a，一个SATA控制器只能连一个SATA盘 USB（1.0，2.0,3.0）：480Mbps（3.0）并行 SCSI(small computer system filesystem)：ultrascsi 320Mbps 串行 --\u003e 以前工业生产用，速度快，功能强大 a，scsi基于IDE接口 b，数据在scsi上传输存储时，也是以包的形式进行传输的 外接的设备成为target;分为两种： 窄带--\u003e 8 --\u003e 1 initiator，7 targets 宽带--\u003e 16 --\u003e 1 initiator，15 targets SAS：更小  6,RAID\na，级别：仅代表磁盘组织方式不同，没有上下之分 b，raid1+0和raid0+1是不一样的概念，有先后之分;raid10好于raid01 0：条带 性能提升，读写性能都有提升;但不提供冗余功能，无法容错，空间利用率100% 1：镜像mirror 写性能下降，读性能提升;具有冗余能力，可以容错，空间利用率50% 2： 3： 4：校验码（校验盘容易成为瓶颈） 5：校验码（轮流做校验盘） 读写都提升;具备冗余能力，空间利用率（n-1）/n 10： 01： 50：先5后0 空间利用率（n-2）/n;最少需要6块盘 c，jbod：简单的将多个盘叠加成一个大的盘（适用于hadoop） 性能提升无；冗余能力无；空间利用率100%  mdadm管理 2 ## 2017-12-07 ## 硬件 RAID 和软件 RAID\n1,MD：multi disks\n2,逻辑 RAID（软件 RAID）\na，制作了软RAID设备文件后，必须选择类型为fd，因为这个逻辑RAID依赖于系统;当系统损坏后，可能导致之前的数据不可使用; 标识为fd设备后，在保存数据后会写入一些元数据，以便在重装系统后加载模块直接使用 b，软RAID不建议配置（生产环境），可能导致数据丢失，要考虑是否可以接受这个结果 c，需要模块md d，mdadm：将任何块设备做成RAID 模式化的命令： 1,创建模式（-C） 专用选项： -l：级别 -n：设备个数 -a：自动为其创建设备文件 -c：chunk大小，2的n次方，默认为64K -x：指定空闲盘 2,管理模式 --add mdadm --manage /dev/md0 --fail /dev/sdb1 mdadm --manage /dev/md0 --remove /dev/sdb1 3,监控模式（-F）， 4,增长模式（-G）， 5,装配模式（-A） 6,查看信息（-D）  3,创建 raid0：\na，raid0需要使用的两个盘必须大小相同 b，mdadm -C /dev/md0 -l 0 -n 2 /dev/sda{5,6}  4,创建 raid1：\na，raid1需要使用两个盘的大小必须相同  5,mdadm --detail（-D） /dev/md1 查看 md1 的详细信息\n6,mdadm --stop（-S）/dev/md1 关闭使用\n7,mdadm -D --scan \u003e /etc/mdadm.conf\nlinux 文件查找 ## 2017-12-11 ##\n1，locate\na、非实时，模糊匹配，查找是根据全系统文件数据库进行的; b、手动生成文件数据库，updatedb（可能需要很长时间）; c、速度快;  2，find\na、实时 b、精确 c、支持众多查找标准 d、遍历指定目录中的所有文件完成查找，速度慢 e、find 查找路径 查找标准 查找到以后的处理动作 查找路径：默认为当前目录 查找标准：默认为当前目录下的所有文件 处理动作：默认为显示  3,find 匹配标准\n-name ‘filename’：对文件名做精确查找 文件名通配： ×：任意长度任意字符 ？ [] -iname ‘filename’：查找文件名不区分大小写 -regex PATTERN：基于正则表达式进行文件名匹配 -user USERNAME：根据文件名查找 -group GROUPNAME：根据组名 -uid UID：使用uid进行查找 -nouser：查找没有属主的文件 -nogroup：没有属组的文件 -type f：普通文件 b，c，s，p d：目录文件 -size [+|-]k，M，G：省略+|-为精确查找，+为大于，-为小于 find -size 10M --\u003e 显示的是9-10M之间的文件，  4,find 组合条件\n-a find -type d -a -nogroup -o find -type d -o -nogroup -not find -not -type d find -not -type d -a -type s  5,find 时间戳查找\n-mtime：修改时间 -ctime：改变时间 -atime：访问时间 [+|-] #单位为天 -amin：单位为分钟 -cmin：单位为分钟 -mmin：单位为分钟 [+|-] #单位为分钟  6,find 使用权限来查找\n-perm： mode：必须精确匹配 -mode：文件的权限完全包含该mode时才匹配 /mode：9为权限位中只要一位匹配即可  7,find 动作：\n-print：显示（默认） -ls：类似ls -l的形式或显示每一个文件的详细情况 -ok ls {} \\; --\u003e 每一次操作都需要用户确认 -exec chmod u-w {} \\; --\u003e不需要用户确认 eg： find ./ -perm -020 -exec mv {} {}.new \\;只要引用文件的文件名，都需要使用{}。 find / \\( -nouser -o -nogroup \\) -a -atime -1 -exec chown root:root {} \\; find /etc/ -mtime -7 -a -not -user root find /etc/ -size +1M \u003e /tmp/etc.largetfiles find /etc/ -size +1M -exec echo {} \u003e\u003e /tmp/etc.largefiles \\; find /etc/ -size +1M | xargs echo {} \u003e\u003e /tmp/etc.largefiles find /etc/ -not \\( -perm -002 -o -perm -020 -o -perm -200 \\) -ls find /etc/ -not -perm -002 -a -not -perm -020 -a -not -perm -200 -ls find /etc/ -not -perm /222 -ls  linux special permission ## 2017-12-11 ##\nSUID：运行某程序时，相应进程的属主是程序文件自身的属主，而不是启动者;\nchmod u+s FILE 如果FILE本身原来就有执行权限，则SUID显示为s;否则显示为S  SGID：运行某程序时，相应进程的属组是程序文件自身的属主，而不是启动者;\nchmod g+s DIRECTORY 在文件夹下面创建文件，文件的属组将继承文件夹的属组  Sticky：在一个公共的目录中，每个都可以创建文件，删除自己的文件，但不能删除别人的文件\nchmod o+t DIR chmod o-t DIR  umask 0002：第一位对应的是特殊权限位\nlinux facl permission ## 2017-12-12 ##\n1,FACL--\u003efilesystem access control list\n利用文件的扩展保存额外的访问控制权限  2,setfacl：\n-m：设定 [d]： u：UID：perm [设置默认] [d]： g：GID：perm [设置默认] -x：取消 u：UID g：GID 文件权限顺序： Owner--\u003eGroup--\u003eOther Owner--\u003efacl，user--\u003eGroup--\u003efacl，group--\u003eOther  3,ls -l 显示文件最后具有+\n归档具有facl属性的文件，很可能文件facl属性被取消，未被归档进去;需要使用特定的命令和选项才行  linux terminal ## 2017-12-12 ##\n1,whoami\n2,终端类型：\nconsole：控制台--\u003e直接连到设备的硬件 pty：物理终端（VGA显卡） tty#：虚拟终端（VGA显卡） ttyS#：串行终端 pts/#:伪终端（伪文件系统）  3,su 过去的用户不是登录用户，虽然有效用户是期望用户（whoami 有效用户/who 登录用户）的差别\nw：显示哪些用户登录并且正在执行的命令是什么 who：显示哪些用户登录 whoami：显示当前有效用户是哪个  4,显示过去登录情况信息\nlast：显示/var/log/wtmp显示系统的用户登录历史和重启历史 last -n 显示近期几次的信息 lastb：显示/var/log/btmp显示系统上错误的登录尝试信息last（b：bad） lastb -n 显示近期几次失败登录信息 lastlog：显示每一个用户的最近一次的登录信息 lastlog -u username显示特定用户最近的登录信息 basename：直接获取一个文件或路径的基名 $0：执行脚本是的脚本路径及名称 mail：邮件使用 -s：指定主题 cat /etc/fstab | mail -s ‘How are you？’ root hostname：显示当前主机的主机名 $HOSTNAME：系统环境下的主机名变量 $RANDOM：保存0-32768之间的随机数  5,随机数生成器：熵池（要用到的时候就被那走了，不是复制），大量的加密软件需要用到该随机数\n/dev/urandom（软件模拟）:可能被攻破，但数量可大量获取 /dev/random（cpu中断，敲键盘间隔时间获取）:安全系数高，但量少，可能导致进程堵塞  linux sed ## 2017-12-16 ##\n1、linux 下需要掌握的三大文本处理器：grep、sed、awk\nsed：流编辑器 awk：报告文本生成器  2、sed 的基本用法（string editor）：只用于处理纯 askii 文本\na、逐行处理（行编辑器）：每次读取一行到内存当中，在内存中处理，而后将模式空间打印至屏幕 b、在内存中占用的空间称之为模式空间 c、默认情况下，sed仅处理模式空间中复制的文本，不更改源文件 d、命令格式： sed ‘AddressCommand’ file ... address和command之间不需要空格间隔 -n：静默模式，不再默认显示模式空间中的内容 -i：直接修改源文件 -e SCRIPT -e SCRIPT：可以同时使用多个脚本 -f /PATH/TO/SCRIPT：读取sed脚本文件 sed -f /path/to/script file -r：表示使用扩展正则表达式（未加该参数，默认使用基本正则表达式） Address： 1、StartLine，Endline --\u003e 1,100 $:最后一行 $-1：倒数第二行 2、/RegExp/做模式匹配，内部有特殊字符时，需要转意 --\u003e /^root/ 3、/pattern1/,/pattern2/ --\u003e 第一次被pattern1匹配到的行开始，到第一次被pattern2匹配到的行结束 这中间的所有行 4、LineNumber 指定的行 5、StartLine,+N 从StartLine开始，往后的N行 Command： p：打印符合条件的行（默认），使用该命令时，会将匹配的内容打印两次（结合sed默认行为） sed '1,+2p' /etc/fstab d：删除符合条件的行 sed '1,$d' /etc/fstab sed -i '/pattern to match/d' ./infile sed -i '/^abc/,+4d' ./xxxfile # To directly modify the file (and create a backup): sed -i.bak '/pattern to match/d' ./infile a \\string：在指定的行后面追加新行，内容为“string” sed '/^\\//a \\#hello world \\n #hello linux' /etc/fstab i \\string：在指定的行前面追加新行，内容为“string” sed '/^\\//i \\Hello.....' /etc/fstab r FILE：将制定的文件的内容添加至符合条件的行处 sed ’$r /etc/issue' /etc/fstab sed ’1,2r /etc/issue' /etc/fstab w FILE：将地址指定范围内的内容另存至指定的文件中 sed ’/oot/w /tmp/oot.file‘ /etc/fstab s/pattern/string/:pattern可以使用正则表达式，string不能(/可以替换成其他的符号） sed ‘s/oot/OOT/’ /etc/fstab sed ‘s/^\\//#/' /etc/fstab（默认替换每行中第一次被模式匹配到的字符串） sed ‘s/^\\//#/g' /etc/fstab 加修饰符： g：全局 i：忽略大小写 后向引用：\\(\\),\\1,\\2,.. sed ’#\\(l..e\\)#\\1r#g' sed.txt --\u003e like替换成liker \u0026：引用模式匹配到的内容 sed ‘s#l..e#\u0026r#g' sed.txt --\u003e like替换成liker 有些时候只能使用后向引用而不能使用\u0026符号，当要替换匹配内容中的内容时 sed ‘s#l\\(..e\\)#L\\1#g’ /etc/fstab  linux 归档 ## 2017-12-16 ##\n1,linux 下常用的压缩格式：gz，bz2,xz，gzip，Z\n2,压缩的方式，使用替换的方式进行，abcd--\u003e将 a 替换成 1,后续全部采用该方式\n算法不同，压缩比也不相同  3,gzip：.gz\ngzip /path/to/somefile：压缩完成后会删除源文件 gzip -d /path/to/somefile：解压缩 gzip -#：1-9，指定压缩比，默认为6; gunzip：解压缩，解压完成后删除源文件  4,zcat：在不解压的情况下查看文本文件内容，zcat /path/to/somefile\n5,bzip2：.bz2 比 gzip 有着更大的压缩比，使用格式近似\nbzip2 /path/to/somefile -k：压缩时保留源文件 bunzip2 /path/to/somefile ... ... bzcat：不解压的情况下查看文本文件内容  6,xz：.xz 压缩比更大\nxz /path/to/somefile -k：压缩时保留源文件 unxz /path/to/somefile xzcat：不解压的情况下查看文本文件内容 默认这些压缩软件压缩完文件会删除源文件  7,zip：大多数系统默认支持的工具，既归档又压缩的工具\nzip FILENAME.zip FILE1 FILE2 ... 默认保存源文件 unzip filename.zip  8,tar：归档工具，只归档不压缩\n-c：常见归档文件 -f FILENAME.tar：操作的归档文件 -x：还原归档，归档文件不动 --xattrs：zai归档时保留文件的扩展文件属性 -t：不展开归档，直接查看归档了哪些文件 -zcf：调用gzip归档并压缩 -zxf：调用gzip解压缩（-z可省略，下同） -jcf：调用bzip归档并压缩 -jxf：调用bzip归解压缩 -Jcf：调用xz归档并压缩  9,cpio：归档工具（比较特殊，在/boot/×.img 文件需要使用）\n10,脚本编程结构：\na、顺序 b、循环 for while until c、选择 if case  linux network 1 ## 2017-12-21 ##\n1、电磁信号\n2、协议\n3、网卡速度需要转换\n4、计算机通信模型：线路、网卡、数据流大小\n5、常用网络模型：\na、总线网络：需要用到线路仲裁，防止通信冲突，一根总线，各台机单独连接上这根线 批注 -- 总线网络基础推出网桥，相当于是网桥上的每两个口互连时只有这两台机占用‘总线’ b、环状网络：主机以环形的方式连接成网络，令牌在哪台机上主机才能发送信号（IBM专利） c、星型网络：需要有集线器（HUB），可以理解为变形的总线，线变成了一个设备  6、MAC：media access control（MAC 地址）\n7、单播与多播：\n多播：一对多的形式 单播：一对一的形式  8、CSMA/CD：carrier sense multipath access collision detection（载波侦听，多路访问，冲突检测） 具有该特征的称为以太网，以太网的标志; Ethernet --\u003e 以太网 9、信号的传输受线路的长度影响，若太长，电阻会减弱信号。此时需要中继器来增强信号，将信号放大之后再传输。\n10、当总线网络大到一定程度后，需要拆分为多个小的总线网络。当分属于两个不同总线网络的主机需要通信时，需要借助网桥来进行通信。\n11、网桥内部存有一个网络和主机对应的信息表，因此在数据传输时，能够正常不出错\na、网桥极端，就是一台主机一个总线网络，两台主机之间发信号，不影响其他主机之间的通信 1、半双工，A给B发信号的时候，B不能给A发;同轴线 --\u003e 对讲机 2、全双工，可以同时互相之间发信号;双绞线 --\u003e 电话 b、变成了交换机，只能的体现在内部的信息表 c、任何一台主机在实现通信之前，新来的成员，让大家认识，都要喊一嗓子，广播寻人 d、交换机（网桥）并不能隔离广播，在主机发出广播之后，交换机必须转发广播;隔离的是冲突，冲突域的概念 e、当一个交换机上连接的主机数很多，因为通信需要广播，会导致很多的问题，所以此时需要再次细分网络 f、细分网络后，交换机与交换机之间增加一个设备，称之为网关设备， g、源ＭＡＣ为自己的ＭＡＣ地址，目标ＭＡＣ则是ｆｆｆｆｆｆｆｆ，交换机（网桥）无条件转发 总线网络(一条总线接多台设备) --\u003e 多个总线网络(网桥连接多个小的总线网络) --\u003e 多个总线网络(一条总线一台设备,全双工,互传不影响) --\u003e 交换机  12、以上所讲均为平面地址（物理地址，基于 MAC 地址）;交换机之间通信引入另一个地址（逻辑地址，基于 IP 地址）\na、MAC地址的工作机制就是基于广播的 b、交换机接收到报文之后不做任何处理，直接转发出去 c、网管设备在接收到报文之后，需要先处理 d、网络传输包的形式： 1.1 | 2.1 -\u003e 1.1 | 2.1 | A | R1 -\u003e 1.1 | 2.1 -\u003e 1.1 | 2.1 | R2 | M 1.1 | 2.1的作用是在网络之间传输数据包 ｅ、网关设备连接交换网络  13、网络类型\na、环型网络中，环状网路中有一个token，在没有传输时，令牌游走在环状网路中，当有机器需要传输时，拿到令牌开始发送 b、星型网络中，居中的设备是一个HUB，在整体结构上来说，仍属与总线型网络  14、网络的进化\n总线网络 -- 集线器连接网络（星型网络） -- 网桥连接网络 -- 网桥（交换机VLAN）连接网络 a、总线用于联通，只满足各pc之间可以通信的功能 b、星型网络，仍只是满足各pc之间通信的功能，只是网线变成了一个设备 c、为了隔离冲突域，出现了网桥，可以将网络细分，减少每个总线网络中的主机数;当到达极致时，就是一台主机一个总线网络 d、当网桥上连接的总线网络过多时，因不能隔离广播，会导致各种问题;此时就出现了VLAN的概念（可隔离广播）  15、几种设备的差别\na、集线器：创建一个冲突域和广播域 b、网桥：网桥分割冲突域，但只形成一个大型广播域，使用硬件地址来过滤网络 c、交换机：交换机是一个更智能的多端口网桥，可以分割冲突域，淡漠人创建一个大型广播域，交换机使用硬件地址来过滤网络 d、路由器：路由器分割冲突域和广播域，并使用逻辑地址过滤网络;路由器执行分组交换、过滤和路径选择，帮助完成互联网通信 - 冲突域: 是一个以太网术语,指的是这样一种网络情形 -\u003e 某台设备在网络上发送分组时,当前网段中的所有其他设备都必须注意到这一点 - 广播域: 同一网段中所有设备的集合,这些设备侦听该网段中发送的所还有广播  linux network 2 ## 2017-12-23 ##\n1、当增加了网关设备之后，有了逻辑地址，同一个交换网络之间的通信也通过逻辑地址来进行\n2、最底层的通信仍然是依赖于 MAC 地址通信，此时引入一个概念，ip 地址和 MAC 地址之间的转换，ARP 协议，地址转换协议\n5、路由器隔离广播\n3、总线网络下，最多只能有一路信号发送，不然会发生冲突\n4、网桥可以理解为就是两个口的交换机\n5、路由器隔离广播\n6、IP 和端口绑定起来，称之为 socket（套接字）IP：port\n7、协议分层（OSI 模型）\n8、各种设备的差别：\n总线：一条网线，一次只允许单台机单向通信 集线器：多个网线接口，可以连接多条网线，每次只能允许两个接口直接的单向通信;可理解为变形的总线，线变成了一个设备 简单交换机：可理解为复杂化的集线器，多个网线接口，可以连接多条网线，但可允许同时多个接口对（两两之间）互相通信 网桥：隔离冲突域的作用，主要是用来联通各个网段 路由器：  9、分辨一台设备工作是在 OSI 模型的第二层还是第三层，最主要的区别的是看是否具有路由选择功能。\n10、网桥工作在 OSI 模型的第二层：数据链路层，因为网桥不具备路由选择功能。\n11、面向连接的网络服务和无连接网络服务\na、面向连接的网络服务使用确认和流量控制来建立可靠的会话;相较无连接服务而言，开销更高 b、无连接服务用于发送无需进行确认和流量控制的数据，但不可靠  12、OSI（Open system interconnection 开放系统互联）七层模型\na、应用层、表示层和会话层属于上层，负责用户界面和应用程序之间的通信 b、传输层提供分段、排序和虚电路（三次握手建立的东西之类的） c、网络层提供逻辑网络编址以及在互联网络中路由的功能 d、数据链路层提供了将数据封装成帧并将其放到网络介质上的功能 e、物理层负责将收到的0和1编码成数字信号，以便在网段中传输  bash scripts 3 ## 2018-01-16 ##\n1、执行结果不是执行状态结果，这个要搞清楚\n2、shell 中怎样进行运算\nA=3;B=6 a、let加上算数表达式 let C=$A+$B b、$[算数表达式] $[$A+$B] c、$((算数运算表达式)) $(($A+$B)) d、expr 算数运算表达式：表达式中各操作数及运算符之间要有空格，而且要使用命令引用 D=$(expr $A + $B) e、圆整，丢弃小数点后数字  3、脚本中分区块判断是否需要执行下去，如果达不到条件，则没有必要继续执行下去，浪费系统资源\n如果系统中没有某个用户，则不需要在后续继续做基于该用户名字的判断和操作  bash scripts 4 ## 2018-01-16 ##\n1、exit\n退出脚本，返回脚本执行结果状态值，可自定义;如果没有明确定义退出状态码，那么最后一条命令的退出码即为脚本的退出码  2、学习完成后，需要单独整理完成，成为一篇单独的博客\n3、bash 中常用的条件判断有三种\n整数测试：这种情况做对比，需要使用中括号 -gt -lt -le -ge -ne -eq 文件测试： -e FILE：是否存在，单目操作 -f FILE：测试文件是否为普通文件 -d FILE：测试指定路径是否为目录 -r/w/x FILE：测试当前用户对指定文件是否具有r/w/x权限  4、测试方法：\n[ expression ] --\u003e命令测试法，[为命令 [[ expression ]] --\u003e关键字测试法，[[为关键字 test expression --\u003etest命令测试  5、bash 相关参数\nbash -n scripts：不能作为依据，模糊参考作用 bash -x scripts：单步执行，可用来做测试，检验脚本中的错误  6、bash 变量的类型：\n本地变量（局部变量） a=1这种方式定义 环境变量（当前shell进程及其子进程） export a=1这种方式定义 位置变量： $1,$2 ... shift:位置参数的更改，执行一次shift（不加数字），位置参数向左移一个 特殊变量： $?: $#:参数的个数 $*:参数列表 $@:参数列表  bash scripts 5 ## 2018-01-18 ##\n1、字符测试：\n==：测试是否相等，在[[]],[]中使用时，=两端需要有空格，否则变成了赋值运算 ！=：测试是否不等，不等为真，相等为假 \u003e \u003c -n string：测试指定字符串是否为空，空则真，不空则假 -s string：测试指定字符串是否为空，空则假，不空则真  2、bc 的使用\n脚本中可以使用两种方式传递参数给bc bc \u003c\u003c\u003c ‘xxxxx;xxxx’ echo “scale=2；222/333” | bc  3、循环：进入条件、退出条件\nfor巡检 seq [start [length]] last declare声明： -i：声明为整数 -x：将一个变量声明为环境变量 while循环 until循环  bash 进程管理 1 ## 2018-01-22 ##\n1、内存：\n线性内存： 32bit： 进程开始即给自己分配4G大小的空间，1G留给内核，剩余均认为属于自己 物理内存  2、接口\n内核空间：涉及到敏感信息均由内核空间进行 内核需要记录追踪每一个进程的运行状态信息，明确知道当前系统运行多少个进程 用户空间  3、内核数据结构（task structure）\n保存在内核当中，用于记录追踪进程状态信息（每一个进程都有）;进程执行到一半（mkdir为例），交接了，执行完交接、 任务后重新开始、依赖于此（可类比于主持人控制流程，不同人上台表演） PPID： PID： name： ... 哪里停止，哪里重新开始  4、MMU（memory management unit）内存管理单元：\n进程的页面数据对应到物理内存（页框）的位置，每一次转换都是由MMU负责完成  5、进程上下文切换（context switch）\nVSZ（virtual size）虚拟内存集 RSS（resident size）常驻内存集  6、cpu 多核也不能同时执行指令，而是在每一个 cpu 核心排队的队列减少\n多线程CPU（mysql多个用户同时发出请求为例） 一个进程下面分为多个线程  7、线程及进程的区别\n线程的优势：还是以mysql为例，三个线程可以共用打开的文件，三个进程则在内存中需要打开文件三次，占用三倍空间 线程的劣势：多个线程在共用一个文件，一个线程在写文件，该文件则被锁，其余线程需要等待释放，cpu不断检查浪费资源  8、进程状态\nuninterruptable sleep：不可中断睡眠，需要调用的外部资源仍然未得到满足，进程等待内存加载I/O设备中的数据，进入到、 睡眠状态，防止资源浪费 interruptable sleep：可中断睡眠，standby状态，当有外部请求进来时进入到活跃状态 判断差别主要看是否调用外部I/O来进行 zombie：僵尸进程，进程结束了，但是内存中占用的空间无法释放 进程包含父子关系，子进程结束由父进程回收资源  bash 进程管理 2 ## 2018-01-23 ##\n1、进程有优先级概念：\nlinux中有0-139共140个优先级，数字越小，优先级越高 100-139用户可控制 0-99仅由内核进行控制  进程的分类：\n 跟终端相关的进程 跟终端无关的进程  2、O 标准：队列长度变长，选取优先执行进程的时间（时间，队列长度）\nO（1）：一条平行于Y轴的直线 O（n）：一条斜线，线性变化 O（logn）：logn曲线 O（2^n）：2^n曲线  3、优先级更高：\na、获得更多的CPU运行时间 b、更优先获得运行的机会 nice值（-20——19）--\u003e （100——139） 普通用户仅能调大自己进程的nice值  4、每一个进程的 pid 号是唯一的，可能已经退出，但不会被其他新建进程占用\n每个进程所有的信息保存在/proc目录下以pid号命名的文件夹中 目录下的文件为内核信息的映射，proc为伪文件系统，参数被映射成为名字  5、相关命令\nps（process state）：进程状态 linux分为两个版本--\u003e system V风格 （命令需要－）\u0026\u0026　ＢＳＤ风格（不能有－） ａ：显示所有跟终端有关的进程 ｕ：显示进程的用户相关信息 ｘ：显示所有与终端无关的进程 -e：显示所有进程 -F：显示更详细的信息 -l：长格式 -o：自己组合输出内容 aux，-elF，-ef，-eF几种组合 ps aux显示的内容当中 TIME：显示的是该进程实际占用CPU的时长 COMMAND：包含有[]表示为内核线程 进程状态： Ｄ：不可中断的睡眠 Ｒ：运行或停止 Ｓ：可中断的睡眠 Ｔ：停止 Ｚ：僵死态 ＜：高优先级进程 Ｎ：低优先级进程 ＋：前台进程组中的进程 ｌ：多线程进程 ｓ：会话进程首进程 pstree：显示进程树 pgrep：仅显示特定进程的进程号 -u（euid）：指定是哪个用户的进程 -U：指定哪个用户的进程 pidof：根据程序名查找进程号 top：实时显示系统上运行的进程状态 c：显示详细的进程命令 -b：批处理模式，分屏列出所有进程信息 -n：在批模式下，指定显示几批 -d：指定刷新时长  6、进程间通信（IPC：inter process communication）\n共享内存： 信号（signal）： 重要的信号： 1：sighup --\u003e 让一个进程不用重启，就可以重读其配置文件，并让新的配置文件生效 2：sigint --\u003e ctrl+c 中止 9：sigkill --\u003e 杀掉一个正在进行的进程（直接杀死，不留时间） 15：sigterm --\u003e 终止一个正在进行的进程（提前通知，有反应时间）--\u003e 默认信号 指定一个信号： 信号号码：kill -1 信号名称：kill -SIGKILL 信号名称简写：kill -KILL semaphore：旗语  7、终止进程\nkill PID：指定pid号 killall command：指定command  8、调整 nice 值\n调整已经启动的进程的nice值：renice NI PID 启动时指定进程的nice值：nice -n NI COMMAND  9、前端后端 bg、fg\n前台：占据了命令提示符 后台：启动之后，释放了命令提示符，后续的操作在后台完成 前台--\u003e 后台： ctrl+z：把正在前台的作业送往后台运行，默认发送STOP信号 command \u0026：让命令在后台运行 bg：让后台停止的作业继续运行 bg [[%]JOBID] jobs：查看后台的所有作业 作业号，不同于进程号 +：命令将默认操作的作业 -：命令将默认操作的第二个作业 fg：将后台的作业调回前台 fg [[%]JOBID] kill %JOBID：终止某作业  10、vmstat（系统状态查看命令）\nr：运行队列长度 b：阻塞队列长度 buff：缓冲 cache：缓存 si：换进 so：换出 bi：读入 bo：写出 in：interrupt cs：context switch（上下文切换，进程数据切换次数）  11、/proc/meminfo\n查看memory相关信息 cat /proc/meminfo 查看进程相关内存使用 cat /proc/pid/maps  bash boot process 1 ## 2018-01-23 ##\n1、启动流程\nPOST--\u003e BIOS（boot sequence按照指定的启动顺序执行）--\u003e MBR（bootloader，446字节）（grub stage1） --\u003e grub stage2 --\u003e kernel --\u003e initrd --\u003e init a、加载mbr的同时加载了kernel和initrd，kernel使用initrd生成ROOTFS b、init：  2、root 文件系统 rootfs\n所有的挂载根源为/  3、内核设计风格：\n单内核：linux（LWP：light weight process） 核心：ko（kernel object） RedHat，SUSE，Debian： 1、动态加载，内核模块 2、内核：/lib/modules/“内核版本号命名的目录”/ 3、!$/kernel/* arch：平台相关 crypto：加密相关 drivers：驱动相关 fs：文件系统相关 kernel：内核其他相关的功能 lib：库文件 mm：内存管理 net：网络相关 sound：声卡 微内核：windows，solaris（实现真正的多线程）  4、initramfs 用于过渡的虚拟文件系统\n在系统安装程序即将完成系统安装时，自动判断需要加载哪些模块才能让内核识别到文件系统，从而打包生成过渡文件系统\\ 加载了initramfs文件，其下包含有/sbin，/bin等目录  5、chroot 命令，用户切换之独立的目录下，并以该目录作为根目录运行系统\nchroot /PATH/TO/TEMPROOT [COMMAND...] ldd /PATH/TO/BINARY_FILE 显示二进制文件依赖的共享库文件 测试： a、mkdir /virroot/bin;mkdir /virroot/lib b、cp /bin/bash /virroot/bin; c、ldd /bin/bash d、cp 上一步找出的依赖库文件，复制至相应目录 e、chroot /virroot可以切换，但仅可使用内置命令 initramfs切换机制同上，但不是使用chroot命令;完完全全的切换，但会搬移三个文件夹，在initramfs阶段已经映射好，没有 必要再次映射 /proc /sys /dev  6、initramfs 为一个文件，可以将物理内存当中的一部分模拟成硬盘来使用\nrhel5：ramdisk --\u003e initrd rhel6：ramfs --\u003e initramfs 内核访问根一般需要两个模块： 识别磁盘的模块 识别根目录文件系统的模块  7、启动过程详解\nbootloader（MBR) --\u003e 硬盘级别的程序 lilo：linux loader grub：grand unified bootloader; rhel5和rhel6使用的grub版本不一样 grub本身是一个程序，需要装在MBR的bootloader（446字节）当中，用来引导操作系统;grub分为两段，是一个两阶段的程序 stage1：装在MBR当中，主要作用是用来引导第二阶段 stage1.5：用来帮助识别不同的文件系统的 stage2：/boot/grub/; 主要作用是用来引导操作系统 /etc/grub.conf 文件是一个链接，链接到/boot/grub/grub.conf grub.conf: 全局配置： default=×：设定默认启动的title编号，从0开始 timeout=×：等待用户选择的超时世间，单位为秒 splashimage=（hd0,0）/grub/xxxx：grub的背景图片 hiddenmenu：隐藏菜单 password：后接字符串（明文密码），后接--md5 字符串（加密密码） 使用命令grub-md5-crypt得到密码的加密输出，填入上面的md5后即可 单独的系统设置： title 后版本号 --\u003e内核版本，或操作系统名称，纯字符串，可自由更改 root（hd0,0）：内核文件所在的设备;对grub而言，所有类型的硬盘一律识别为hd×，最后的0表示对应磁盘的分区，，隔开 kernel /vmlinux××××××：内核文件路径，及传递给内核的参数 initrd /initrd-×××：ramdisk文件路径 所有的内容都可以单独更改，重启后生效;image需要注意的是，格式为xpm，像素为14,需要使用gzip压缩 boot单独分区和boot不单独分区，在系统引导时访问的路径不一样 单独分区时，/vmlinuzxxx 不单独分区时，/boot/vmlinuz 文件系统的结构数据是放在磁盘上的 虚拟机重启时（vcenter上），不要按重启按钮直接重启，可能导致文件丢失，要这样做的时候，先执行sync命令 看一下马哥的博客  bash boot process 2 ## 2018-01-31 ##\n1、grub 界面的使用\ne edit 进入到内核行，空格后输入1、s、S、single都可进入到单用户模式 password字段可以放在顶部全局配置，也可以放在某个title下，用作启动内核输入密码（输入密码才能启动系统） c command b boot  2、查看当前系统运行级别\nrunlevel who -r  3、安装 grub stage1，要判断是哪块磁盘\n第一种方式： a、命令行界面下输入grub，进入grub命令行界面 b、指定root位置; grub\u003e root （hd0,0）无报错内容 c、直接键入setup （hd0,0），在正确的分区上重新生成grub grub\u003e setup （hd0,0） d、执行成功 第二种方式： grub-install --root-directory=/path/to/boot‘s parent directory/ /PATH/TO/DEVICE 确保内核所在分区挂载在root目录下0  4、在删除了 grub.conf 的系统上怎样手动引导进入操作系统\na、启动操作系统后会进入到grub界面 grub\u003e b、键入各个root组合，判断是否可用 grub\u003e root （hd0,0） c、查找vmlinux和initrd文件的具体路径和名字，可以在grub界面下使用find命令 grub\u003e find （hd0,0）/ 输出结果中会将该分区下的文件显示出来 d、输入kernel行内容 grub\u003e kernel /vmlinuzxxx tab建可以补全 e、键入initrd行内容 grub\u003e initrd /initramfsxx tab键可以补全 f、键入boot进入系统 grub\u003e boot  5、kernel 初始化的过程\na、设备探测 b、驱动初始化（可能会从initrd（initramfs）文件中装载驱动模块） c、以只读方式挂载根文件系统 --\u003e 出于安全考虑，防止启动过程bug导致根文件系统崩溃，后续init进程会重新以读写方式挂载 d、装载第一个进程init（PID：1）  6、/sbin/init：（/etc/inittab）\n过往较早的unix init启动速度很慢 由ubuntu开发的upstart可以并行启动，速度变快很多，基于D-bus来完成各进程间的通信，event-driven，rhel6中使用 systemd：完整意义上并行启动多个进程的方式，rhel7中使用 以下为rhel5中的机制，inittab： id：runlevels：action：process id：标识符 runlevels：在哪个运行级别运行此行 action：在什么情况下执行此行 initdefault：设定默认运行级别 sysinit：系统初始化 wait：等待级别切换至此级别时完成 respawn：一旦程序终止，进程重新启动，登录错误（用户，密码错误） --\u003e 在登录界面的时候使用，用于控制终端的×××× process：要运行的程序  7、/etc/rc.d/rc.sysinit 完成的任务有哪些\na、激活udev和selinux b、根据/etc/sysctl.conf来设定内核参数 c、设定系统时钟 d、装载键盘映射 e、启用交换分区 f、设置主机名 g、根文件系统检测，并以读写方式重新挂载 h、激活软raid和LVM设备 i、启用磁盘配额（quota） j、根据/etc/fstab，检查并挂载其他文件系统 k、清理过期的锁和PID文件  8、rhel5 中/etc/inittab 文件\nl0：0：wait：/etc/rc.d/rc 0 l1：0：wait：/etc/rc.d/rc 1 l2：0：wait：/etc/rc.d/rc 2 ... 一行的意思为，等待进入系统后，执行/etc/rc×.d/下K×，S×的文件（使用脚本判断出来的）  9、/etc/init.d/ /etc/rc.d/init.d/是同一个位置，前一个是后一个的链接\nbash boot sysv scripts ## 2018-02-01 ##\n1、由/etc/rc.d/rc.sysinit 脚本完成系统的初始化\n2、/etc/rc.d/init.d/目录下的脚本称为服务类脚本，符合 sysV 风格\n每个脚本至少要接受四个参数 主要的：start|stop|restart|status 选用的：reload|configtest  3、在 init.d 目录下的脚本都必须包含以下的内容：\n# chkconfig：runlevels SS KK a、当chkconfig命令来为此脚本在rc×.d目录创建链接时，runlevels表示默认创建为S×开口的链接，除此之外的级别默认创建 为K*开头的链接;-表示没有级别默认为S*开头的链接。 b、S后面的启动优先级为SS所表示的数字; c、K后面关闭优先次序为KK所表示的数字; d、一般而言，先开启的后关闭，后开启的先关闭，考虑的是程序之间的依赖关系 # description：×××× a、用于说明次脚本的简单功能;当描述较长时，使用’\\‘续行  4、一般情况下，当一个程序运行起来后，会在/var/lock/[subsys/]目录下创建一个.lock 结尾的文件，锁文件\n5、chkconfig\n--list --\u003e 查看所有独立守护服务的启动设定;独立守护进程; --add SERVICE_NAME --\u003e 将某个服务加入到chkconfig管理 --del SERVICE_NAME --\u003e 删除，服务不由chkconfig管理 [--level RUNLEVELS] SERVICE_NAME {on|off} --\u003e 特定级别的启动和关闭，如果省略了runlevels，默认指定为2345 将自定义的服务类脚本加入到chkconfig管理的步骤： a、编写好服务启动类脚本（确保包含chkconfig和description这两行内容） b、将脚本放到/etc/init.d/目录下 c、chkconfig --add SERVICE_NAME d、chkconfig --list SERVICE_NAME即可发现，在相应的rc×.d目录下已经生成了K*，S*链接了  6、/etc/rc.d/rc.local：系统最后启动的一个服务，准确说，应该执行的一个脚本\na、默认在rc×.d目录下会有一个S99local（系统服务器最后启动）的链接，指向/etc/rc.local /etc/rc.local --\u003e /etc/rc.d/rc.local  7、/etc/inittab 的任务（rhel5）：\na、设定默认运行级别 b、运行系统初始化脚本 c、运行指定运行级别对应目录下的脚本 d、设定ctrl+alt+del组合键的操作 e、定义UPS在电源故障/恢复时执行的操作; f、启动虚拟终端（2345级别） g、启动图形化终端（5级别）  8、守护进程的类型：\n独立守护进程 xinetd：超级守护进程，代理人（可类比于超级商城内的小店面） 瞬时守护进程：不需要关联至运行级别  how to customed system os 1 ## 2018-02- ##\n1、系统\n核心：/boot/vmlinuz-version 内核模块（ko）：/lib/modules/version  2、模块装载\ninsmod modprobe  3、用户空间访问、监控内核的方式\n通过修改和查看以下两个目录下的文件来实现的 /proc/ a、该目录下的文件基本为只读文件 b、/proc/sys/此目录中的文件很多是可读写的，通过修改该目录下的文件内容来修改内核运行的特性 eg： echo 1 \u003e /proc/sys/vm/drop_cache /sys/ a、该目录下很多文件都可读写，大部分与硬件相关  4、设定内核参数值的方法：\na、echo VALUE \u003e /proc/sys/TO/SOMEFILE echo 1 \u003e /proc/sys/vm/drop_cache b、sysctl -w kernel.hostname='mylab.com' --\u003e 省略/proc/sys/路径，后面每多一层目录则使用.连接 sysctl -w kernel.hostname='liawne' 以上两种方式更改后能够立即生效，但不能永久有效，重启即失效 c、永久有效，但不能立即生效：更改/etc/sysctl.conf 1、修改文件完成后，执行sysctl -p让更改立即生效 2、sysctl -a 打印所有内核参数  5、内核模块管理\na、lsmod：显示系统所加载的模块 b、modprobe --\u003e 探测模块 modprobe MODNAME：装载某模块 --\u003e 自动到/lib/modules/version/下找到相对应的模块名字 modprobe -r MODNAME：卸载某模块 c、modinfo：查看模块的信息 modinfo MODNAME d、insmod：装载模块 insmod /PATH/TO/MODULE/FILE e、rmmod：移除模块 rmmod MODULE/FILE f、depmod /PATH/TO/MODULES_DIR：生成特定目录下各模块之间的依赖关系，并将生成的依赖文件保存在该目录下  6、内核中的功能除了核心功能之外，在编译时，大多数功能都有三种选择\na、不使用此功能 b、编译成内核模块 c、编译进内核  7、如何手动编译内核\nmake gconfig：Gnome桌面环境才能使用，需要安装图形开发库GNOME Software Development make kconfig：KDE桌面环境使用，需要安装图形开发库 make menuconfig：在内核目录下使用 a、tar xf linux-xxxx.tar.xz -C /usr/src 解压完成后，需要复制一个可参考的config文件去到linux目录下 cp /boot/config××× /usr/src/.config b、ln -sv /usr/src/linux-xxxx /usr/src/linux c、cd /usr/src/linux d、make menuconfig 1、*做进内核 2、M做成模块 3、什么都不选，就什么都不做 e、编辑目录下的.config文件，设定自己系统的特性 f、make开始进行编译，维持时间会比较长，超过半小时 g、make modules_install 模块编译 i、make install 开始编译 不要在远程连接的时候编译内核，中断了之后需要完全从头开始  8、screen 命令\nscreen -ls：查看当前已经建立的screen屏幕 screen：直接打开一个新的屏幕 ctrl+a，d：拆除屏幕 在screen界面下直接使用exit会退出当前的screen屏幕 screen -r ID：通过上一条命令查看到有哪些打开的screen，通过这个进行切换回该screen 使用场景： a,需要共享操作界面，模拟环境之后，让别人协助解决问题： 1,screen -S help打开一个名为help的screen窗口 2,另外一个人通过screen -x help连接进入到同一个窗口 3,一方敲的任何命令在另一方都能正常显示  9、二次编译时清理，如果有需要请备份配置文件.config\nmake clean：清理此前编译好的二进制模块 make mrproper：清理此前编译所残留的编译参数，包括config文件;建议执行该命令前先备份config文件  how to customed system os 2 ## 2018-02-07 ##\n1、在一个新盘上手动创建一个可以启动的系统：\na、fdisk -l /dev/sdb --\u003e /dev/sdb1 --\u003e /dev/sdb2 --\u003e partprobe b、mkfs.ext3 /dev/sdb{1,2} c、mkdir /mnt/{boot,sysroot} d、mount /dev/sdb1 /mnt/boot mount /dev/sdb2 /mnt/sysroot e、grub-install --root-directory=/mnt /dev/sdb ---\u003e 生成grub f、cp /boot/vmlinuz- /mnt/boot/vmlinuz ---\u003e 生成vmlinuz文件 g、更改initrd（更改mkrootdev那一行内容，若有swap内容，将swap那一行注释掉，重新压缩成initrd文件）内容后， 将文件放到/mnt/boot目录下（步骤参照3） ---\u003e 生成initrd文件 # rhel5: mkinitrd /boot/initrd-$(uname -r).img $(uname -r) # rhel6: dracut /boot/initramfs-$(uname -r).img $(uname -r) h、vim /mnt/boot/grub/grub.conf ---\u003e 配置grub.conf文件 # default=0 # timeout=5 # title Test Linux (Liawne Test) # root (hd0,0) # kernel /vmlinuz # initrd /initrd.gz i、cd /mnt/sysroot;mkdir proc sys dev etc/rc.d lib bin sbin home boot var/log usr/{bin,sbin} root tmp -pv j、cp /sbin/init /mnt/sysroot/sbin/;cp /bin/bash /mnt/sysroot/bin/; k、ldd /bin/bash --\u003e 复制相应的依赖库文件到对应的/mnt/sysroot/lib目录下 ldd /sbin/init --\u003e 复制相应的依赖库文件到对应的/mnt/sysroot/lib目录下 l、chroot /mnt/sysroot --\u003e 试验是否可以使用 m、vim /mnt/sysroot/etc/inittab 编辑该文件，设定启动级别等 # id:3:initdefault: # si::sysinit:/etc/rc.d/rc.sysinit n、vim /mnt/sysroot/etc/rc.d/rc.sysinit; chmod +x !$ # #!/bin/bash # echo \"Welcome to test linux !\" ## insmod /lib/modules/mii.ko \u003c--- 后面新加内容 ## insmod /lib/modules/pcnet32.ko \u003c--- ## ifconfig 192.168.110.99/24 \u003c--- ## ifconfig 127.0.0.1/8 \u003c--- # /bin/bash o、sync;sync;sync p、将盘卸载，在其他机器上挂载，并以该盘启动，系统可以正常运行 ！！  2、grub --\u003e kernel --\u003e initrd --\u003e ROOTFS（/sbin/init，/bin/bash）\n3、/boot/initrd 文件为一个 gzip 压缩文件（file 查看），查看内部包含的内容：\n第一种解压方式： a、cp /boot/initrd-×××× /root/ b、mv /root/initrd-×××× /root/initrd-××××.gz c、gunzip /root/initrd-××××.gz d、ls /root/initrd-×××× （cpio文件） e、mkdir /root/test \u0026\u0026 cd /root/test f、cpio -id \u003c /root/initrd-×××× /root/test -i：读入 -d：展开到当前目录下 第二种解压方式： a、mkdir /root/iso \u0026\u0026 cd /root/iso b、zcat /boot/initrd-××××.img | cpio -id 更改initrd文件内容后，重新压缩： a、cd /root/iso b、find . | cpio -H newc --quiet -o | gzip -9 \u003e /mnt/boot/initrd.gz  4、创建脚本，设定复制命令需要的 lib 库文件在执行脚本后直接可以满足需求\na、脚本已经创建，名字为bincopy.sh b、在启动单独当作一个可以启动的磁盘之前，复制两个文件到/mnt/sysroot/lib/modules/目录下 mii --\u003e （被pcnet32依赖） pcnet32 文件作用是在系统开启启动的时候可以赋予ip地址（参照上面编辑rc.sysinit文件内容）  5、exec 命令的使用\na、exec的作用为使启动的进程直接替换掉父进程来执行，例如在当前shell下执行一个命令，加上exec后，命令所产生的进程起来 bash进程终止 b、在rhel中，使用软链接链接到同一个脚本，实现关机/重启的功能  6、mingetty 的作用\na、mingetty是一个命令，rhel/centos系统使用这个命令来登录系统，执行/sbin/mingetty后打开一个tty，然后在这个tty上 执行login命令，提示登录 b、可使用stty设置终端的size和属性 stty -F /dev/console size|speed --\u003e 查看终端属性，显示横纵字符数|速度  7、修复文件系统的参考方式（文件系统错乱），在修复过程中，会将检查出错的文件直接删除的\na、在执行fsck修复之前，将文件先打包备份 find . | cpio -H newc --quiet -o | gzip \u003e /root/sysroot.gz b、umount 相应的设备 c、mkfs重新格式化后挂载 d、将之前打包的文件解压后放回 zcat /root/sysroot.gz | cpio -id  script knowledge ## 2018-02-27 ##\n1，脚本编程知识点\n变量中的字符长度：${#var}  how to customed system os two (bash script threeteen) ## 2018-02-28 ##\n1、系统刚开机启动时显示的内容，默认就是/etc/issue 中的内容，可以自己定制内容\na、agetty，stty，mingetty都可以实现 1、系统上默认以mingetty为例，cat /etc/issue的内容存在/r及/m的内容，表示uname -r/-m的输出内容 可以在mingetty的man文档中查看到 2、stty和agetty同样也有自己相应的用法  2、系统用户设置\n绕过pam进行登录 a、/bin/login到文件passwd和group存在一个中间层，为nsswitch（network service switch） b、在nsswitch中定义一个框架，去哪里找到用户信息 c、nsswitch有一堆的库文件，还有自己的配置文件（库：libnss_file.so,libnss_nis.so,libnss_ldap.so） d、配置文件nsswitch.conf，在这个文件中定义去哪里找认证信息，这就是所谓的框架的意义 e、/lib目录下以libnss开头的库文件，实现不同的用户名解析的方式  3、复制一个文件，保留链接地址不变\ncp -d --\u003e 复制文件，保留链接 --\u003e 复制链接，直接就复制了链接对应的文件本身 vim :.,$d --\u003e 当前行到文件末尾全部删除 :1,.d --\u003e 从第一行到当前行全部删除  busybox setting 15_03 ## 2018-03-06 ##\n1，busybox：一个二进制文件，模拟实现了许许多多的命令\n2，RHEL5.8+initrd（busybox）+rootfs（busybox）\n3，查看本机硬件信息\na、查看cpu信息： cat /proc/cpuinfo b、查看usb信息： lsusb c、查看pci信息 lspci d、硬件抽象层 hal-device（rhel5） e、dmidecode（rhel6）  4，实现部分编译\na、只编译某子目录下的相关代码 make dir/ make arch/ make drivers/net/ b、只编译部分模块 make M=drivers/net/ c、只编译某一个模块 make drivers/net/pcnet32.so d、将编译完成的结果放至其他目录 make O=/tmp/kernel  5,如何编译 busybox\nbash signal 16_01 ## 2020-11-25 ##\n1, 交叉编译(用于在一个平台上编译可在多个平台上运行的程序) make ARCH= 2, bash 中变量的赋值 ${param:-word}: 如果 param 为空或者未定义,则展开变量为\"word\",否则,展开为 param 的值 ${param:+word}: 如果 param 为空或者未定义,不做任何操作,否则,展开为\"word\"的值 ${param:=word}: 弱国 param 为空或者未定义,则变量展开为\"word\",并将展开之后的值赋值给 param ${param:offset}: 偏移多少后,取剩下的 param 变量值 ${param:offset:length}: 偏移 offset 之后,再取 length 长度的 param 3, 脚本配置文件 /etc/rc.d/init.d/服务脚本 服务脚本支持配置文件,/etc/sysconfig/服务脚本同名的配置文件\nsystem problem solving 17_02 ## 2018-03-06 ##\n1，常见系统故障排除\na、确定问题的故障特征 b、重现故障 c、使用工具收集进一步信息，确定故障的真正原因 d、排除不可能的原因 e、定位故障 1、从最简单的问题入手 2、一次尝试一种方式  2,故障排除中的一些原则\na、任何涉及到修改源文件的操作时，都需要备份源文件 b、尽可能的借助于工具  3，可能出现的故障\na、管理员密码忘记 b、系统无法启动 1、grub损坏（MBR损坏，grub配置文件丢失） MBR损坏： 模拟环境： dd if=/dev/sda of=/root/mbr.backup bs=512 count=1 --\u003e 备份操作 dd if=/dev/zero of=/dev/sda count=1 bs=200 --\u003e bs小于446,否则分区表被损坏，文件系统无法使用 解决方法： a、借助别的主机修复 b、使用紧急救援模式 1、boot.iso 2、使用完整的系统安装光盘 3、进入到grub交互界面 4、填入grub的启动root（hd0,0），find （hd0,0）2×tab，确认后执行setup（hd0,0） grub.conf丢失 模拟环境： mv /boot/grub/grub.conf /root 解决方法： a、系统无法启动，进入到grub界面 b、find （hd0,0）2×tab，填入root×××回车，kernel×××回车，initrd×××回车，boot启动系统 c、进入系统后，看看能否找回配置文件，找不回则手动建立 手动建立--\u003e1222 2、系统初始化故障（某文件系统无法正常挂载，驱动不兼容） grub：编辑模式 emergency mode：系统启动过程不执行rc.sysinit脚本，在emergency模式下对系统进行修改 3、服务故障 某些服务无法启动导致系统卡住也无法启动 a、单用户模式下设置该服务不启动 b、单用户模式下更改该服务配置是其能够正常启动 c、在内核行敲击‘I'来进入交互式模式指定系统服务的启动与否（交互式模式） 4、图形界面出现故障 5、用户无法登录系统（帐号密码输入错误，bash程序故障） bash文件被删除后，系统连1级别也无法进入 mingetty文件被删除，可以进入到单用户模式下，修复文件 PATH环境变量被损坏，可以手动export进行设定 c、命令无法运行 d、编译过程无法继续（开发环境缺少基本组件） e、kernel panic（内核恐慌） f、另外的故障 把默认启动级别设置为0或者6 --\u003e 进入单用户模式，编辑inittab文件 /etc/init.d/rc*.d/目录被删除了 --\u003e 进入单用户模式，编辑inittab文件  4,使用 rescue 进入救援模式后，chroot 切换至原有的根文件系统，缺少了脚本 rc.sysinit 脚本的执行，相应的就缺少了部分功能\na、常见的情况，无法识别挂载的光盘，因为缺少了udev的激活过程（/dev目录下缺少设备文件） 手动创建设备文件 --\u003e mknod  5,系统启动过程回顾\nPOST --\u003e BIOS（启动设备顺序依次找其MBR中的bootloader）--\u003e kernel（加载initrd，挂载根文件系统rootfs，\\ 执行/sbin/init脚本）--\u003e /etc/inittab  sudo settings 17_03 ## 2018-03-06 ##\n1、sudo 的功能是某个用户能够以哪一个用户的身份通过哪些主机执行哪些命令\n2、不要使用 vi/vim /etc/sudoers，保存后无法检查编辑的语法\n3、sudoers 文件中的语法格式\n一、用户条目 who which_host = (runas) commands which user 哪些主机可以连上来 以谁的身份连上来 允许使用哪些命令 二、default设定一些默认属性 别名：类似于组的概念，别名必须全部而且只能使用大写英文字母的组合，必须先定义才能使用，均可使用’！‘取反 a、user_alias：用户别名，可以将一些用户统一起来，用一个别名统称 User_Alias USERNAME = 用户的用户名 组名，使用%引导 还可以包含其他已经用户别名 b、host_alias：主机别名，可以将一些主机统一起来，用一个别名统称 Host_Alias 主机名 IP 网络地址 其他主机别名 c、runas：以哪个用户的身份来执行的 Runas_Alias 用户名 %组名 #uid 其他主机别名 d、cmnd_alias：命令别名，将一些命令统一起来 Cmnd_Alias 命令路径 目录（表示该目录下的所有命令） 其他事先定义过的命令别名 三、可在命令前增加标签，定义命令使用的方式 a、最常用的方式为在命令前增加NOPASSWD： --\u003e 不再需要用户在使用命令前输入密码 b、对特定命令需要使用密码，某些不要使用，则在各个命令前增加（PASSWD：|NOPASSWD：）做限定  4、示例\na、为hadoop用户增加useradd，usermod权限 # visudo # hadoop ALL=(root) /usr/sbin/userdel,/usr/sbin/usermod b、增加别名，不需要使用密码 User_Alias USERADMIN = hadoop, %hadoop, %useradmin Cmnd_Alias USERNAMECMD = /usr/sbin/usermod,/usr/sbin/userdel,/usr/sbin/useradd,/usr/bin/passwd,! /usr/bin/passwd root USERADMIN ALL=(root) NOPASSWD:USERNAMECMD  5、sudo 命令的用法\n-k：使认证信息失效 -l：列出当前用户所有sudo能够使用的命令列表 -i：切换至root用户  6、sudo 及/etc/sudoers 文件的具体使用方法都可以在 man 文档中找到\n7、sudo 的日志文件保存在/var/log/secure 日志中，权限设置为 600\nbash array 31-01 ## 2018-03-13 ##\n1、变量：命名的内存空间，bash 中所有的变量均被以字符型的类型存储\n2、数组：内存中存储连续变量\n3、如何声明一个数组：\ndeclare -a AA --\u003e声明数组AA 赋值方法一： AA[0]=tom AA[1]=jerry AA[2]=cat AA[6]=natasa 赋值方法二： AA=(tom jerry cat) 赋值方法三： AA=([0]=tom [1]=jerry [2]=cat [6]=natasa)  4、一些特殊使用情景\n查看数组中某个元素的长度 echo ${#AA[0]} --\u003e 显示数组中第一个元素的长度 echo ${#AA[*]} --\u003e 显示数组中不为空的元素的个数 echo ${#AA[@]} --\u003e 显示数组中不为空的元素的个数  5、在脚本中捕捉信号，并且可以实现特定处理\ntrap --\u003e 捕捉信号，用户替换执行用户发出的指令 trap ‘’ SIG --\u003e 将捕捉到的SIG替换成‘’中的命令（函数也可）执行 使用的场景：用户使用ctrl + C终止脚本执行，将之前定义的变量和生成的文件删除 9/15一般不可被捕捉，  getopts 31-02 ## 2018-03-23 ##\n1，getopts\nshell的内置命令，使用help getopts查看相应的使用方法 a、getopts只能获取一个选项 b、命令格式：getopts optstring name [arg] 1,getopts 'bd' OPT \u0026\u0026 echo $OPT --\u003e 可接受-b，-d选项，接受的内容存在变量OPT中 2,getopts 'bd:' OPT \u0026\u0026 echo $OPT \u0026\u0026 echo $OPTARG --\u003e d可接受参数（b缺少：，不可以接受参数）， 使用shell内置变量OPTARG可显示参数的内容（使用选项不同的时候，变量对应的值不同） 3,getopts只可接受一个选项，不接受同时接多个选项（-b -d同时用） c、可使用循环来让getopts接受多个选项 while getopts \":d:\" OPT; do case $OPT in d) echo $OPT echo $OPTARG ;; ?) echo \"Wrong choice\" echo \"USAGE : mkscript [-d DESCRIPTIONS] FILENEME\" ;; esac done d、接了：之后，后面必须接上参数，不然返回值为错误 e、getopts还有一个内置的函数OPTIND（选项索引） 作用:执行了命令./mkscripts -b -d -c /tmp/testfile，$OPTIND取完了-b之后取-d..，一直到将所有的参数取完 注意点：使用不同参数时，对应的OPTIND对应的值也不同 f、getopts命令的具体使用方法可参见定制命令vims,attach-scripts/getinterface  vnc 31-03 ## 2018-03-24 ##\n1，vnc：virtual network computing 虚拟网络计算\n2，vnc 能够实现跨平台共享桌面，桌面的打开可基于客户端实现也可基于浏览器实现\n3, 能够实现本机没有开启任何图形化界面的情况下，远端的 windows 或者 linux 打开本机的图形界面\n4,vnc 的传输是明文的，跨越网络实现 vnc 链接不安全\n5，实现连接：\na，查看是否安装vnc-server rpm -qa |grep vnc b，同样的用户登录ｖｎｃ，使用的密码不一定是该用户的系统登录密码，为ｖｎｃ专用密码，保存密码是加密的，但登录认证的 过程不是加密的 ｃ，设定当前用户基于ｖｎｃ协议访问当前主机的ｖｎｃ密码 vncpasswd d，启动服务 第一次启动vnc服务：vncserver \u0026，稍等片刻会出现c6u6test1：1 desktop for root的提示，表示现在是第一 个桌面（root），类似于使用screen命令，每个用户只能用一个桌面，需要两个用户登录最少要开启两个桌面 再次执行vncserver \u0026 以后启动使用：service vncserver start e，登录桌面 打开windows上的vncviewer，在服务器行输入172.16.100.1：1，确认之后再输入密码 f，默认打开的桌面是xterm，仍类似于文本界面，twm（著名的桌面管理器），若需要打开图形化，则需要进行配置; 在需要进行vnc链接的用户家目录下会生成一个.vnc的文件夹，该目录下存在文集那xstartup文件，进行编辑，将 twm \u0026 改为gnome-session，去掉注释unset SESSION_MANAGER和exec /etc/X11/xinit/xinitrc g，重启服务，vncserver -kill ：2; vncserver -kill ：1关掉刚才打开的session;重新打开vncserver \u0026  iptables-1 28-01 ## 2018-03-24 ##\n1,linux 网络防火墙\nnetfilter：Frame（网络过滤器） iptables：生成防火墙规则，并且能够将其附加在netfilter上，真正实现数据报文过滤，NAT，mangle等规则生成的工具  2,iptables 依赖于网络的相关内容，分别是 IP 报文首部，TCP 报文首部\na、以http数据包为例：IP报文\u003cTCP首部\u003chttp首部  3,iptables 使用规则\na、iptables [-t TABLE] COMMAND CHAIN [num] 匹配条件 -j 处理办法 b、匹配条件： 通用匹配 -s:源地址 -d:目标地址 -p:匹配协议\u003ctcp|udp|icmp\u003e 扩展匹配 隐含扩展 -p tcp当指定了某个协议之后,就可以使用该协议的相应扩展功能 --sport PORT[-port]:源端口(port不能使离散的端口,只能是连续的端口) --dport PORT[-port]:目标端口 --tcp-flags mask comp:只检查mask指定的标志位,是逗号分割的标志位列表;comp:此列表中出现在mask中,标记为必须为1,而mask中剩下的必须为0 --tcp-flags SYN,FIN,ACK,RST SYN,ACK == --syn(匹配tcp三次握手中的第一次)(31:30) 命令示例: 1,放行来自172.16.0.0/24到达172.16.100.7的ssh连接(注意应该有两条规则 ,一进一出) iptables -t filter -A INPUT -s 172.16.0.0/24 -d 172.16.100.7 -p tcp --dport 22 -j ACCEPT --\u003e要注意sport和dport的使用 iptables -t filter -A OUTPUT -s 172.16.100.7 -d 172.16.0.0/24 -p tcp --sport 22 -j ACCEPT -p icmp --icmp-type:icmp是有类型的,ping命令需要用到的是code为0和8两种 0:echo reply(响应报文) 8:echo request(请求报文) 命令示例: 1,设置filter所有鏈的默认策略为DROP,放行172.16.100.7 ping其他主机(自己能ping别人,别人ping不了你) iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -i lo -j ACCEPT iptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -o lo -j ACCEPT iptables -A OUTPUT -s 172.16.100.7 -p icmp --icmp-type 8 -j ACCEPT iptables -A INPUT -d 172.16.100.7 -p icmp --icmp-type 0 -j ACCEPT -p udp --sport --dport 命令示例: 1,设置filter所有鏈的默认策略为DROP;主机作为一台DNS服务器,相应来自客户端的DNS请求(能联网的主机) 总共需要8条规则,tcp和udp各占一半,剩余四条分别是作为DNS服务端,接收并响应客户端请求;以及需要联网查询的时候,作为客户端时,请求并接收外部主机 显示扩展:使用额外的匹配机制 -m EXTENSION --spec-opt state:状态扩展,结合ip_conntrack追踪会话的状态(根据IP来追踪状态的,不是根据tcp来追踪) NEW:新连接请求 ESTABLISH:已经建立的连接,对新请求的响应 INVALID:非法连接请求 RELATED:相关联的,由命令连接激活的另一个连接,两个连接之间的关系叫做related -m state --state NEW,ESTABLISHED -j ACCEPT 命令示例: 1,只允许http的外部连接请求进来,不允许主机发送新连接请求到其他主机(为了防止反弹木马--\u003e主动连接外部主机) iptables -A INPUT -d 172.16.100.7 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.100.7 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT -m multiport:离散的多端口扩展匹配 --source-ports --destination-ports --ports 命令示例: 1,同时匹配三个规则 iptables -I INPUT -d 172.16.100.7 -p tcp -m multiport --destination-ports 21,22,80 -m state --state NEW -j ACCEPT -m iprange:指定ip地址范围 --src-range --dst-range 命令示例: iptables -A INPUT -p tcp -m iprange --src-range 172.16.100.3-172.16.100.100 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT -m connlimit:连接数限制 ! --connlimit-above n:指定连接的上限 命令示例: 1,限定本机连接到172.16.100.7的连接不能超过两个 iptables -A INPUT -d 172.16.100.7 -p tcp --dport 80 -m connlimit ! --connlimit-above 2 -j ACCEPT iptables -A INPUT -d 172.16.100.7 -p tcp --dport 80 -m connlimit --connlimit-above 2 -j REJECT -m limite:用于限制连接速率的 --limit RATE:限定速率 --limit-brust:限定次数 -m string:用来屏蔽请求返回内容包含匹配字符的 --algo {bm|kmp} --string \"string\" 条件取反:加上!  4,常用命令:\na, 管理规则 -A:附加一条规则(鏈的尾部) -I CHAIN [num]:插入一条规则(指定添加的位置),省略则为第一条 -D CHAIN [num]:删除指定鏈中的第num条规则,省略也可匹配 -R CHAIN [num]:替换指定的规则 b, 管理鏈 -F [CHAIN]: flush,清空指定规则鏈,如果省略CHAIN,则可以实现删除对应表中的所有鏈 -P CHAIN:设定指定鏈的默认策略; -N:自定义一条新的空鏈 -X:删除一个自定义的空鏈(必须是空鏈,非空则需要先使用-F清空) -Z:清空指定鏈中所有规则的计数器 -E:重命名一条自定义鏈 c,查看 -L:显示指定表中的规则 -n:以数字格式显示主机地址和端口 -v:显示鏈及规则详细信息(可接收-vv),显示的是可读形式 -x:显示精确值(exact) --line-numbers:显示规则号码 d,可执行的动作(target): ACCEPT:放行 DROP:丢弃 REJECT:明确告诉拒绝 DNAT:目标地址转换 SNAT:源地址转换 REDIRECT:端口重定向 MASQUERADE:地址伪装 LOG:日志 LOG还可以包含各种不同的参数,例如记录序列号,用户uid等 LOG与其他的动作结合使用时,需要把相应的规则放在前面,否则匹配了之后到不了LOG处 使用LOG作为记录使用时,最好结合速率限制一起使用,防止记录过多信息 MARK:给匹配的包打上标记,不放行也不拒绝  5,iptables 服务:\na,iptables不是服务,但有服务脚本;服务脚本的作用主要在于管理保存的规则 b,可以使用lsmod来查看iptables的相应模块是否被加载(ip_tables,ip_nat,ip_contract,iptable_nat等) c,停止了iptables服务,其实就是将iptables的相应模块移除了 d,加载或者移除iptables/netfilter相关的内核模块  6,连接追踪功能 ip_conntrack\na,功能:客户端,服务端彼此之间建立的连接关系,并且能够追踪到一个连接与另外一个连接彼此之间处于什么样的一个状态,并且拥有什么样的关系 b,文件/proc/net/ip_conntrack,保存有当前系统上每一个客户端与当前主机建立的连接关系 c,使用命令iptstate查看当前系统的包追踪状态 -t:显示个数 d,内核参数ip_conntrack_max保存有当前系统最多可追踪的连接数,超出这个数字之后,新的连接会因超时而被丢弃 1,对于web服务器,连接数需要调大,否则可能导致连接错误 2,对于特别繁忙的服务器,尽量不要开启这个模块 3,使用iptables命令查看规则的时候(iptables -t nat -nL),会加载该模块,自动开始追踪 e,iptables的规则保存文件/etc/sysconfig/iptables  7,iptables 规则保存\na,service iptables save 默认保存在/etc/sysconfig/iptables b,iptables-save \u003e xxx 使用重定向的方式将规则保存起来 c,iptables-restore \u003c xxx读取规则文件  understanding the linux operating system 1 ## 2018-04-09 ##\n1、OS：operating system 本身就是一个虚拟机\n2、计算机构成：五大部分\nCPU： 运算器：负责运算，算数运算、逻辑运算 控制器：控制指令，数据的存取过程 寄存器：CPU计算数据来源及计算结果暂存位置（register）  3、程序就是指令加数据构成的\n4、CPU 与内存的沟通（CPU、north bridge、RAM）\na、理解为CPU通过桥（总线）连接到North bridge，North bridge在通过桥（总线）连接到RAM;桥的宽度可以是32bit、64bit 桥的宽度影响CPU能够寻址的大小，32bit时为2^32=4GB大小;64bit时为4G×4GB大小。 b、CPU的控制指令、数据存取都是通过这个32bit、64bit，也即是线路复用的情况  5、PAE：物理地址扩展 physical address extension\n作用：为32位的寻址总线加上了4bit;32bit，+4bit;增加了该功能够，使本身只支持4G的系统可以支持4GB×16=64GB  6、缓存的使用\na、程序：局部性 b、CPU的缓存：指令缓存，数据缓存;一级缓存、二级缓存各cpu独有，三级缓存一般是共享的;缓存的大小会影响系统性能 c、对于ram存取数据来说，保存有数据实际上就是ram中带有电荷，读取完成之后，电荷就消失了;ram需要不停的刷新来存取数据  7、缓存的置换策略\na、空间局部性：一个数据被使用到，则其旁边的数据被用到的概率更大 b、时间局部性：一个数据如果被用到，那他再次被用到的概率更大  8、若 CPU 有输出，有数据被更改，则可能对一级缓存、二级缓存、三级缓存、主存、硬盘都要进行写操作，这种方式称为通写（write through）;\n9、若 CPU 有输出，有数据被更改，但是没有立即写入到各层级存储中去，只有数据在被丢弃的时候才写入后面的存储，这种方式称为回写（write back）;目前绝大多数情况都是回写的方式，性能相对而言高了很多;\n10、一般情况下，显卡也是直接接到 North bridge 上的，需要使用到 CPU 对图像进行渲染和计算，数据交换量是非常大的;\n11、IO 分为高速 IO 和低速 IO\na、高速IO一般是指PCI的IO，高速IO总线 b、南桥一般是把慢速IO汇总起来，一并交给北桥进行处理 c、PCI是连接到南桥的，速度其实不能算是很快;现有PCI-E口，直接接到北桥上，速度比PCI口快了不止一点点; d、使用PCI-E口的USB速度会很快，带宽足够了，瓶颈可能变成了USB的读写能力，这个时候可以将多个USB设备整合成为一个存储 设备，并行读写，这种方式就是固态硬盘的方式;仍有选择使用PCI（SATA）口的固态硬盘，建议用PCI-E口的固态硬盘;  12、各种设备连接到南桥，南桥在连接到北桥，北桥在连接到 CPU;北桥和内存又相连;北桥给各种不同的设备分配地址（32bit/64bit）用做 CPU 来区分和识别\na、任何一个设备，为了能够和主机交互，在加电自检完成之后，每一个硬件都必须向CPU注册申请整个IO端口上一片连续的端口; 每一次注册的结果可能不一样;在开启后，CPU与这些设备交互都是通过这些端口来进行; b、虽然各个设备已经注册了不同的端口与CPU交互，但仍然还是通过同一个总线进行 --\u003e 总线复用 c、没一个硬件设备的内部线路可能与CPU不一致，但都会有各自的控制器（适配器），作用是将这个设备能够理解的信号转换成 总线上能够识别的信号，是个翻译官，还可能附带是司令官，控制校验，速率设定等;  13、（可编程）中断控制器（Interrupt Controller）\na、CPU上自带有一个中断控制器，用于接收处理中断信号的; b、当硬件设备上来了信号之后（区别于IO端口），由这个硬件设备负责通知CPU（中断控制器）进行处理; c、中断控制器帮助CPU识别是哪个硬件发过来的中断请求;中断控制器上有中断控制线（中断通路）; d、硬件发送过来的中断信号，也即是中断向量 e、每一个硬件设备在启动的时候，必须要向中断控制器（可编程中断控制器）来申请注册使用一个中断向量 --\u003e 有地址 的通知机制;当信号发送过来后，能够自动被CPU识别，即认识到是哪个硬件设备发送过来的。 f、一般将中断处理分为上半部和下半部;上半部，将请求接近来;下半部，处理中断请求。  14、直接内存访问 DMA（direct memory access）\na、cpu将数据从磁盘中读取写入的操作授权给其他助手使用（总线的使用），可能出现资源争抢的情况，容易出现争抢现象的 位置称为临界区 b、CPU告诉DMA有15M可以读取，将线路授权给DMA;DMA没有CPU那么打的总线带宽，一般系统会预留低地址的内存给DMA 使用（寻址限制）  15、BIOS 自举\na、系统启动之后，系统会将ROM空间内容映射到内存最开始的部分 b、CPU加电后，什么事都不干，先执行内存最初始部分的代码，完成自检，加载bootloader c、内存的空间分配为ROM：DMA：left  16、系统启动之后，CPU 一直处于运行状态，区别只是有用的转和无用的转，运行称为时钟周期\na、CPU内部通常有一个称为时钟产生器的东西（晶体震荡器） b、内存可能在一个CPU的时钟周期内只走了一点点 c、CPU以时间片来进行资源的利用和分配，通过时间的流逝来体现计算能力  17、操作系统的演变（所有的程序运行都要向监控程序申请资源）\na、有一个管理系统（管理程序），负责从磁盘中加载一个程序到内存中，然后加载程序到CPU进行运算，运算结果保存到内存 中，再把数据写回到硬盘;再加载另一个程序来运行，周而复始;这个程序早期叫做monitor，就是一个监控程序，其他程序的 监控程序 b、程序发展得越来越大，变成了OS（operating system） c、OS把整个机器抽象出来，变成了一个虚拟机VM（virtual machine）  18、process：进程，一个独立的运行单位\na、进程无法直接在硬件上运行，由监控程序（OS）来监控运行 b、系统资源：CPU时间、存储空间  19、OS：VM\n a、CPU：站在CPU的角度，以时间来进行区分 1、时间：切片来进行;一个10GHz的CPU可以虚拟看成是10个1GHz的虚拟CPU 2、缓存：缓存当前程序数据，在数据清空前需要进行回写 3、指令计数器：CPU当中包含的，当前的进程分配的时间用完了，但是进程仍未执行完，下次怎么继续处理呢，依赖于 指令计数器来实现 4、进程切换：进程切换的时候要保留现场，恢复现场;进程切换是有开销的，如缓存在切换的过程中被清掉了，恢复现场 的时候则需要重新加载数据，保存现场的数据保存在主存当中 b、MEM：站在内存的角度，以空间大小来进行区分，同样还是切片 1、内存的实现方式为：将内存切割，分成4K大小的存储槽，每个存储槽称作一个页框;每个槽能够存储的数据称为一个 页面（page），每一个页面的存储空间称为一个页框（page frame），在页框上增加一个页框和页的映射关系; 2、每一个进程都认为自己是有4G空间可用的 a、内存空间的分配：指令区（代码区），数据区，bss段，heap区 \u003c--\u003e stack区 -------------- | ----- | ---- | ----- | |------- --\u003e 4G大小 只使用了有限的空间，中间为空 以上面的为例解释，假设指令区一个页，数据区一个页，bss一个页，heap一个页，stack一个页;通过映射，指 令区映射到一个页框，数据区映射到一个页框，bss映射到一个页框，heap映射到一个页框，stack映射到一个 页框（不一定连续） b、虚拟出来的空间可以认为是一个进程描述结构 c、这个是有内核在内存中维护的，当进程需要使用时，内核告诉进程相应的映射关系 d、页目录，映射关系由一个芯片负责维护，在进程需要使用到自己的数据时，怎么样能够更快的找到虚拟地址（线 性地址）实际对应的物理地址呢;通过页目录来实现的，页目录分为一级、二级、三级。。来实现更高效率的 查找;用于方便建立线性地址到物理地址的对应关系 e、通过空间映射来完成 f、实现映射关系的芯片的引入还同时具有了内存保护的功能 c、IO设备：在进程层次上，IO设备不需要去做虚拟，IO设备在谁获得了当前的焦点，IO对应的切换就交给哪个进程了 1、IO只能是内核控制，一旦产生IO中断，一定是和内核交互，再由内核转给进程 2、内核，N×进程 --\u003e 系统 a、内核运行时，是内核模式 b、进程运行时，是用户模式 c、在内存当中，内核占用空间是内核空间，进程占用空间是用户空间 d、进程是不能直接控制硬件的  20、早期 x86 架构的系统是不适合用来做虚拟机的，在后来 CPU 支持硬件虚拟化之后才实现了\na、在进程的层次上，资源已经被虚拟化过一次了  21、CPU 指令分为四个层级，环 0-3,环 0 为内核模式（特权模式），环 3 是用户模式（限制模式）\n22、虚拟机的运行模式有多种，其中一种是仿真（模拟）出来硬件层，在虚拟机系统层面查看不出来是否是在虚拟机上运行\na、这种模式下，虚拟机上的内核运行特权指令时是通过虚拟机先翻译传给物理机内核，内核处理完再返还 b、在后来更改了一种机制，物理机上增加环-1（包含最最特权的指令），虚拟机可以运行环0的指令（不包含一些特权指令） 硬件虚拟化也就是提供了-1环  23、IO 准备的过程\na、进程空间交接给内核空间 b、内核开始调用，将辅存当中的数据读取出来，先放到内核空间的缓存中 c、内核空间缓存转移到用户空间缓存中 d、地址映射，物理内存映射完成 e、资源准备完成，内核唤醒进程  24、进程队列\na、就绪状态，sleeping状态（可中断、不可中断）  understanding the linux operating system 2 ## 2018-04-16 ##\n1、操作系统、硬件、软件结构图\n ---------------------------------------------------- | Applications | |--------------------------- | | Libraries | | |----------------------------------------------------| | | | Kernel -------------------------| | | Drivers | | -------------------------- | | | Firmware | | |----------------------------------------------------| | Hardware | ----------------------------------------------------  2、在 linux 中，进程是通过双向链表（list）来进行管理组织的\na、进程描述符：没一个进程都有其进程描述符 b、在创建一个进程的时候，首先一步就是要创建一个进程描述符，并将其添加到双向链表上 c、杀掉一个进程，就是将这个进程描述符删除，内核不在能够追踪此描述符 d、创建了一个进程后除了给进程分配CPU、内存等资源外，还需要在内核的内存空间中维护一个进程描述符文件，里面保存有进程 当前的所有相关信息  3、task_struct（进程描述）\n task_struct -------------- |status |-------------- |thread_info |-------------- |usage |flags |... |-------------- |run_list | |tasks |-------------- |... mm_struct |-------------- -------------------- |mm -----\u003e | pointers to memory | |-------------- | aera descriptors | | -------------------- |-------------- |real_parent |parent |-------------- |... |-------------- |tty -----\u003e ... |-------------- |... |-------------- |thread -----\u003e ... |-------------- |... |------------- |fs -----\u003e ... |-------------- |files -----\u003e ... |------------- | |------------- |signals |pending |------------- | -------------  4、进程切换\na、进程切换也称为上下文切换（context switch） b、进程A切换至进程B，A挂起，称为保存现场;B恢复，称为恢复现场 c、进程切换由内核进行管控;每次进程切换都需要经过内核，进程由用户模式切换至内核模式，内核模式在切换回用户模式 d、进程切换需要时间，分为用户模式需要占用的时间和内核模式需要占用的时间（分别对应top中的sys和usr） e、进程切换太多不好（内核模式占用时间多，用于处理事件的用户模式占用时间就少了）;进程切换太少也不好（10个进程， 每个进程等待时间过长，影响用户体验） f、linux支持进程抢占，linux有自己内部的系统时钟：tick（滴答），每一次tick即可产生一次时钟中断  5、linux 中进程分类\na、交互式进程（IO密集型，等待IO）：桌面型优先级相对高一些 b、批处理进程（CPU密集型）：服务器型优先级相对高一些 c、实时进程（real-time）：优先级特别高 d、分配策略：为CPU密集型进程设定时间片长，优先级低;为IO密集型设定CPU时间片短，优先级高  6、linux 优先级\na、实时优先级：1-99,数字越小，优先级越低 b、静态优先级：100-139,数字越小，优先级越高 c、实时优先级比静态优先级高 d、在top的输出结果中，表头显示PR（priority）的列中出现RT表示real time;riprio（实时优先级） e、在top命令的输出结果中comm列包含[]的命令表示为内核线程  7、linux 调度类别\na、实时进程： 1、SCHED_FIFO：First In First Out 2、SCHED_RR ：Round Robin 3、SCHED_OTHER：用来调度100-139的进程 b、在top命令输出结果中的CLASS列表示的是该进程的调度类别 c、动态优先级：在内核当中，若某个进程长时间为被运行，内核会临时性的调高其优先级 d、chrt命令用来调整1-99的进程，nice/renice用于调整100-139的进程 1、chrt -f -p prio pid ：fifo 2、chrt -r -p prio pid ：rr  8、优先级算法 O（1）\n2.6的内核使用方式为划分为1-139共140×2=280个队列（每个级别有两个队列，一个是活动队列，一个是过期队列）， 将每个级别的进程分别加入各自对应的队列，每次需要选择进程进行执行，扫描队列的首部即可  understanding the linux operating system 3 ## 2018-04-16 ##\n1、中断\na、硬中断：硬件产生的中断 b、软中断：由用户空间进入到内核空间  2、CPU 缓存\na、一级缓存有两个，分别是I1（指令缓存），D1（数据缓存）  3、SMP 对称多处理器：在一个主板上有多个 cpu 插槽，每一个插槽称为一个 socket\na、完成一次正常的内存访问，CPU至少需要三个时钟周期，分别是 1、向内存控制器传输一个寻址要求 2、完成地址确定后（内存地址的编址是由内存控制器来完成的），CPU找到内存地址并施加一定的请求机制（对内存施加锁） 3、完成读或者写的操作 b、内存节点只有一个，性能的提升是有限的（增加CPU），在于内存的争用  iptables-4 28-04 ## 2018-09-10 ##\n1,iptables 创建自定义鏈(在包进入到主机前,先让其经过 clean_in 自定义鏈处理)\n命令示例:自定义规则鏈,让其能够备主鏈调用 # iptables -N clean_in # iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP # iptables -A clean_in -d 172.16.255.255 -p icmp -j DROP # iptables -A clean_in -p tcp ! --syn -m state --state NEW -j DROP # iptables -A clean_in -p tcp --tcp-flags ALL ALL -j DROP # iptables -A clean_in -p tcp --tcp-flags ALL NONE -j DROP # iptables -A clean_in -d 172.16.100.7 -j RETURN # iptables -I INPUT -j clean_in 自定义鏈有一个reference属性,可以看出被其他主鏈引用的次数  2,利用 iptables 的 recent 来抵御 DOS 攻击\n# iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 3 -j DROP # iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH # iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP a.利用connlimit模块将单IP的并发设置为3；会误杀使用NAT上网的用户，可以根据实际情况增大该值； b.利用recent和state模块限制单IP在300s内只能与本机建立3个新连接。被限制五分钟后即可恢复访问。 下面对最后两句做一个说明： 1.第二句是记录访问tcp 22端口的新连接，记录名称为SSH --set 记录数据包的来源IP，如果IP已经存在将更新已经存在的条目 2.第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接 --update 是指每次建立连接都更新列表； --seconds必须与--rcheck或者--update同时使用 --hitcount必须与--rcheck或者--update同时使用 3.iptables的记录：/proc/net/ipt_recent/SSH  3,NAT(network address translation)\na,DNAT(目标地址转换) b,SNAT(源地址转换)(30:00)  加密类型及其相关算法 18-01 ## 2021-06-08 ##\n TCP/IP 安全问题: 刚开始设计时,没有考虑安全性要求的深远  a,以 A --\u003e B 两台主机建立连接为例说明 - 机密性: 明文传输(ftp, http, smtp, telnet),所有经手人都能看到内容(明信片和信件的差异) - 完整性: 传输时不能随意被篡改掉(交易时订单数目被修改) - 身份验证: 保证访问的官网是真的官网 b,机密性的保证: - 传输方: plaintext --\u003e 转换规则 --\u003e ciphertext - 接收方: ciphertext --\u003e 转换规则 --\u003e plaintext 1,在互联网中安全设计体系结构中的基本法则: 保证数据机密性的核心不是算法本身,而是密钥 - 别人可以知道算法,加密依赖的不是算法,主要是密钥,主要是维护性的考虑(换一个密钥比换一个算法简单的多) 2,对称加密:提供算法本身,用户提供一个密钥;结合密钥和算法,能够将明文转换为密文;解密也使用的是同一个密钥,有加密算法和解密算法 - 对称加密的好处是算法计算速度很快,但安全性几乎完全依赖于密钥 - 对称加密的一个坏处是当通信对象过多时,无法有效的对密钥进行管理 c,完整性的保证: - 单向加密算法: 提取数据特征码,A: plaintext:footprint --\u003e B a,输入一样,输出必然相同 b,雪崩效应:输入的微笑改变,将会引起结果的巨大改变 c,定长输出:无论原始数据多巨大,结果大小都是相同的 d,不可逆的:无法根据特征码还原原来的数据 - 攻击类型: 中间人攻击: E 截取了 A 发给 B 的内容,篡改了 plaintext 后,重新生成了 footprint \u003e\u003e A: plaintext:footprint --\u003e E: plaintext2:footprint2 --\u003e B 修复方式: 将 A 发送给 B 的 footprint 内容也使用密钥加密,B 接受到了之后使用密钥解密 - 密钥加密算法(协商密钥): 一种情况,A 和 B 从来没有见过面,也没有约定过加密解密密钥 - 协商生成密码: 密钥交换(Internet key-exchange: IKE),双方协商生成密码,但是不让第三方得到这个密码 - Diffie-Hellman 协议,按照如下方式协商密钥: a,A --\u003e B,A 和 B 准备建立连接 b,明文确认两个数 p, g(大素数, 生成数) c,A 自己取一个随机数 x, B 自己取一个随机数 y d,A(g^x%p) --\u003e B; B(g^y%p) --\u003e A(此时互联网上明文传输的有四个数,分别是 p/g/g^x%p/g^y%p),因为离散数学原理,无法获取到 x,y 的具体数值 e,协商的结果为,密钥是 g^xy%p - 由软件自己实现 - 该方式仍然无法解决身份认证的问题(可能协商密钥已经被截取替换),为了解决这个问题,有了非对称加密,公钥加密算法 - 公钥加密算法(非对称加密算法): - 密钥对(一般都是成对出现的): a,公钥 p: 公钥不是独立的,公钥是从私钥中提取出来的 b,私钥 s: 为了保证安全性,私钥一般都特别长 c,公钥是所有人都可以知道的,私钥必须只能自己知道 - 用公钥加密的,只能用私钥解密;反之亦然 a,A --\u003e B,使用 B 的公钥加密,能够解密的只可能是 B(这样就完成了机密性/身份验证的问题) b,发送方用自己的私钥加密,可以实现身份认证; 发送方用对方的公钥加密,可以保证数据机密性 - 公钥加密算法很少用来加密数据: 主要是速度太慢了,一般来说公钥加密会比对称加密慢上三个数量级 - 公钥加密算法主要用在身份验证上 - 已下列传输方式说明: a,A(plaintext/footprint): A 使用自己的私钥加密特征码,发送给 B b,B 通过 A 的公钥解密特征码,验证是否正常是 A 的 c,假设中间有 E 截取了 A 发送给 B 的内容,E 能够获取到 A 的特征码,但是无法修改 plaintext 后再生成 footprint(特征码),因为此时生成特征吗只能使用 E 自己的私钥加密,B 在获取到之后,无法使用 A 的公钥解密 E 发送过来的特征码,这样就可以确保身份验证 d,主要保证的是身份验证,数据不被篡改(篡改了获取之后能判断出来,直接丢弃了);拿到特征码之后,要确认能够用 A 的公钥解密,不能解密就已经有问题 - 公钥加密主要用在身份验证上 - 涉及到另外一个问题,怎么获取到 A 的公钥 d,公钥签名(签名机构问题) e,三重验证怎么完成问题   the differences between RHEL6 \u0026 RHEL7 ## 2018-06-08 ##\n----------------------------------------------------------------------------------------------------------------- - RHEL6 - RHEL7 ------------------------------------------------------------------------------------------------------------------ filesystem - ext4 - xfs ------------------------------------------------------------------------------------------------------------------- kernel version - 2.6.x-x - 3.10.x-x ------------------------------------------------------------------------------------------------------------------- kernel name - Santiago - Maipo ------------------------------------------------------------------------------------------------------------------- release time - 2010-11-09 - 2014-06-09 ------------------------------------------------------------------------------------------------------------------- progress name - init - systemd ------------------------------------------------------------------------------------------------------------------- - runlevel0 - runlevel0.target-poweroff.target - runlevel1 - runlevel1.target-rescue.target - runlevel2 - runlevel2.target-multi-user.target runlevel - runlevel3 - runlevel3.target-multi-user.target - runlevel4 - runlevel4.target-multi-user.target - runlevel5 - runlevel5.target-graphical.target - runlevel6 - runlevel6.target-reboot.target - /etc/inittab - /etc/systemd/system/default.target ------------------------------------------------------------------------------------------------------------------- hostname - /etc/sysconfig/network - /etc/hostname ------------------------------------------------------------------------------------------------------------------- max file size - 16TB - 500TB ------------------------------------------------------------------------------------------------------------------- filesystem check tool - e2fsck - xfs.repair ------------------------------------------------------------------------------------------------------------------- boot tool - GRUB - GRUB2 ------------------------------------------------------------------------------------------------------------------- service start - upstart - systemd ------------------------------------------------------------------------------------------------------------------- - service xxxx start - systemctl enable xxxx.service - service xxxx stop - systemctl start xxxx.service service control - service xxxx status - systemctl stop xxxx.service - service xxxx restart - systemctl status xxxx.service - chkconfig xxxx on|off - backwards compativility chkconfig service ------------------------------------------------------------------------------------------------------------------- firewall - iptables - firewalld,iptables ------------------------------------------------------------------------------------------------------------------- network bond - bonding - teaming,bonding ------------------------------------------------------------------------------------------------------------------- time set - ntp - chrony,ntp ------------------------------------------------------------------------------------------------------------------- nfs version - NFS4 - NFS4.1，支持NFSv3.0,4.0,4.1客户端 ------------------------------------------------------------------------------------------------------------------- cluster management - rgmanager - pacemaker ------------------------------------------------------------------------------------------------------------------- load-balance tool - rgmanager - HAProxy，Keepalived ------------------------------------------------------------------------------------------------------------------- desktop environment - GNOME2.0 - GNOME3.0,KDE4.10 ------------------------------------------------------------------------------------------------------------------- database - mysql - mariadb ------------------------------------------------------------------------------------------------------------------ the commands's differences between RHEL6 \u0026 RHEL7 ----------------------------------------------------------------------------------------------------------------- - RHEL6 - RHEL7 ------------------------------------------------------------------------------------------------------------------- GUI tool - system-config-* - gnome-control-center ------------------------------------------------------------------------------------------------------------------- network tool - nmcli,nmtui,nm-connection-editor - system-config-network ------------------------------------------------------------------------------------------------------------------- language tool - system-config-language - localectl ------------------------------------------------------------------------------------------------------------------- time tool - system-config-date,date - timedatactl,date ------------------------------------------------------------------------------------------------------------------- time synchronise - ntpdate,/etc/ntp.conf - ntpdate,/etc/chrony.conf ------------------------------------------------------------------------------------------------------------------- keyboard tool - system-config-keyboard - localectl ------------------------------------------------------------------------------------------------------------------- service list - service --status-all - systemctl -t status --state=active ------------------------------------------------------------------------------------------------------------------- add service - chkconfig --add - systemctl daemon-reload ------------------------------------------------------------------------------------------------------------------- get runlevel - runlevel - systemctl get-default ------------------------------------------------------------------------------------------------------------------- change runlevel - init,runlevel - systemctl isolate name.target,init,runlevel ------------------------------------------------------------------------------------------------------------------- log file - /var/log/ - /var/log/,journalctl ------------------------------------------------------------------------------------------------------------------- single mode - 1,s,/bin/bash - rd.break,init=/bin/bash ------------------------------------------------------------------------------------------------------------------- shutdown system - shutdown - systemctl shutdown ------------------------------------------------------------------------------------------------------------------- poweroff host - poweroff - systemctl poweroff ------------------------------------------------------------------------------------------------------------------- halt the system - halt - systemctl halt ------------------------------------------------------------------------------------------------------------------- reboot the system - reboot - systemctl reboot ------------------------------------------------------------------------------------------------------------------- modify runlevel - /etc/inittab - systemctl set-default ------------------------------------------------------------------------------------------------------------------- configure grub - /boot/grub/grub.conf - /etc/default/grub,grub2-mkconfig,grub-set-default ------------------------------------------------------------------------------------------------------------------- install packages - yum install,yum groupinstall - yum install,yum group install ------------------------------------------------------------------------------------------------------------------- package information - yum info,yum groupinfo - yum info,yum group info ------------------------------------------------------------------------------------------------------------------- lvm management - vgextend,lvextend,resize2fs - vgextend,lvextend,xfs_growfs ------------------------------------------------------------------------------------------------------------------- - /etc/sysconfig/network - /etc/hosts network configuration - /etc/hosts - /etc/resolve.conf - /etc/resolve.conf - /etc/sysconfig/network-scripts/ifcfg* - /etc/sysconfig/network-scripts/ifcfg* - ------------------------------------------------------------------------------------------------------------------- hostname - hostname,/etc/sysconfig/network - hostnamectl,/etc/hostname,nmcli ------------------------------------------------------------------------------------------------------------------- ip addr configure - ip a,ifconfig,brctl - ip a,nmcli dev show,teamdctl,brctl bridge ------------------------------------------------------------------------------------------------------------------- port listing - ss,netstat,lsof - ss,lsof -------------------------------------------------------------------------------------------------------------------  ","description":"","tags":["linux","basic","note"],"title":"Linux 学习笔记","uri":"/tech/basics/notes/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]