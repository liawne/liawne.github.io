[{"categories":["tech"],"content":"说明 PEM (Privacy Enhanced Mail的缩写)文件最初是为了确保电子邮件安全而发明的, 现在它是一个互联网安全标准. PEM 文件是 X.509 证书、CSR(certificate signing request) 和加密密钥的最常见格式.\n什么是 PEM 文件 PEM 文件是一个文本文件, 文件中包含一个或多个采用 Base64 ASCII 编码的条目, 每个条目都有纯文本的页眉和页脚\n 例如: --BEGIN CERTIFICATE-- 和 --END CERTIFICATE--\n PEM 是一种容器格式, 可能只包括公共证书, 也可能包括整个证书链, 包括公钥、私钥和根证书.\nPEM可以有多种扩展名\n 例如: .pem、.key、.cer、.cert 等\n 典型的 PEM 文件是：\n key.pem: 包含私有加密密钥 cert.pem: 包含证书信息  PEM 文件格式 页眉和页脚用于标识文件的类型, 但并非所有 PEM 文件都需要它们. 如下说明几种不同类型的PEM文件\n   页眉页脚内容 文件类型     —–BEGIN CERTIFICATE REQUEST—–\n....\n—–END CERTIFICATE REQUEST—– CSR文件   —–BEGIN RSA PRIVATE KEY—–\n....\n—–END RSA PRIVATE KEY—– 私钥文件   —–BEGIN CERTIFICATE—–\n....\n—–END CERTIFICATE—– 证书文件    如果 PEM 文件包含 SSL 证书链, 则格式如下所示:\n1 2 3 4 5 6 7 8 9  —–BEGIN CERTIFICATE—– //end-user —–END CERTIFICATE—– —–BEGIN CERTIFICATE—– //intermediate —–END CERTIFICATE—– —–BEGIN CERTIFICATE—– //root —–END CERTIFICATE—–   文件示例 如下示例是一个私钥 pem 文件:\n1 2 3 4 5 6 7 8 9  —–BEGIN PRIVATE KEY—– MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDBj08sp5++4anG cmQxJjAkBgNVBAoTHVByb2dyZXNzIFNvZnR3YXJlIENvcnBvcmF0aW9uMSAwHgYD VQQDDBcqLmF3cy10ZXN0LnByb2dyZXNzLmNvbTCCASIwDQYJKoZIhvcNAQEBBQAD … bml6YXRpb252YWxzaGEyZzIuY3JsMIGgBggrBgEFBQcBAQSBkzCBkDBNBggrBgEF BQcwAoZBaHR0cDovL3NlY3VyZS5nbG9iYWxzaWduLmNvbS9jYWNlcnQvZ3Nvcmdh z3P668YfhUbKdRF6S42Cg6zn —–END PRIVATE KEY—–   如下是根证书 pem 文件的示例:\n1 2 3 4 5 6 7 8 9 10 11  # Trust chain root certificate —–BEGIN CERTIFICATE—– MIIDdTCCAl2gAwIBAgILBAAAAAABFUtaw5QwDQYJKoZIhvcNAQEFBQAwVzELMAkG YWxTaWduIG52LXNhMRAwDgYDVQQLEwdSb290IENBMRswGQYDVQQDExJHbG9iYWxT aWduIFJvb3QgQ0EwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDaDuaZ … jc6j40+Kfvvxi4Mla+pIH/EqsLmVEQS98GPR4mdmzxzdzxtIK+6NiY6arymAZavp 38NflNUVyRRBnMRddWQVDf9VMOyGj/8N7yy5Y0b2qvzfvGn9LhJIZJrglfCm7ymP HMUfpIBvFSDJ3gyICh3WZlXi/EjJKSZp4A== —–END CERTIFICATE—–   其他   使用 openssl 命令检查 PEM 证书文件\nopenssl 是一个开源命令行工具, 通常用于生成私钥、创建 CSR、安装我们的 SSL/TLS 证书以及识别证书信息.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  ## 命令格式是: openssl x509 -text -in server.pem -noout # 示例:  $ openssl x509 -in /etc/pki/fwupd/LVFS-CA.pem -text -noout Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: CN = LVFS CA, O = Linux Vendor Firmware Project Validity Not Before: Aug 1 00:00:00 2017 GMT Not After : Aug 1 00:00:00 2047 GMT Subject: CN = LVFS CA, O = Linux Vendor Firmware Project Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public-Key: (3072 bit) Modulus: 00:b5:f5:17:1f:73:70:0c:9c:d6:ca:19:0f:c8:f7: ...... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: critical CA:TRUE, pathlen:1 X509v3 Subject Alternative Name: URI:http://www.fwupd.org/, email:sign@fwupd.org X509v3 Extended Key Usage: Code Signing X509v3 Key Usage: critical Certificate Sign, CRL Sign X509v3 Subject Key Identifier: B1:8D:EA:E4:23:A7:7E:09:8E:B5:EE:31:E0:6A:DD:9E:34:37:65:AC X509v3 CRL Distribution Points: Full Name: URI:http://www.fwupd.org/pki/ Signature Algorithm: sha256WithRSAEncryption ......     ssh 使用的 PEM\nPEM 文件也用于 ssh, 如果我们执行过 ssh-keygen 用来配置 ssh 的免密, 则 ~/.ssh/id_rsa 就是一个 PEM 文件, 只是没有扩展名.\n我们可以在 ssh 中使用 -i 标志来指定我们要使用新密钥而不是 id_rsa：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 生成一对新公私钥对 $ ssh-keygen -f ./test_rsa -t rsa -P '' Generating public/private rsa key pair. Your identification has been saved in ./test_rsa Your public key has been saved in ./test_rsa.pub The key fingerprint is: SHA256:r+NkIS+z7wZcjYjsQ1q/mWDkBkbSXjE1W7mS74W69AE liawne@ruiwen The key's randomart image is: +---[RSA 3072]----+ | . ooo .. | |. o .. +. | | + o ..o + | | + * + + . | | . O oE+S. | | . B ++oo. | | o o+B=.. | | .=B+o | | o**. | +----[SHA256]-----+ # 使用新生成的密钥对配置免密 $ ssh-copy-id -i ./test_rsa.pub pi@192.168.8.106 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"./test_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed ...... # 使用对应的私钥连接服务器 $ ssh -i ./test_rsa pi@192.168.8.106 Last login: Tue Mar 22 23:10:35 2022 from 192.168.8.102 ......     ","description":"PEM 是什么, 我们有哪些日常使用的命令和 PEM 相关","tags":["PEM","证书","openssl","CA"],"title":"什么是PEM文件","uri":"/tech/certificate/%E4%BB%80%E4%B9%88%E6%98%AFpem%E6%96%87%E4%BB%B6/"},{"categories":["tech"],"content":"背景 使用 vim 打开 windows 上编辑的 txt 文件, 出现下面的乱码现象 在 manjaro 的 kate 中打开, 可以正常显示 定位 判断出 vim 编辑乱码的原因是因为 vim 的编码方式问题, 需要调整 vim 的相关配置\n对于 vim 的配置文件 ~/.vimrc 或者 /etc/vimrc, 如果不清楚配置文件各个配置项的具体作用, 则最好不要随意更改调整, 否则可能出现自己不清楚的错误, 后续想修复又不容易找到是什么原因导致的. 这个自己之前踩过坑, 网上抄写大牛发出来的配置, 确实能用, 但那是他们调教出来的效果, 不一定就是自己想要的; 想调整成最适合自己的, 还是要自己折腾.\n/etc/vimrc 是全局配置, ~/.vimrc 是用户配置, 我们只需要调整~/.vimrc 即可\n先了解一下 vimrc 中涉及到格式编码的几个配置项\n进入 vim 命令行界面, shift + : 进入到 COMMAND mode, 输入 help encoding 查找编码相关的帮助内容 :\n1 2  $ vim :help encoding   配置介绍    配置项 配置说明     encoding vim 内部使用的字符编码方式, 主要包括 buffer, 寄存器, 表达式中的字符, 保存在viminfo中的内容等. 对 MS-windows 来说默认是 UTF-8, 对其他的系统则通过$LANG读取或者是latin1. 默认情况下, encoding 是设置成当前 locale 的值, 如果 encoding 没有设置成 locale 的 $LANG, 则 termencoding 必须设置成 locale 的 $LANG用于转换终端显示的文本内容   fileencoding 设置当前打开文件的 buffer 文件字符编码方式, 默认为空值；当 fileencoding 的设置和 encoding 设置值不一样时, vim 编辑后保存文件时会将文件保存为 fileencoding 设置的字符编码方式；fileencoding为空时, 使用encoding 的编码方式保存文件. 当需要以特定编码方式读取一个文件时, 配置fileencoding不生效, 需要使用++enc 参数来设置, 也有一种特殊情况, 当fileencodings的值是空时, fileencoding的值才会被使用   fileencodings vim设置fileencoding的顺序列表, 默认值为ucs-bom(Byte Order Mark), vim 打开文件时会按照fileencodings 的内容, 依次检测罗列的字符编码方式, 当一项编码解析出现错误时, 会自动使用下一项进行探测. 最终确认一项可用时, 会将fileecoding 设置为该值; 若都失败, fileencoding 则设置为空, 则当前打开的缓冲文件使用默认的 encoding 设置内容进行编码. fileencodings 只对已存在文件生效, 新文件使用的是fileencoding配置值, 也就是说新文件和空文件使用的编码方式可能是不一样的.   termencoding vim 所在的命令行终端的字符编码方式, 键盘打印输出和显示器显示内容的编码, 对 GUI 环境来说, 则只对 键盘产生的数据生效, GUI 使用encoding的配置值; termencoding的默认值是空值.    相关参数罗列完成后, 整理一下 vim 打开文件的过程, 这几项参数在这个过程中的作用\n vim 使用配置文件(/etc/vimrc 或 ~/.vimrc)中 encoding 配置的编码方式打开文件, 设置缓冲区文件, viminfo 文件, 寄存器等内容的编码方式 因为是已经存在的文件, vim 加载fileencodings 内容, 逐项检测配置的编码方式, 若存在无错误的项时, 分配该编码方式的值给fileencoding 对比encoding 和 fileencoding 的值, 若不相同, 则使用fileencoding 的编码方式重新编码缓冲区文件内容, 最终体现为当前终端打开文件的显示内容. 转换的动作是由iconv() 完成的, 或者在COMMAND mode指定 charconvert 进行转换 编辑完文件后保存, 还是对比 encoding 和 fileencoding 的内容, 不一致就将缓存区文件内容以 fileencoding 设置的编码方式更新到文件中   encoding 和 fileencoding的转换可能导致文件内容部分丢失, 当 encoding 是 utf-8 或者其他 Unicode 编码, 转换的内容很大概率还是能够被反解析成相同的内容; 但当 encoding 不是 utf-8时, 一些字符可能在转换的过程丢失\n 修复 先确认当前文件的编码方式:\n1 2  $ chardetect make\\ iso\\ image.txt make iso image.txt: GB2312 with confidence 0.99   配置文件增加相应的编码方式:\n1 2 3 4  ## 编辑 ~/.vimrc, 增加相应的配置项 $ vim ~/.vimrc $ cat ~/.vimrc | egrep 'fileencoding|encoding' set fileencodings=utf-8,ucs-bom,gb2312,cp936   重新打开文件, 显示正常\n","description":"vim 打开 windows 上编辑的 txt 文件格式乱码","tags":["vim","解码"],"title":"vim 打开 txt 文件乱码","uri":"/tech/miscell/vim%E6%89%93%E5%BC%80txt%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/"},{"categories":["tech"],"content":"Devops核心要点及kubernetes架构概述 1, ansible:应用编排工具\n 可以安装,配置应用 可以依照playbook来配置有依赖关系的应用程序  2, docker的编排工具,docker的编排不能再采用传统意义应用的方式来编排,因为接口已经发生了变化\n docker呼唤面向容器的新式编排工具的实现  docker编排三剑客 1,docker compose(主要功能是编排,可以单机,可以资源池 ) 2,docker swarm(跨机执行,能够将多个主机集成为一个资源池,可以算作一个集群管理工具 ) 3,docker machine(新扩入集群的主机,能够将一个主机迅速初始化加入到一个docker swarm集群中)   mesos: IDC的OS,能够将一个IDC所提供的所有硬件资源提供的计算资源统一分配,是一个资源分配工具 1,marathon: 提供面向容器编排的框架 kubernetes,现有占据80%以上的份额  3, 新概念\n MicroServices: 微服务, 应用不再分层,将应用拆解成一个个的微服务,很可能当前使用的一个应用以- 微服务体现的话,需要拆解成上百个的微服务,彼此之间互相写作 CI: continious intergration持续集成 CD: continious delivery持续交付 CD: continious deployment持续部署  4, 容器技术的出现,使得DevOps的落地实现成为了可能\n1 2 3 4 5  trigger(commit, push and so on) --\u003e CI --\u003e CD(交付) --\u003e CD(部署) DevOps progress --------------------------------------------------------------\u003e # DevOps中异构环境的问题,因为容器的出现而可以解决   5, 容器编排的必要性\n 通过微服务的方式来发布应用,一个应用几百个微服务构成,出故障是必然的,每天出现多少次,人为修复是不可能的,所以需要容器编排工具来完成这个工作 因为容器技术的出现,使得DevOps得以落地; 因为DevOps的落地,使得容器编排技术成为一个底层技术 devops是一种文化, 打破dev和ops的隔阂, 使传统手工方式自动化完成  6, openshift\n redhat使用的paas工具是openshift, openshift的核心是kubernetes, kubernetes还没达到paas这个层面; openshift可以理解为kubernetes的发行版(linux的发行版有ubuntu,redhat,debian等) kubernetes实现的东西很底层,如果要具有paas的功能,还需要自行安装很多工具;openshift则提供了一个完整的工具链供客户使用  7,kubernetes是站在borg肩膀上的开源软件\n kubernetes相关功能  自动装箱: 基于资源依赖及其他约束能够自动完成容器的部署而且不影响其可用性 自动修复: 自我修复,自愈能力,容器的轻量,能够在挂掉之后很短的时间内拉起;  容器方式拉起的应用处理逻辑也发生了变化, 一个应用崩掉了, 可以直接kill掉容器进程, 然后重新拉起来 有了k8s这种编排工具之后, 我们关注的更多的是群体, 而不再是个体了   自动实现水平扩展: 在资源足够的情况下,可以自动扩展节点 服务发现和负载均衡:  当在k8s上运行了很多应用程序(微服务)后, 服务可以通过服务发现自动找到依赖到的服务 每一种服务拉起来之后,自动做负载均衡   自动发布和回滚 密钥和配置管理 存储编排: 使存储卷实现动态供给(某一个容器需要用到存储卷时,根据容器自身的需求创建能够满足其需要的存储卷) 批处理执行   kubernetes就是一个集群, 组合多台主机的资源,组合成一个大的资源池,并统一对外提供存储,计算的集群 kubernetes是一个有中心节点架构的集群系统, master-nodes模型  8, kubernetes编排的应用\n 非云原生应用的启动方式: entrypoint中定义一个脚本,脚本能够接受用户传递给容器的参数,脚本将其转化为应用可读取的配置信息;应用再通过配置文件来读取配置 云原声的启动方式: 基于环境变量的方式传递参数, 修改环境变量, 容器应用自动通过读取环境变量实现不同动作  通过kubernetes来编排的应用需要是云原声应用, 非云原声的应用可能会碰到各种各样的问题(比如配置文件保存在哪里等等)    9, kubernetes工作\n 用户在kubernetes上运行一个应用  客户的请求先发给master(启动容器的请求) master当中存在一个调度器,分析各个node现有的可用资源状态 找出一个最佳适配运行客户容器的节点 节点上的容器引擎来运行这个容器(先检查本地是否有镜像,没有镜像则从harbor上拉取镜像)   怎样保证kubernetes实现自愈能力的  kubelet监控节点上应用容器的状态,确保容器应用的状态正常(节点正常的情况下) 控制器确保容器是否正常,如果不正常,控制器上报给master,由master重新调度新的(节点宕机的场景);  kubernetes有一大堆的控制器来监控容器是否正常; 控制器在本地不断的loop,来监控各个容器的状态; 确保处于用户期望的状态,或者说是移向用户期望的状态   控制器有问题了, 在master上有controller-manager,用来监控控制器的状态；控制器有冗余(3个master, 做了高可用, 三个节点中只有一个可用) master是整个集群的大脑, 有三个核心组件:  apiserver: 负责接受并处理请求的 scheduler: 调度容器创建的请求 controller-manager: 确保控制器状态正常(确保容器状态正常的控制器只是众多控制器中的一种)     kubernetes并不直接调度容器,调度的最小对象是pod(可以理解为容器的外壳,给容器做了一层抽象的封装)  kubernetes做了一个逻辑组件叫pod,在pod内用来运行容器  一个pod内可以包含多个容器,共享的namespace有NET,IPC,UTS,另外三个互相隔离(USER,MNT,PID) pod对外像一个虚拟机 同一个pod中的容器共享存储卷; 存储卷可以理解为不属于容器, 而是属于pod     kubernetes上运行的node, 负责运行由master指派的各种任务,最核心的就是一pod形式去运行容器的  10, kubernetes区分\n master:  apiserver scheduler controller manager   node:  kubelet: node的核心组件, 用来同集群交互, 尝试拉起容器等 docker: 容器引擎,不一定是docker,只是docker最流畅 kube-proxy: 随时与apiserver通信, 监控本地相关资源的情况,当发生变化通知到apiserver后,apiserver生成一个通知事件,可以被所有关联的组件接收到  service的创建需要kube-proxy生成相应规则 service的更新,也需要kube-proxy更新相应的规则      kubernetes基础概念 1, pod说明\n pod:  kubernetes的最小调度单元 pod很重要的一个属性: label,众多元数据中的一个,用于区分筛选pod,负责筛选的是label selector   人为分类(官方未做分类):  自主式pod: 由kubelet监控管理,在节点故障时,pod消失,无法再自动创建 控制器管理的pod: 控制器存在多种    2, 控制器\n ReplicationController: 副本控制器 ReplicaSet: Deployment:  HPA: 自动水平扩展功能(horizontal Pod Autoscaler), 通过监控当前CPU或者内存等资源的消耗情况(比如定义不能超过60%), 来自动添加pod, 当负载下降后还可以自动减少,但有一个最少值   StatefulSet: DaemonSet: Job, cronjob  3, Service\n pod时时在变化,在容器时代,不能再按照以前通过写配置文件,固定IP地址或者主机名的方式来访问固定的Pod了; 客户端发送一个请求过来,路由到相应的pod是怎么实现的  在client和目标Pod之间,存在一个中间层,这个中间层就是service service固定IP地址或者端口, 在没有手动删除的情况下, service不会消失 客户端访问service, service将相应的请求路由到后端对应的pod service通过label去匹配pod的 service不是什么应用程序,也不是实体组件,是iptables的DNAT规则(现已修改为ipvs规则) 客户端访问service名称,然后被kubernetes中的dns服务解析,得到service的地址,再由service的DNAT转发到相应的pod(现已修改为ipvs规则); service只是用来调度分配到各个pod上的流量的 创建了service之后,其相应的iptables/ipvs规则会反映在所有的node主机上    4, 云计算平台和kubernetes天生具有良好的兼容性\n 物理机在kubernetes创建服务时,若需要对外提供服务,需要有loadbalance,但已经不属于kubernetes的管理范围 云平台则不一样,aws,阿里云等可以提供lbaas的接口,在kubernetes需要创建对外提供服务的service时,可以通过调用云平台的lbaas接口来创建loadbalance  5, kubernetes涉及的网络\n 三类网络  pod使用的网络(pod网络): 供pod通信使用,各个pod共享同一个network namespace,网络可以互相ping通,类似于一个正常的IP地址 Service使用的网络(集群网络): 和pod的地址是不同网段的,虚拟的网络,只存在于iptables或者ipvs中 各个node的网段(节点网络): 各个节点各自的IP地址   三类通信  同一个pod内的多个容器间通信: 直接是哟你lo就可以 各个pod之间的通信: 与docker之间的网络通信实现方式不同(两层NAT转发实现跨主机的容器网络通信), kubernetes是直接通过pod地址来通信的(各个pod的地址唯一)  使用物理机桥接网络, 但当集群中pod数多起来之后,广播量太大,无法承受 使用overlay network(叠加网络),使得虽然跨主机,但仍像工作在同一个二层网络中;叠加网络可以实现二层广播,也可以实现三层广播(隧道)   pod与service的通信:  service的iptables/ipvs规则是反映在所有的节点上的,当一个容器需要去访问一个service时,容器的请求转发给docker0网桥就可以了     网络功能kubernetes不提供,需要依赖插件来完成  网络插件提供商最少要提供两个功能:节点网络, 集群网络 kubernetes通过CNI插件体系来接入外部的网络服务解决方案  flannel: 支持网络配置,叠加网络实现,相对简单 calico: 既支持网络配置,也支持网络策略,三层网络隧道实现,相对复杂 canel: 这种方式是上面两种方式的折中 各个CNI插件可以作为容器托管在集群上,也可以作为守护进程在各个节点上运行      6, kubernetes使用到的证书\n etcd是整个集群的核心,整个集群的状态信息都在etcd当中存储,故etcd需要做高可用  etcd是restful风格的集群:通过http/https通信,kubernetes使用的是https方式 etcd是一个端口用于集群内部通信,一个端口用于对客户端提供服务   证书使用  etcd集群内部通信,点对点通信https,需要使用一个证书 etcd对客户端(集群中的apiserver)提供服务,使用另外一套证书(一套ca) kubernetes的apiserver需要使用https对外提供服务,一套证书(不要与etcd使用同一套ca来签署) apiserver与kubelet,kube-proxy等通信,每个组件需要单独的证书 手动部署k8s集群,大概需要手动部署5套ca左右(etcd之间,apiserver访问etcd,client访问apiserver,apiserver与内部集群间的通信,还剩一个需要确认)    使用kubeadm安装kubernetes  常用kubernetes安装方式  使用rpm包的方式安装或者源码编译的方式安装: 这种方式很麻烦,为了提高安全性,需要手动提供很多套的ca和证书 使用kubeadm部署  每个节点都需要安装docker和kubelet,并确保两个服务都已经运行起来 选择一个节点初始化为master后, 将controller-manager,api-server,etcd,kube-schedule以pod的方式运行在master节点上 其他node上以pod的方式运行kube-proxy服务 所有的组件pod都是static pod(静态pod)     使用kubeadm安装kubernetes的步骤  master, nodes:安装kubelet, kubeadm, docker 在master节点上执行kubeadm init来完成集群初始化  先决条件预捡 生成证书,私钥,配置文件 生成每一个静态pod的清单文件 完成部署addon   在各个node节点上执行kubeadm join  检查先决条件,看能否满足需求   查看github上kubeadm的designvx_xx.md文档说明即可 解决docker下载kubernetes镜像需要翻墙的问题  在安装完docker之后,修改/usr/lib/systemd/system/docker.service文件, 增加一个Environment=\"HTTPS_PROXY=http://www.ik8s.io:10080\" 在下载完kubernetes相关镜像之后,将上面的内容注释掉,正常使用国内源即可      kubernetes应用快速入门   kubectl就是apiserver的客户端程序\n 通过连接master节点上的apiserver apiserver也是整个kubernetes集群的唯一管理入口,kubectl就是这个管理入口的客户端工具,完成kubernetes上各种对象的增删改查等基本操作    kubectl命令\n run子命令  通过run命令生成一个deployment或者job来管理相应容器 1 2  kubectl run nginx --image=nginx kubectl run nginx-deploy --image=nginx:1.14-alpine --port=80 --replicas=3 --dry-run=true    传递给pod的命令默认方式是后接-- run命令是通过生成deployment或者job,再拉起pod,不是直接直接创建的pod      kubernetes网络分配\n pod可分配网段是10.244.0.0/16,各个节点分配一个24位掩码的子网,比如node2分配到的是10.244.2.0/24 pod的客户端主要有两类: 其他pod,外部访问 使用kubectl expose来创建service(视频是1.11版本的), 指定端口用于转发 - 参考示例: kubectl expose deployment nginx-deploy --name=xxx --port=xxx --target-port=xxx --protocol=xxx - 外部访问转发: --\u003e service_ip:service_port --\u003e pod_ip:pod_port - 参数type: ClusterIP:仅供集群内部使用,是默认的类型 NodePort:可用于将svc暴露给外部使用,默认会自动生成一个随机端口映射至内部各个节点,网关地址,外部访问时,可以随机使用任意一个node的该端口  service给有生命周期的pod提供了一个固定的访问入口  service是iptables或者ipvs规则 访问svc的端口,都会被调度至该svc用Label Selector关联到的各个pod后端      命令使用\n 使用watch方式监控资源变化  kubectl get pods -w   动态扩展pod数(也可以缩减)  kubectl scale --replicas=x TYPE NAME   动态更新容器镜像  kubectl set image TYPE NAME CONTAINER_NAME_1=CONTAINER_IMAGE_1 ... 使用kubectl rollout status TYPE NAME 来查看滚动更新的状态 使用kubectl rollout undo TYPE NAME来回滚更新 kubectl rollout --help可以查看支持的各个命令   k8s支持自动扩缩容,但是需要有监控系统,这个需要单独部署 kubectl run/expose只是一个简单的命令,用于测试学习等场景;因为这些单独的命令无法实现全部功能,无法实现全部定制,实际使用应该基于yaml的配置文件来实现    05-kubernetes资源清单定义入门   kubernetes有一个RESTful风格的API,把各种操作对象都一律当作资源来管理,通过标准的http请求方法(GET,PUT,POST,DELETE)_来完成操作\n 但是通过相应的命令(kubectl run/expose/edit/get),反馈到命令行上    资源实例化之后变成对象\n 工作资源负载型对象(workload): Pod, ReplicaSet, Deployment, StatefulSet, DaemonSet, Job, CronjobSet, Deployment, StatefulSet, DaemonSet, Job, Cronjob 服务发现及服务均衡: Service, Ingress 配置与存储: Volume(有状态的持久存储需求的应用必须要用到的),CSI(存储卷),  configmap:为了配置容器化应用必然会用到的 secret:保存敏感数据   集群级资源:  namespace node role clusterrole rolebinding clusterrolebinding   元数据型资源  HPA Podtemplate LimitRange      资源清单定义\n 运行中的pod为例,说明各个字段的作用  apiVersion定义,有两个部分组成,分别是group名+version(组名+版本号),如果group省略,则表示属于core(核心组)  apiVersion: v1 --\u003e apiVersion: core/v1 组管理的好处:某一组的改动,只改一组就行,不影响其他组的使用; 一个组的多个版本号还可以并存 version一般有3个:alpha(内测版本), beta(公测版本), stable(稳定版本)  不同版本支持的可嵌套字段可能是不一样的\n    kind定义,确定资源类别,用来指明实例化成一个资源对象时使用 metadata,元数据, spec(specification):用来定义接下来需要创建的资源应该具有什么样的特性,或者应该满足什么样的规范;基本是一个资源对象中最重要的字段 status,与spec对应,显示当前的状态,spec是预期值,status是实际值,当实际值与预期值不符时,会向预期值靠拢      apiversion仅接收json格式的资源定义,yaml格式提供配置清单,apiserver可自动将其转为json格式,而后再提交\n  大部分资源的配置清单组成有5部分(一级字段):\n apiversion  pod是最核心的资源,所以属于核心群组vxxxx;deployment,replicaset属于应用程序管理的核心资源,他们属于app/vxxxxx kubectl api-versions即可获取   kind:资源类别 metadata:元数据  name: 在同一类别中,那么必须是唯一的,同一命名空间中 namespace: name需要受限于namespace,是kubernetes的概念,和操作系统的namespace要区分好 labels: 标签 annotations: 资源注解   spec:最重要的一个字段,定义期望状态(desired state)  不同资源类型,spec部分需要嵌套的内容不同   status:当前状态(current state),本字段由kubernetes集群维护,不能人为定义 各个字段的man文档可以使用如下命令查看: kubectl explain KIND.OBJECT.xxx.xxx --\u003e kubectl explain pod.metadata/pod.spec.containers.livenessprobe # explain输出的内容中,设定格式有 # \u003cstring\u003e: 字串 # \u003c[]string\u003e: 字串列表,字串类型的数组 # \u003cObject\u003e: 嵌套类型的三级字段 # \u003cmap[string]string\u003e: 键值组成的映射 # \u003c[]Object\u003e: 对象列表 # -required-: 表示该字段必须存在     每个资源的引用PATH:\n /api/GROUP/VERSION/namespaces/NAMESPACE/TYPE/NAME    一个pod定义的yaml文件示例\npod-demo.yaml: -------------------------------------------------------------- apiVersion: v1 kind: Pod metadata: name: pod-demo namespace: default labels: ---\u003e labels字段是属于map(kv字典), 这里也可以写成labels: {\"app:myapp\", \"tire:frontend\"} app: myapp tire: frontend ---\u003e labels字段可以有多个label map spec: containers: ---\u003e containers是对象列表格式 - name: myapp image: ikubernetes/myapp:v1 - name: busybox ---\u003e 多个容器存在于一个pod中, 用于辅助主容器工作, 这种方式称为边车模型 image: busybox:latest command: ---\u003e command字段属于列表, 这里也可以写成command: [\"/bin/sh\", \"-c\", \"sleep 3600\"]; command用于覆盖容器的默认命令 - \"/bin/sh\" - \"-c\" - \"sleep 3600\" --------------------------------------------------------------  基于这个yaml文件可对资源进行管理  kubectl create -f pod-demo.yaml: 根据这个文件内容,创建相应的资源 kubectl delete -f pod-demo.yaml: 根据yaml文件内容,删除相应的资源 kubectl apply -f pod-demo.yaml: 根据yaml修改内容,滚动更新相应的资源   问题:  使用pod-demo.yaml文件定义的pod,没有控制器被创建,都是我们自己去控制了,这种形式的pod称之为\u003c自主式Pod资源\u003e  有控制器的pod,一删除会被自动创建 我们这里创建的这个pod,一删除就被删除了        在定义pod资源时, spec字段常用的字段有哪些\n spec.containers: \u003c[]object\u003e  name:  image:  imagePullPolicy: ,有Always,Never,IfNotPresent这几个值可选择;  如果镜像标签选择了latest,则使用的是Always 其他策略时默认为IfNotPresent; 该字段不能更改 各个策略的优缺点:  always(好处是可以一直拿到最新的镜像,确保拿到最新的发布镜像;缺点是会占用带宽,而且拉起时间长); never: 可以节省带宽和时间,但可能本地就有的基础镜像是被修改过的,有问题的,也无法被更新 ifnotpresent: 折中的一种方式,当不可用的时候才去拿镜像     ports: \u003c[]object\u003e,informational功能,只是提供信息而已,和docker中的暴露端口不一样  containerPort可以有多个 containerPort以列表的方式展示   command/args: \u003c[]string\u003e  args:entrypoint arguments;  当这个参数没有提供时,容器镜像的默认ENTRYPOINT会被使用 变量引用的格式是$(variable_name),需要特别注意;若自己需要使用命令替换方式,则格式为$$(variable_name),作为逃逸   command:entrypoint array;  当这儿参数没有被使用时,容器镜像的默认CMD会被使用 给定的内容不会在shell中执行,所以若需要在shell中执行内容,需要自己在内容中增加'/bin/sh', '-c', 'contents' 变量引用的格式是$(variable_name),需要特别注意;若自己需要使用命令替换方式,则格式为$$(variable_name),作为逃逸   docker中entrypoint/cmd和k8s中command/args的结合使用 ------------------------------------------------------------------------------------------------------------------------ | 描述 | Docker filed name | Kubernetes field name | ------------------------------------------------------------------------------------------------------------------------ | The command run by the container | Entrypoint | command | ------------------------------------------------------------------------------------------------------------------------ | The arguements passwd to the command | Cmd | args | ------------------------------------------------------------------------------------------------------------------------ # 资源清单中没有给容器提供command和args,则容器镜像的默认entrypoint和cmd生效 # 资源清单中给容器提供了command但没有args时,则仅仅command生效,容器镜像默认的entrypoint和cmd被忽略 # 资源清单中给容器提供了args但没有command时,则容器镜像的Entrypoint使用给定的args # 资源清单中给容器提供了command和args,则command使用给定的args生效      有些字段是可以被修改,而且改完之后能即时生效的;有些字段不能修改 docker中如果同时存在entrypoint和cmd时,cmd将作为参数被传递给entrypoint    使用kubectl管理资源有三种用法\n 命令式用法: kubectl run/expose/edit xxxx 配置清单式用法: 本章讲解的内容(命令式资源清单) 也是使用命令清单,但用法不同(声明式资源清单)    kubernetes Pod控制器应用进(一)   label是kubernetes上很有特色的一个功能\n 提升资源管理效率,在同一套集群中,k8s的资源量上去后,需要被管理的资源通过label可以被快速识别 当给资源配置了label之后,还可以通过label来查看,删除等管理操作 所谓的label就是附加在对象上的一个键值对 一个资源上可以存在多个label,每个label都可以被标签选择器进行匹配度检查,从而完成资源挑选 标签可以在资源创建时配置,也可以在资源创建之后配置 key=value,键值对的长度都不能超过63个字符 # key:字母,数字,_,-,. # value:可以为空,只能字母或数字开头及结尾  直接给资源打标签 # kubectl label pods pod-demo release=canary # kubectl label pods pod-demo release=stable --overwrite     标签选择器的类型\n 等值关系的标签选择器,可以使用'=','==','!=' kubectl get pods -l release=canary kubectl get pods -l release=stable kubectl get pods -l release!=stable(没有相应的键同样包含在条件内) kubectl get pods -l release=stable,app=myapp  集合关系的标签选择器 # KEY in (VALUE1,VALUE2,...) kubectl get pods -l \"release in (canary,alpha,beta)\" # KEY notin (VALUE1,VALUE2,...) kubectl get pods -l \"release notin (canary,alpha,beta)\" # KEY(存在某个键) # !KEY(不存在某个键)     deployment,service等资源通常支持通过以下字段来匹配相应的标签\n# matchLabels: 直接给定键值 # matchExpression: 基于给定的表达式来定义使用标签选择器 # # 方式为:{key: \"KEY\", operator:\"OPERATOR\", values:[VAL1,VAL2,...]} # 操作符常用的有: # In, Notin: values字段的值必须为非空列表 # Exists, NotExists: value字段的值必须为空列表   node也可以打标签\n 创建pod时,有一个字段叫做nodeSelector\u003cmap[string]string\u003e(节点标签选择器),可以用来选择在哪些标签节点上运行  - spec: containers: - xxx - xxx 选择节点可以有以下方式: ---------------- nodeSelector: disktype: ssd ---------------- nodeName: node02     annotation:\n 与labels的区别在于,他不能用于挑选资源对象,仅用于为对象提供\"元数据\";  这些\"元数据\"在某些时候可能被某些程序用到,并且很重要 annotation中键值的大小可大可小,不再受字符的限制 查看annotations可以通过describe来查看      pod的生命周期:\n 如下图:   -------------------------------------------------------------------- | Pod | -------------------------------------------------------------------- a--\u003e| -------- | | |init c| | | -------- | | -------- | | |init c| | | -------- | | -------- | | |init c| | | -------- | | | ----------------- | | |liveness probe | | | ----------------- | | ----------------- | | |readiness probe| | | ----------------- | | ------------ ---------- | | |post start| |pre stop| | | ------------ ---------- | b | |\u003c--------------------------\u003e| -------------------------------- | | | main container | | | -------------------------------- | |\u003c--------------------------------- | | c | |  各个阶段说明   1,a是pod中创建容器前的初始化动作(entrypoint中定义的初始化动作内容),这里需要一点时间,时间可能比较短,可以忽略 2,在主容器启动前,可能需要做一些环境设定和配置,此处有一系列的init container,专门用于给主容器做环境初始化动作(初始化容器是需要串行执行的) 3,等所有的初始化容器完成之后,拉起主容器 4,主容器退出,pod的生命周期结束 5,在主容器的启停前后,可以存在两个分别称为post start和pre stop的 - post start:在启动完执行一次后自动退出 - pre stop: 在结束前执行一次的动作 - 钩子触发,用于开始前的预设,结束前的清理 6,还可以做health check,一般来说,在post start执行完成之后,可以做两类检测(k8s支持两类) - liveness probe : 存活状态检测,检测主进程是否还在运行(避免已经进入死循环还不退出的情况),主容器是否处于运行状态 - readiness probe: 就绪状态检测,容器中的主进程是否已经准备就绪并可以对外提供服务 - 两种probe都支持三种探测行为: a,执行自定义命令 b,向指定的套接字发请求(向指定端口发请求) c,向指定的http发请求(向指定url发送GET请求) - kubernetes和docker的探测差别:docker不需要探测liveness,因为只有一个容器,kubernetes需要,因为一个pod中可能有多个容器存在  pod的各种状态:  pending:挂起,启动条件没满足,调度未完成(比如已经创建,但没有适合运行的节点,即没有符合nodeselector或者nodename的节点) running:运行中 failed:失败 succeed:成功,存在时间很短 unknown:所有信息的获取都是apiserver和各个节点上的kubelet交互获取的,如果kubelet出故障了,就有可能出现unknown的状态   用户创建pod时会经历哪些阶段:  用户创建pod时,发送请求给到apiserver apiserveri将创建请求的目标状态保存到etcd中 apiserver请求schedule,进行调度,并将调度的结果保存到etcd中(运行在哪个节点上) etcd状态信息更新后,调度节点上的kubelet通过与apiserver通信,获取到有一些任务给到自己了 此时此kubelet通过apiserver拿到此前用户提交的创建清单,根据清单在当前节点上运行这个pod 启动后,pod有一个当前状态,再将当前pod状态发回给apiserver apiserver再次将该信息存入etcd中   pod生命周期中的重要行为:  初始化容器 容器探测  liveness probe readiness probe   pod在kubernetes上代表的是运行的程序或者进程,给用户提供服务的主要单位,当pod发生故障时,需要让其平滑终止,才能确保数据不会丢失  在给pod发送delete请求时,pod给各个容器发送TERM信号,容器自己停止(给予一个宽限期) 超过宽限期后,发送kill信号,杀掉进程     restartPolicy:  Always: 总是重启 OnFailure: 只有状态为错误时才重启 Never: 从不重启 一旦一个pod被调度到某个节点以后,只要这个节点在,这个pod就不会被重新调度了;pod里面的容器只会被重启,如果容器不满足启动条件,则容器会一直在那不断重启(取决于策略定义)      kubernetes Pod控制器应用进阶(二)   探针(kubectl explain pods.spec.containers.livenessProbe)\n# a, ExecAction # b, TCPSocketAction # c, HTTPGetAction ------------------------------------------------------------------------ Exec: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: liveness-probe-pod namespace: default spec: containers: - name: liveness-probe-container image: busybox:latest imagePullPolicy: IfNotPresent command: [\"/bin/sh\", \"-c\", \"touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 3600\"] livenessProbe: exec: command: [\"test\", \"-e\", \"/tmp/healthy\"] initialDelaySeconds: 1 periodSeconds: 3 ------------------------------------------------------------------------ TCPSocket: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: liveness-httpget-pod namespace: default spec: containers: - name: liveness-httpget-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3   就绪性探测使用的场景\n pod提供的服务是通过war来展开的  war包很大,容器运行之后,war包展开还需要10s钟时间 容器运行之后,service作为服务入口,通过标签选择器已经关联到该pod了(请求可以调度到该pod了) 新分配到这个pod的请求因还未准备好,所以会出现请求失败的情况      使用pod提供服务,必须要用到liveness probe和readiness probe\n# readiness probe ------------------------------------------------------------------------ TCPSocket: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: readiness-probe-pod namespace: default containers: - name: readiness-probe-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 readinessProbe: httpGet: port: http path: /index.html indexDelaySeconds: 1 periodSeconds: 3   lifecycle(postStart,preStop)字段,启动停止钩子函数\n# a, ExecAction # b, TCPSocketAction # c, HTTPGetAction ------------------------------------------------------------------------ postStart: ------------------------------------------------------------------------ apiVersion: v1 kind: Pod metadata: name: poststart-pod namespace: default spec: containers: - name: poststart-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent lifecycle: postStart: exec: command: [\"/bin/sh\", \"-c\", \"sed -i 's/MyApp/Home_Page/' /usr/share/nginx/html/index.html\"] command: [\"nginx\"] args: [\"-g\", \"daemon off\", \"-c\", \"/etc/nginx/nginx.conf\"] -----------\u003e注意不要和lifecycle的command有强依赖   ","description":"k8s学习笔记记录","tags":["cloud","docker","云原生","kubernetes"],"title":"Kubernetes学习笔记","uri":"/tech/cloud/kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["tech"],"content":"#. 容器是什么 1, LXC(linux container): linux容器\n2, 虚拟化类型:\n 主机级虚拟化: Type-I: 直接在硬件上安装一个hypervisor,再在hypervisor上使用虚拟机 Type-II: virtualbox,vmware workstation,kvm等;先存在一个宿主机,安装好host os,在host os上再安装vmm(virtual machine manager),vmm上再启动虚拟机,还需要自己安装操作系统 容器级虚拟化: 所有的用户空间不再分属于不同内核,从属于同一内核  主机级虚拟化可以在创建时就天然限制资源(CPU,MEM) CPU资源属于可压缩资源,MEM不属于,当进程申请MEM时没有,则会触发OOM 内核级必须实现一种功能,来限制用户空间中每一个进程所有可用资源总量  可以实现在整体资源上按比例分配,也可以在单一用户空间上,实现做核心绑定,通过CGrouop(control group)来实现      3, 内核和用户空间\n 能够有产出的都是用户空间的应用程序,像部署一个nginx服务,http服务,再对外提供服务 内核是协调资源的作用,出于通用目的而设计的资源管理平台 现代软件基本都是对内核的系统调用和库调用,应用程序依赖着内核和操作系统  4, kvm等虚拟化\n 资源需要经过两层调度,虚拟机操作系统层面是一层,宿主机层面又是一层,浪费,存在额外的开销,效率低 优点是资源隔离彻底,某台虚拟机出现问题,不要影响到其他的虚拟机 提高效率的方式: 减少中间层  5, 容器最早出现的形式是freebsd里面的jail,迁移到linux中后,变成了vserver(chroot)\n6, 用户空间的隔离类型,都是在内核级别实现的\n UTS: CLONE_NEWUTS,2.6.19之后支持;主机名和域名,在内核当中以名称命名,并且单独隔离开;可以分别各自使用,而不影响主的,真正的命名空间 Mount: CLONE_NEWNS,2.4.19之后支持;文件系统 IPC: CLONE_NEWIPC,2.6.19之后支持;信号量,消息队列和共享内存,进程间通信 PID: CLONE_NEWPID,2.6.24之后支持;进程号 User: CLONE_NEWUSER,3.8之后支持;用户(组)等相关信息也要做隔离,以root用户说明,只在容器内部是root用户,在宿主机上实际是普通用户 Net:CLONE_NEWNET,2.6.29之后支持;网络设备,网络栈,端口等,有自己专有的TCP/IP协议栈  7, 一个操作系统运行存在两棵树: 进程树,文件系统树\n 进程管理从来都是白发人送黑发人,父进程只有把所有子进程,子进程的子进程...都送完才能放心离开 每个用户空间都有一个init进程(docker中自己定义),当init进程结束时,docker容器实例也停止 一个docker容器中可以存在多个进程,但需要是由同一个最原始的init进程生成  8, linux现已在内核中原生支持名称空间(namespaces),并且通过系统调用向外输出\n clone() setns(): 进程创建完成后放到某个命名空间中去 unshare(): 将进程从某个命名空间中拿出来  9, 要想使用容器,得靠用于支撑用户空间的内核级的内核资源的名称空间隔离来实现\n10, CGroup(control group)控制组: 把系统资源分为多个组,然后把每个组的资源指派或者分配到特定的用户空间的进程上去,分类如下:\n blkio: 块设备IO cpu: CPU cpuacct: CPU资源使用报告 cpuset: 多处理器平台上的CPU集合 devices: 设备访问 freezer: 挂起或恢复任务 memory: 内存使用量及报告 perf_event: 对cgroup中的任务进行统一性能测试 net_cls: cgroup中的任务创建的数据报文的类别标识符  11, 可以给一个系统上所有运行的进程分门别类的进行分类,每个类就是一个组,叫做控制组\n 每个控制组内部还可以继续进行划分,分配完成后,每个子组当中的进程自动拥有该控制组分配的资源,除非进一步对子组进行分类  12, 容器级虚拟化相对主机级虚拟化,安全隔离相差很多,相应的为了防止利用漏洞使用其他用户空间的资源,docker也相应的做了一些加固\n 结合selinux使用  13, 容器实现的三个核心技术:\n chroot namespaces cgroups  14, 一个容器只运行一个主进程,相应的优缺点\n 缺点:  空间占用更多 工具不能共用了,如果需要调试工具,需要在容器中安装 不方便运维,需要专门的编排,不然使用容器部署应用比单独安装服务更麻烦   优点:  方便研发,一次打包,到处运行    15, docker分层构建,联合挂载\n 每一个镜像都是只读的,多层联合挂载后提供的视图就是当前使用的镜像 每一个容器有一个自己的可写层,在联合挂载的最顶层附加一个新层,能读能写,容器专有的  如果要删除一个文件,且刚好属于上一层镜像中的文件,实现方式为标记为不可见 需要修改一个文件,该文件属于上一层或多层的文件,则通过写时复制的方式实现   持久化使用的数据,通过在容器外部挂载一个共享存储(ceph,glusterfs,iscsi等)实现  16, 在docker的基础之上,能够把这些应用程序之间的依赖关系,从属关系,隶属关系等等反映在启动,关闭时的次序和管理逻辑中,这种功能叫做容器编排\n docker-compose(单机),docker-swarm(多机集群),docker-machine mesos+marathon kubernetes --\u003e k8s  17, docker后面研发libcontainer,替换了lxc,后面libcontainer进化为runc(run container)\n lxc(linux container) --\u003e libcontainer --\u003e runc 为了标准化容器相关(容器引擎,容器底层镜像格式) runc,容器运行时的环境标准 容器镜像格式标准OCF(open container format),事实上的工业标准  #. docker基础用法 1, 相关名词\n OCI(open container initiative),开放容器协会,主要目的是围绕容器格式和运行时制定一个开放的工业化标准,由两部分组成:  runtime-spec(The Runtime Specification): 运行时标准 image-spec(The Image Specification): 镜像格式标准   OCF(open container format),开放容器镜像格式 runC是一个cli工具,依照OCI标准来运行容器  容器以runC子程序的方式启动,可以被集成到各种不同的操作系统,而且可以不需要守护进程存在 runC是从libcontainer发展而来的    2, docker架构,由一下几部分组成\ndocker可以认为是一个C/S的架构,无论时server端还是client端,都是由一个docker程序来提供,这个docker程序有很多子程序\n docker client  docker pull docker build docker run   docker host  docker daemon: docker众多子程序中的一个,运行为daemon,即守护进程  mysql接入用户请求一般有两种方式,分别是: a,标准的TCP/IP协议,IP+端口的方式 b,使用socket文件,在本机接入 类似于mysql监听,docker也监听在套接字上,为了安全起见,默认时只监听本机,支持三种套接字 a,ipv4套接字(ipv4地址+端口) b,ipv6套接字(ipv6地址+端口) c,unix socket file,监听在本机的一个文件上,上面两个没有放开的话,就会只监听本机(127.0.0.1)   docker containers  启动容器时,就是基于镜像来启动,在已有的镜像之上,为一个容器启动一个专用的可写层   docker images  不确定要用哪些,具体要用的时候再下载 要用的时候就必须要加载到本地     docker registry(docker镜像仓库,默认就是dockerhub)  支持http/https,默认必须使用https,为了安全 要使用http,必须在配置文件中明确定义,才能正常使用 registry而不是repository,因为registry有三个功能  repository: 存储镜像的仓库 auth: 用于认证 catalog: 提供已有镜像的索引,即仓库名(nginx) + tag(1.10)      3, docker支持restful风格的调用,docker中的资源对象\n images和containers的关系可以类比与程序(software)和进程(process),镜像是静态的,容器是动态的,存在生命周期 restful风格的资源对象都是可以增删改查的  images containers networks volumes plugins other objects    4, docker的安装使用\n 为了能够正常使用docker,要求环境的内核版本必须要在3.10以上(user namespace是在3.8之后才支持的) 红帽在2.6.32之后可以安装docker,打了补丁补进去了(但还有很多不确定与因素,建议不要跑在centos6上) 建议不要使用Centos-Base.repo这个源中的docker,因为版本较老,有很多软件要求使用新版本docker的特性,但也不要使用最新的docker版本(k8s不支持最新版),使用docker-ce.repo中stable版 当前docker的配置文件是/etc/docker/daemon.json  使用images时,建议使用加速器(docker cn/阿里云)   需要查看当前docker的详细信息,可以使用docker version来查看  docker info输出中的Storage Drive这项很重要 a,docker镜像需要使用到多层构建,联合挂载,这两项要求必须使用特殊的文件系统才能实现,专用的文件驱动 b,一般包含overlay2和aufs;centos7.4之前没有使用可能和内核版本有关系,之前的还不支持 c,centos7之前还有使用到dm(弱爆了),就是lvm的实现,使用dm的方式,docker的性能很差,而且还不稳定    5, docker镜像及容器\n alpine: 专门用于构建非常小的镜像文件的一个微型发行版,能够给程序提供运行环境,但体积非常小(缺少相应的调试工具) 停掉一个容器的方式有:  stop: 相当于sigterm kill: 相当于sitkill   启动一个容器时,不能让其跑在后台,不然启动就会停止(一个容器就是为了一个进程,如果跑后台,终端没有任何程序,那docker就认为已经结束了)  #. docker镜像管理基础 1, docker镜像含有启动容器所需要的文件系统及其内容,容器镜像用于创建并启动docker容器\n 采用分层构建的机制,最底层为bootfs,其次为rootfs  bootfs: 用于系统引导的文件系统,包括bootloader和kernel,容器启动完成后会被卸载以节约内存资源  bootfs只在容器启动的时候存在,当容器已经挂载了rootfs后,bootfs层将会被卸载(不是被删除) 存在一个问题,如果存在bootfs这一层,那是否拉起的容器可以支持宿主机内核不支持的特性?   rootfs: 位于bootfs之上,表现为docker容器的根文件系统  传统模式中,系统启动时,内核挂载rootfs时会首先将其挂载为只读模式,完整性自检完成后将其重新挂载为读写模式 docker中,rootfs由内核挂载为'只读'模式,而后通过联合挂载技术而外挂载成一个'可写'层   最上层为'可读写'层,其下的均为'只读'层  容器启动后,所有的写操作都是在最上一层的'可读写'层完成的,当删除一个容器时,可读写层一并被释放      2, 联合挂载文件系统分类\n aufs(advanced multi-layered unification filesystem): 高级多层统一文件系统  用于为linux文件系统实现'联合挂载' aufs是之前的UnionFS的重新实现,但未能整合到linux内核中(据说是代码很烂),所以如果需要使用,需要给内核打补丁(redhat系不支持,因为不允许) docker最初使用aufs作为容器文件系统层,目前仍作为存储后端之一来支持   aufs的竞争产品为overlay,从3.18版本开始被合并到linux内核中 docker的分层镜像,除了aufs,docker还支持btrfs,devicemapper和vfs等  在ubuntu系统下,docker默认ubuntu的aufs 在centos7上,用的时devicemapper(性能差还不稳定)   目前推荐使用overlay2  overlay是抽象文件系统,属于二级文件系统,需要先有一层文件系统(xfs,ext...)    3,docker registry分类\n registry 用于保存docker镜像,包括镜像的层次结构和元数据 用户可以自建registry,也可以使用官方的dockerhub 分类:  sponsor registry: 第三方registry,供客户和docker社区使用 mirror registry: 第三方registry,供客户使用 vendor registry : 由发布docker镜像的供应商提供的registry private registry: 通过设有防火墙和额外的安全层的私有实体提供的registry   docker registry中的镜像通常由开发人员制作,而后推送至'公共'或'私有'registry上保存 获取镜像的标准格式: docker pull :[:port]/[/]/:  4,云原生的解释\n 面向云环境中去运行这个程序而调云系统本身自有的功能而开发的应用程序,就是为了云环境运行而生的 docker容器本身如果通过修改配置文件的方式来改配置,相对麻烦,故想了一种方式,通过运行时传入环境变量的方式来运行(早期的解决方式)  5,docker hub的使用 docker hub主要提供如下的功能特性:\n image repository: 镜像仓库 automated builds: 自动构建 dockerfile(change/push) --\u003e github --\u003e build image --\u003e docker hub webhooks: 当dockerfile提交成功时,自动触发钩子构建镜像  6,镜像的生成途径\n Dockerfile 基于容器制作  基于先有容器制作镜像时,建议先暂停该镜像,再commit,防止文件数据的缺失 1 2 3 4 5  # 命令为: docker commit -p \u003ccontainer\u003e [repository[:tag]] # 替换原有镜像的CMD或者其它参数 docker commit -p \u003ccontainer\u003e -c \"CMD ['/bin/httpd', '-f', '-h', '/data/html']\" [repository[:tag]]      Docker Hub automated build(也是基于Dockerfile)  7,不通过registry,直接导入导出镜像文件\n docker save -o  docker load -i   #. 容器虚拟化网络 1,网络名称空间主要是实现网络设备(网卡,协议栈)的隔离\n 当网络设备不够用时,可以通过命令生成虚拟网络设备,linux内核支持实现生成两种网络设备:  二层网络设备  成对出现,类似一根网线两头,一根接入网络命名空间,一头接入虚拟交换机(虚拟网桥),就可以模拟一台主机连接到一台交换机的场景   三层网络设备   linux内核原生支持二层网桥虚拟设备(软件构建交换机),虚拟化网络 linux上实现路由的方式,可以通过直接增加一个netns实现,将相应网桥的网卡接入该netns,然后在netns中配置路由规则即可  桥接不安全,跨机容易出现风暴    2,virtualbox/vmware桥接模式的实现\n 将物理网卡当作交换机来使用,虚拟机的流量都是通过物理网卡转发过去的,对于物理机本身的流量,是通过对本机增加一个虚拟网卡,物理网卡流量转到该网卡实现的  3,overlay network(叠加网络)\n 叠加网络(隧道实现),用于实现跨机同网段通信  C1(container)在H1(host)上,C1 IP 172.17.0.11 C2(container)在H2(host)上,C2 IP 172.17.0.22 通过隧道实现直接通信,省去了两次NAT的动作(先SNAT,再DNAT),类似12inN中的vxlan实现(报文两次三层封装)    4,容器类型,及容器类型\n bridged container(bridge): 桥接容器,默认模式,每起一个容器,新增一对veth peer,一个接在容器中,一个接入docker0 open container(host): 开放式容器,共享宿主机的协议栈,网卡,主机名,进程见通信(UTC,IPC,NET) closed container(none): 封闭式容器,拉起的容器只有lo,不需要网络 joined container: 联盟式容器,几个容器共享网络名称空间(UTC,IPC,NET名称空间是共享的)  5,可以使用inspect命令查看任何一个docker对象的情况\n docker network inspect  docker container inspect  docker volume inspect   #. 容器网络 1,容器间可以共享IPC,UTC,NET命名空间\n2,可以手动操作网络名称空间,因为由ip命令\n 想模拟容器的网络名称空间,只靠ip命令就能完成  3,容器启动时可以指定的一些参数\n -h指定hostname --dns指定dns服务器(/etc/resolv.conf文件会记录) --add-host直接外部注入host解析内容  4,opening inbound communication(如何开放nat桥桥接式服务到宿主机外部提供服务,可以使用-p参数来实现)\n 使用-p来实现,有以下@sh几种方式: 1 2 3 4 5 6 7 8 9 10 11  # -p \u003ccontainerPort\u003e: 将指定的容器端口映射至主机所有地址的一个动态端口 docker run --name myweb --rm -p 80 mageedu/httpd:v0.2 # -p \u003chostPort\u003e:\u003ccontainerPort\u003e: 将容器端口映射至指定的主机端口 docker run --name myweb --rm -p 172.20.0.67::80 mageedu/httpd:v0.2 # -p \u003cip\u003e::\u003ccontainerPort\u003e: 将指定的容器端口映射至主机指定\u003cip\u003e的动态端口 docker run --name myweb --rm -p 80:80 mageedu/httpd:v0.2 # -p \u003cip\u003e:\u003chostPort\u003e:\u003ccontainerPort\u003e:将指定的容器端口映射至主机指定\u003cip\u003e的端口\u003chostPort\u003e docker run --name myweb --rm -p 172.20.0.67:8080:80 mageedu/httpd:v0.2 # 动态端口指的是随机端口,具体的映射结果可以使用docker port命令查看 ## 使用-P时,可以不用指定端口,默认会将容器监听的端口暴露出去     5,joined containers(联盟式容器)\n 联盟式容器是指使用某个已存在容器的网络接口的容器,接口被联盟内的各容器共享使用; 因此联盟式容器间完全无隔离 1 2 3 4 5 6 7 8  # 创建一个监听2222端口的http服务容器 docker run -d -it --rm -p 2222 busybox:latest /bin/httpd -p 2222 -f # 创建一个联盟式容器,并查看其监听的端口 docker run -it --rm --net container:web --name joined busybox:latest netstat -tan ## another example docker run --name b1 -it --rm busybox docker run --name b2 --network container:b1 -it --rm busybox    联盟式容器彼此间虽然共享一个网络名称空间,但其他名称空间如User,Mount等还是隔离的 联盟式容器彼此间存在端口冲突的可能性,因此通常只会在多个容器上的程序需要程序loopback接口互相通信,或对某已存的容器的网络属性进行监控时才使用此种模式的网络模型  6,可以自定义docker的一些配置(修改/etc/docker/daemon.json)\n 定义docker0网桥的IP段及其他相关配置 1 2 3 4 5 6 7 8  ## docker0使用的网段,会自动识别出所属的网段 \"bip\": \"192.168.1.5/25\" ## mtu \"mtu\": 1500 ## 如果想让容器不获取宿主机的dns,获取指定的dns,可以如下配置 \"dns\": [\"10.20.1.2\", \"10.20.1.3\"] ## 设定容器的默认网关 \"default-gateway\": \"10.20.1.1\"     7,docker默认只支持在本机使用,通过/var/run/docker.sock通信\n -H可以指定指向的docker服务器 可以放开选项,在daemon.json文件中放开 1 2  ## 增加本机2375端口的监听 \"hosts\": [\"tcp://0.0.0.0:2375\", \"unix:///var/run/docker.sock\"]     8,自定义创建docker桥接桥\n 示例如下: 1 2 3 4 5 6  ## 新增mybr0桥 docker network create -d bridge --subnet \"172.26.0.0/16\" --gateway \"172.26.0.1\" mybr0 ## 新起一个容器,网络设置为mybr0 docker run -it --name t1 --net mybr0 busybox:latest ## 默认加入docker0网桥的命令是(default,不加默认就是) docker run -it --name t2 --net bridge busybox:latest     #. 容器存储 1,为什么要使用data volume\n docker镜像由多个只读层叠加而成,启动容器时,docker会加载只读镜像层并在镜像栈顶添加一个读写层 如果运行中的容器修改了现有的一个已经存在的文件,那该文件将会从读写层下面的只读层复制到读写层,该文件的只读版本仍然存在,之时已经被读写层中该文件的副本所隐藏,此即\"写时复制(COW)\"机制 经过多层联合挂载,IO性能肯定不高,对于一些IO要求比较高的应用,这种联合挂载的方式肯定不满足条件  2,使用容器的可读写层完成相关读写\n 缺点:  删除容器时,所有内容都被删除了 实现数据存取时,效率比较低   若想绕故上述的限制,可以通过存储卷的方式来实现  可以理解为在特权名称空间中(宿主机),在宿主机本地找一个文件系统上的目录(或者文件)与容器内的某一文件系统目录(或文件)建立绑定关系 绑定的实现是通过mount的bind参数实现的,绑定之后,容器写入相应的目录就是写到了宿主机上对应目录下 使得容器内的进程在数据保存时,能跳过或绕过容器文件系统的限制,从而与宿主机的文件系统建立关联关系,使得可以在容器内与宿主机共享数据或者内容(宿主机可以直接访问容器内内容,宿主机可以给容器直接提供内容)   使用了volume的docker容器,run时加--rm参数,实现就类似进程了  进程是程序的实例(类比容器是镜像的实例) 进程执行过程,生成的数据保存在文件系统,停止后,数据仍然还在(类比docker单独挂载了volume保存数据后,容器停止,数据已经保存在volume中)    3,容器启动时,参数会比较多,当需要完全复现一个容器时,可能不记得当时的启动参数了,这个功能可以通过容器编排工具提供\n4,有状态应用和无状态应用\n 有状态应用是当前这次连接请求是和之前有关联关系的,大多数有状态应用需要持久化数据的 无状态应用是当前请求和之前没有关联关系  5,docker的存储卷默认情况下是使用其所在的宿主机之上的本地文件系统目录的\n 存储卷是关联到宿主机上的一个目录而已,要单独挂载磁盘,需要先在宿主机上完成才行  6,为什么使用数据卷\n 关闭并重启容器,其数据不受影响;但删除容器,则其更改将会全部丢失 存在的问题:  存储于联合文件系统中,不利于宿主机访问 容器间共享数据不便 删除容器其数据会丢失   解决方案: 卷(volum)  卷是容器上一个或多个'目录',此类目录可以绕过联合文件系统,与宿主机上的某个目录绑定    7,卷提供了几项有用的特性以支持持久化存储或共享存储\n volume在容器创建之初就会创建,由base image提供的卷中的数据会于此期间完成复制  存储卷可以在容器之间复用 对卷中的数据更改实时生效 对卷中的数据更改不影响容器镜像的更新 容器删除后,卷中的数据仍然存在   volume的初衷是独立于容器的生命周期实现数据持久化,因此删除容器既不会删除卷,也不会对那些未被应用的卷做垃圾回收操作  8,卷为docker提供了独立于容器的数据管理机制\n 可以把镜像想象成静态文件,例如程序,把卷类比于动态内容,例如数据,于是,镜像可以重用,而卷可以共享 卷实现了'程序(镜像)'和'数据(卷)'的分离,以及'程序(镜像)'和'制作镜像的主机'分离,用户制作镜像时无需再考虑镜像运行的容器所在的主机的环境  9,卷的类型,docker有两种类型的卷,每种类型的卷都在容器中存在一个挂载点,但其在宿主机上的位置有所不同\n bind mount volume(绑定挂载卷): 在宿主机上需要指定挂载路径,在容器中也要指定挂载路径,两个已知路径建立关联关系  指定的宿主机路径不存在,默认情况下,会自动创建出来 1 2  docker run -it -v HOSTDIR:VOLUMEDIR --name bbox2 busybox:latest docker inspect -f {% raw %}{{.Mounts}}{% endraw %} bbox2      docker-managed volume(docker管理卷):只需要指定容器中的挂载路径,宿主机路径不指定,由docker自动指定一个空目录,与挂载目录建立关联关系 1 2  docker run -it -v /data --name bbox1 busybox:latest docker inspect -f {% raw %}{{.Mounts}}{% endraw %} bbox1    使用其他容器的卷 1  docker run -it --name bbox1 --volume-from bbox2 busybox:latest     10,使用docker inspect去查看容器的相关信息时,可以使用go模板(go template),类似与ansible的jinja2模板\n docker inspect -f {% raw %}{{.Mounts}}{% endraw %} b2 docker inspect -f {% raw %}{{.NetworkSettings.IPAddress}}{% endraw %} b2  11,joined-container使用共享卷,实现nmt(nginx+mysql+tomcat)\n 可以先启动一个基础支撑容器(互联网上有专门的这种容器),先提供一个卷,给后面的容器使用 nmt三个容器共用一个存储卷,共用(net,uts,ipc)名称空间 只有nginx对外暴露端口,tomcat和mysql监听在lo上 1 2 3 4  docker run -it --name infracon -it -v /data/infracron/volume/:/data/web/html/ busybox docker run -it --name nginx --network container:infracon --volume-from infracon nginx:latest docker run -it --name tomcat --network container:infracon --volume-from infracon tomcat:latest docker run -it --name mysql --network container:infracon --volume-from infracon mysql:latest    对于这种需求,可以使用docker-compose来实现,主要功能是单击编排(还可以做镜像,镜像现做,容器现启动)  #. Dockerfile详解(一) 1,生产环境下使用nginx场景,修改配置生效的几种方式\n docker exec CONTAINER vi, reload进入容器修改配置文件,再reload服务 挂载存储卷,配置文件在存储卷中,但修改之后还是需要reload操作 自己制作镜像  2,制作镜像的两种方式\n 基于已有镜像制作,修改完成后,提交可读写层  日常运维修改很频繁,相应的提交也就很频繁 版本管理混乱,后续想制作同样的镜像很难   Dockerfile  Dockerfile仅仅就是构建docker镜像的源代码 Dockerfile的内容就是一个用户可以在命令行下操作,用来装配好docker镜像的指令集合 docker可以通过读取Dockerfile的内容,自动构建docker镜像    3,Dockerfile的组成\n 格式:  INSTRUCTION其实并不区分大小写,但是为了规范且和参数区别,一般大写 docker是按照顺序执行Dockerfile中的INSTRUCTION的 Dockerfile的第一行必须是FROM开头,用来指定需要构建的镜像的基础镜像是哪个 Dockerfile中可以执行很多shell命令,但是这个命令是docker容器中的命令,不是宿主机上的命令 1 2  # CommentINSTRUCTION arguements     构建规范和逻辑  要有单独的工作路径(目录) 工作目录中,要有Dockerfile文件 需要使用到的文件,需要存放在工作目录下,Dockerfile中引用的路径都是以当前工作目录为起始路径 对于子目录中不需要拷贝的文件,可以使用.dockerignore文件来罗列(文件排除列表)  一行一个文件 支持通配符     环境变量替换  环境变量(以ENV开头的部分)同样能被Dockerfile解析 环境变量在Dockerfile中引用的格式时$variable_name或者${variable_name} ${variable_name}同样支持少量的shell变量替换操作  ${variable_name:-word}:变量为空或者变量未设置时,引用的值就是word,变量有值的时候,则使用变量的值 ${variable_name:+word}:变量有值则显示为word,没值就什么都没有      4,Dockerfile中的指令\n FROM  FROM指令是最重要的一个,且必须是Dockerfile文件开篇的第一个非注释行,用于为影响文件构建过程指定基准镜像,后续的指令基于此基准镜像提供的运行环境 基准镜像可以使用任何镜像文件,默认情况下,docker build会在docker主机上查找指定的镜像文件,在其不存在时,则会从docker hub registry上拉取所需要的镜像文件(如果找不到指定的镜像文件,则返回报错) 语法: 1 2 3 4  FROM\u003crepository\u003e:\u003ctag\u003e## 或者FROM\u003crepository\u003e@\u003cdigest\u003e## digest是镜像的哈西码,为的是避免同名镜像被替换     MAINTANIER(depreacted已废弃)  用于让镜像制作者提供本人信息 Docker并不限制MAINTANIER出现的位置,建议放在FROM后面 语法: 1  MAINTANIER \u003cauthor's details\u003e     LABEL  LABEL指令用于给镜像增加元数据 一个镜像可以有多个LABEL 可以在一行中指定多个label(键值对) 语法: 1 2  LABEL \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e## MAINTANIER可以作为LABEL中的一个键值数据存在     COPY  用于从Docker主机复制文件至创建的新映像文件 语法如下: 1 2 3 4 5  COPY \u003csrc\u003e...\u003cdest\u003e或者COPY [\"\u003csrc\u003e\",...\"\u003cdest\u003e\"] # \u003csrc\u003e:要复制的源文件或者目录,支持使用通配符 # \u003cdest\u003e:目标路径,即正在创建的image的文件系统路径;建议为\u003cdest\u003e使用绝对路径,否则,COPY指定则以WORKDIR为其起始路径 # 注意: 在路径中有空白字符时,通常使用第二种格式   文件复制准则:  必须是build上下文中的路径,不能是父目录中的文件 如果是目录,则其内部文件或子目录会被递归复制,但目录自身不会被复制 如果指定了多个,或在中使用了通配符,则必须是一个目录,且必须以/结尾 如果事先不存在,他将会被自动创建,这包括岐阜目录路径     ADD  类似于COPY指令,ADD支持使用TAR文件和URL路径 语法如下: 1 2  ADD \u003csrc\u003e...\u003cdest\u003e或者ADD [\"\u003csrc\u003e\",...\"\u003cdest\u003e\"]   文件复制准则:  同COPY指令 如果为URL且不以/结尾,则指定的文件将被下载并直接被创建为;如果以/结尾,则文件名URL指定的文件将被下载下来并保存为/ 如果是一个本地文件系统上的压缩格式的tar文件,它将被展开为一个目录,其行为类似于'tar -x'命令;然而,通过URL获取到的tar文件将不会自动展开 如果有多个,或其间接或直接使用了通配符,则必须是一个以/结尾的目录路径;如果不以/结尾,则其被视作一个普通文件,的内容将被直接写入到     WORKDIR  用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 语法如下: 1 2 3 4 5 6  WORKDIR\u003cdirpath\u003e # 在Dockerfile文件中,WORKDIR指令可以出现多次,其路径也可以为相对路径,不过,其是相对此前一个WORKDIR指令指定的路径 # 另外,WORKDIR也可调用由ENV指定定义的变量# 示例:WORKDIR/var/logWORKDIR$STATEPATH     VOLUME  用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上卷 语法如下: 1 2  VOLUME\u003cmountpoint\u003e或者VOLUME [\"\u003cmountpoint\u003e\"]   如果挂载点目录下此前在文件存在,docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 与run命令使用的volume不同,Dockerfile中指定VOLUME只能指定docker挂载目录   EXPOSE  用于为容器打开指定要监听的端口以实现与外部通信 语法如下: 1 2 3 4 5 6 7 8 9  EXPOSE\u003cport\u003e[/\u003cprotocol\u003e][\u003cport\u003e[/\u003cprotocol\u003e]...] # \u003cprotocol\u003e用于指定传输层协议,可为tcp或者udp二者之一,默认为TCP协议 # 注意:写在Dockerfile中的端口暴露,只是提示可以暴露,而不是以该镜像启动的容器就暴露端口 # 在需要暴露时,docker run指定-P选项,会读取到哪些端口需要暴露,并将其暴露出去 # 示例:(构建惊险的Dockerfile中已经存在EXPOSE 80/tcp) # docker run --name tinyweb1 --rm tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html # docker port tinyweb1 --\u003e none # docker run --name tinyweb1 --rm -P tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html # docker port tinyweb1 --\u003e 80/tcp -\u003e 0.0.0.0:32768   EXPOSE可以一次指定多个端口,如:  EXPOSE 11211/udp 11211/tcp   写在镜像中的端口,在运行容器时没有指定则被称为待暴露端口,而不会真正暴露,除非在运行容器时加上-P(默认暴露端口)选项   ENV  用于为镜像定义所需的环境变量,并可以被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY)所调用 语法如下: 1 2 3 4 5  ENV \u003ckey\u003e \u003cvalue\u003e 或者ENV \u003ckey\u003e=\u003cvalue\u003e...# 第一种格式中,\u003ckey\u003e之后的所有内容均会被视作其\u003cvalue\u003e的组成部分,因此,一次只能设置一个变量# 第二种格式可以用于一次设置多个变量,每个变量为一个\"\u003ckey\u003e=\u003cvalue\u003e\"的键值对,如果\u003cvalue\u003e中包含空格,可以以反斜线(\\)进行转意,亦可通过对\u003cvalue\u003e加引号进行标识;另外,反斜线也可用于续行.# 定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能   在Dockerfile中ENV定义的变量,可以在依照其构建出的镜像启动的容器中直接使用    5,Dockerfile中请惜字如金,因为每一条指令都会生成一个新的层\n#. Dockerfile详解(二) 1,在docker的上下文当中,有一个重要的特点,一个容器只是为了运行单个程序或者单个应用\n2,在命令行下通过\u0026符放后台执行的程序都是当前shell的子进程,当退出当前shell时,该shell的子进程会被杀掉,相应的该shell下的后台进程也被关闭\n 如果要实现退出shell时,仍然可以正常运行,需要增加nuhup command \u0026,剥离command与当前shell的关系,相当于把启动这个进程的父进程安排给了init 在一个用户空间中,不是以shell的子进程去启动一个程序,很多的经验和参数则不能使用 1 2 3  ls /var/* # --\u003e 不在shell下执行的话,*无法被内核解析 # 变量替换 --\u003e 同样不能被解析 # 管道,输入输出重定向等 --\u003e 无法识别     3,Dockerfile中的指令\n CMD  在docker容器中,需要让容器运行的进程变为pid为1的进程   在容器当中,希望以shell的方式启动一个主进程\n 先在用户空间中启动一个shell(pid为1),在shell中以剥离终端的方式启动需要启动的主进程;解决主进程pid不为一的方式为,在shell中exec command --\u003e exec顶替shell的pid=1,取代shell进程,shell退出,command成为pid=1的进程\n   在docker容器中,可以不基于shell,直接启动进程;也可以基于shell,通过shell启动进程,但要基于shell启动,并且不违背这个主进程id为1的原则,需要通过exec来实现\n   CMD是定义一个容器启动时,默认需要执行的程序  类似于RUN指令,CMD指令也可用与运行任何命令或应用程序,不过二者的运行时间点不同  RUN指令运行于映像文件构建过程中,而CMD指令运行于基于Dockerfile构建出的新镜像文件启动为一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序,且其运行结束后,容器也将终止;不过CMD指定的命令可以被docker run的命令行选项所覆盖 在Dockerfile中,可以存在多个CMD指令,但仅有最后一个会生效     语法: 1 2 3 4 5  CMD \u003ccommand\u003eCMD [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]CMD [\"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 前两种语法格式的意义同RUN# 第三种则用于为ENTRYPOINT指令提供默认参数     RUN  用于指定docker build过程中运行的程序,其可以是任何命令 语法: 1 2 3 4 5  RUN \u003ccommand\u003eRUN [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 第一种格式中,\u003ccommand\u003e通常是一个shell命令,且以'/bin/sh -c'来运行它,这意味着此进程在容器中的PID不为1,不能接收Unix信号,因此,当使用docker stop \u003ccontainer\u003e命令停止容器时,此进程接收不到SIGTERM信号RUN ['/bin/bash', '-c', '\u003cexecutable\u003e', '\u003cparam1\u003e']# 第二种格式中的参数是一个JSON格式的数组,其中\u003cexecutable\u003e为要运行的命令,后面的\u003cparamN\u003e为传递给命令的选项或者参数;然而,此种格式指定的命令不会以'/bin/sh -c'来发起,因此常见的shell操作如变量替换以及通配符(?,*等)替换将不会进行;不过,如果要运行的命令依赖于此shell特性的话,可以将其替换为类似下面的格式   示例用法: 1 2 3 4  ENV WEB_DOC_ROOT='/data/web/html/'CMD /bin/httpd -f -h ${WEB_DOC_ROOT} # ---\u003e 可用CMD [\"/bin/httpd\", \"-f\", \"-h ${WEB_DOC_ROOT}\"] # ---\u003e 不可用,如上b所述,该写法不是在shell中执行,不能解析${WEB_DOC_ROOT}CMD [\"/bin/sh\", \"-c\", \"/bin/httpd\", \"-f\", \"-h ${WEB_DOC_ROOT}\"] # ---\u003e 可用     ENTRYPOINT  类似CMD指令的功能,用于为容器指定默认运行程序,从而使得容器像是一个单独的可执行程序 与CMD不同的是,由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖,而且,这些命令行参数会被当作参数传递给ENTRYPOINT指定的程序  docker run命令的--entrypoint选项的参数可以覆盖ENTRYPOINT指令指定的程序   语法: 1 2 3 4 5 6  ENTRYPOINT \u003ccommand\u003eENTRYPOINT [\"\u003cexecutable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\"]# 示例:ENTRYPOINT /bin/sh -c # --\u003e inspect image会发现存在两层/bin/sh -c,因为默认这种格式就是/bin/sh -cENTRYPOINT ['/bin/sh', '-c'] # --\u003e inspect image正常   docker run命令传入的命令参数会覆盖CMD指令的内容并附加到ENTRYPOINT命令最后,作为其参数使用 ENTRYPOINT在Dockerfile中也可以存在多个,但仅有最后一个会生效   USER  用于指定运行image时的或运行Dockerfile中任何RUN,CMD或ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下,container的运行身份为root用户 语法: 1 2  USER\u003cUID\u003e|\u003cUserName\u003e# 需要注意的是,\u003cUID\u003e可以为任意数字,但实践中必须要为/etc/passwd中某用户的有效UID,否则,docker run命令将运行失败     HEALTHCHECK  HEALTHCHECK指令是通过给定内容给docker,令其检查容器是否还在正常运行,检查主进程工作状态健康与否 语法: 1 2 3 4 5 6 7 8 9 10 11 12 13  HEALTHCHECK [OPTION] CMD command # --\u003e 通过在容器中运行command来检测容器是否运行正常 - 可在CMD前指定的option --interval=DURATION(default: 30s) --timeout=DURATION(default: 30s) --start-period=DURATION(default: 0s) --\u003e等待多长时间(docker run容器起来后,可能还需要初始化动作,这个时候不应该算到检测内容中) --retries=N(default: 3) - command执行的返回值反映了容器的健康状态,可能的value包括如下: 0:success --\u003e 容器健康且能提供服务 1:unhealthy --\u003e 容器未能正常运行 2:reserved --\u003e 不使用该返回值(预留的,没什么意义) # 示例内容: HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1HEALTHCHECK NON禁用任何从容器尽享中继承的healthcheck     STOPSIGNAL  STOPSIGNAL指令用于指定发送给容器,用于停掉的容器的system call signal 语法: 1  STOPSIGNALsingal     ARG  定义变量,但只能在docker build过程中使用  ARG后定义的变量可以在docker build过程中被替换,这种场景适用于一个Dockerfile可以接收不同参数,构建不同镜像的   语法: 1 2  ARG \u003ckey\u003e=\u003cvalue\u003e# 使用了之后,可以在构建镜像时使用--build-arg \u003ckey\u003e=\u003cvalue2\u003e替换     ONBUILD  在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile用作FROM指令的参数,并以之构建新的镜像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时,将会触发创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 语法: 1  ONBUILD \u003cINSTRUCTION\u003e   尽管任何指令够可注册成为触发器指令,但ONBUILD不能自我嵌套,且不会触发FROM和ENTRYPOINT指令 使用ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签,例如ruby:2.0-onbuild 在ONBUILD指令中使用ADD或者COPY指令应该格外小心,因为新构建过程的上下文缺少指定的源文件时会报错    4,nginx Dockerfile示例\n 内容如下: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  FROMnginx:1.14:alpineLABLE maintainer=\"MageEdu \u003cmage@magedu.com\u003e\"ENV NGX_DOC_ROOT='/data/web/html/'ADD entrypoint.sh /bin/CMD ['/usr/sbin/nginx', '-g', 'daemon off;']ENTRYPOINT ['/bin/entrypoint.sh']##################################cat entrypint.sh#!/bin/bash#cat \u003e /etc/nginx/conf.d/www.conf \u003c\u003cEOFserver { server_name $HOSTNAME; listen ${IP:-0.0.0.0}:${PORT:-80}; root ${NGX_DOC_ROOT:-/usr/share/nginx/html};}exec \"$@\"EOF    5,在写Dockerfile时,注意json传入时必须要写双引号,单引号会报错\n#. Docker私有registry 1,registry用于保存docker镜像,包括镜像的层次结构和元数据\n2,启动registry有几种方式\n docker run -d xxxx registry yum install docker-registry(在epel源中,实际名称为docker-distribution)  实际上时一个python开发的web自运行程序 数据保存目录在/var/lib/docker下,配置文件在/etc下,可以通过更改/etc下配置文件修改镜像保存位置和监听端口    3,建议使用harbor来管理镜像,搭建harbor需要使用到docker-compose\n harbor有两种安装方式,离线和在线  离线版安装需要下载tgz文件,文件较大,需要下载一段时间 在线版是在更改完配置文件后,执行安装脚本,安装过程中下载相应镜像 不管离线还是在线安装,需要先完成harbor.cfg文件的配置,而后才能进行部署   harbor是一个多容器服务,需要使用到各种容器镜像,编排内容在docker-compose.yml中定义  一般执行docker-compose命令,会在docker-compose.yml文件所在目录执行 根据docker-compose.yml文件启动相应服务 --\u003e docker-compose start 根据docker-compose.yml文件关闭相应服务 --\u003e docker-compose stop 查看docker-compose的帮助命令 --\u003e docker-compose help    4,harbor的一些特性:\n 多租户登录和验证 安全和风险验证 日志监控 RBA(role-base control) 实例间镜像拷贝 扩展API和web UI界面  #. Docker的资源限制 1,默认情况下,容器是没有资源限制的,可以使用完宿主机上内核分配给该容器的所有资源\n2,docker提供了一个途径,可以用来控制容器可以使用多少CPU,memory,块设备IO(限制有限);可以通过设置运行时(runtime)配置\n 内存是不可压缩资源,当容器需要使用的内存分配不到时,可能触发容器内的oom CPU的分配可以通过少分配来实现  3,这些资源限制功能的实现依赖于内核是否支持来实现\n4,在linux主机上,如果内核探测到但前内存无法满足重要系统功能实现时,会抛出OOME(out of memory exception),并开始杀掉进程来释放空间\n 一旦发生oome,任何进程都有可能被杀死,包括docker daemon 为此docker特地调整了docker daemon的OOM优先级,以免被内核杀掉,但容器内的优先级并未被调整 每个进程有一个oom_adj,用来计算oom权重(优先级)  5,限制一个容器可以使用的内存\n -m或者--memory:最少为4M --memory-swap:不使用--memory时,不能使用该项  ------------------------------------------------------------------------------------------------ | --memory-swp | --memory | 功能 ------------------------------------------------------------------------------------------------ | 正数S | 正数M | 容器可用总内存为S,其中ram为M,swap为(S-M),若S=M,则无可用swap资源 ------------------------------------------------------------------------------------------------ | 0 | 正数M | 相当于未设置swap(unset) ------------------------------------------------------------------------------------------------ | unset | 正数M | 若主机(Docker Host)启用了swap,则容器的可用swap为2M ------------------------------------------------------------------------------------------------ | -1 | 正数M | 若主机(Docker Host)启用了swap,则容器的可用swap可使用到主机上所有swap ------------------------------------------------------------------------------------------------ # 注意:在容器内部使用free命令可以看到的swap空间并不具有其所展现出的空间指示意义  --memory-swappiness --memory-reservation --kernel-memory --oom-kill-disable  6,限制一个容器可以使用的CPU\n 默认情况下,每个容器可以使用的CPU时间片是不受限制的 可以通过多种方式来限制容器可以使用的CPU资源 大多数用户通过CFS(completely fair scheduler)来调度 在1.13之后版本的docker上,还可以使用realtime调度器 --cpus= 限定一个容器最多能够使用几核 --cpu-period= --cpu-quota= --cpuset-cpus 限制在哪些核上 -- cpu-shares 配置为共享方式(各个容器共享宿主机CPU)  7,下载压测镜像,可以在dockerhub上搜索stress\n","description":"介绍容器的实现,讲解docker常用命令和Dockerfile的使用","tags":["云原生","docker","cloud"],"title":"docker学习","uri":"/tech/cloud/docker%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"变量及操作符 #1. 特殊字符使用 # --\u003e 注释(不包括#!) --\u003e 变量替换使用 echo ${PATH#*:} ; --\u003e 命令分隔符,用于连接多个命令 ;; --\u003e 用于终止一个case语句 . --\u003e 等同于source命令 --\u003e 可作为隐藏文件的文件名开头 --\u003e 相对路径的表示,当前路径和父目录路径 --\u003e 匹配单个字符 '' --\u003e 忽略所有特殊字符,全部引用 \"\" --\u003e 忽略除去`,$,\\外所有的特殊字符,部分引用 , --\u003e 连接一串运算,只返回最后一个的结果 let \"t2 = ((a = 9, 15 / 3))\" ## set \"a=9\" and \"t2 = 15 / 3\" --\u003e for file in /{,usr/}bin/*calc ## 与{}一起使用,用作选择的一种,简略代码 1.1 变量替换中的大小写替换 echo ${var,} --\u003e 第一个字符小写 echo ${var,,} --\u003e 所有字符小写 echo ${var^} --\u003e 第一个字符大写 echo ${var^^} --\u003e 所有字符大写 \\ --\u003e 脱意符,除去特殊字符的含义,\\X等效与'X' ` --\u003e 运算符,将命令的输出结果作为内容传递给变量 : --\u003e 空命令,no op,执行结果返回值为0 --\u003e 在if/then记过中作为占位符使用 if condition;then :;else action;done --\u003e 为需要二进制文件存在的场合提供占位符 : ${username=`whoami`} | : ${1?\"Usage: $0 ARGUMENT\"} --\u003e 作为切片使用,同python中的切片 ${var:1} ${var:3:3} --\u003e 同重定向一同使用,用于清空一个文件而不更改其权限,如果文件不存在,则创建该文件 : \u003e /tmp/testfile --\u003e 可以用作注释符使用,但与#不同,:仍然会检查注释内容中命令是否正确 --\u003e 用作/etc/passwd文件和$PATH的分隔符 ! --\u003e 更改命令返回值,反转test命令的含义 --\u003e ${!variable},获取变量$variable的变量值 --\u003e 调用历史命令,在脚本中无法使用 * --\u003e 通配符,用以指代在给定的目录下的任何文件 --\u003e 在正则表达式中,表示任意数量的(包括0)xxx --\u003e 运算符,**便是乘方 ? --\u003e 在双括号结构中,可以用做判断 (( var0 = var1\u003c98?9:21 )) --\u003e 变量替换,当parameter不存在是,打印err_msg内容,返回值为1,两种形式的差别仅当parameter被声明且为空值时有差别 ${parameter?err_msg}, ${parameter:?err_msg} --\u003e 通配符,给定目录中的单字符文件名,在扩展正则表达式中代表单个字符 $ --\u003e 变量替换 --\u003e 锚定符,代表行尾 ${} --\u003e 参数替换 $* --\u003e 位置参数 $@ --\u003e 位置参数 $? --\u003e 命令返回值 $$ --\u003e 进程ID () --\u003e 小括号中的一组命令开启一个子shell,在脚本当中,其他部分无法读取括号中定义的变量 --\u003e 用于数组的初始化 Array=(e1 e2 e3) {} --\u003e 大括号展开 echo {file1,file2}\\ :{\\ A,\" B\",' C'} --\u003e 扩展大括号展开 echo {a..e} echo {1..10..2} 显示10以内的奇数，步长为2 --\u003e 代码块,内联组(inline group), anonymous function, the variate in the inline group \\ can be seen in the scripts anywhere { read line1 read line2 } \u003c /tmp/passwd line1和line2可以直接读取passwd中的文件内容 在{}中的代码块,一般情况下不会开启一个新的子shell --\u003e {}可以用在非标准的for循环当中 for ((n=1; n\u003c=10; n++)); { echo -n \"* $n *\"; } --\u003e many commands can be used in a {} section, just like a function, return the outcome --\u003e 占位符, use with xargs; 'ls . | xargs -i -t cp ./{} $1' {} \\; --\u003e 该结构用在find架构当中,不作为shell的关键字存在 The \";\" ends the -exec option of a find command sequence. It needs to be escaped to protect it from interpretation by the shell. [] --\u003e test命令,[是test命令的内置指令(test的同义字),并不是test的链接 --\u003e 数组元素,用于展开各个序号的数组元素 --\u003e 正则表达式中使用,用于表示一个序列 \"[B-Pk-y]\" $[] --\u003e 运算符,等效与(()) echo $[$a+$b] $[...] --\u003e 整数扩展符, 可用于整数的计算; 'echo $[3*5]' (())--\u003e 运算符 (( a = 23 )); (( a++ )) \u003c\u003e --\u003e 重定向,包含\u003e,\u0026\u003e,\u003e\u0026,\u003e\u003e,\u003c,\u003c\u003e --\u003e \u0026\u003e 把标准输出和标准错误都重定向 --\u003e \u003e\u00262重定向到标准错误 --\u003e \u003e\u003e 追加 --\u003e [i]\u003c\u003efilename 打开文件filename读写,分配文件描述符i给文件,若i不存在,则默认使用stdin #!/bin/bash ## example 1-1 lock_file=/tmp/$(basename $0).lock exec 300\u003c\u003e$lock_file if ! flock -x -n 300; then echo \"already running\" else echo \"starting...\" sleep 30 fi --\u003e (command)\u003e 进程替换, 暂且记下,后续有具体讲解 --\u003e \u003c\u003c here document --\u003e \u003c\u003c\u003c here string --\u003e askii 比较,对比文本字符顺序 \\\u003e --\u003e 单词边界,同时还有\\\u003c grep '\\\u003cthe\\\u003e' textfile [[]]--\u003e test,比[]更灵活 | --\u003e 管道,将命令的输出作为输入传递给下一个命令 echo ls -l | sh ## 可以作为一种方式执行命令 --\u003e 管道运行在子shell当中,所以不能在管道中定义变量 variable=\"initial_value\";echo \"new_value\" | read variable;echo \"variable = $variable\" # variable = initial_value \u003e| --\u003e 强制重定向,强制清空文件内容,即使已经设置了noclobber属性已经设置了 || --\u003e 或逻辑运算符,在test结构中使用 \u0026 --\u003e 在后台运行任务,在脚本中,命令甚至是循环结构可以运行在后台中 for i in {1..10};do echo -n \"$i\"; done \u0026 脚本中包含后台运行的命令可能会导致脚本hang死,可以设置补救措施; a,在后台命令后面增加一个wait命令可以解决该问题 b,在将结果重定向至/dev/null或者一个文件也可 ls -l \u0026; ehco \"Done.\"; wait \u0026\u0026 --\u003e 逻辑和运算符,用于test结构中 - --\u003e 选项前缀, ls -l --\u003e 从stdin重定向输入或从stdout重定向输入 1, (cd /source/directory \u0026\u0026 tar cf - . ) | (cd /dest/directory \u0026\u0026 tar xpvf -) 2, bunzip2 -c linux-2.6.16.tar.bz2 | tar xvf - 3, grep Linux file1 | diff file2 - --\u003e 前一个工作目录,由$OLDPWD变量保存 --\u003e 减号,用作逻辑运算符 -- --\u003e 命令长格式选项前缀 ls --all --\u003e 与set结合使用,设置位置参数 variable=\"one two three four five\" set -- $variable; first_param=$1 second_param=$2 shift; shift echo \"first parameter = $first_param\" # one echo \"second parameter = $second_param\" # two = --\u003e 赋值运算符;a=28 + --\u003e 逻辑运算符,相加 --\u003e 正则表达式,1各或者多个 --\u003e 特定命令的参数前缀,+为开启,-为关闭,如set命令 % --\u003e 逻辑运算符,余 ~ --\u003e 家目录,由$HOME保存 ~+ --\u003e 当前工作目录,由$PWD保存 ~- --\u003e 上一个工作目录,由$OLDPWD保存 =~ --\u003e 正则表达式中匹配 variable=\"This is a fine mess.\" if [[ \"$variable\" =~ T.........fin*es* ]] ^ --\u003e 行开头 --\u003e 参数替换中,大写替换 ^^ --\u003e 参数替换中,大写替换 ' ' --\u003e 空格,用作命令或者是变量的分隔 #2. 变量及参数 1, 变量名是变量值的占位符,获取变量值的操作称之为变量替换 2, 变量裸露的情况(没有前缀'$'符) --\u003e 变量声明或者是赋值的时候 --\u003e 取消变量unset --\u003e 被export --\u003e 逻辑运算表达式(())中 3, 变量的赋值可以在如下结构中 --\u003e '='中 --\u003e read结构 --\u003e 类似for var in xx的循环结构中 4, 变量引用中 --\u003e 使用$a,不用\"\"括起来,移除变量中的tab和newline --\u003e 使用\"$a\",保存whitespace(空白) 5, 使用$(...)替换`...`来进行变量赋值 6, shell变量没有类型 7, 特殊类型的变量 --\u003e 本地变量: 只在代码块或者是函数中可见 --\u003e 环境变量: 影响shell动作的变量,如PATH或者是PS1等 --\u003e 位置参数: $0,$1这些,$0表示脚本;$*和$@代表所有的位置参数 8, 每次新建shell,在shell中会创建相应的环境变量 9, 使用export命令来将本地变量变成环境变量 --\u003e 脚本中,变量只能export给子子进程,也即在脚本中声明的变量无法作用于脚本之外 10,shift命令的作用是重新赋值位置参数,每执行一次,位置参数向左偏移一位 --\u003e 默认可调用10个 --\u003e $0不参与 --\u003e 被重新赋值的变量是move,不是copy(只有两个位置参数,shift后,$2不存在) --\u003e shift可接受数字,表示每次偏移多少 --\u003e 如下示例: # 脚本名称不变,使用软链接给创建多个脚本名称,调用不同的名称,执行不同的功能 ln -s /usr/local/bin/wh /usr/local/bin/wh-ripe ln -s /usr/local/bin/wh /usr/local/bin/wh-apnic ln -s /usr/local/bin/wh /usr/local/bin/wh-tucows E_NOARGS=75 if [ -z \"$1\" ]; then echo \"Usage: `basename $0` [domain-name]\" exit $E_NOARGS fi case `basenam $0` in # Or: case ${0##*/} in \"wh\" ) whois $1@whois.tucows.com;; \"wh-ripe\" ) whois $1@whois.ripe.net;; \"wh-apnic\" ) whois $1@whois.apnic.net;; \"wh-cw\" ) whois $1@whois.cw.net;; * ) echo \"Usage: `basename $0` [domain-name]\";; esac  #3. 引用 1, grep '[Ff]irst' *.txt;在''中的特殊情况,这里并不会去除[]的作用,而是作为被保护的内容传递给grep 2, \"\"保护除过$,\\,`的其他符号 3, 可以引用\\n quote=$'\\116' echo -e '\\'${quote,} 4, $'...'可以将8进制或者16进制数转换成ascii字符保存到变量中 quote=$'\\042' 5, echo -e用于转换特殊含义字符  #4. 测试 测试结构: 1, if/then/elif/else结构,结合if后面的返回值确定执行顺序 --\u003e if结构不仅仅只能判断[]结构,后面可借命令 --\u003e if和then都是关键字参数,关键字开启代码块,在同一行开启一行新语句,就语句必须终结 2, []结构,等效于test 3, [[]]关键字结构,类比于test 4, ((...))和let ...结构,运算结果为非零时,返回值为0;运算结果为零时,返回值为非零 5, test是bash的内建命令,因此在一个脚本中使用test,使用的并不是/usr/bin/test二进制文件 --\u003e 在脚本中需要使用/usr/bin/test命令,需要写全路径 6, 使用[[]]替换[]做测试结构可以防止很多脚本中的逻辑错误 --\u003e \u0026\u0026, ||, \u003c, \u003e可以用在[[]]中,但无法在[]中使用 --\u003e 8进制,10进制,16进制可在[[]]中进行比较,[]会报错 7, (())也可用于测试,展开并对括号中的变量进行运算;当运算结果非零或为0或者'true';当运算结果为零时返回1或者'false' 8, 文件测试,如下不同场景返回true --\u003e -e 文件存在 --\u003e -f 是普通文件,不是目录或设备文件 --\u003e -s 大小不为零 --\u003e -d 是个目录 --\u003e -b 块设备 --\u003e -c 字符设备 --\u003e -p 管道文件 # 示例内容: function show_input_type() { [ -p /dev/fd/0 ] \u0026\u0026 echo PIPE || echo STDIN } show_input_type \"Input\" # STDIN echo \"Input\" | show_input_type # PIPE --\u003e -h 符号链接 --\u003e -L 符号链接 --\u003e -S socket文件 --\u003e -t 文件绑定一个终端设备 [ -t 0 ]用来测试脚本执行是不是在终端上 --\u003e -r/w/x/g/u/k 检测文件是否具有相应的权限 --\u003e -O/G你是文件所属者(组) --\u003e f1 -nt f2 文件f1比f2新 --\u003e f1 -ot f2 文件f1比f2旧 --\u003e f1 -ef f2 文件f1和f2是指向同一个文件的硬链接 --\u003e ! 非  #5. 操作符 --\u003e bash不明白浮点数的运算,会将浮点数当作字符处理;需要处理浮点数的运算,可以使用bc操作 --\u003e 逻辑运算符: 1, \u0026\u0026 和/与 --\u003e if [ $condition1 ] \u0026\u0026 [ $condition2 ] Same as: if [ $condition1 -a $condition2 ] 2, ! 非 --\u003e if [ ! -f $file ] 3, || 或 --\u003e if [ $condition1 ] || [ $condition2 ] Same as: if [ $condition1 -o $condition2 ] 4, \u0026\u0026/||在判断结构中的使用 --\u003e if [[ $a -eq 24 \u0026\u0026 $b -eq 24 ]] works. --\u003e if [ \"$a\" -eq 24 \u0026\u0026 \"$b\" -eq 47 ] error 5, 进制换算 --\u003e 可以使用$((...))结构对各个进制数进行换算 echo $((0x9abc)) --\u003e 在shell中,默认使用10进制,当把8进制或者16进制数使用let赋值存储在变量中,打印后变为10进制 let 'hex = 0x32';echo $hex --\u003e 不限制进制数格式,可以使用let进行换算,可以使用10 digits + 26 lowercase characters + 26 uppercase characters + @ + _ echo $((36#zz)) $((2#10101010)) $((16#AF16)) $((53#1aA)) # 1295 170 44822 3375 --\u003e 双括号结构: 同let,(())结构允许逻辑展开和运算 1, (( a = 23 )) 赋值,等号左右两侧都要有空格 2, (( --a ))和(( a-- ))都可以进行运算 3, (( t = a\u003c45?7:11 )) echo \"if a \u003c 45;then t = 7;else t = 11;fi\" # a = 23 echo \"t = $t \" # t = 7 --\u003e 运算符优先顺序: if [ \"$v1\" -gt \"$v2\" -o \"$v1\" -lt \"$v2\" -a -e \"$filename\" ] # Unclear what's going on here...,不能有超过三个的叠加存在(-a/-o) if [[ \"$v1\" -gt \"$v2\" ]] || [[ \"$v1\" -lt \"$v2\" ]] \u0026\u0026 [[ -e \"$filename\" ]] # Much better -- the condition tests are grouped in logical sections.  #6. 其他变量视角 内部变量 1, $BASHPID(返回当前shell),不同于$$(返回父shell),虽然大部分时候两个值相同 echo $BASHPID;(echo $BASHPID) ## output different echo $$;(echo $$)\t## output same 2, $DIRSTACK,在目录栈中的第一个值,被pushd和popd影响 内置变量响应dirs命令,dirs会显示栈中所有的信息 3, $EDITOR,默认被脚本引用的编辑器,一般是vi或者emacs,nano 4, $EUID,有效UID 5, $FUNCNAME,在函数中,显示当前函数的名字 6, $GROUPS,当前用户所属用户组,是一个数组 echo ${GROUPS[1]} 7, $HOSTTYPE,检查当前系统的硬件类型 echo $HOSTTYPE # i686 8, $IFS,内部边界分隔符;这个变量决定bash怎样判断词组,字符串的边界 --\u003e 默认为空白符(空格,tab,新行) --\u003e 这个值可以被更改 bash -c 'set w x y z; IFS=\":-;\"; echo \"$*\"' ## w:x:y:z --\u003e 在设置IFS时需要注意,IFS对待空格和其他字符不一样 var=\" a b c \"使用for循环打印出来时,会变成三行,而不是和','一样,变为多行(超过三行) 对于使用在awk中的FS也存在同样的问题 9, $PATH,二进制文件路径 10,$PIPESTATUS,保存上一条命令的执行返回值 11,$PPID,父进程的PID号 12,$PROMPT_COMMAND,保存将要被执行的命令(是否为该含义待查) 13,$PS1,主提示符,命令行界面显示 14,$PS2,备提示符,在需要输入额外输入是显示,显示为'\u003e' 15,$PS3,select loop中使用 16,$PS4,set -x后界面显示的提示符'+' 17,$PWD,pwd命令显示结果 18,$REPLY,当且仅当上一条read命令无变量时,保存read的变量值 19,$SECONDS,当前脚本运行了多长时间 while [ \"$SECONDS\" -le \"$TIME_LIMIT\" ] 20,$SHELLOPTS,保存set -o的options项 21,$TMOUT,设置为一个非零值之后,超时会自动登出 --\u003e 可以在脚本中设置超时,在一定时间内未输入,则退出 TMOUT=3 # Prompt times out at three seconds. echo \"What is your favorite song?\" echo \"Quickly now, you only have $TMOUT seconds to answer!\" read song if [ -z \"$song\" ] then song=\"(no answer)\" # Default response. fi 位置参数 1, $0,$1,$2...,位置参数,从命令行传递给脚本,函数;或者使用set进行设置 2, $#,位置参数或者命令行参数的数目 3, $*,所有的位置参数,视为一个word,需要使用\"\"外加 4, $@,同$*,但每个参数单独使用\"\"括起来,同样也需要使用\"\"括起来 --\u003e 使用IFS和$@,$*时需要注意 --\u003e $@和$*仅在使用双引号引用的时候有差别 5, $!,上一个跑在后台的job的进程号 --\u003e 可用于任务控制 { sleep ${TIMEOUT}; eval 'kill -9 $!' \u0026\u003e /dev/null; } --\u003e 另一种方式 TIMEOUT=30 count=0 possibly_hanging_job \u0026 { while ((count \u003c TIMEOUT )); do eval '[ ! -d \"/proc/$!\" ] \u0026\u0026 ((count = TIMEOUT))' # /proc is where information about running processes is found. # \"-d\" tests whether it exists (whether directory exists). # So, we're waiting for the job in question to show up. ((count++)) sleep 1 done eval '[ -d \"/proc/$!\" ] \u0026\u0026 kill -15 $!' # If the hanging job is running, kill it. } 6, $_,映射为执行的上一个命令最后一项内容 --\u003e du \u003e /dev/null;echo $_ # du --\u003e ls -al \u003e /dev/null;echo $_ # -al 7, $?,命令,函数或者是脚本的执行状态返回值 8, $$,脚本自己的pid号,常用于创建惟一的temp文件,相较于mktemp使用更简单 变量归类 1, 使用declare/typeset完成变量定义 2, declare/typeset属于内建命令 3, -r,设置只读变量 --\u003e declare -r var1=xx 等效于 readonly var1=xx 4, -i,设置为整数变量 --\u003e 设置为整数变量,允许直接进行运算,不需要expr结构 n=6/3 echo \"n = $n\" declare -i n echo \"n = $n\" # n = 6/3 # n = 2 5, -a,设置为数组变量 6, -f,显示函数 --\u003e declare -f后未接任何参数,显示所有的函数;可以用在ssh远程连接,传递函数使用 --\u003e declare -f func_name仅显示func_name函数内容 7, -x,等效于export 8, 使用declare声明一个变量会限制其scope 9, 使用declare可以非常方便的辨别变量,尤其是在辨认数组时 --\u003e declare | grep HOME --\u003e Colors=([0]=\"purple\" [1]=\"reddish-orange\" [2]=\"light green\");declare |grep Colors 变量操作 --\u003e bash允许大量字符串操作,部分属于变量替换操作,部分属于UNIX的expr功能 1, 字符串长度 --\u003e ${井号string},显示变量string的长度 --\u003e expr length $string,使用expr功能显示字符串长度 --\u003e expr \"$string\" : '.*',同样是显示变量string中字符串的长度值 2, substring从string开头匹配的字符数,substring是正则表达式 --\u003e expr match \"$string\" '$substring' stringZ=abcABC123ABCabc --\u003e expr \"$string\" : '$substring' echo `expr match \"$stringZ\" 'abc[A-Z]*.2'` # 8 echo `expr \"$stringZ\" : 'abc[A-Z]*.2'` # 8 3, substring在string中第一次匹配的下标号 --\u003e expr index $string $substring echo `expr index \"$stringZ\" 1c` # 'c' (in #3 position) matches before '1'. 变量取出 1, 切片用法 --\u003e ${string:position} # 从position处开始抽取string,此处的position和length都可以是变量 --\u003e ${string:position:length} # 从position处抽取length个string字符 stringZ=abcABC123ABCabc echo ${stringZ:7} # 23ABCabc echo ${stringZ:7:3} # 23A echo ${stringZ:(-4)} # Cabc 区别于${stringZ:-4},这种形式等效于${string:-default} --\u003e ${*:position} # 从position处开始取位置参数 --\u003e ${@:position} # 同上一条 --\u003e ${*:position:length} # 同string 的用法,换成位置参数 --\u003e expr substr $string $position $length # expr用法,切片用法 --\u003e expr match \"$string\" '\\($substring\\)'\t# 获取第一次匹配的substring内容,substring为正则表达式 --\u003e expr \"$string\" : '\\($substring\\)'\t# 同上 echo `expr match \"$stringZ\" '\\(.[b-c]*[A-Z]..[0-9]\\)'`\t# abcABC1 echo `expr \"$stringZ\" : '\\(.[b-c]*[A-Z]..[0-9]\\)'` # abcABC1 echo `expr \"$stringZ\" : '\\(.......\\)'` # abcABC1 --\u003e expr match \"$string\" '.*\\($substring\\)' # 获取尾部第一次匹配的substring内容,substring为正则表达式 --\u003e expr \"$string\" : '.*\\($substring\\)' # 同上 echo `expr match \"$stringZ\" '.*\\([A-C][A-C][A-C][a-c]*\\)'` # ABCabc echo `expr \"$stringZ\" : '.*\\(......\\)'`\t# ABCabc 变量置换 file=/dir1/dir2/dir3/my.file.txt --\u003e ${file#*/} # 拿掉第一条/及其左边的字串：dir1/dir2/dir3/my.file.txt --\u003e ${file##*/} # 拿掉最后一条/及其左边的字串：my.file.txt --\u003e ${file#*.} # 拿掉第一个.及其左边的字串：file.txt --\u003e ${file##*.} # 拿掉最后一个.及其左边的字串：txt --\u003e ${file%/*} # 拿掉最后一条/及其右边的字串：/dir1/dir2/dir3 --\u003e ${file%%/*} # 拿掉第一条/及其右边的字串：（空值） --\u003e ${file%.*} # 拿掉最后一个.及其右边的字串：/dir1/dir2/dir3/my.file --\u003e ${file%%.*} # 拿掉第一个.及其右边的字串：/dir1/dir2/dir3/my mv $filename ${filename%$1}$2 # 可以用作重命名 --\u003e ${file:0:5} # 提取最左边的5个字节：/dir1 --\u003e ${file:5:5} # 提取第5个字节右边的连续5个字节：/dir2 --\u003e ${file-my.file.txt} # 假如$file没有设定，则使用my.file.txt作传回值。（空值及非空值时不作处理） --\u003e ${file:-my.file.txt} # 假如$file没有设定或为空值，则使用my.file.txt作传回值。（非空值时不作处理） ${username-`whoami`} # when username has not been set, return the value of result of whoami filename=${1:-DEFAULT_FILENAME} --\u003e ${file+my.file.txt} # 假如$file设为空值或非空值，均使用my.file.txt作传回值。（没设定时不作处理） --\u003e ${file:+my.file.txt} # 若$file为非空值，则使用my.file.txt作传回值。（没设定及空值时不作处理） --\u003e ${file=my.file.txt} # 若$file没设定，则使用my.file.txt作传回值，同时将$file赋值为my.file.txt。\\ （空值及非空值时不作处理） --\u003e ${file:=my.file.txt} # 若$file没设定或为空值，则使用my.file.txt作传回值，同时将$file赋值为my.file.txt。\\ （非空值时不作处理） --\u003e ${file?my.file.txt} # 若$file没设定，则将my.file.txt输出至STDERR,用于变量报错设置（空值及非空值时不作处理） --\u003e ${file:?my.file.txt} # 若$file没设定或为空值，则将my.file.txt输出至STDERR。（非空值时不作处理） --\u003e 要分清楚unset与null及non-null这三种赋值状态。一般而言，: 与null有关，若不带 : 的话，null不受影响，若带 : 则连null \\ 也受影响。 --\u003e ${var,,} # 更改var的大小写,将$var中的大写字符转换成小写 --\u003e ${井号var} # get the length of the variate of var 变量替换 stringZ=abcABC123ABCabc --\u003e echo ${stringZ/abc/xyz} # xyzABC123ABCabc,将开头的abc替换成xyz --\u003e echo ${stringZ//abc/xyz} # xyzABC123ABCxyz,将字符串中的所有abc替换成xyz abc和xyz都可以使用变量替换 --\u003e echo ${stringZ/abc} # ABC123ABCabc,不包含replacement时,则是直接删除第一处匹配内容 --\u003e echo ${stringZ//abc} # ABC123ABC,同上,删除所有的匹配内容 --\u003e echo ${stringZ/#abc/XYZ} # XYZABC123ABCabc,匹配前端的第一个,进行替换 --\u003e echo ${stringZ/%abc/XYZ} # abcABC123ABCXYZ,匹配后端的最后一个,进行替换 --\u003e echo ${!varprefix*} # 匹配所有已声明已xyz开头的变量 --\u003e echo ${!varprefix@} # 匹配所有已声明已xyz开头的变量 abc23=something_else b=${!abc*} echo \"b = $b\" # b = abc23 c=${!b} # Now, the more familiar type of indirect reference. echo $c awk的使用,等效变量替换 String=23skidoo1 # 012345678 Bash 变量替换中bash的下标计算方式 # 123456789 awk 变量替换中awk的下标计算方式 --\u003e echo | awk '{ print substr(\"'\"${String}\"'\",3,4) }' # skid 前面使用空echo的作用是,所谓伪输入,不需要填写输入文件  #7. 循环和分支结构 1 2 3  1, for循环 for arg in [list]; do command;done --\u003e for循环和set结合使用,会很方便,以下是例子    set `uname -a`; for item in $(seq $#); do echo ${!item}; done for planet in \"Mercury 36\" \"Venus 67\" \"Earth 93\" \"Mars 142\" \"Jupiter 483\"; do set -- $planet echo \"$1 $2,000,000 miles from the sun\" done  --\u003e set中使用的--,避免难预测的bug,当后面的变量为空或者是以'-'开头 --\u003e [list]可以是一个变量,保存了多个值,用于for循环使用 --\u003e [list]也可以使用*通配符 --\u003e 无[list]项也可,循环使用的内容为位置参数 for a; do echo -n \"$a \"; done # 写入脚本后,执行脚本时,后接参数或者不接参数,得出结果不同 --\u003e [list]内容同样可为命令替换后的结果 for name in $(awk 'BEGIN{FS=\":\"}{print $1}' \u003c \"$PASSWORD_FILE\" ) # 系统上所有用户 for word in $(generate_list) # 函数运行结果 --\u003e for loop结束后,在done后面可直接使用管道进行操作,例如排序等 for file in \"$( find $directory -type l )\";do echo \"$file\"; done | sort # 对循环执行后的结果进行排序 --\u003e C风格的for循环,需要用到(()); LIMIT=10; for ((a=1; a \u003c= LIMIT ; a++)); do echo $a; done for ((a=1, b=1; a \u003c= LIMIT ; a++, b++)); do echo -n \"$a-$b \"; done --\u003e 一般情况下,do和done分割for循环的结构,但在特定情况下,省略do和done for((n=1; n\u003c=10; n++)) { # No do echo -n \"* $n *\" } # No done! for n in 1 2 3 { echo -n \"$n \"; } # 在经典的for结构中,花括号中需要包含;,用于结尾 --\u003e E_NOARGS=65 --\u003e The standards of variate naming, exit-because-no-arguments --\u003e read command read reads a line every time, in the function 'while read i j', i stands for the first word, j stands for the rest of this line --\u003e the difference between return and exit 若在script里，用exit RV来指定其值，若没指定，在结束时以最后一道命令之RV为值。 若在function里，则用return RV来代替exit RV即可。 若在loop里，则用break 2, while循环 相对于for循环,while循环更适合用于不确定condition情况下进行的循环 while [condition]; do command(s); done --\u003e 在while循环中可能存在多个条件,但只有最后一个条件决定什么时候终止循环 while echo \"previous-variable = $previous\" echo previous=$var1 [ \"$var1\" != end ]; do ... --\u003e 同for循环一样,while可以接收C风格的条件格式 while (( a \u003c= LIMIT )) do echo -n \"$a\" ((a += 1)) # let \"a+=1\" done --\u003e while的条件可以直接接函数 condition(){ ((t++)) if [ $t -lt 5 ]; then return 0 # true else return 1 # false fi } while condition --\u003e 与read一起结合使用,得到while read结构 cat file | while read line # 同时是以管道作为输入内容 --\u003e while可以在done后使用'\u003c'来作为内容输入 3, until循环 循环体在顶部,直到条件正确,才退出执行循环结构中的内容;与while循环相反 until [ condition-is-true ]; do command(s); done until循环结构格式类同于for循环 --\u003e 条件为真才退出 END_CONDITION=end until [ \"$var1\" = \"$END_CONDITION\" ] # Tests condition here, at top of loop. do echo \"Input variable #1 \" echo \"($END_CONDITION to exit)\" read var1 echo \"variable #1 = $var1\" echo done --\u003e until同样接受C风格的判断条件,使用双括号的格式(()) until (( var \u003e LIMIT )) 4, 嵌套循环 一个循环结构属于另一个循环结构的构成部分,称为嵌套循环 5, 循环控制 影响循环行为的命令 break;continue --\u003e break的作用为终止当前循环 --\u003e continue的作用为跳过当前这次的循环,在该分支中,跳过该分支后面需要执行的命令和操作   while [ $a -le \"$LIMIT\" ]; do a=$(($a+1)) if [ \"$a\" -eq 3 ] || [ \"$a\" -eq 11 ]; then # Excludes 3 and 11. continue\t# Skip rest of this particular loop iteration. fi echo -n \"$a\"\t# This will not execute for 3 and 11. done while [ \"$a\" -le \"$LIMIT\" ]; do a=$(($a+1)) if [ \"$a\" -gt 2 ]; then break # Skip entire rest of loop. fi echo -n \"$a\" done \t--\u003e break可以后接参数,单个的break表示终止当前循环;break N表示终止几层循环 --\u003e continue也可以接参数,单个的continue表示此次循环,continue N会终止当前层级的循环,开始下一次的循环,从N层开始 6, 测试和分支 case和select结构不属于循环结构,但他们通过条件判断引导程序流向 --\u003e case对标的是C/C++中的switch结构;case可以说是简化版的if/elif/elif/.../else结构,case可以用于设置程序接口 case \"$variable\" in \"$condition1\") command... ;; \"$condition2\")\tcommand... ;; esac --\u003e 判断后接参数 E_PARAM=1 case \"$1\" in \"\") echo \"Usage: ${0##*/} \u003cfilename\u003e\"; exit $E_PARAM;; # 提示信息,精简化 -*) FILENAME=./$1;; # 如果后面所接参数包含破折号,将其替换为./$1,这样后面的命令嗯就不会把其当做$1 * ) FILENAME=$1;; esac   --\u003e while和case一起使用: while [ $# -gt 0 ]; do case \"$1\" in -d|--debug) DEBUG=1 ;; -c|--conf) CONFFILE=\"$2\" shift if [ ! -f $CONFFILE ]; then echo \"Error: Supplied file doesn't exist!\" exit $E_CONFFILE fi ;; esac shift done --\u003e 做匹配函数: match_string (){ MATCH=0 E_NOMATCH=90 PARAMS=2 E_BAD_PARAMS=91 [ $# -eq $PARAMS ] || return $E_BAD_PARAMS case \"$1\" in \"$2\") return $MATCH;; * ) return $E_NOMATCH;; esac } --\u003e select继承自ksh,同样是一个可用于构建入口的工具 select variable [in list] do command... break done ​\n\t--\u003e select结构提示用户输入给定的选项之一,默认情况下使用环境变量PS3作为提示符,但这个可以被改变  \tPS3='Choose your favorite vegetable: ' # Sets the prompt string. # Otherwise it defaults to #? . select vegetable in \"beans\" \"carrots\" \"potatoes\" \"onions\" \"rutabagas\" do echo echo \"Your favorite veggie is $vegetable.\" echo \"Yuck!\" echo break # What happens if there is no 'break' here? done \t--\u003e 如果结构中list不存在,select会使用传递给脚本或包含select结构的函数的位置参数$@;可类比for variable [in list]   PS3='Choose your favorite vegetable: ' choice_of(){ select vegetable\t# [in list] omitted, so 'select' uses arguments passed to function. do echo echo \"Your favorite veggie is $vegetable.\" echo \"Yuck!\" echo break done } choice_of beans rice carrots radishes rutabaga spinach ------------------------------------------------------------------------------------------------------ #8. 命令替换 命令替换重新单个甚至多个命令的输出结果,逐字的将输出内容传递给另一个上下文 --\u003e 命令的输出结果可以是传递给其他命令的参数,可以是设置变量,甚至生成for循环需要使用的内容参数 --\u003e 命令替换有两种形式:`commands`,$(commands),两种方式等效 --\u003e 命令替换生成一个子shell --\u003e 命令替换可能把输出结果分片 COMMAND `echo a b` # 2 args: a and b COMMAND \"`echo a b`\"\t# 1 arg: \"a b\" note: 有时命令替换会出现不期望的结果 mkdir 'dir with trailing newline ' cd \"`pwd`\" # error inform cd \"$PWD\" # works fine --\u003e 使用echo输出命令替换厚的未括变量,echo会将换行符去除 --\u003e 命令替换允许使用重定向或者cat来获取文件内容作为变量内容 echo ` \u003c$0` # 输出脚本内容 --\u003e 不要将一个长文本内容作为值赋给一个变量，也不要将二进制文件内容作为变量的值 --\u003e 没有缓冲溢出的情况出现，这是翻译性语言的特性，相较编译语言提供更多的保护 --\u003e 变量声明甚至可以通过一个循环结构来赋值   variable1=`for i in 1 2 3 4 5 do echo -n \"$i\" done` --\u003e 命令替换使用$()替换掉反引号的使用 允许这种形式：content=$(\u003c$File2) --\u003e $()的形式允许多重嵌套  #9. 运算展开 算数展开提供了一个强大的工具，用于在脚本中进行算数运算；常用的有反引号、双括号、let 变种： --\u003e 使用反引号的算数运算，常常和expr结合使用 z=`expr $z + 3` --\u003e 算数展开使用双括号和let，反引号的结构已经被(())，$(())和let替换 z=$(($z+3))或者z=$((z+3))也可以 (( n += 1 ))是正确的；(( $n += 1 ))是错误的 let z=z+3是正确的；let \"z += 3\"也可以  linux命令 #1. 内部命令和内部指令 ​ 内建指令是指包含在bash工具集内部的命令；内建命令的作用一方面是为了提升性能，常用于需要fork新进程的命令，另一方面是出于某些命令需要直接访问shell内部\n--\u003e 父进程获取到子进程的pid后，可以传递参数给子进程，反过来则不行；这个需要注意，出现这种问题时，一般难以排查   PIDS=$(pidof sh $0) # Process IDs of the various instances of this script. P_array=( $PIDS ) echo $PIDS let \"instances = ${井号P_array[*]} - 1\" echo \"$instances instance(s) of this script running.\" echo \"[Hit Ctl-C to exit.]\"; echo sleep 1 sh $0 exit 0 --\u003e 一般来说，bash内建指令不会自动fork新的进程，外部命令或者管道过滤时会fork新进程 --\u003e 内建指令可能和系统命令有同样的名字，但bash会使用内建命令，echo和/bin/echo并不一样 echo \"This line uses the \\\"echo\\\" builtin.\" /bin/echo \"This line uses the /bin/echo system command.\" --\u003e 关键字是预留字、符号，或者是操作符；关键字对shell来说具有特殊的含义，是shell的语句块的构成部分；关键字属于bash的硬编码部分，不同于内建指令，关键字是命令的子单元  #2. IO命令 echo：打印表达式或者变量到标准输出 --\u003e 和-e使用，用来打印脱意符 --\u003e 默认情况下，每个echo会打印一个终端换行符，当与-n一起使用时，会将换行符省略掉 --\u003e echo `command`的形式会删除所有由command生成的换行符 变量$IFS默认情况下降'\\n'作为分隔符之一，bash将换行符后面的内容作为参数传递给echo，echo将这些参数打印出来，使用空格分隔 printf：格式化打印，增强型的echo，是一个C语言中printf()函数的限制型变体，部分内容与原函数使用不同 printf format-string... parameter... --\u003e 格式化输出  declare -r PI=3.14159265358979 printf \"Pi to 2 decimal places = %1.2f\" $PI printf \"Pi to 9 decimal places = %1.9f\" $PI --\u003e 格式化输出错误内容很实用  # 注意$'strings...'的格式，在此处与%s的使用 error() { printf \"$@\" \u003e\u00262 # Formats positional params passed, and sends them to stderr. echo exit $E_BADDIR } cd $var || error $\"Can't cd to %s.\" \"$var\" read：通过标准输入读取变量值，动态的通过键盘获取值，与-a选项一起使用时可获取数组变量 --\u003e read通常情况下，'\\'会去除换行的含义，当与-r参数一同使用时，'\\'按照原意进行输出 --\u003e -s：不显示输入内容到屏幕上 --\u003e -n：设置仅接收多少字符，-n同样能接受特殊按键，但需要清楚特殊按键对应的字符，但不能获取到回车的字符 arrowup='\\[A' arrowdown='\\[B' arrowrt='\\[C' arrowleft='\\[D' insert='\\[2' delete='\\[3' --\u003e -p：在接收输入内容前，打印后续内容到屏幕上，作为提示用 --\u003e -t：用在设置超时时间的场景下 --\u003e -u：获取目标文件的文件描述符 --\u003e read命令同样可以通过重定向到标准输入的文件来读取变量，如果文件内容超过一行，则只有第一行内容会被用于变量读取； --\u003e 当read后接的参数多余一个时，默认会以空格（或者连续空格）作为分隔符来读取变量，此行为可通过更改环境变量$IFS来改变  read var1 \u003c /tmp/file1 read var1 var2 \u003c /tmp/file1 while read line; do echo $line; done \u003c /tmp/file1 #3. 文件系统命令 cd：切换路径命令 --\u003e 使用-P参数，忽略链接文件 --\u003e cd -,切换到上一个目录，$OLDPWD变量保存的内容 --\u003e 使用两个斜杠时，cd命令会出现我们不期望的情况  # 以下的问题在命令行和脚本中都存在，需要注意 $ cd // $ pwd // pwd：显示当前工作目录路径 --\u003e使用该命令的效果同$PWD完全相同 pushd,popd,dirs：这个命令集合是一个工作目录书签工具，用于在工作目录中有序的来回切换；后进先出的堆栈方式处理工作目录组，允许对这个堆栈进行各种不同的操作 --\u003e pushd dir-name把目录dir-name放入到到堆栈中（栈顶），同时切换当前目录到dir-name中去 --\u003e popd 将目录栈顶的目录从栈中移除，同时将工作目录切换至此时的栈顶目录中去 --\u003e dirs 列出栈中的目录列表，popd和pushd会引用到dirs 在脚本中需要切换多个目录工作时，使用这个命令集可以方便的进行管理，$DIRSTACK数组包含有目录的列表栈内容  #4. 变量操作命令 let：let命令执行对变量的算数运算操作，在很多种情况下，let相当于简化版的expr命令  let a=11; let a=a+5 let \"a \u003c\u003c= 3\" let \"a += 5\" let a++(++a) let \"t = a\u003c7?7:11\" --\u003e 使用let命令，在特定情况下，命令返回值和通常情况不同  $ var=0 $ echo $? 0 $ let var++ $ echo $? 1 eval： eval arg1 [arg2] ... [argN] 结合一个表达式或者一列表达式中的参数，是这些参数联合；所有在表达式中的变量都会被展开，得出的字符串被转换为命令  $ command_string=\"ps ax\" $ eval \"$command_string\" --\u003e 每次调用eval都会强制重新评估其参数  $ a=\"$b\" $ b=\"$c\" $ c=d $ echo $a $ eval echo $a $ eval eval echo $a params=$# param=1 while [ \"$param\" -le \"$params\" ] do echo -n \"Command-line parameter \" echo -n \\$$param echo -n \" = \" eval echo \\$$param (( param ++ )) done --\u003e 使用eval命令有一定的风险，如果存在替换的方案，尽量使用替换方案来实现目的；像是eval $COMMANDS，在命令的返回结果中可能存在危险的内容如rm -rf *等 set： set命令可用于更改脚本内部的变量值或者脚本选项，用法之一是可以设置option flags来更改脚本执行的动作；另一个用法是可以是将命令的输出结果设置为位置参数。  set `uname -a` --\u003e 当单独使用set命令时，终端显示所有的环境变量以及已经设置的变量 --\u003e set后接--,表示将一个变量的内容设置为位置参数,当--后没有任何参数时,表示取消所有的位置参数  variable=\"one two three four five\" set -- $variable first_param=$1 second_param=$2 shift; shift remaining_params=\"$*\" echo \"first parameter = $first_param\" # one echo \"second parameter = $second_param\" # two echo \"remaining parameters = $remaining_params\" # three four five set -- first_param=$1 second_param=$2 echo \"first parameter = $first_param\" # (null value) echo \"second parameter = $second_param\" # (null value) unset: unset命令删除一个shell变量,将变量的值设置为null,改命令不影响位置参数 --\u003e 大多数情况下,使用unset设置过的变量和undeclare设置过的变量是等效的;但对于${parameter:-default}还是有区分的 export: export命令将变量的值声明至所有由脚本生成的子shell或者是shell,令其都可使用;在开机启动脚本中使用是export一个重要使用场景,有初始化环境的作用,让后启用的脚本能够继承环境变量 --\u003e 父进程是没有办法获取到子进程的变量的 --\u003e 大部分情况下,export var=xxx和var=xxx;export var是等效的,但在某些情况下有差别  bash$ export var=(a b); echo ${var[0]} (a b) bash$ var=(a b); export var; echo ${var[0]} a declare/typeset: 这两个命令用来设定或者限制变量的属性 readonly: 等效于declare -r,将一个变量设置为只读,或者实际效用为设置成一个常量,这个命令类似于C中的const getopsts: 这个强大的命令解析命令行参数,传递给脚本使用,这个命令类似于C中的外部命令getopt,getopt库函数;命令允许传递和连接多个选项,并且为脚本联合多个参数,如下所示:  scriptname -abc -e /usr/local --\u003e getopts使用两个默认的变量: $OPTIND(OPTion INDex)是参数指针 $OPTARG(OPTion ARGument)是参数指定一个选项 选项名声明时后接冒号表明这个选项有一个指定的参数 --\u003e getopts结构一般会同while循环使用,每次处理一个选项和参数,然后变量$OPTIND指针指向下一个值 命令行传递给脚本的参数前面必须接'-',存在'-'的前缀,让getopts识别命令行参数为选项;实际上,没有'-'时,getopts不会去处理这些参数,直接当作缺失选项处理 getopts模板与while循环有些许差别 getopts结构是外部命令getopt命令的替换  while getopts \":abcde:fg\" Option # Initial declaration. # a, b, c, d, e, f, and g are the options (flags) expected. # The : after option 'e' shows it will have an argument passed with it. do case $Option in a ) # Do something with variable 'a'. b ) # Do something with variable 'b'. ... e) # Do something with 'e', and also with $OPTARG, # which is the associated argument passed with option 'e'. ... g ) # Do something with variable 'g'. esac done shift $(($OPTIND - 1)) # Move argument pointer to next. # All this is not nearly as complicated as it looks \u003cgrin\u003e. NO_ARGS=0 E_OPTERROR=85 if [ $# -eq \"$NO_ARGS\" ]\t# Script invoked with no command-line args? then echo \"Usage: `basename $0` options (-mnopqrs)\" exit $E_OPTERROR # Exit and explain usage. # Usage: scriptname -options # Note: dash (-) necessary fi while getopts \":mnopq:rs\" Option do case $Option in m) echo \"Scenario #1: option -m- [OPTIND=${OPTIND}]\";; n | o ) echo \"Scenario #2: option -$Option- [OPTIND=${OPTIND}]\";; p) echo \"Scenario #3: option -p- [OPTIND=${OPTIND}]\";; q) echo \"Scenario #4: option -q- with argument \\\"$OPTARG\\\" [OPTIND=${OPTIND}]\";; r | s ) echo \"Scenario #5: option -$Option-\";; *) echo \"Unimplemented option chosen.\";; # Default. esac done shift $(($OPTIND - 1)) exit $? #5. 脚本行为命令 source/. (点命令) 这个命令,当在脚本外使用时,作用为调用一个脚本; 在脚本内部使用,source file-name的作用为加载file-name的内容; --\u003e source一个文件,将该文件的代码加载进入当前脚本(作用内容于C里面的#include作用) --\u003e 最终结果是,一个被source过的文件,代码就像在当前脚本物理上包含了被source过的文件的代码内容;当多个脚本使用同一个数据文件时,这种方式很有用 --\u003e 如果被source的文件本身是一个可执行脚本,当source后,脚本会执行,然后将控制权交回调用其的脚本;一个可执行的source文件可以使用return来实现目的 --\u003e 参数(可选)可以传递给被source的文件作为位置参数  source $filename $args1 $args2 --\u003e 脚本甚至可以在执行时source自己,随然可能没有什么实际的应用场景  #!/bin/bash MAXPASSCNT=100 echo -n \"$pass_count \" let \"pass_count += 1\" while [ \"$pass_count\" -le $MAXPASSCNT ]; do . $0 done echo exit 0 exit 无条件的终止一个脚本;exit命令可以选择性的后接一个整数参数,用作脚本的exit返回状态 --\u003e 最简单的方式是直接使用exit 0, 指明此次运行成功 --\u003e 如果一个脚本以未接参数的exit作为结尾,那么脚本的返回值则为最后一条命令的返回值,等效于exit $? --\u003e 一个exit命令也可以用于终止一个子shell exec 这个shell内建命令替换当前进程为一个指定的命令 --\u003e 通常情况下,当shell遇到一个命令时,会fork一个子进程来执行该命令,当使用exec命令时,shell不再fork子进程,并且exec调用的命令替换了shell --\u003e 当exec在脚本中使用时,当exec调用的命令结束时,会强制退出脚本  #!/bin/bash exec echo \"Exiting \\\"$0\\\" at line $LINENO.\" # Exit from script here. # $LINENO is an internal Bash variable set to the line number it's on. # The following lines never execute. echo \"This echo fails to echo.\" exit 99 #!/bin/bash # self-exec.sh # Note: Set permissions on this script to 555 or 755, #\tthen call it with ./self-exec.sh or sh ./self-exec.sh. echo echo \"This line appears ONCE in the script, yet it keeps echoing.\" echo \"The PID of this instance of the script is still $$.\" # Demonstrates that a subshell is not forked off. echo \"==================== Hit Ctl-C to exit ====================\" sleep 1 exec $0 # Spawns another instance of this same script #+ that replaces the previous one. echo \"This line will never echo!\"\t# Why not? exit 99\t# Will not exit here! # Exit code will not be 99! --\u003e exec同时还具有重新声明文件描述符的功能,例如:exec \u003czzz-file用文件zzz-file内容替换标准输入 --\u003e 在find命令中使用的-exec选项和shell内建命令exec不同,需要注意 shopt 这个命令允许在运行的过程中更改shell选项,通常出现在bash启动文件中,同样在脚本中可以使用,需要version 2以上版本的bash  shopt -s cdspell # Allows minor misspelling of directory names with 'cd' # Option -s sets, -u unsets. cd /hpme # Oops! Mistyped '/home'. pwd # /home # The shell corrected the misspelling. caller 在一个函数中放置一个caller命令,会打印出是在第几行调用这个函数,不再函数中使用没有作用  #!/bin/bash function1 () { caller 0\t# Tell me about it. } function1 --\u003e caller命令在被source后,同样能够打印出在被source文件中的位置,类似于一个函数,这个被称作为子程序 --\u003e caller在debug中比较有用  #6 常用命令 true 一个返回成功(0)的退出状态码命令,不做任何其他动作 常用与无限循环结构中: while true false 一个返回失败(非0)退出状态码命令,不做任何其他动作 常用场景同样为无限循环结构: while false type[cmd] 类似于which的外部命令,type命名用于鉴定cmd命令; --\u003e 不同于which,type是一个内建命令 --\u003e type使用-a参数时,用于鉴定关键字和内建命令,同样定位命令在系统上的唯一名称  bash$ type '[' [ is a shell builtin bash$ type -a '[' [ is a shell builtin [ is /usr/bin/[ bash$ type type type is a shell builtin --\u003e 在测试一个命令是否存在时,type命令非常有用,可以在判断结构中使用  bash$ type bogus_command \u0026\u003e/dev/null bash$ echo $? 1 hash [cmds] 记录指定命令的path名--在shell的哈希表中--因此shell或者脚本不需要逐次的查找$PATH变量目录来调用这些命令 --\u003e 当hash命令后不接参数时,则仅仅将已经hash的命令列出来 --\u003e 使用-r参数是清空hash表操作 bind 内建命令bind显示或者修改readline关键子绑定 readline:The readline library is what Bash uses for reading input in an interactive shell. help 获取简短的shell内建命令帮助信息,这个命令whatis的副本,但是是一个内建命令 help命令在bash v4后显示的信息详尽很多  #7. job控制命令 该部分内容的部分命令需要后接任务鉴定符作为参数 jobs 列出当前在后台运行的所有job,给出job数字,没有ps有用 --\u003e job和process的概念很容易混淆;一些特定的内建命令,像kill,disown,wait后接job号或者进程号作为参数;但fg,bg和jobs命令则仅接收任务号(job号)作为参数  bash$ sleep 100 \u0026 [1] 1384 bash $ jobs [1]+ Running\tsleep 100 \u0026 上面的命令及其输出中,数字1是任务号(由当前shell获取的job号),1384是进程号(由系统获取),杀掉job/process,使用kill %1或者kill 1384 disown 移除shell中table内正在运行的job  $ jobs [1] Running sleep 1000 \u0026 [2] Running sleep 1000 \u0026 [3]- Running sleep 1000 \u0026 [4]+ Running sleep 1000 \u0026 $ disown $ jobs [1] Running sleep 1000 \u0026 [2]- Running sleep 1000 \u0026 [3]+ Running sleep 1000 \u0026 fg,bg fg命令将一个运行在后台的任务切换至前台. bg命令重新启动一个挂起的任务,并在后台执行 --\u003e 如果没有指定任务号,则默认fg和bg会作用与当前正在running状态的任务 wait 暂时挂起脚本的执行过程,直到所有的后台运行任务已经结束,或者是作为参数的任务号/进程号已经终止,返回wait后接命令的返回状态码 --\u003e 使用wait的场景通常为:指定的后台任务已完成,再继续执行脚本后续内容  #!/bin/bash ROOT_UID=0\t# Only users with $UID 0 have root privileges. E_NOTROOT=65 E_NOPARAMS=66 if [ \"$UID\" -ne \"$ROOT_UID\" ]; then echo \"Must be root to run this script.\"\t# \"Run along kid, it's past your bedtime.\" exit $E_NOTROOT fi if [ -z \"$1\" ]; then echo \"Usage: `basename $0` find-string\" exit $E_NOPARAMS fi echo \"Updating 'locate' database...\" echo \"This may take a while.\" updatedb /usr \u0026\t# Must be run as root. wait # Don't run the rest of the script until 'updatedb' finished. # You want the the database updated before looking up the file name. locate $1 # Without the 'wait' command, in the worse case scenario, #+ the script would exit while 'updatedb' was still running, #+ leaving it as an orphan process. exit 0 --\u003e wait也可以后接一个任务识别号作为参数,例如: wait %1或者wait $PPID --\u003e 在一个脚本中,使用\u0026符号让命令在后台执行可能会导致脚本hang死直到按下enter键,这种情况主要出现在需要输出到标准输出的命令,这种情况的出现比较让人烦;在这种命令后接wait  #!/bin/bash # test.sh\tls -l \u0026 echo \"Done.\" wait bash$ ./test.sh Done. [bozo@localhost test-scripts]$ total 1 -rwxr-xr-x 1 bozo bozo 34 Oct 11 15:09 test.sh 将命令输出写入到文件或者/dev/null中也可以解决这个问题 suspend 改命令与ctrl+Z有相似的效果,但是这个命令是挂起shell(shell的父进程应该在合适的时候恢复该shell的运行) logout 退出一个登录shell,后面可借参数n,指定登出shell的状态返回码 times 显示进程执行用时数据,区别于time命令;得出的信息价值有限,对于profile和基础shell脚本并不通用 kill 强制终止一个进程,通过传递合适的终止信号  #!/bin/bash # self-destruct.sh kill $$\t# Script kills its own process here. # Recall that \"$$\" is the script's PID. echo \"This line will not echo.\" # Instead, the shell sends a \"Terminated\" message to stdout. exit 0\t# Normal exit? No! # After this script terminates prematurely, #+ what exit status does it return? # # sh self-destruct.sh # echo $? # 143 # # 143 = 128 + 15 #\tTERM signal --\u003e kill -l列出所有支持的信号列表(包含在文件/usr/include/asm/signal.h) --\u003e kill -9是一个确认杀死,通常使用在单独使用kill命令无法杀死的场景下,有时,kill -15也能生效 --\u003e 僵尸进程是一个子进程已经终止,但父进程还没有被kill,无法被一个loged-on用户杀死--你无法杀死一个已经死的物件--但是init迟早会清理这些进程 killall killall命令通过名字杀死一个运行进程,而不是通过pid --\u003e 如果同时存在多个命令运行实例,则执行killall命令会将所有的这些实例全部杀死 --\u003e 此处的killall是指在/usr/bin/下的命令,而不是/etc/rc.d/init.d下的killall脚本 command command命令禁用接在其后的命令的alias和function --\u003e 这个命令是三个影响脚本命令执行的指令之一,其他两个分别是builtin和enable builtin 使用命令builtin BUILTIN_COMMAND将命令BUILTIN_COMMAND当作一个shell内建命令来执行;临时禁用与调用命令同名的functions或者是系统外部命令 enable 改命令能够启用或者禁用一个shell内建命令 例如: 命令enable -n kill禁用了shell内建命令kill,当bash继续调用kill时,调用的是外部命令kill --\u003e enable的-a选项列出所有的shell内建命令,指示这些命令是否被enable --\u003e -f filename选项让enable加载一个内建命令作为一个共享库模块从一个正确编译的二进制文件  #8. 任务识别符    内容 含义     %N 任务号   %S 引用以S开头的job   %?S 引用包含S的job   %% 当前job(最后一个在前台停止的任务或者是最后一个在后台启动的任务)   %+ 当前job(最后一个在前台停止的任务或者是最后一个在后台启动的任务)   %- 上一个job   $! 上一个后台任务    #9. 外部过滤器,程序及命令 标准的UNIX命令让shell脚本更加灵活,shell脚本的能力通过多个系统命令和shell指令的整合来实现\n#10. 基础命令 ls 基础文件罗列命令.很容易理解这个命令的低调; 用-R参数是递归的罗列出当前目录下的内容 用-S参数是按照文件的大小来排序 用-t参数是按照文件的修改时间来排序 用-v参数是文件名逆序罗列(依照数值顺序) 用-b参数是显示脱意字符 用-i参数是显示inode信息 --\u003e ls返回一个非零返回值,当目标文件不存在时 cat/tac cat是concatenate的缩写,获取一个文件的内容,显示到标准输出,当与重定向符(\u003e或者\u003e\u003e)一同使用时,一般用来连接文件 --\u003e -n参数是在文件的前面加上行号 --\u003e -b参数是只显示非空行内容 --\u003e -v参数是显示不可打印字符 --\u003e -s参数是将多行空行显示为一行空行 --\u003e 在一个管道中,直接使用重定向会比cat的效率更高  cat filename | tr a-z A-Z tr a-z A-Z \u003c filename --\u003e tac是cat的反向命令,反向输出一个文件的内容(最后一行变为第一行,依次向上) rev 将文件的每一行内容反向输出到标准输出,注意这个通tac功能是不一样的 cp 文件复制命令 cp file1 file2 --\u003e 将file1复制到文件file2,如果file2存在,则覆盖文件file2内容 --\u003e 尤其注意-a(archive)参数的使用,可以用于将一个目录完整复制 --\u003e -u(update)参数避免覆盖 --\u003e -r/-R 递归的复制 move 文件移动命令 命令等效与cp和rm的结合体,用来将多个文件移动到一个文件夹中,或者重命名文件夹; --\u003e 当mv用在一个非交互的脚本中时,mv会使用-f(force)参数来忽略用户的输入内容 --\u003e 当把一个目录mv为另一个已经存在目录名称时,该目录会变成已存在目录的子目录 rm 删除文件命令 --\u003e -f(force)参数用于强制删除文件,即使该文件为只读,在脚本中使用,用来绕开用户输入非常有用 --\u003e 当一个文件以'-'开头时,使用rm删除会失败;rm将以'-'的内容作为参数使用 a.解决方式之一是在要删除文件的前面加上'--'(选项结束标识符) b.另一种方式是,在文件名前加上./,表示是在当前目录下的文件  rm -- -badname rm ./-badname --\u003e 当使用-r参数时,表示从当前指定目录递归删除 a.使用路径名称中包含变量的时候,尤其小心,当变量不存在时,有可能就变成了rm -rf / b.使用rm -rf *时需要注意;若命令执行时,当前工作路径不对,改命令结束后,效果将等同如rm -rf / rmdir 删除文件夹命令 当使用这个命令删除文件夹时,目录必须为空(包括.文件--隐藏文件) --\u003e 特定场景下使用这个命令来替代rm -rf dirname,防止误删错误文件夹 mkdir 创建文件夹命令 创建一个新的文件夹,如: mkdir -p project/programs/December; -p参数会自动创建任何必需的父目录 chmod 更改已存在文件或者文件夹的属性命令 --\u003e 数字方式 chmod 755 /dirname --\u003e 字符方式 chmod u+rwx /filename chattr 更改文件属性命令,这个命令与chmod的功能类似,但是使用不同的选项和语法方式,(仅在ext文件系统上使用?) --\u003e chattr的一个特殊的参数'i'(immutable),当一个文件具有了i属性,表示这个文件是不可更改的,不能被修改,删除,链接(root也不行) --\u003e 当一个文件具有了's'(secure)属性时,文件被删除后,之前文件占用的块将被二进制0填充 --\u003e 当一个文件具有了'u'(undelete)属性时,文件被删除后,文件内容仍能够获取到(状态为undeleted) --\u003e 当一个文件具有了'c'(compress)属性时,当文件被写时,自动压缩到磁盘文件,当文件被读时,自动从磁盘解压读取 --\u003e chattr包含的文件属性不同使用ls -l显示出来 ln 为存在的文件创建链接,链接是一个文件的映射,文件的别名 --\u003e ln命令允许被链接的文件包含不止一个映射名 --\u003e ln命令还可以用作别名来使用,在脚本中充作别名(abs-p38) --\u003e ln只创建文件的映射,指向文件的指针大小只有几个字节大小 --\u003e ln命令最常与-s选项一同使用(符号链接或者称为软链接);软链接的优势之一是可以跨越文件系统创建 ln -s oldfile newfile将oldfile链接一个新的文件名称newfile --\u003e 更改文件被链接文件的内容时,软链接和硬链接同时能够体现更改的文件内容;不同点是 a.删除或者重命名被链接文件后,硬链接不受影响,源文件的存储块内容并没有发生变化;但对于指向源文件名称的软链接来说,旧文件名称已经不存在,软链接将失效 b.软链接的优点是可以跨越文件系统进行链接,并且,不同于硬链接,软链接还可以指向文件夹,硬链接则不行 --\u003e 链接的存在可以让脚本(或其他任何可执行的文件)通过不同的名称来调用(eg:/sbin/iptables -\u003e xtables-multi),通过名称来限定脚本执行哪部分功能  #!/bin/bash # hello.sh ln -s hello.sh goodbye HELLO_CALL=65 GOODBYE_CALL=66 if [ $0 = \"./goodbye\" ]; then echo \"Good-bye!\"\t# Some other goodbye-type commands, as appropriate. exit $GOODBYE_CALL fi echo \"Hello!\" exit $HELLO_CALL man/info 获取帮助文档,info文档一般描述信息会比man文档更详尽 --\u003e man文档的书写可以通过脚本来优化(abs-709)  #11. 高级命令 find 命令形式: -exec COMMAND \\; 为每一行find匹配的内容执行COMMAND命令,命令序列是以';'结尾 --\u003e 此处使用的-exec与shell自带命令exec别混淆了 --\u003e 注意此处不是命令分隔使用到的';',find命令序列中';'是脱意的,为了确保shell将';'按照字面意思传递给find --\u003e 如果COMMAND中包含有{},则find将find匹配的路径或者文件名通过{}来替换;  find ~/ -name 'core*' -exec rm {} \\; find /etc -exec grep '[0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*' {} \\; find /home -type f -atime +5 -exec rm {} \\; 时间匹配: find可以通过文件的时间戳进行查找匹配 mtime = last modification time of the target file ctime = last status change time (via 'chmod' or otherwise) atime = last access time (-mtime -1表示前一天被修改过的文件) 文件匹配: find可以通过文件类型进行查找匹配 f = regular file d = directory l = symbolic link, etc.  ## 删除当前目录下包含特殊字符的文件 find . -name '*[+{;\"\\\\=?~()\u003c\u003e\u0026*|$ ]*' -maxdepth 0 -exec rm -f '{}' \\; ## 通过inum删除文件 inum=`ls -i | grep \"$1\" | awk '{print $1}'` find . -inum $inum -exec rm {} \\; xargs 一个用来传递参数给命令的过滤器,同样也是一个集合命令的工具 --\u003e xargs将数据流打散成足够小的块,用来给命令或者进程处理,可以将这个命令想成更加强大的后向引用 --\u003e 在有些场景下,命令替换报too many arguements时,用xargs却可以使用 --\u003e 一般场景下,xargs通过管道或者标准输入读取数据,但也可以通过一个文件的内容来获取 --\u003e 默认传递给xargs的命令是echo,这表示当输入管道给到xargs时,换行符和一些其他空白字符会被跳过  bash$ ls -l | xargs total 0 -rw-rw-r-- 1 bozo bozo 0 Jan 29 23:58 file1 -rw-rw-r-- 1 bozo bozo 0 Jan... --\u003e 命令ls | xargs -p -l gzip 将当前目录下的每个文件用gzip打包,每次一个,每进行一次会提示一次 --\u003e xargs依次序处理传递给其的参数,一次一项 --\u003e -n NN形式;限制每次传递给命令的参数数目,ls | xargs -n 3 echo -- 每次打印三个名字 --\u003e 另外一个有用的参数是-0,通常和find -print0或者grep -lZ一同使用;这个场景下允许处理的参数中包含空白字符或者引用  find / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f grep -rliwZ GUI / | xargs -0 rm -f --\u003e -P选项允许并行执行命令,在多核机器中能够提高执行速度  ls *gif | xargs -t -n1 -P2 gif2png # Converts all the gif images in current directory to png. # Options: # ======= # -t Print command to stderr. # -n1 At most 1 argument per command line. # -P2 Run up to 2 processes simultaneously. --\u003e 在find中使用,一对花括号的作用是作为占位符使用的  ls . | xargs -i -t cp ./{} $1 # -t is \"verbose\" (output command-line to stderr) option. # -i is \"replace strings\" option. # {} is a placeholder for output text. # This is similar to the use of a curly-bracket pair in \"find.\" expr 通用表达式求值运算命令 连接并对给出的命令选项和参数进行求值操作(各个参数之间必须用空格隔开) --\u003e 可进行的操作包括有: 算数运算,比较,字符或者逻辑运算  expr 3 + 5 expr 5 % 3 expr 1 / 0 expr 5 \\* 3 # 乘法运算,在expr表达式中,乘号需要脱意 y=`expr $y + 1` # 变量自增,等效于 let y=y+1 and y=$(($y+1)) z=`expr substr $string $position $length` # 获取变量string中position位置length长度的字符 --\u003e ':'运算符可以用来替代match;命令 b=`expr $a : [0-9]*`等效于 b=`expr match $a [0-9]*`  #12. 时间/日期命令 date 打印当前时间和日期信息到标准输出,这个命令的格式化输出和解析选项很有用 --\u003e -u选项显示UTC时间 --\u003e date可以用来计算不同时间之间的时间间隔 --\u003e date有大量的输出选项可供选择;比如%N是给出当前时间的纳秒格式,这个形式可以用来获取随机数  date +%N | sed -e 's/000$//' -e 's/^0//' date --date='6 days ago' date --date='1 year ago' zdump 时区dump:打印指定时区的时间  bash$ zdump EST EST Tue Sep 18 22:09:22 2001 EST time 显示执行一个命令的准确时间 --\u003e time不同于命令times,注意  bash$ time ls -l / real 0m0.004s user 0m0.004s sys 0m0.001s touch 更新文件的访问/修改时间为系统/指定时间,同时具有新建一个文件的功能 --\u003e 当文件zzz不存在时,touch zzz会创建一个大小为0的文件zzz;这种方式用来存储日期/时间戳很有用 --\u003e touch命令等效于:\u003e\u003e newfile或者\u003e\u003e newfile(普通文件) --\u003e 可以结合cp -a一起使用,使用touch更新不想被覆盖的文件时间戳,再用cp -u at at任务控制命令在指定的时间执行一系列指定的命令;命令类似于cron,at命令很适合只执行一次的命令 --\u003e 使用-f选项或者\u003c输入重定向,at充文件中读取命令;文件应该是一个可执行的shell脚本,同时是非交互式脚本 --\u003e 需要执行较多内容时,可以结合run-parts命令来实现  bash$ at 2:30 am Friday \u003c at-jobs.list job 2 at 2000-10-27 02:30 batch batch命令类似于at命令,但要求在系统负载低于0.8时执行;类似于at,可以接-f选项 cal 打印简化版的日历到标准输出,可接不同选项,显示不同年份和月份的日历 sleep 这个是shell形势下的wait循环;命令暂停指定秒数的时间,什么都不做 --\u003e 对于后台运行的命令或者定时进程很有用,定时检查事件 --\u003e sleep命令默认情况下是使用秒,但也可以用分钟,小时或者天来定时 --\u003e watch命令比sleep命令更适合周期性检查命令执行情况 usleep 类似与sleep,但默认时间为微秒,用在对时间更加精准或查询更加频繁的场景下 hwclock/clock 命令hwclock获取或者调整机器的硬件时间,某些选项需要root权限才能使用 --\u003e 在rhel6中,启动时,/etc/rc.d/rc.sysinit启动文件通过hwclock获取硬件时间来设置系统时间 --\u003e clock是hwclock的同义词  #13. 文本处理命令 sort 文件归类工具,通常用在管道后过滤使用 --\u003e 命令用来正序,逆序或者指定位置关键字/字符位置来处理文本流或者文件 --\u003e 使用-m选项,合入预处理过的文件 --\u003e 可以查看info文档来获取sort的使用场景 tsort 拓扑排序,读取以空格分隔的字符串对，并根据输入模式进行排序;通常情况下tsort命令排序的结果与sort排序结果有较大差别 uniq 该命令移除文件中重复出现的行,通常会结合sort和管道一同使用  cat list-1 list-2 list-3 | sort | uniq \u003e final.list --\u003e 使用-c选项,在输出结果中显示重复出现的次数 --\u003e sort INPUTFILE | uniq -c | sort -nr　命令打印出在INPUTFILE中出现的频次信息,使用场景为分析log文件或者字典列表等  sed -e 's/\\.//g' -e 's/\\,//g' -e 's/ //g' \"$1\" | tr 'A-Z' 'a-z' | sort | uniq -c | sort -nr expand/unexpand 命令expand用来将tab展开为空格,通常与管道结合使用 命令unexpand将空格转换为tab,是expand的反转命令 cut 展开文件指定区域的命令.命令类似于在awk结构中的print $N,但相比较之下,限制更多.在脚本中使用cut命令会比使用awk更简单.cut重要的选项-f和-d  # 使用cut来获取挂载文件系统列表 cut -d ' ' -f1,2 /etc/mtab # 使用cut列出OS和内核版本 uname -a | cut -d\" \" -f1,3,11,12 # 使用cut来解析email信息头部 bash$ grep '^Subject:' read-messages | cut -c10-80 Re: Linux suitable for mission-critical apps? MAKE MILLIONS WORKING AT HOME!!! Spam complaint Re: Spam complaint --\u003e 甚至可以指定换行符作为分隔符  bash$ cut -d' ' -f3,7,19 testfile This is line 3 of testfile. This is line 7 of testfile. This is line 19 of testfile. --\u003e cut -d ' ' -f2,3 filename的结果等效于awk -F'[ ]' '{ print $2, $3 }' filename paste 用于将多个文件合成为一个文件,将合成的结果输出到标准输出 join 这是一个特殊形式的paste命令;这个强大的程序允许按照一定的关联关系来合并两个文件内容,这实际上已经是一个简化版的关系数据库形式了 --\u003e join命令只对两个文件进行操作，但只粘贴那些带有公共标记字段（通常是数字标签）的行，并将结果写入stdout --\u003e 要加入的文件应根据标记字段进行排序，以使匹配正常工作  File: 1.data 100200300Shoes Laces Socks File: 2.data 100200300$40.00 $1.00 $2.00 bash$ join 1.data 2.data File: 1.data 2.data 100 Shoes $40.00 200 Laces $1.00 300 Socks $2.00 # 标识字段只出现一次 head 打印一个文件的启示内容到标准输出,默认行数是10,但允许设置不同数字 --\u003e head有多个不同的参数可以使用,如-c(字符数),-n(行数) tail 打印一个文件的尾部到标准输出,默认行数是10,但该数字可以通过接-n选项更改;通常用来追踪一个文件内容的变化 --\u003e tail -f等效于tailf,动态实时的显示文件内容 --\u003e 显示某个文件的指定行内容,其中一种方式: head -n 8 database.txt | tail -n 1 l --\u003e 使用新的 tail -n $LINES filename 代替旧有形式tail -$LINES filename grep 一个多功能的搜索工具,可以使用正则表达式;命令形式grep pattern [file...] --\u003e -i选项,忽略大小写 --\u003e -w选项,仅匹配整个单词 --\u003e -l选项,仅显示匹配相关内容的文件名 --\u003e -r选项,递归搜索 --\u003e -n选项,显示匹配到的内容所在行,并将行数显示在匹配内容的前面 --\u003e -v选项,不显示匹配到的内容 --\u003e -c选项,显示匹配到的次数 --\u003e --color选项,将匹配到的内容上色显示 --\u003e -o选项,仅打印匹配到的内容,不显示一整行 --\u003e -q选项,不打印任何内容,在判断结构中使用很方便 --\u003e 当仅搜索一个文件时,在输出结果中要将文件名一同打印,可以后接/dev/null作为第二个文件名  bash$ grep Linux osinfo.txt /dev/null --\u003e grep匹配到相关内容后,返回值为0,这样可以结合判断结构来使用 --\u003e 使用sed命令可以仿真grep的行为: sed -n /\"$1\"/p $file --\u003e 怎样让grep匹配两个不同的匹配模式,可以使用方式grep pattern1 | grep pattern2来实现 --\u003e egrep等效于grep -E,允许使用扩展正则表达式来进行匹配,形式更加灵活 --\u003e fgrep等效于grep -F,逐字匹配(不使用正则表达式),速度会更快一些 --\u003e agrep(近似匹配/模糊匹配),扩展grep的能力,使其能够进行模糊匹配 --\u003e 匹配压缩文件内容时,使用zgrep/zegrep/zfgrep,这些命令同样能用在普通文件,虽然速度慢一些,但对于包含多种文件类型(普通文件/压缩文件)的场景下操作则更方便 --\u003e 匹配bzip文件时使用bzgrep命令 look look命令工作形式类似于grep,但是是基于字典(一个已排序的单词列表)进行查询;默认情况下,look在/usr/dict/words下进行匹配,但可以指定进行匹配的字典  file=words.database # Data file from which to read words to test. while [ \"$word\" != end ]; do # Last word in data file. read word look $word \u003e /dev/null lookup=$? if [ \"$lookup\" -eq 0 ]; then echo \"\\\"$word\\\" is valid.\" else echo \"\\\"$word\\\" is invalid.\" fi done \u003c\"$file\" sed/awk 脚本语言,非常适合用来处理文本文件和标准输出的内容 sed 非交互式的流编辑器,在batch(不需要用户介入的情况下运行一组命令)模式下允许使用很多ex命令,在脚本中使用很广泛 awk 可编程式文件内容提取及格式化程序,适合用来操作或展开格式化的文本文件的列,语法格式类似于C语言 wc 计数程序 --\u003e -w:单词数;-l:行数;-c:字节数;-m:字符数;-L:给出最长行的长度 tr 字符转化过滤器 --\u003e 视情况决定是否需要使用引用或者括号,引号引用可以防止shell将属于tr的特殊字符先行处理了,括号必须被引起来,防止直接被展开  tr \"A-Z\" \"*\" \u003cfilename tr A-Z \\* \u003cfilename --\u003e 接上-d选项,用于删除一系列的指定字符 --\u003e --squeeze-repeats(-s)选项用来删除连续的字符(保留第一个),这个选项用来移除多余的空白字符很有用 --\u003e -c(补足)选项将未匹配的内容用指定的字符替代  bash$ echo \"acfdeb123\" | tr -c b-d + +c+d+b++++ bash$ echo \"abcd2ef1\" | tr '[:alpha:]' - ----2--1 fold 将输入的行折叠成指定宽度的过滤器 --\u003e 使用-s选项用来以空格作为隔断符,防止直接截断字符  b=`ls /usr/local/bin` $ echo $b | fold - -s -w 40 cnpm compile cops-cli gitbook pacvim ptyping qr-filetransfer runenpass sle study s-tui t termtosvg tget tiv # 等效于echo $b | fmt -w $WIDTH fmt 简单的格式化工具,用于将长行分割为多行 column 列格式化工具,将列类型的文本输出转换成格式友好的打印形式,在合适的位置插入tab --\u003e 对于文件中存在多列内容,但未对齐的格式,使用column -t处理会很方便 colrm 列删除处理器,该命令删除文件中的列内容并直接写该文件 --\u003e colrm 2 4 \u003cfilename 删除文件中的第二到第四列内容 --\u003e 上列命令使用时,若文件中包含有tab之类的不可打印字符,则可能导致无法预估的结果,考虑使用expand/unexpand命令处理之后再管道传输给colrm nl 打印文件内容并附上行号 --\u003e 打印的是非空行内容 --\u003e nl的操作非常类似于cat -b,同样是不打印非空行 cpio 这个特定的归档复制命令已经很少用了,基本已经被tar/gzip取代;但在某些场景下,还是能够使用 --\u003e 指定块大小进行复制,速度会比tar更快 find \"$source\" -depth | cpio -admvp \"$destination\" rpm2cpio 这个命令从rpm包中解压一个cpio文件出来 gzip 结合-c选项使用时,将gzip的输出写入到标准输出,结合管道使用非常有用 zcat/bzcat 可以用来查看gzip/bzip文件中的内容,相当与bzip/gzip文件下的cat readlink 获取符号链接指向的文件 strings 用来获取二进制文件或其他数据文件中的可打印字符 diff 逐行打印两个对比文件的不同内容 --\u003e 使用--side-by-side选项,每个文件内容显示一列,相较原来的形式更方便对比查看 --\u003e 使用-c和-u选项可以让输出结果更适合查看 --\u003e 可以在判断结构中使用diff命令,当比较的两个文件同一的时候,命令返回值为0,当比较的两个文件不一样时,返回值非零 patch 一个非常灵活的版本记录命令,结合diff使用比较常见,可以给出一个由diff命令创建的差异文件 diff3 diff命令的升级版命令,可以一次比较三个文件,正常执行后命令返回值为0,但改命令不会打印文件差异内容出来 split/csplit 用于将一个文件切片为小块的工具,使用场景一般为文件太大,需要切片后邮件发送或者拷贝到移动磁盘 csplit命令通过文件内容来进行分片 sum,cksum,md5sum,sha1sum 以上命令是用于创建校验和的工具,校验和是通过对一个文件内容进行数学计算得出的字符串,用于检查文件的完整性 openssl 可以用于加密使用,结合tar一同使用,可以方便的加密相关目录和文件 shred 用随机字符多次重写文件,可用在安全要求高的场景下 mktemp 创建一个拥有唯一名称的临时文件,不使用其他参数是,在/tmp目录下创建一个大小为0的文件 --\u003e tempfile=`mktemp $PREFIX.XXXXXX` 指定创建的新文件包含有多少个随机字符 ptx ptx[targetfile]命令输出目标文件的排列索引（交叉引用列表）。如有必要，可以在管道中进一步过滤和格式化。 ipcalc 用于换算和查看ip相关的内容 traceroute 通过发送的包追踪路由 sx,rx 命令集通过xmodem协议与远端服务器传输文件 sz,rz 命令集通过zmodem协议与远端服务器传输文件,zmodem的速度相对xmodem更快 ssh --\u003e 在循环中使用ssh时,可能出现不可预期的情况,可以后接-f或者-n选项来避免 tput --\u003e 初始化终端和/或从terminfo数据中获取有关它的信息。各种选项允许某些终端操作：tput clear等于clear；tput reset等于reset。 --\u003e tput可以用来对终端进行操作,更改字符显示方式等 reset 重置终端参数并且清屏 script 记录键盘敲击记录,执行该命令后,会在当前目录下生成一个文件,用于记录后面敲击的键盘记录 factor 后接一个数字,将该数字的各个因数打印出来 bc bash无法进行浮点数计算,且缺少一些重要的运算功能,bc可以满足部分需求 --\u003e bc可以用在脚本中,用来对变量进行计算获值variable=$(echo \"OPTIONS; OPERATIONS\" | bc) --\u003e 另外一种形式是结合here document的方式来作为输入  \u003c\u003c EOF 18.33 * 19.78 EOF ` awk 另外一种进行浮点数运算的方式是使用awk命令  AWKSCRIPT=' { printf( \"%3.7f\\n\", sqrt($1*$1 + $2*$2) ) } ' # command(s) / parameters passed to awk # Now, pipe the parameters to awk. echo -n \"Hypotenuse of $1 and $2 = \" echo $1 $2 | awk \"$AWKSCRIPT\" jot,seq 生成一个整数序列,用户可以自定义步长和分隔符 --\u003e seq -s : 5 指定分隔符为:,默认情况下是换行符 --\u003e jot和seq都可以用在for循环中 run-parts run-parts命令会执行目标目录下的所有脚本,默认依照ascii字母顺序执行,当然,脚本需要有执行权限 yes yes默认的动作为返回y及换行符到标准输出,需要使用ctrl+C来终止 --\u003e 使用yes string,则后面会不断重复出现string --\u003e 使用场景: yes | rm -r dirname tee 类似与重定向,但与重定向不同 (redirection) |----\u003e to file | ==========================|==================== command ---\u003e command ---\u003e |tee ---\u003e command ---\u003e ---\u003e output of pipe =============================================== mkfifo 命令创建一个命名管道,一个临时的first-in-first-out用于在不同的进程之间传递数据,一般情况下,一个进程向FIFO中写数据,另一个进程则从FIFO中读取数据  (cut -d' ' -f1 | tr \"a-z\" \"A-Z\") \u003epipe2 \u003cpipe1 \u0026 ls -l | tr -s ' ' | cut -d' ' -f3,9- | tee pipe1 | cut -d' ' -f2 | paste - pipe2 rm -f pipe1 rm -f pipe2 #14. 其他命令 groups 显示当前用户属于哪些组 lid 命令将显示给出的用户名所属的groups列表 logname 显示登录当前终端登录系统的用户名称,即使su之后,改命令仍显示为源用户 ac 显示用户登录的时长 newgrp 更改当前用户的组id而不需要登出系统 tty 显示当前终端所在的文件名称 stty 显示或者是更改终端的设置,改命令较复杂,在脚本中使用时,可以控制终端的行为以及其输出内容的形式 setterm 设置指定的终端属性,这条命令会更改输出到标准输出结果的显示情况 getty/agetty 使用getty/agetty来初始化终端进程,这些命令不能在脚本中使用,脚本中可使用的是stty lastcomm 显示上一条执行命令的一些相关信息,内容是存储在/var/accounut/pacct文件中的 strace(system trace) 用于诊断和debug系统调用的工具,该命令和ltrace可用来查找一个程序运行失败的原因 itrace(library trace) 用于诊断和debug库调用的工具 nc(netcat) nc工具集是一个用来连接和监听TCP/UDP端口的工具 dmesg 打印所有的系统启动日志信息到标准输出 size size /path/to/binary 会给出一个二进制文件的各个段大小,对于程序员来说,需要使用 logger 追加用户自定义的内容到/var/log/messages中去,普通用户也可以使用 --\u003e 该命令可以用来在脚本中增加debug信息到日志中 logrotate 该工具用于管理系统的日志文件,轮转,压缩,删除或者email发送等,一般是结合cron一起使用来实现日志管理的 fuser 获取当前正在访问给定文件,文件集,或者目录的进程(通过进程号显示) --\u003e 同-k选项一同使用时,杀掉这些进程,在插拔可移动设备的场景下使用较多 --\u003e 同-n选项一同使用时,获取到当前在访问指定端口的进程,与nmap一同搭配使用非常有用  # nmap localhost PORT STATE SERVICE 25/tcp open smtp # fuser -un tcp 25 25/tcp: 2095(root) nmap network mapper and port scanner,网络映射和端口扫描,查看指定主机开放的端口 sync 执行命令后,强制当前环境下,将buffer中的数据写入到磁盘中 losetup 创建或者配置loop设备 mkswap 创建一个swap分区或者文件,swap区域启动需要使用swapon命令 swapon/swapoff 启用/关闭swap设备 dumpe2fs 打印显示详细的文件系统相关信息,必须由root用户调用 hdparm 显示/更改磁盘参数,必须由root用户使用,错误使用很危险 badblocks 检查一个存储设备的坏块,在一个刚格式化后的设备或者备份文件时使用 lsusb,usbmodules 显示所有的usb设备信息 lspci 列出当前使用到的pci总线 chroot 顾名思义,更改当前的根目录位置 lockfile 属于procmail包的一部分,他创建一个lock 文件,用于作为一个标记文件存在,控制文件,设备或者资源的可获取性 flock 命令给文件设置一个锁信息的公告,当命令执行完成之后,其他命令或者进程才能操作刚才的文件  flock $0 cat $0 \u003e lockfile__$0 # Set a lock on the script the above line appears in, #+ while listing the script to stdout. --\u003e 与lockfile命令不同的是,flock命令不会自动创建一个lock文件 mknod 创建一个块设备或者字符设备(当在系统上新增了一个新的设备之后可能有必要这样做),MAKEDEV工具比mknod更容易使用,且具备相应的功能 MAKEDEV 用于创建设备文件的命令,必须由root用户来执行,文件保存在/dev下,是高级版的mknod tmpwatch 自动删除有一段时间没有被访问过的文件,通常结合cron一同使用,用于删除log文件 dump/restore dump命令是设计用于备份文件系统的命令,命令读取磁盘分区的裸数据并写一个二进制文件 ulimit 设置一个更高的系统使用极值 quota 显示用户或者组的磁盘配额信息 setquota 设置用户或者组的磁盘配额 depmod 生成模块依赖文件,通常会被启动脚本调用 ldd 显示一个可执行文件需要使用到的共享库依赖 watch 以特定间隔运行一个命令  特殊内容 #1. here document \u003c\u003c 可以结合vi一同使用,如下所示:  # Insert 2 lines in file, then save. #--------Begin here document-----------# vi $TARGETFILE \u003c\u003cx23LimitStringx23 i This is line 1 of the example file. This is line 2 of the example file. ^[ ZZ x23LimitStringx23 #----------End here document-----------# 可以使用vi +n的形式指定文件打开后在第几行  ","description":"通过advanced-bash-scripting学习bash的笔记内容","tags":["bash","linux","基础知识"],"title":"learning bash via abs","uri":"/tech/basics/bash%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"learning ansible 本文内容参考自朱双印ansible笔记\n配置主机清单 主机清单配置有两种方式\n# ini方式 1 2 3 4 5 6 7 8 9 10 11  # 1,如下示例: [ctl] 10.168.0.2 10.168.0.3 10.168.0.4 [nova:children] ctl [nova-compute:children] nova   # yaml方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 1,如下示例:all:children:k8s:hosts:master:ansible_host:192.168.110.11ansible_port:22ansible_user:rootansible_pass:'123.com'node2:ansible_host:192.168.110.22ansible_port:22ansible_user:rootansible_pass:'123.com'node3:ansible_host:192.168.110.33ansible_port:22ansible_user:rootansible_pass:'123.com'  常用模块 # 文件类操作 1,copy: 将ansible主机上的文件拷贝至远端主机\n 同fetch类似,不过操作动作相反,fetch是从远端主机拿文件到ansible主机 可使用content直接代替src 可备份远端重名文件 可设定拷贝文件的权限  2,file: 完成一些对文件的基本操作,包括创建,删除,修改文件和目录的权限等\n path是必须项,需要和state结合使用 state参数是核心,对不同类型的文件对应的动作不相同,path如果是文件(touch),是目录(directory); absent时不用管path是什么(目录或者文件)  3,blockinfile: 在文件中插入一段文本,这段文本是被标记过的,方便我们后面对标记内容的操作(删除,修改等)\n 对文件中块的操作,文件位置定位使用insertbefore,insertafter 使用block/content制定块内容 使用该模块marker会在插入内容前后增加marker内容 可使用regex,匹配文件中内容进行操作 包含backup相关内容  4,lineinfile: 确保某一行文本存在于文件中,或不存在与文本中,可使用regex进行替换\n line指定行内容 包含regex参数,使用regex来匹配相应的行,当替换文本时，如果有多行文本都能被匹配，则只有最后面被匹配到的那行文本才会被替换，当删除文本时，如果有多行文本都能被匹配，这么这些行都会被删除 backrefs参数：默认情况下，当根据正则替换文本时，即使regexp参数中的正则存在分组，在line参数中也不能对正则中的分组进行引用，除非将backrefs参数的值设置为yes 插入内容为insertbefore,insertafter, 包含backup相关内容  5,find: 类似find命令,可在远端机器中找到相应文件\n 使用方式ansible-doc -s find查看  6,replace: replace模块可以根据我们指定的正则表达式替换文件中的字符串，文件中所有被正则匹配到的字符串都会被替换\n 使用方式ansible-doc -s replace查看  # 命令类操作 1,command: 在远端主机上执行命令\n 使用command模块在远程主机中执行命令时，不会经过远程主机的shell处理，在使用command模块时，如果需要执行的命令中含有重定向、管道符等操作时，这些符号也会失效，比如”\u003c“, “\u003e”, “|”, “;” 和 “\u0026” 这些符号，如果你需要这些功能，需要使用shell模块 具体使用方式,参考ansible-doc -s command  2,shell: 在远端主机上执行命令,与command不同的是,shell模块在远端执行命令时,会经过远端主机的/bin/sh程序处理\n 具体使用方式,参考ansible-doc -s shell  3,scripts: 在远端主机上执行ansible主机上的脚本,脚本在ansible主机上,不需要拷贝到远端主机\n 具体使用方式,参考ansible-doc -s scripts  # 系统类操作 1,cron: 管理远端主机上的定时任务,功能同crontab\n 具体使用方式,参考ansible-doc -s cron  2,service: 管理远端主机上的服务\n 具体使用方式,参考ansible-doc -s service  3,user: 管理远端主机上的用户,类似命令usermod\n 还可以管理用户的ssh密钥 具体使用方式,参考ansible-doc -s user  4,groupo: 管理远端主机上的组,类似命令groupmod\n 具体使用方式,参考ansible-doc -s group  # 包管理类操作 1,yum_repository: 管理远端主机上的yum仓库\n 具体使用方式,参考ansible-doc -s yum_repository  1,yum: 通过远端主机上的yum管理软件包\n 具体使用方式,参考ansible-doc -s yum  认识ansible-playbook 1,ansible-playbook的使用,可以理解为ansible -m \u003cmodule_name\u003e -a 'xxxx'的转换,将命令行使用模块操作的内容写成脚本内容,按照脚本内容完成相关操作\n2,上述脚本在ansible-playbook中称作为'playbook',即剧本\n 每个playbook(剧本)又多个play(桥段)组成,每个剧本是由多个桥段组成的,每个桥段包含有人物,场景,故事 每个play在执行时,都会执行一个默认任务('Gathering Facts),任务会收集当前当前play对应的目标主机的相关信息(IP,hostname,硬件版本,系统版本等),收集完成后才会完成我们定义的相关任务  3,ansible有个重要特性:幂等性\n 在ansible调用模块或者ansible-playbook执行相应play时,输出内容会有颜色区分,黄色表示有修改,绿色表示么有修改;区别是远端的内容是否满足我们的预期 ansible是”以结果为导向的”，我们指定了一个”目标状态”，ansible会自动判断，”当前状态”是否与”目标状态”一致，如果一致，则不进行任何操作，如果不一致，那么就将”当前状态”变成”目标状态”，这就是”幂等性”，”幂等性”可以保证我们重复的执行同一项操作时，得到的结果是一样的  使用handlers 1,handlers的使用场景:\n 有个任务需要修改nginx的配置文件,将listen端口由8080改为8088,使用handler可以在nginx配置文件有修改的环境上重启nginx,没有修改的不会出发重启nginx handlers可以理解为另一种tasks,handlers是另一种'任务列表',handlers中的任务会被tasks中的任务调用; handlers被调用并不一定会执行,只有当tasks中的任务真正被执行后(真正的进行了实际操作,造成了实际变化),handlers中的任务才会真正执行 如果tasks中的任务并没有作出任何实际的操作,那么handlers中的任务即使被调用,也不会执行 handlers和tasks是平级的,所以缩进相同  2,handlers的调用:\n handlers需要被关键字notify调用 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:allremote_user:roottasks:- name:change nginx configurationlineinfile:path=/etc/nginx/conf.d/test.confregexp=\"listen(.*) 8080(.*)\"line=\"listen\\1 8088\\2\"backrefs=yesbackup=yesnotify:restart nginxhandlers:- name:restart nginxservice:name=nginxstate=restarted   3,handlers中可以有多个任务,被tasks中不同的任务调用\n handler执行的顺序与handler在playbook中定义的顺序相同,与handler被notify的顺序无关(下述内容ht1先触发,ht2后触发),如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ---- hosts:allremote_user:roottasks:- name:make testfile1file:path=/testdir/testfile1state=directorynotify:ht2- name:make testfile2file:path=/testdir/testfile2state=directorynotify:ht1handlers:- name:ht1file:path=/testdir/ht1state=touch- name:ht2file:path=/testdir/ht2state=touch   默认情况下,所有tasks执行完成后,才会执行各个handlers 当存在多个同名的handler时,只会执行一个handler  4,若要在执行完某个task后立即执行其对应的handler,需要使用meta模块\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  ---- hosts:allremote_user:roottasks:- name:task1file:path=/testdir/testfilestate=touchnotify:handler1- name:task2file:path=/testdir/testfile2state=touchnotify:handler2- meta:flush handlers- name:task3file:path=/testdir/testfile3state=touchnotify:handler3handlers:- name:handler1file:path=/testdir/hd1state=touch- name:handler2file:path=/testdir/hd2state=touch- name:handler3file:path=/testdir/hd3state=touch   meta可以理解为tasks下一个特殊任务,使用的是meta模块 meta: flush_handlers指的是立即执行之前的task对应的handlers,上述例子中flush_handlers之前有两个task,在执行了这两个task之后立即执行他们对应的handler 使用meta配合task和handler,可以让任务调用更加灵活  5,如果需要一次性notify多个handler,需要使用到listen\n 可以把'listen'理解为'组名',可以把多个handler分成'组',当我们需要一次性notify多个handler时,只要将多个handler分成一组,使用相同的组名即可 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:allremote_user:roottasks:- name:task1file:path=/testdir/testfilestate=touchnotify:handler group1handlers:- name:handler1listen:'handler group1'shell:'echo handler1'- name:handler2listen:'handler group1'shell:'echo handler2'  使用tags 1,写了一个很长的playbook,在调试时只想跑其中很少的一部分,tag在这种场景下可以使用,指定执行哪些任务,不执行哪些任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:allremote_user:roottasks:- name:test 1file:path=/testdir/testfilestate=touchtags:t1- name:test 2file:path=/testdir/testfile2state=touchtags:t2- name:test 3file:path=/testdir/testfile3state=touchtags:t3$ ansible-playbook --tags=t2 test.yaml$ ansible-playbook --skip-tags=t2 test.yaml   --tags=t2,只执行tag为t2部分的task,--skip-tags=t2,跳过tag=t2的tag tag相关使用命令:  1 2 3 4  # 指定多个tag时,使用命令为 $ ansible-playbook -t tag1,tag2,tag3 test.yaml # 执行play前,查看当前有哪些tag $ ansible-playbook --list-tags test.yaml    ansible预置了几个特殊tag:  # always: 如果任务的tags包含always,则该task一定会被执行,除非指定--skip-tags always(该情况也不合理,可能其他任务也包含always,这样其他task也不会执行) # never: 永远不执行,与always刚好相反 ## 下列只在调用标签时生效 # tagged: ansible-playbook --tags tagged test.yaml --\u003e 只执行有标签的task,没有标签的task不会被执行 # untagged: ansible-playbook --tags untagged test.yaml --\u003e 只执行没有tag的task,有tag的不会被执行 # all: 默认使用,所有都会被执行  可以为task指定多个tag,如下:  1 2 3 4 5 6 7 8  # method onetags:- testing- t1# method twotags:testing, t1# method threetags:['testing','t1']  2,play也可以指定tags,当一个play之指定了tags,这个play下的所有task都包含该tag,若该play下的task还有自己的tags,则该task的实际tags为'play tags' + 'task tags'\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:test70remote_user:roottags:httpdtasks:- name:install httpd packagetags:['package']yum:name=httpdstate=latest- name:start up httpd servicetags:- serviceservice:name:httpdstate:started  使用变量(一) 1,怎么定义变量\n 变量由数字,字母,下划线组成,要以字母开头 ansible的关键字不能作为变量名  2,变量的定义及引用\n 变量定义可以使用vars,和tasks同级,如下(普通定义方式):  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ---- hosts:allremote_user:rootvars:testvar1:testfiletestvar2:testfile2# 或者使用yaml写法vars:- testvar1:testfile- testvar2:testfile2tasks:- name:task1file:path:/testdir/{{testvar1}}state:touch   使用属性的方式定义  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  - hosts:allremote_user:rootvars:nginx:conf80:/etc/nginx/conf.d/80.confconf8080:/etc/nginx/conf.d/8080.conftasks:- name:task1file:path:\"{{nginx.conf80}}\"# 或者path: \"{{nginx['conf80']}}\"state:touch- name:task2file:path:\"{{nginx.conf8080}}\"# 或者path: \"{{nginx['conf8080']}}\"state:touch# 使用=给模块参数赋值时,可以不考虑变量是否加引号# - name: task2# file:# path={{nginx.conf8080}}# # 或者path={{nginx['conf8080']}}# state=touch   注意: 上面列举的两个例子有些差别,第一个例子中变量没有加引号,第二个有加引号,因为第一个变量不是'开头'位置,第二个是'开头'位置 但实际上也有例外,给模块参数赋值时,可以选择':',也可以选择'=',当使用'='时,可以不用考虑引号的问题\n 3,在文件中定义变量给playbook使用\n 将变量在单独的文件中定义的好处是,可以做到变量文件分离,不给看到变量的值 在文件中定义变量时,不用使用vars关键字,直接定义变量即可,如下集中语法:  1 2 3 4 5 6 7 8 9 10  # method onetestvar1:testfiletestvar2:testfile2# method two- testvar1:testfile- testvar2:testfile2# method threenginx:conf80:/etc/nginx/conf.d/80.confconf8080:/etc/nginx/conf.d/8080.conf   在文件中定义完变量,在playbook中使用变量,需要使用vars_files,被导入的文件以'-'开头(可以引入多个变量文件),以yaml中块序列的方式导入  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:allremote_user:rootvars_files:- /testdir/ansible/nginx_vars.ymltasks:- name:task1file:path:\"{{nginx.conf80}}\"state:touch- name:task2file:path:\"{{nginx['conf8080']}}\"state:touch  使用变量(二) 1,在playbook执行前,有一个Gathering Facts的动作,调用的是setup模块; 这些信息会保存在对应的变量中，我们在playbook中可以使用这些变量,我们可以称这些信息为facts信息\n setupa模块的返回值是json格式的,方便返回时内容展示 setup模块可以获取远端主机很详尽的信息,若需要过滤相关信息,可以使用setup的filter参数(支持通配符)  1 2 3 4  # 显示内存相关信息 ansible all -m setup -a 'filter=ansible_memory_mb' # 不确定信息相关信息,使用通配符来获取 ansible all -m setup -a 'filter=*mb*'    setup模块获取的信息都保存在相应的变量中,我们可以通过引用变量获取到这些值  2,setup模块支持获取自定义内容\n 要求:自定义内容存在于目标主机的/etc/ansible/facts.d/下以.fact结尾的文件; 这些文件需要以json或者ini格式保存变量信息  1 2 3 4  $ cat /etc/ansible/facts.d/test.fact [testmsg] msg1='test message 1' msg2='test message 2'    这些自定义的变量称为'local facts',可以在setup获取时通过filter=ansible_local获取  3,另一个模块debug,可用于playbook的调试使用,把调试信息打印到控制台上,方便我们查看和定位问题\n debug模块常用的两个参数分别是var和msg,var用于测试变量,msg用于打印输出是否符合预期  # 连接到主机,但是并没有做任何事情,debug引用的是testvar,测试testvar是否能用 ---yaml - hosts: all remote_user: root vars: testvar: value of testvar tasks: - name: test debug debug: var: testvar 使用变量(三) 1,变量注册\n ansible模块在执行之后都会有一些返回值,默认情况下,这些返回值不会显示而已;我们可以把这些返回值写入到某个变量中,我们可以通过引用相应的变量获取到这些返回值,将模块的返回值写入到变量中,这种方式称为'注册变量'; 如下为变量注册的的一个范例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:allremote_user:roottasks:- name:test registershell:\"echo test \u003e /tmp/testfile\"register:testvar- name:shell module return valuesdebug:var:testvar# 执行完成后,在控制台中看到名为”[shell module return values]”的任务中已经显示了第一个任务的返回值的信息，返回信息:TASK [shell module return values] ************************************ok:[master] =\u003e { \"testvar\": {\"changed\": true,\"cmd\": \"echo test \u003e /tmp/testfile\",\"delta\": \"0:00:00.010963\",\"end\": \"2021-03-30 09:26:47.432571\",\"failed\": false,\"rc\": 0,\"start\": \"2021-03-30 09:26:47.421608\",\"stderr\": \"\",\"stderr_lines\": [],\"stdout\": \"\",\"stdout_lines\": []}}# register的变量testvar其实是一个json格式的返回值,可以通过引用testvar的不同属性获取相应的值  2,变量的传入方式,ansible支持多种变量传入的方式,包括:交互式传入,命令行传入,文件传入\n 交互式传入,需要使用到var_prompt关键字,属于vars的一种,当出现该关键字时,会让你在命令行下输入  普通使用,以下输入内容不会在控制台显示(默认情况下private: yes)    1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:allremote_user:rootvars_prompt:- name:'your_name'prompt:\"What is your name?\"# private: no- name:'your_age'prompt:\"What is your age?\"# private: notasks:- name:output varsdebug:msg:your name is {{your_name}}, your age is {{your_age}}  - 普通使用,可以做到提供选项供选择 - 特殊使用,例如增加用户,设定密码  1 2 3 4 5 6 7 8 9 10 11 12 13  # 需要使用到vars_prompt下encrypt,指定加密方式,而且该方式需要passlib库,么有的话需要安装---- hosts:test70remote_user:rootvars_prompt:- name:\"hash_string\"prompt:\"Enter something\"private:noencrypt:\"sha512_crypt\"tasks:- name:Output the string after hashdebug:msg:\"{{hash_string}}\"   命令行传入,直接在ansible-playbook执行时增加-e 'key=value'即可,可有多个,变量赋值有多种方式,还可以是json格式 文件传入,类似命令行-e \"@变量文件绝对路径\"  使用变量(四),register,set_fact 1,配置主机清单时,可以配置主机或主机组变量,但只对配置的主机或主机组生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  ## 主机配置,配置/etc/ansible/hosts如下# method onenode2 ansible_host=192.168.110.22 testhostvar=node2_host_var# method twoall:hosts:node2:ansible_host:192.168.110.22ansible_port:22testhostvar:node2_host_vartesthostvar2:node2_host_var2testhostvar3:thv31:3.1thv32:3.2$ ansible node2 -m shell -a 'echo {{testhostvar}}$ ansible node2 -m shell -a 'echo {{testhostvar3.thv31}}' or '{{testhostvar3['thv32']}}'## 主机组配置,配置/etc/ansible/hosts如下# method one[testB]node2 ansible_host=192.168.110.22node3 anisble_host=192.168.110.33[testB:vars]test_group_var1='group var test'test_group_var2='group var test2'# method twoall:children:testB:hosts:node2:ansible_host:192.168.110.22ansible_port:22node3:ansible_host:192.168.110.33ansible_port:22vars:test_group_var1:'group var test1'test_group_var2:'group var test2'$ ansible testB -m shell -a 'echo {{test_group_var1}}'  2,通过set_fact定义变量,set_fact是一个模块,可以通过set_fact模块在task中定义变量\n 普通使用,直接与task同级定义一个变量  1 2 3 4 5 6 7 8  ---- hosts:node2remote_user:roottasks:- set_fact:testvar:\"testtest\"- debug:msg:\"{{testvar}}\"   普通使用,将一个变量的值赋给另一个变量  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:node2remote_user:rootvars:testvar1:test1_stringtasks:- shell:\"echo test2_string\"register:shellreturn- set_fact:testsf1:\"{{testvar1}}\"testsf2:\"{{shellreturn.stdout}}\"- debug:msg:\"{{testsf1}} {{testsf2}}\"   通过set_fact模块创建的变量还有一个特殊性，通过set_fact创建的变量就像主机上的facts信息一样，可以在之后的play中被引用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:node2remote_user:rootvars:testvar1:tv1tasks:- set_fact:testvar2:tv2- debug:msg:\"{{testvar1}} ----- {{testvar2}}\"- hosts:node2remote_user:roottasks:- name:other play get testvar2debug:msg:\"{{testvar2}}\"- name:other play get testvar1debug:msg:\"{{testvar1}}\"# 这两个变量在第一个play中都可以正常的输出.但是在第二个play中，testvar2可以被正常输出了，testvar1却不能被正常输出，会出现未定义testvar1的错误   如果想要在tasks中给变量自定义信息，并且在之后的play操作同一个主机时能够使用到之前在tasks中定义的变量时，则可以使用set_facts定义对应的变量  使用变量(五),内置变量,host_vars 1,ansible有一些内置变量可供使用,这些变量被ansible保留,我们定义变量时不能使用\n ansible_version  1  $ ansible node2 -m debug -a 'msg={{ansible_version}}'   2,hostvars可以在我们操作当前主机时获取到其他主机中的信息\n 如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---# 第一个什么也没做,只是获取node3的facts内容,这一步是需要的,只有收集过的facts才能被后面的play使用# 如果没有收到对应主机的facts信息,即使使用hostvars内置变量,也无法获取到对应主机的facts内容- name:\"play 1: gather facts of node3\"hosts:node3remote_user:root# 下面的gather_facts默认是yes# gater_facts: yes- name:\"play 2: gathter facts of node3 when operating on node2\"hosts:node2remote_user:roottasks:- debug:msg:\"{{hostvars['node3'].ansible_enp0s3.ipv4}}\"# 下面两种也可以#msg: \"{{hostvars.node3.ansible_enp0s3.ipv4}}\"#msg: \"{{hostvars['node3']['ansible_enp0s3']['ipv4']}}\"   hostvars除了获取到其他主机的facts内容,还可以获取到其他类型的一些变量信息,如其他主机的注册变量,主机变量,组变量等;如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---# 1,通过hostvars内置变量可以直接获取到其他主机中的注册变量# 2,注册变量并不用像facts信息那样需要事先收集，即可直接通过hostvars跨主机被引用到# 3,如果你在清单中为node3主机配置了主机变量，或者为node3主机所在的组配置了组变量，也是可以通过hostvars直接跨主机引用- hosts:node3remote_user:rootgather_facts:notasks:- shell:\"echo register_var_in_play1\"register:shellreturn- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.shellreturn.stdout}}\"   通过vars关键字定义的变量使用上例中的hostvars方法是无法被跨主机引用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  # 下列内容会报错,变量需要注册才行,直接使用vars定义的变量无法传递---- hosts:node3remote_user:rootgather_facts:novars:testvar:testvar_in_3tasks:- debug:msg:\"{{testvar}}\"- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.testvar}}\"# 通过set_fact将vars定义的内容注册,则可以---- hosts:node3remote_user:rootgather_facts:notasks:- set_fact:testvar:testvar_in_3- debug:msg:\"{{testvar}}\"- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{hostvars.node3.testvar}}\"   通过”set_fact”结合”hostvars”的方式，可以实现跨play获取其他主机中的变量信息  3,内置变量inventory_hostname,获取到被操作的当前主机的主机名称\n 主机名称并不是linux系统的主机名，而是对应主机在清单中配置的名称,清单中配置的名称即是  4,内置变量inventory_hostname_short,获取到被操作的当前主机的主机名称,简版\n 无论是IP还是别名，如果清单的主机名称中包含”.”，inventory_hostname_short都会取得主机名中第一个”.”之前的字符作为主机的简短名称  5,内置变量play_hosts,获取到当前play所操作的所有主机的主机名列表\n 如下示例  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ---- hosts:node2,node3remote_user:rootgather_facts:notasks:- debug:msg:\"{{play_hosts}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": [\"node2\",\"node3\"]}ok:[node3] =\u003e {\"msg\": [\"node2\",\"node3\"]}  6,内置变量groups,可以获取到清单中”所有分组”的”分组信息”\n 同inventory_hostname,但能获取到分组的信息  1 2  $ ansible all -m debug -a 'msg={{groups}}' $ ansible all -m debug -a 'msg={{groups.k8s}}'   7,内置变量group_names,获取到当前主机所在分组的组名\n 如下示例:  1 2 3 4 5 6 7  # ansible node2 -m debug -a \"msg={{group_names}}\" node2 | SUCCESS =\u003e { \"changed\": false, \"msg\": [ \"k8s\" ] }   8,内置变量inventory_dir,获取到ansible主机中清单文件的存放路径,默认是/etc/ansible,但也可以自定义\n 如下示例:  1 2 3 4 5  # ansible node2 -m debug -a \"msg={{inventory_dir}}\" node2 | SUCCESS =\u003e { \"changed\": false, \"msg\": \"/etc/ansible\" }   9,除了直接在hosts文件中定义主机变量和组变量，还有另外一种方法也可以定义主机变量和组变量，我们可以在清单文件的同级目录中创建两个目录，这两个目录的名字分别为”group_vars”和”host_vars”，我们可以将组变量文件放在”group_vars”目录中，将主机变量文件放在”host_vars”目录中，这样ansible就能获取到对应组变量和主机变量\n使用循环(一),with_items的使用 1,使用with_items处理循环的内容\n 普通示例:  1 2 3 4 5 6 7 8 9 10 11  # \"with_items\"关键字会把返回的列表信息自动处理，将每一条信息单独放在一个名为\"item\"的变量中，只要获取到名为\"item\"变量的变量值，即可循环的获取到列表中的每一条信息# 下列debug被循环3次,每次单独输出相应循环的debug输出内容---- hosts:node2remote_user:rootgather_facts:notasks:- name:test with_itemsdebug:msg:\"{{item}}\"with_items:\"{{groups.k8s}}\"  2,with_items可以自定义\n 列表  1 2 3 4 5 6 7  # method onewith_items:- 1- 2- 3# method twowith_items:[1,2,3]   相对复杂的列表  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item.test1}}\"with_items:- {test1: a, test2:b}- {test1: c, test2:d}  3,result的使用\n 当使用了循环以后，每次shell模块执行的返回值放入名为”results”的序列中，”results”也是一个返回值，当模块中使用循环时，模块每次执行的返回值都会追加存放到”results”这个返回值中,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # 两次debug循环,输出的内容都保存在results序列中,属于results---- hosts:node2gather_facts:notasks:- shell:\"{{item}}\"with_items:- \"ls /opt\"- \"ls /home\"register:returnvalue- debug:var:returnvalue# 可以使用如下方式,避免所有结果在最后的results中去获取---- hosts:node2gather_facts:notasks:- shell:\"{{item}}\"with_items:- \"ls /opt\"- \"ls /home\"register:returnvalue- debug:msg:\"{{item.stdout}}' with_items: \"{{returnvalue.results}}\"# 先使用循环重复的调用了shell模块，然后将shell模块每次执行后的返回值注册到了变量”returnvalue”中，之后，在使用debug模块时，通过返回值”results”获取到了之前每次执行shell模块的返回值（shell每次执行后的返回值已经被放入到item变量中），最后又通过返回值”stdout”获取到了每次shell模块执行后的标准输出  使用循环(二),对列表循环的操作 1,对序列循环有几个关键字\n with_items: 当循环的序列元素也是列表时,展开与预期的有差异,会将所有的列表展开 with_list: 其他动作与with_items相同,只有在嵌套列表循环时有差异,子列表将会作为元素使用 with_flattened: 与with_items相同 with_together: 列对齐,”对齐合并”功能  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_together:- [1,2,3]- [a, b, c ]# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=[1, u'a']) =\u003e {\"changed\": false,\"item\": [1,\"a\"],\"msg\": [1,\"a\"]}ok:[node2] =\u003e (item=[2, u'b']) =\u003e {\"changed\": false,\"item\": [2,\"b\"],\"msg\": [2,\"b\"]}ok:[node2] =\u003e (item=[3, u'c']) =\u003e {\"changed\": false,\"item\": [3,\"c\"],\"msg\": [3,\"c\"]}  使用循环(三),嵌套循环 1,with_cartesian和with_nested\n 当我们需要两个列表嵌套循环时,可以使用with_cartesian或者with_nested,将每个小列表中的元素按照”笛卡尔的方式”组合后，循环的处理每个组合,如下示例  1 2 3 4 5 6 7 8 9 10 11 12  # 下面的例子会在node2下创建6个目录---- hosts:node2remote_user:rootgather_facts:notasks:- file:state:directorypath:\"/testdir/testdir/{{ item.0 }}/{{ item.1 }}\"with_cartesian:- [a, b, c ]- [test1, test2 ]  使用循环(四),序列索引循环 1,使用到with_indexed_items,在处理列表中的每一项时，按照顺序为每一项添加了编号,如下示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_indexed_items:- test1- test2- test3# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=(0, u'test1')) =\u003e {\"changed\": false,\"item\": [0,\"test1\"],\"msg\": [0,\"test1\"]}ok:[node2] =\u003e (item=(1, u'test2')) =\u003e {\"changed\": false,\"item\": [1,\"test2\"],\"msg\": [1,\"test2\"]}ok:[node2] =\u003e (item=(2, u'test3')) =\u003e {\"changed\": false,\"item\": [2,\"test3\"],\"msg\": [2,\"test3\"]}   ”with_indexed_items”会将嵌套的两层列表”拉平”，”拉平”后按照顺序为每一项编号 当多加了一层嵌套以后，”with_indexed_items”并不能像”with_flattened”一样将嵌套的列表”完全拉平”，第二层列表中的项如果仍然是一个列表，”with_indexed_items”则不会拉平这个列表，而是将其当做一个整体进行编号  使用循环(五),with_sequence,with_random_choice 1,with_sequence\n 使用with_sequence生成序列,with_sequence可以按照顺序生成数字序列,如下示例:  1 2 3 4 5 6 7 8 9 10 11  # debug模块被循环调用了5次，msg的值从1一直输出到了5，值的大小每次增加1---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_sequence:start=1 end=5 stride=1# 下列写法结果一致# with_sequence: count=5   使用with_sequence还可以格式化输出  1 2 3 4 5 6 7 8  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_sequence:start=2 end=6 stride=2 format=\"number is %0.2f\"  2,with_random_choice,使用with_random_choice可以从列表的多个值中随机返回一个值\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_random_choice:- 1- 2- 3- 4- 5  使用循环(六),with_dict,with_subelements,with_file 1,with_dict,循环遍历字典元素,如下示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item}}\"with_dict:\"{{users}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item={'value': {u'gender': u'male', u'name': u'Bob Bananarama', u'telephone': u'987-654-3210'}, 'key': u'bob'}) =\u003e {\"changed\": false,\"item\": {\"key\": \"bob\",\"value\": {\"gender\": \"male\",\"name\": \"Bob Bananarama\",\"telephone\": \"987-654-3210\"}},\"msg\": {\"key\": \"bob\",\"value\": {\"gender\": \"male\",\"name\": \"Bob Bananarama\",\"telephone\": \"987-654-3210\"}}}ok:[node2] =\u003e (item={'value': {u'gender': u'female', u'name': u'Alice Appleworth', u'telephone': u'123-456-7890'}, 'key': u'alice'}) =\u003e {\"changed\": false,\"item\": {\"key\": \"alice\",\"value\": {\"gender\": \"female\",\"name\": \"Alice Appleworth\",\"telephone\": \"123-456-7890\"}},\"msg\": {\"key\": \"alice\",\"value\": {\"gender\": \"female\",\"name\": \"Alice Appleworth\",\"telephone\": \"123-456-7890\"}}}  2,with_subelements:\n with_subelements会将hobby子元素列表中的每一项作为一个整体，将其他子元素作为一个整体，然后组合在一起  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  # 如下示例:---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{ item }}\"with_subelements:- \"{{users}}\"- hobby# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=({u'gender': u'male', u'name': u'bob'}, u'Skateboard')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"male\",\"name\": \"bob\"},\"Skateboard\"],\"msg\": [{\"gender\": \"male\",\"name\": \"bob\"},\"Skateboard\"]}ok:[node2] =\u003e (item=({u'gender': u'male', u'name': u'bob'}, u'VideoGame')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"male\",\"name\": \"bob\"},\"VideoGame\"],\"msg\": [{\"gender\": \"male\",\"name\": \"bob\"},\"VideoGame\"]}ok:[node2] =\u003e (item=({u'gender': u'female', u'name': u'alice'}, u'Music')) =\u003e {\"changed\": false,\"item\": [{\"gender\": \"female\",\"name\": \"alice\"},\"Music\"],\"msg\": [{\"gender\": \"female\",\"name\": \"alice\"},\"Music\"]}   由于item由两个整体组成，所以，我们通过item.0获取到第一个小整体，即gender和name属性，然后通过item.1获取到第二个小整体，即hobby列表中的每一项  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{ item.0.name }} 's hobby is {{ item.1 }}\"with_subelements:- \"{{users}}\"- hobby# msg内容如下:\"msg\": \"bob 's hobby is Skateboard\"\"msg\": \"bob 's hobby is VideoGame\"\"msg\": \"alice 's hobby is Music\"  使用循环(七) with_file, with_fileglob 1, ansible主机中有几个文件,若需要获取到这些文件的内容，可以使用with_file关键字，循环的获取到这些文件的内容\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11  # 无论目标主机是谁，都可以通过with_file关键字获取到ansible主机中的文件内容---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_file:- /testdir/testdir/a.log- /opt/testfile  2,可以通过with_fileglob关键字，在指定的目录中匹配符合模式的文件名，with_file与with_fileglob相同的地方，它们都是针对ansible主机的文件进行操作，而不是目标主机\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"with_fileglob:- /testdir/(此处为星号,删除防止下面格式错乱)# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e (item=/testdir/testfile) =\u003e {\"changed\": false,\"item\": \"/testdir/testfile\",\"msg\": \"/testdir/testfile\"}ok:[node2] =\u003e (item=/testdir/test.sh) =\u003e {\"changed\": false,\"item\": \"/testdir/test.sh\",\"msg\": \"/testdir/test.sh\"}# 需要注意的是，with_fileglob只会匹配指定目录中的文件，而不会匹配指定目录中的目录  条件判断(六),with_dict,with_subelements,with_file 1,绝大多数语言中，都使用if作为条件判断的关键字，而在ansible中，条件判断的关键字是when\n 如下示例:  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:roottasks:- name:test whendebug:msg:\"System is centos\"# 如果需要获取到facts中的key的值，都是通过引用变量的方式获取的，即\"{{ key }}\"# 在when关键字中引用变量时，变量名不需要加\"{{ }}\"when:ansible_distribution == \"CentOS\"  2,使用when关键字为任务指定条件，条件成立，则执行任务，条件不成立，则不执行任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"with_items:- 1- 2- 3when:item \u003e 1  3,在ansible中，使用如下比较运算符.\n 如下所示:  == :比较两个对象是否相等，相等为真 != :比较两个对象是否不等，不等为真 \u003e :比较两个值的大小，如果左边的值大于右边的值，则为真 \u003c :比较两个值的大小，如果左边的值小于右边的值，则为真 \u003e= :比较两个值的大小，如果左边的值大于右边的值或左右相等，则为真 \u003c= :比较两个值的大小，如果左边的值小于右边的值或左右相等，则为真 上述总结的这些运算符其实都是jinja2的运算符，ansible使用jinja2模板引擎，在ansible中也可以直接使用jinja2的这些运算符 上述为比较运算符，再来说说逻辑运算符，可用的逻辑运算符如下: and :逻辑与，当左边与右边同时为真，则返回真 or :逻辑或，当左边与右边有任意一个为真，则返回真 not :取反，对一个操作体取反 ( ) :组合，将一组操作体包装在一起，形成一个较大的操作体  如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # 示例1:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is centos7\"when:# 使用列表,列表中的每一项都是一个条件，列表中的所有条件同时成立时，对应的任务才会执行- ansible_distribution == \"CentOS\"- ansible_distribution_major_version == \"7\"# 示例2:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is centos6 or centos7\"# 比较运算符和逻辑运算符结合使用作为条件判断when:ansible_distribution == \"CentOS\" and(ansible_distribution_major_version == \"6\" or ansible_distribution_major_version == \"7\")# 示例3:---- hosts:node2remote_user:roottasks:- debug:msg:\"System release is not centos\"# 逻辑取反when:not ansible_distribution == \"CentOS\"# 示例4:---- hosts:node2remote_user:roottasks:- name:task1shell:\"ls /testabc\"register:returnmsg- name:task2debug:msg:\"Command execution successful\"# 通过shell指令的返回值判断是否执行when:returnmsg.rc == 0- name:task3debug:msg:\"Command execution failed\"when:returnmsg.rc != 0  3,结合ignore_errors和when来限定playbook的执行\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:node2remote_user:roottasks:- name:task1shell:\"ls /testabc\"register:returnmsg# 此处增加了ignore_errors,在不存在/testabc目录的节点就不会报错,playbook不会退出,task2,task3通过rc值来确定是否要执行ignore_errors:true- name:task2debug:msg:\"Command execution successful\"when:returnmsg.rc == 0- name:task3debug:msg:\"Command execution failed\"when:returnmsg.rc != 0  条件判断与tests 1,在ansible中也有类似bash中test的用法,不过是借助jinja2的tests，借助tests，可以进行一些判断操作，tests会将判断后的布尔值返回，如果条件成立，返回true，否则返回false，通常在条件判断时使用到tests\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:megather_facts:noremote_user:rootvars:testpath:/testdirtasks:- name:test testsdebug:msg:\"test dir exist\"# \"is exists\"中的\"exists\"就是tests的一种，它与\"test -e\"命令的作用是相同的，通过\"exists\"可以判断ansible主机中的对应路径是否存在# \"is not exists\"表示对应路径不存在时返回真# 上述内容都是在ansible主机中判断的,和远端目标主机无关when:testpath is exists  2,判断变量的一些tests\n defined: 判断变量是否已经定义，已经定义则返回真 undefined: 判断变量是否已经定义，未定义则返回真 none: 判断变量值是否为空，如果变量已经定义，但是变量值为空，则返回真 上述内容,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:meremote_user:rootgather_facts:novars:testvar:\"test\"testvar1:tasks:- debug:msg:\"Variable is defined\"when:testvar is defined- debug:msg:\"Variable is undefined\"when:testvar2 is undefined- debug:msg:\"The variable is defined, but there is no value\"when:testvar1 is none  3,判断执行结果的一些tests\n success或者succeeded: 通过任务的返回信息判断任务的返回状态,任务执行成功则返回真 failure或者failed: 通过任务的返回信息判断任务的返回状态,任务执行失败则返回真 change后者changed: 通过任务的返回信息判断任务的返回状态,任务执行状态为changed则返回真 skip或者skipped: 通过任务的返回信息判断任务的返回状态,当任务没有满足执行条件,而被跳过执行时,则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  ---- hosts:meremote_user:liawnegather_facts:novars:doshell:\"yes\"tasks:- name:executeshell:cat /testdir/testwhen:doshell == \"yes\"register:retmsgignore_errors:true- debug:msg:\"task success\"when:retmsg is success- debug:msg:\"task failed\"when:retmsg is failed- debug:msg:\"task skipped\"when:retmsg is skip- debug:msg:\"task changed\"when:retmsg is changed  4,判断路径的一些tests\n 注:如下tests的判断均针对于ansible主机中的路径,与目标主机无关 file : 判断路径是否是一个文件,如果路径是一个文件则返回真 directory :判断路径是否是一个目录,如果路径是一个目录则返回真 link :判断路径是否是一个软链接,如果路径是一个软链接则返回真 mount:判断路径是否是一个挂载点,如果路径是一个挂载点则返回真 exists:判断路径是否存在,如果路径存在则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  ---- hosts:meremote_user:liawnegather_facts:novars:testpath1:\"/testdir/test\"testpath2:\"/testdir/\"testpath3:\"/testdir/testsoftlink\"testpath4:\"/testdir/testhardlink\"testpath5:\"/boot\"tasks:- debug:msg:\"file\"when:testpath1 is file- debug:msg:\"directory\"when:testpath2 is directory- debug:msg:\"link\"when:testpath3 is link- debug:msg:\"link\"when:testpath4 is link- debug:msg:\"mount\"when:testpath5 is mount- debug:msg:\"exists\"when:testpath1 is exists  5,判断字符串的一些tests\n lower:判断包含字母的字符串中的字母是否是纯小写,字符串中的字母全部为小写则返回真 upper:判断包含字母的字符串中的字母是否是纯大写,字符串中的字母全部为大写则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:meremote_user:liawnegather_facts:novars:str1:\"abc\"str2:\"ABC\"tasks:- debug:msg:\"This string is all lowercase\"when:str1 is lower- debug:msg:\"This string is all uppercase\"when:str2 is upper  6,判断整除的一些tests\n even :判断数值是否是偶数,是偶数则返回真 odd :判断数值是否是奇数,是奇数则返回真 divisibleby(num) :判断是否可以整除指定的数值,如果除以指定的值以后余数为0，则返回真 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ---- hosts:meremote_user:liawnegather_facts:novars:num1:4num2:7num3:64tasks:- debug:msg:\"An even number\"when:num1 is even- debug:msg:\"An odd number\"when:num2 is odd- debug:msg:\"Can be divided exactly by\"when:num3 is divisibleby(8)  7,其他一些tests\n version:可以用于对比两个版本号的大小,或者与指定的版本号进行对比，使用语法为 version(‘版本号', ‘比较操作符')  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ---- hosts:meremote_user:liawnevars:ver:7.4.1708ver1:7.4.1707tasks:- debug:msg:\"This message can be displayed when the ver is greater than ver1\"when:ver is version(ver1,\"\u003e\")- debug:msg:\"system version {{ansible_distribution_version}} greater than 7.3\"when:ansible_distribution_version is version(\"7.3\",\"gt\")# ”\u003e”与”gt”都表示”大于”,当使用version时，支持多种风格的比较操作符，你可以根据自己的使用习惯进行选择，version支持的比较操作符如下# 大于:\u003e, gt# 大于等于:\u003e=, ge# 小于:\u003c, lt# 小于等于:\u003c=, le# 等于: ==, =, eq# 不等于:!=, \u003c\u003e, ne   subset:判断一个list是不是另一个list的子集,是另一个list的子集时返回真 superset : 判断一个list是不是另一个list的父集,是另一个list的父集时返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ---- hosts:meremote_user:liawnegather_facts:novars:a:- 2- 5b:[1,2,3,4,5]tasks:- debug:msg:\"A is a subset of B\"when:a is subset(b)- debug:msg:\"B is the parent set of A\"when:b is superset(a)# 注:2.5版本中上述两个tests从issubset和issuperset更名为subset和superset   string:判断对象是否是一个字符串,是字符串则返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:meremote_user:liawnegather_facts:novars:testvar1:1testvar2:\"1\"testvar3:atasks:- debug:msg:\"This variable is a string\"when:testvar1 is string- debug:msg:\"This variable is a string\"when:testvar2 is string- debug:msg:\"This variable is a string\"when:testvar3 is string# 上例playbook中只有testvar2和testvar3会被判断成字符串,testvar1不会   number:判断对象是否是一个数字,是数字则返回真  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---- hosts:meremote_user:liawnegather_facts:novars:testvar1:1testvar2:\"1\"testvar3:00.20tasks:- debug:msg:\"This variable is number\"when:testvar1 is number- debug:msg:\"This variable is a number\"when:testvar2 is number- debug:msg:\"This variable is a number\"when:testvar3 is number# 上例playbook中只有testvar1和testvar3会被判断成数字,testvar2不会  条件判断与block 1,在ansible中,可以使用\"block\"关键字将多个任务整合成一个\"块\",这个\"块\"将被当做一个整体,我们可以对这个\"块\"添加判断条件,当条件成立时,则执行这个块中的所有任务\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:meremote_user:roottasks:- debug:msg:\"task1 not in block\"- block:- debug:msg:\"task2 in block1\"- debug:msg:\"task3 in block1\"when:2\u003e 1  2,block用在错误处理的场景下\n 之前的方式如下:  1 2 3 4 5 6 7 8 9 10 11  ---- hosts:meremote_user:roottasks:- shell:'ls /ooo'register:return_valueignore_errors:true# 通过注册变量,且忽略错误(ignore_errors)来做分支判断- debug:msg:\"I cought an error\"when:return_value is failed   使用block+rescue的方式  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:meremote_user:roottasks:- block:- shell:'ls /ooo'# rescue直接承接上面的block,当block中的内容出现错误时,执行rescue中的内容# rescue关键字与block关键字对齐,rescue的字面意思为\"救援\",表示当block中的任务执行失败时,会执行rescue中的任务进行补救# rescue中的内容由自己定义rescue:- debug:msg:'I caught an error'   block的优势,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  ---- hosts:meremote_user:roottasks:- block:# block可以接多个任务,任何一个任务出错,都会执行rescue中的任务,所以通常使用block和rescue结合,完成\"错误捕捉,报出异常\"的功能# 不仅block中可以有多个任务,rescue中也可以定义多个任务,当block中的任何一个任务出错时,会按照顺序执行rescue中的任务.- shell:'ls /opt'- shell:'ls /testdir'- shell:'ls /c'rescue:- debug:msg:'I caught an error'   block+rescue+always的使用示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 还能再加入always关键字,加入always关键字以后,无论block中的任务执行成功还是失败,always中的任务都会被执行---- hosts:meremote_user:roottasks:- block:- debug:msg:'I execute normally'- command:/bin/false- debug:msg:'I never execute, due to the above task failing'rescue:- debug:msg:'I caught an error'- command:/bin/false- debug:msg:'I also never execute'always:- debug:msg:\"This always executes\"# 如上例所示,block中有多个任务,rescue中也有多个任务,上例中故意执行\"/bin/false\"命令,模拟任务出错的情况,当block中的'/bin/false'执行后,其后的debug任务将不会被执行,因为'/bin/false'模拟出错,出错后直接执行rescue中的任务,在执行rescue中的任务时,会先输出 ‘I caught an error',然后又在rescue中使用'/bin/false'模拟出错的情况,出错后之后的debug任务不会被执行,直接执行always中的任务,always中的任务一定会被执行,无论block中的任务是否出错  条件判断与错误处理 1,使用fail模块来处理出错\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ---- hosts:meremote_user:roottasks:- shell:\"echo 'This is a string for testing--error'\"register:return_value- fail:msg:\"Conditions established,Interrupt running playbook\"when:\"'error' in return_value.stdout\"- debug:msg:\"I never execute,Because the playbook has stopped\"# a, 当使用\"in\"或者\"not in\"进行条件判断时,整个条件需要用引号引起,并且,需要判断的字符串也需要使用引号引起,所以,使用'in'或者'not in'进行条件判断时,如下两种语法是正确的:# when: ' \"successful\" not in return_value.stdout '# when: \" 'successful' not in return_value.stdout \"# b,fail可以单独使用,不加msg和when,效果是直接报错  2,使用failed_when\n 'failed_when'的作用就是,当对应的条件成立时,将对应任务的执行状态设置为失败  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:meremote_user:roottasks:- debug:msg:\"I execute normally\"- shell:\"echo 'This is a string for testing error'\"register:return_valuefailed_when:' \"error\" in return_value.stdout'- debug:msg:\"I never execute,Because the playbook has stopped\"# 'failed_when'关键字与shell关键字对齐,表示其对应的条件是针对shell模块的,'failed_when'对应的条件是 ‘ “error\" in return_value.stdout',表示\"error\"字符串如果存在于shell模块执行后的标准输出中,则条件成立,# 当条件成立后,shell模块的执行状态将会被设置为失败,由于shell模块的执行状态被设置为失败,所以playbook会终止运行,于是,最后的debug模块并不会被执行# 'failed_when'虽然会将任务的执行状态设置为失败,但并不代表任务真的失败了,以上例来说,shell模块的确是完全正常的执行了,只不过在执行之后,' failed_when'对应的条件成立了,' failed_when'将shell模块的执行状态设置为失败而已  3,使用changed_when\n ‘changed_when'关键字的作用是在条件成立时,将对应任务的执行状态设置为changed  1 2 3 4 5 6 7 8  ---- hosts:meremote_user:roottasks:- debug:msg:\"test message\"changed_when:2\u003e 1# debug模块在正常执行的情况下只能是\"ok\"状态,上例中,我们使用'changed_when'关键字将debug模块的执行后的状态定义为了\"changed\"   与handler结合使用  1 2 3 4 5 6 7 8 9 10  # 只有任务作出了实际的操作时（执行后状态为changed）,才会真正的执行对应的handlers# 而在某些时候,如果想要通过任务执行后的返回值将任务的最终执行状态判定为changed,则可以使用'changed_when'关键字,以便条件成立时,可以执行对应的handlers,# 'changed_when'除了能够在条件成立时将任务的执行状态设置为\"changed\",还能让对应的任务永远不能是changed状态,示例如下:---- hosts:meremote_user:roottasks:- shell:\"ls /opt\"changed_when:false# 当将'changed_when'直接设置为false时,对应任务的状态将不会被设置为'changed',如果任务原本的执行状态为'changed',最终则会被设置为'ok',所以,上例playbook执行后,shell模块的执行状态最终为'ok'  过滤器 1,过滤器是一种能够帮助我们处理数据的工具,其实,ansible中的过滤器功能来自于jinja2模板引擎\n2,过滤器有些是jinja2内置的,有些是ansible特有的,如果这些过滤器都不能满足你的需求,jinja2也支持自定义过滤器\n3,一些常见的过滤器\n 字符串相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  ---- hosts:meremote_user:rootvars:testvar:\"abc123ABC 666\"testvar1:\" abc \"testvar2:'123456789'testvar3:\"1a2b,@#$%^\u0026\"tasks:- debug:#将字符串转换成纯大写msg:\"{{ testvar | upper }}\"- debug:#将字符串转换成纯小写msg:\"{{ testvar | lower }}\"- debug:#将字符串变成首字母大写,之后所有字母纯小写msg:\"{{ testvar | capitalize }}\"- debug:#将字符串反转msg:\"{{ testvar | reverse }}\"- debug:#返回字符串的第一个字符msg:\"{{ testvar | first }}\"- debug:#返回字符串的最后一个字符msg:\"{{ testvar | last }}\"- debug:#将字符串开头和结尾的空格去除msg:\"{{ testvar1 | trim }}\"- debug:#将字符串放在中间,并且设置字符串的长度为30,字符串两边用空格补齐30位长msg:\"{{ testvar1 | center(width=30) }}\"- debug:#返回字符串长度,length与count等效,可以写为countmsg:\"{{ testvar2 | length }}\"- debug:#将字符串转换成列表,每个字符作为一个元素msg:\"{{ testvar3 | list }}\"- debug:#将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序#shuffle的字面意思为洗牌msg:\"{{ testvar3 | shuffle }}\"- debug:#将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序#在随机打乱顺序时,将ansible_date_time.epoch的值设置为随机种子#也可以使用其他值作为随机种子,ansible_date_time.epoch是facts信息msg:\"{{ testvar3 | shuffle(seed=(ansible_date_time.epoch)) }}\"   数字相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  ---- hosts:meremote_user:rootvars:testvar4:-1tasks:- debug:#将对应的值转换成int类型#ansible中,字符串和整形不能直接计算,比如{{ 8+'8' }}会报错#所以,我们可以把一个值为数字的字符串转换成整形后再做计算msg:\"{{ 8+('8' | int) }}\"- debug:#将对应的值转换成int类型,如果无法转换,默认返回0#使用int(default=6)或者int(6)时,如果无法转换则返回指定值6msg:\"{{ 'a' | int(default=6) }}\"- debug:#将对应的值转换成浮点型,如果无法转换,默认返回'0.0'msg:\"{{ '8' | float }}\"- debug:#当对应的值无法被转换成浮点型时,则返回指定值'8.8‘msg:\"{{ 'a' | float(8.88) }}\"- debug:#获取对应数值的绝对值msg:\"{{ testvar4 | abs }}\"- debug:#四舍五入msg:\"{{ 12.5 | round }}\"- debug:#取小数点后五位msg:\"{{ 3.1415926 | round(5) }}\"- debug:#从0到100中随机返回一个随机数msg:\"{{ 100 | random }}\"- debug:#从5到10中随机返回一个随机数msg:\"{{ 10 | random(start=5) }}\"- debug:#从5到15中随机返回一个随机数,步长为3#步长为3的意思是返回的随机数只有可能是5、8、11、14中的一个msg:\"{{ 15 | random(start=5,step=3) }}\"- debug:#从0到15中随机返回一个随机数,这个随机数是5的倍数msg:\"{{ 15 | random(step=5) }}\"- debug:#从0到15中随机返回一个随机数,并将ansible_date_time.epoch的值设置为随机种子#也可以使用其他值作为随机种子,ansible_date_time.epoch是facts信息#seed参数从ansible2.3版本开始可用msg:\"{{ 15 | random(seed=(ansible_date_time.epoch)) }}\"   列表相关  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  ---- hosts:meremote_user:rootvars:testvar7:[22,18,5,33,27,30]testvar8:[1,[7,2,[15,9]],3,5]testvar9:[1,'b',5]testvar10:[1,'A','b',['QQ','wechat'],'CdEf']testvar11:['abc',1,3,'a',3,'1','abc']testvar12:['abc',2,'a','b','a']tasks:- debug:#返回列表长度,length与count等效,可以写为countmsg:\"{{ testvar7 | length }}\"- debug:#返回列表中的第一个值msg:\"{{ testvar7 | first }}\"- debug:#返回列表中的最后一个值msg:\"{{ testvar7 | last }}\"- debug:#返回列表中最小的值msg:\"{{ testvar7 | min }}\"- debug:#返回列表中最大的值msg:\"{{ testvar7 | max }}\"- debug:#将列表升序排序输出msg:\"{{ testvar7 | sort }}\"- debug:#将列表降序排序输出msg:\"{{ testvar7 | sort(reverse=true) }}\"- debug:#返回纯数字非嵌套列表中所有数字的和msg:\"{{ testvar7 | sum }}\"- debug:#如果列表中包含列表,那么使用flatten可以'拉平'嵌套的列表#2.5版本中可用,执行如下示例后查看效果msg:\"{{ testvar8 | flatten }}\"- debug:#如果列表中嵌套了列表,那么将第1层的嵌套列表‘拉平'#2.5版本中可用,执行如下示例后查看效果msg:\"{{ testvar8 | flatten(levels=1) }}\"- debug:#过滤器都是可以自由结合使用的,就好像linux命令中的管道符一样#如下,取出嵌套列表中的最大值msg:\"{{ testvar8 | flatten | max }}\"- debug:#将列表中的元素合并成一个字符串msg:\"{{ testvar9 | join }}\"- debug:#将列表中的元素合并成一个字符串,每个元素之间用指定的字符隔开msg:\"{{ testvar9 | join(' , ') }}\"- debug:#从列表中随机返回一个元素#对列表使用random过滤器时,不能使用start和step参数msg:\"{{ testvar9 | random }}\"- debug:#从列表中随机返回一个元素,并将ansible_date_time.epoch的值设置为随机种子#seed参数从ansible2.3版本开始可用msg:\"{{ testvar9 | random(seed=(ansible_date_time.epoch)) }}\"- debug:#随机打乱顺序列表中元素的顺序#shuffle的字面意思为洗牌msg:\"{{ testvar9 | shuffle }}\"- debug:#随机打乱顺序列表中元素的顺序#在随机打乱顺序时,将ansible_date_time.epoch的值设置为随机种子#seed参数从ansible2.3版本开始可用msg:\"{{ testvar9 | shuffle(seed=(ansible_date_time.epoch)) }}\"- debug:#将列表中的每个元素变成纯大写msg:\"{{ testvar10 | upper }}\"- debug:#将列表中的每个元素变成纯小写msg:\"{{ testvar10 | lower }}\"- debug:#去掉列表中重复的元素,重复的元素只留下一个msg:\"{{ testvar11 | unique }}\"- debug:#将两个列表合并,重复的元素只留下一个#也就是求两个列表的并集msg:\"{{ testvar11 | union(testvar12) }}\"- debug:#取出两个列表的交集,重复的元素只留下一个msg:\"{{ testvar11 | intersect(testvar12) }}\"- debug:#取出存在于testvar11列表中,但是不存在于testvar12列表中的元素#去重后重复的元素只留下一个#换句话说就是:两个列表的交集在列表1中的补集msg:\"{{ testvar11 | difference(testvar12) }}\"- debug:#取出两个列表中各自独有的元素,重复的元素只留下一个#即去除两个列表的交集,剩余的元素msg:\"{{ testvar11 | symmetric_difference(testvar12) }}\"   变量未定义时相关操作的过滤器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ---- hosts:meremote_user:rootgather_facts:novars:testvar6:''tasks:- debug:#如果变量没有定义,则临时返回一个指定的默认值#注:如果定义了变量,变量值为空字符串,则会输出空字符#default过滤器的别名是dmsg:\"{{ testvar5 | default('zsythink') }}\"- debug:#如果变量的值是一个空字符串或者变量没有定义,则临时返回一个指定的默认值msg:\"{{ testvar6 | default('zsythink',boolean=true) }}\"- debug:#如果对应的变量未定义,则报出“Mandatory variable not defined.\"错误,而不是报出默认错误msg:\"{{ testvar5 | mandatory }}\"  4,上述使用到的default参数,default过滤器,还有一个很方便的用法,default过滤器不仅能在变量未定义时返回指定的值,还能够让模块的参数变得\"可有可无\"\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # method one,循环了两次- hosts:meremote_user:rootgather_facts:novars:paths:- path:/tmp/testmode:'0444'- path:/tmp/foo- path:/tmp/bartasks:- file:dest={{item.path}} state=touch mode={{item.mode}}with_items:\"{{ paths }}\"when:item.mode is defined- file:dest={{item.path}} state=touchwith_items:\"{{ paths }}\"when:item.mode is undefined# method two- hosts:meremote_user:rootgather_facts:novars:paths:- path:/tmp/testmode:'0444'- path:/tmp/foo- path:/tmp/bartasks:- file:dest={{item.path}} state=touch mode={{item.mode | default(omit)}}with_items:\"{{ paths }}\"# 没有对文件是否有mode属性进行判断,而是直接调用了file模块的mode参数,将mode参数的值设定为了\"{{item.mode | default(omit)}}\",这是什么意思呢？它的意思是,如果item有mode属性,就把file模块的mode参数的值设置为item的mode属性的值,如果item没有mode属性,file模块就直接省略mode参数,'omit'的字面意思就是\"省略\",换成大白话说就是:[有就用,没有就不用,可以有,也可以没有]  变量(六)include_vars 1,通过'vars_files'可以将文件中的变量引入playbook,以便在task中使用,但是vars_files加载时是静态的引入变量,即后续在vars_files中新增的变量,无法被引用\n vars_files变量文件在ansible控制节点中,与目标主机无关 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ---# 为了更加方便的操作变量文件进行测试,此处将目标主机设置为me,主机me为ansible控制主机- hosts:meremote_user:rootgather_facts:novars_files:- /testdir/ansible/testfile# /testdir/ansible/testfile内容为:# testvar1: aaa# testvar2: bbbtasks:- debug:msg:\"{{testvar1}},{{testvar2}}\"- lineinfile:path:\"/testdir/ansible/testfile\"line:\"testvar3: ccc\"- debug:msg:\"{{testvar1}},{{testvar2}},{{testvar3}}\"# 上述执行出错,因为在playbook载入vars_files对应的变量文件时,文件中只有两个变量,在执行第三个任务执行,并没有重新载入对应的变量文件  2,include_vars可以在任务执行过程中,随时的引入变量文件,以便动态的获取到最新的变量文件内容\n 接上例,调整内容如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ---# 为了更加方便的操作变量文件进行测试,此处将目标主机设置为me,主机me为ansible控制主机- hosts:meremote_user:rootgather_facts:novars_files:- /testdir/ansible/testfiletasks:- debug:msg:\"{{testvar3}}\"- lineinfile:path:\"/testdir/ansible/testfile\"line:\"testvar4: ddd\"- include_vars:\"/testdir/ansible/testfile\"- debug:msg:\"{{testvar4}}\"   include_vars还有一种使用场景,有些时候,变量文件可能并没有位于ansible主机中,而是位于远程主机中,所以需要先把变量文件从远程主机中拉取到ansible主机中,当通过前面的task拉取到变量文件以后,也可以使用'include_vars'模块加载刚才拉取到的变量文件,以便后面的task可以使用变量文件中的变量.  3,include_vars的一些常用参数\n file,如下示例:  1 2 3 4 5 6 7 8 9 10 11  ---- hosts:node2remote_user:rootgather_facts:notasks:- include_vars:file:/testdir/ansible/testfile# 等效于:# - include_vars: \"/testdir/ansible/testfile\"- debug:msg:\"{{testvar4}}\"   'include_vars'可以把变量文件中的变量全部赋值给另外一个变量,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:node2remote_user:rootgather_facts:notasks:- include_vars:file:/testdir/ansible/testfilename:trans_var- debug:msg:\"{{trans_var}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[test70] =\u003e {\"msg\": {\"testvar1\": \"aaa\",\"testvar2\": \"bbb\",\"testvar3\": \"ccc\",\"testvar4\": \"ddd\"}}# 'trans_var'变量的值就是变量文件中的所有变量,可以使用name参数指定一个变量,然后将文件中的所有变量都赋值给这个指定的变量# 当使用name参数时,要获取到文件中的某一个变量的值,可以使用如下方法tasks:- include_vars:file:/testdir/ansible/testfilename:trans_var- debug:msg:\"{{trans_var.testvar4}}\"   ‘include_vars'不仅能够加载指定的变量文件,还能够一次性将指定目录下的所有变量文件中的变量加载,使用dir参数即可指定对应的目录  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  ---- hosts:node2gather_facts:noremote_user:roottasks:- include_vars:dir:/testdir/ansible/test/name:trans_var- debug:msg:\"{{trans_var}}\"# 上例中,使用dir参数指定了\"/testdir/ansible/test/\"目录,此目录中的所有变量文件都会被加载,但是在使用dir参数时,需要注意如下三点# 第一:指定目录中的所有文件的文件后缀必须是 ‘.yaml' 、'.yml' 、'.json'中的一种,默认只有这三种后缀是合法后缀,如果目录中存在非合法后缀的文件,执行playbook时则会报错.# 第二:如果此目录中的子目录中包含变量文件,子目录中的变量文件也会被递归的加载,而且子目录中的文件也必须遵守上述第一条规则.# 第三:dir参数与file参数不能同时使用.# 第一点与第二点都是默认设置,可以通过其他选项修改# 当使用dir参数时,指定目录中的所有文件必须以 ‘.yaml' 、'.yml' 、'.json' 作为文件的后缀,如果想要手动指定合法的文件后缀名,则可以使用extensions参数指定哪些后缀是合法的文件后缀,extensions参数的值需要是一个列表tasks:- include_vars:dir:/testdir/ansible/test/extensions:[yaml,yml,json,varfile]name:trans_var- debug:msg:\"{{trans_var}}\"# 上例中extensions参数的值为 “[yaml,yml,json,varfile]\",这表示指定目录中的合法文件后缀名为yaml、yml、json和varfile.# 当使用dir参数时,默认情况下会递归的加载指定目录及其子目录中的所有变量文件,如果想要控制递归的深度,则可以借助depth参数,示例如下tasks:- include_vars:dir:/testdir/ansible/test/depth:1name:trans_var- debug:msg:\"{{trans_var}}\"# 上例表示,加载\"/testdir/ansible/test/\"目录中的变量文件,但是其子目录中的变量文件将不会被加载,depth的值为1表示递归深度为1,默认值为0,表示递归到最底层的子目录.# 在使用dir参数时,我们还可以借助正则表达式,匹配那些我们想要加载的变量文件,比如,我们只想加载指定目录中以\"var_\"开头的变量文件,则可以使用如下方法tasks:- include_vars:dir:/testdir/ansible/test/files_matching:\"^var_.*\"name:trans_var- debug:msg:\"{{trans_var}}\"# 如上例所示,使用'files_matching'参数可以指定正则表达式,当指定目录中的文件名称符合正则时,则可以被加载# 还可以明确指定,哪些变量文件不能被加载,使用'ignore_files'参数可以明确指定需要忽略的变量文件名称,'ignore_files'参数的值是需要是一个列表tasks:- include_vars:dir:/testdir/ansible/test/ignore_files:[\"^var_.*\",varintest.yaml]name:trans_var- debug:msg:\"{{trans_var}}\"# 加载 /testdir/ansible/test/目录中的变量文件,但是所有以\"var_\"开头的变量文件和varintest.yaml变量文件将不会被加载, ‘files_matching'参数和'ignore_files'参数能够同时使用,当它们同时出现时,会先找出正则匹配到的文件,然后从中排除那些需要忽略的文件  3, 在2.4版本以后的ansible中,当执行了include_vars模块以后,include_vars模块会将载入的变量文件列表写入到自己的返回值中,这个返回值的关键字为'ansible_included_var_files',所以,如果我们想要知道本次任务引入了哪些变量文件,则可以使用如下方法\n 如下示例:  1 2 3 4 5 6  tasks:- include_vars:dir:/testdir/ansible/test/register:return_val- debug:msg:\"{{return_val.ansible_included_var_files}}\"  过滤器(二) json_query 1,ansible可以通过include_vars加载日志文件,debug格式化输出json/yaml内容,方便查看\n json是yaml的子集,yaml是json的超集,yaml格式的数据和json格式的数据是可以互相转换的 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  ---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/wsCdnLogList\"name:testvar- debug:msg:\"{{ testvar }}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": {\"logs\": [{\"domainName\": \"asia1.cdn.test.com\",\"files\": [{\"dateFrom\": \"2018-09-05-0000\",\"dateTo\": \"2018-09-05-2359\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-0000-2330_asia1.cdn.test.com.all.log.gz\",\"fileSize\": 254,\"logUrl\": \"http://log.testcd.com/log/zsy/asia1.cdn.test.com/2018-09-05-0000-2330_asia1.cdn.test.com.all.log.gz?wskey=XXXXX5a\"}]},{\"domainName\": \"image1.cdn.test.com\",\"files\": [{\"dateFrom\": \"2018-09-05-2200\",\"dateTo\": \"2018-09-05-2259\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-2200-2230_image1.cdn.test.com.cn.log.gz\",\"fileSize\": 10509,\"logUrl\": \"http://log.testcd.com/log/zsy/image1.cdn.test.com/2018-09-05-2200-2230_image1.cdn.test.com.cn.log.gz?wskey=XXXXX1c\"},{\"dateFrom\": \"2018-09-05-2300\",\"dateTo\": \"2018-09-05-2359\",\"fileMd5\": \"error\",\"fileName\": \"2018-09-05-2300-2330_image1.cdn.test.com.cn.log.gz\",\"fileSize\": 5637,\"logUrl\": \"http://log.testcd.com/log/zsy/image1.cdn.test.com/2018-09-05-2300-2330_image1.cdn.test.com.cn.log.gz?wskey=XXXXXfe\"}]}]}}# 变量文件的格式可以是yaml格式的,也可以是json格式的,上例就是将json格式的数据文件当做变量文件使用的# 对于ansible来说,当我们把上例中的json数据文件当做变量文件引入时,就好像引入了一个我们定义好的yaml格式的变量文件一样,对于ansible来说是没有区别的   当需要从上例中获取到logUrl时,可以使用如下方式获取:  1 2 3 4 5 6 7 8 9  tasks:- include_vars:file:\"/testdir/ansible/wsCdnLogList\"name:testvar- debug:msg:\"{{ item.1.logUrl }}\"with_subelements:- \"{{testvar.logs}}\"- files  2,上述例子中除with_subelements外,还可以使用json_query来获取\n json_query的使用方式:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 假设testvarfile中内容如下{\"users\": [{\"name\": \"tom\",\"age\": 18},{\"name\": \"jerry\",\"age\": 20}]}# 如果要获取到所有user的name---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/testvarfile\"name:testvar- debug:msg:\"{{ testvar | json_query('users[*].name') }}\"# 这段数据当做变量赋值给了testvar变量,使用json_query过滤器对这个变量进行了处理,json_query('users[*].name')表示找到users列表中所有元素的name属性,输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[test70] =\u003e {\"msg\": [\"tom\",\"jerry\"]}   更进一步  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  # 假设testvarfile中内容如下---test:users:- name:tomage:18hobby:- Skateboard- VideoGame- name:jerryage:20hobby:- Music# 要获取到所有的爱好---- hosts:meremote_user:liawnegather_facts:notasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query('test.users[*].hobby[*]') }}\"# 当数据结构中存在列表时,我们可以使用”列表名[*]”获取到列表下面的所有项,输出结果如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": [[\"Skateboard\",\"VideoGame\"],[\"Music\"]]}# 想要根据条件获取到某个用户的某些信息# method onetasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:# 此处使用了反引号,因为已经使用了'和\",使用`用作区分msg:\"{{ testvar | json_query('test.users[?name==`tom`].hobby[*]') }}\"# method twotasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query(querystring) }}\"vars:querystring:\"test.users[?name=='tom'].age\"# 在debug任务中使用vars关键字定义了一个只有当前debug任务能够使用的变量,从而避免了多层引号嵌套时所产生的冲突问题.# 同时获取到用户的姓名、年龄两个属性的值,当需要同时获取多个属性值时,需要通过键值对的方式调用属性tasks:- include_vars:file:\"/testdir/ansible/testvarfile1\"name:testvar- debug:msg:\"{{ testvar | json_query('test.users[*].{uname:name,uage:age}') }}\"# 输出内容如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": [{\"uage\": 18,\"uname\": \"tom\"},{\"uage\": 20,\"uname\": \"jerry\"}]}   回到第一个示例,获取logUrl的方式如下:  1 2 3 4 5 6 7 8 9 10  ---- hosts:meremote_user:liawnegather_facts:novars_files:- /testdir/ansible/wsCdnLogListtasks:- debug:msg:\"{{item}}\"with_items:\"{{ logs | json_query('[*].files[*].logUrl') }}\"  过滤器(三) 其他过滤器 1,其他一些常用的过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172  ---- hosts:meremote_user:liawnegather_facts:notasks:#######################################################################在调用shell模块时,如果引用某些变量时需要添加引号,则可以使用quote过滤器代替引号#示例如下,先看示例,后面会有注解- shell:\"echo {{teststr | quote}} \u003e /testdir/testfile\"vars:teststr:\"a\\nb\\nc\"#上例中shell模块的写法与如下写法完全等效#shell: \"echo '{{teststr}}' \u003e /testdir/testfile\"#没错,如你所见,quote过滤器能够代替引号#上例中,如果不对{{teststr}}添加引号,则会报错,因为teststr变量中包含\"\\n\"转义符#######################################################################ternary过滤器可以实现三元运算的效果 示例如下#如下示例表示如果name变量的值是John,那么对应的值则为Mr,否则则为Ms#简便的实现类似if else对变量赋值的效果- debug:msg:\"{{ (name == 'John') | ternary('Mr','Ms') }}\"vars:name:\"John\"#######################################################################basename过滤器可以获取到一个路径字符串中的文件名- debug:msg:\"{{teststr | basename}}\"vars:teststr:\"/testdir/ansible/testfile\"#######################################################################获取到一个windows路径字符串中的文件名,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_basename}}\"vars:teststr:'D:\\study\\zsythink'#######################################################################dirname过滤器可以获取到一个路径字符串中的路径名- debug:msg:\"{{teststr | dirname}}\"vars:teststr:\"/testdir/ansible/testfile\"#######################################################################获取到一个windows路径字符串中的文件名,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_dirname}}\"vars:teststr:'D:\\study\\zsythink'#######################################################################将一个windows路径字符串中的盘符和路径分开,2.0版本以后的ansible可用- debug:msg:\"{{teststr | win_splitdrive}}\"vars:teststr:'D:\\study\\zsythink'#可以配合之前总结的过滤器一起使用,比如只获取到盘符,示例如下#msg: \"{{teststr | win_splitdrive | first}}\"#可以配合之前总结的过滤器一起使用,比如只获取到路径,示例如下#msg: \"{{teststr | win_splitdrive | last}}\"#######################################################################realpath过滤器可以获取软链接文件所指向的真正文件- debug:msg:\"{{ path | realpath }}\"vars:path:\"/testdir/ansible/testsoft\"#######################################################################relpath过滤器可以获取到path对于“指定路径”来说的“相对路径”- debug:msg:\"{{ path | relpath('/testdir/testdir') }}\"vars:path:\"/testdir/ansible\"#######################################################################splitext过滤器可以将带有文件名后缀的路径从“.后缀”部分分开- debug:msg:\"{{ path | splitext }}\"vars:path:\"/etc/nginx/conf.d/test.conf\"#可以配置之前总结的过滤器,获取到文件后缀#msg: \"{{ path | splitext | last}}\"#可以配置之前总结的过滤器,获取到文件前缀名#msg: \"{{ path | splitext | first | basename}}\"#######################################################################to_uuid过滤器能够为对应的字符串生成uuid- debug:msg:\"{{ teststr | to_uuid }}\"vars:teststr:\"This is a test statement\"#######################################################################bool过滤器可以根据字符串的内容返回bool值true或者false#字符串的内容为yes、1、True、true则返回布尔值true,字符串内容为其他内容则返回false- debug:msg:\"{{ teststr | bool }}\"vars:teststr:\"1\"#当和用户交互时,有可能需要用户从两个选项中选择一个,比如是否继续,#这时,将用户输入的字符串通过bool过滤器处理后得出布尔值,从而进行判断,比如如下用法#- debug:# msg: \"output when bool is true\"# when: some_string_user_input | bool#######################################################################map过滤器可以从列表中获取到每个元素所共有的某个属性的值,并将这些值组成一个列表#当列表中嵌套了列表,不能越级获取属性的值,也就是说只能获取直接子元素的共有属性值.- vars:users:- name:tomage:18hobby:- Skateboard- VideoGame- name:jerryage:20hobby:- Musicdebug:msg:\"{{ users | map(attribute='name') | list }}\"#也可以组成一个字符串,用指定的字符隔开,比如分号#msg: \"{{ users | map(attribute='name') | join(';') }}\"#######################################################################与python中的用法相同,两个日期类型相减能够算出两个日期间的时间差#下例中,我们使用to_datatime过滤器将字符串类型转换成了日期了类型,并且算出了时间差- debug:msg:'{{ (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 19:00:00\" | to_datetime) }}'#默认情况下,to_datatime转换的字符串的格式必须是“%Y-%m-%d %H:%M:%S”#如果对应的字符串不是这种格式,则需要在to_datetime中指定与字符串相同的时间格式,才能正确的转换为时间类型- debug:msg:'{{ (\"20160814\"| to_datetime(\"%Y%m%d\")) - (\"2012-12-25 19:00:00\" | to_datetime) }}'#如下方法可以获取到两个日期之间一共相差多少秒- debug:msg:'{{ ( (\"20160814\"| to_datetime(\"%Y%m%d\")) - (\"20121225\" | to_datetime(\"%Y%m%d\")) ).total_seconds() }}'#如下方法可以获取到两个日期“时间位”相差多少秒,注意:日期位不会纳入对比计算范围#也就是说,下例中的2016-08-14和2012-12-25不会纳入计算范围#只是计算20:00:12与08:30:00相差多少秒#如果想要算出连带日期的秒数差则使用total_seconds()- debug:msg:'{{ ( (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 08:30:00\" | to_datetime) ).seconds }}'#如下方法可以获取到两个日期“日期位”相差多少天,注意:时间位不会纳入对比计算范围- debug:msg:'{{ ( (\"2016-08-14 20:00:12\"| to_datetime) - (\"2012-12-25 08:30:00\" | to_datetime) ).days }}'#######################################################################使用base64编码方式对字符串进行编码- debug:msg:\"{{ 'hello' | b64encode }}\"#使用base64编码方式对字符串进行解码- debug:msg:\"{{ 'aGVsbG8=' | b64decode }}\"########################################################################使用sha1算法对字符串进行哈希- debug:msg:\"{{ '123456' | hash('sha1') }}\"#使用md5算法对字符串进行哈希- debug:msg:\"{{ '123456' | hash('md5') }}\"#获取到字符串的校验和,与md5哈希值一致- debug:msg:\"{{ '123456' | checksum }}\"#使用blowfish算法对字符串进行哈希,注:部分系统支持- debug:msg:\"{{ '123456' | hash('blowfish') }}\"#使用sha256算法对字符串进行哈希,哈希过程中会生成随机\"盐\",以便无法直接对比出原值- debug:msg:\"{{ '123456' | password_hash('sha256') }}\"#使用sha256算法对字符串进行哈希,并使用指定的字符串作为\"盐\"- debug:msg:\"{{ '123456' | password_hash('sha256','mysalt') }}\"#使用sha512算法对字符串进行哈希,哈希过程中会生成随机\"盐\",以便无法直接对比出原值- debug:msg:\"{{ '123123' | password_hash('sha512') }}\"#使用sha512算法对字符串进行哈希,并使用指定的字符串作为\"盐\"- debug:msg:\"{{ '123123' | password_hash('sha512','ebzL.U5cjaHe55KK') }}\"#如下方法可以幂等的为每个主机的密码生成对应哈希串#有了之前总结的过滤器用法作为基础,你一定已经看懂了- debug:msg:\"{{ '123123' | password_hash('sha512', 65534|random(seed=inventory_hostname)|string) }}\"  lookup插件 1,ansible中有很多种类的插件,比如之前总结的”tests”,也是插件的一种,ansible官网总结了各个插件的作用,并且将这些插件按照功能进行了分类\n https://docs.ansible.com/ansible/latest/plugins/plugins.html  2,前文总结的”循环”在本质上也是一种插件,这种插件叫做”lookup插件”,先回忆一些”循环”的使用方法,以便能够更好的描述”循环”和”lookup插件”之间的关系\n 列表示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"index is {{item.0}} , value is {{item.1}}\"with_indexed_items:['a','b','c']# 等价于---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"index is {{item.0}} , value is {{item.1}}\"loop:\"{{ lookup('indexed_items',['a','b','c']) }}\"# 第一个示例使用”with_indexed_items关键字”处理列表# 第二个示例使用”loop关键字”配合”lookup插件”处理列表# 上例中,”lookup(‘indexed_items',[‘a','b','c'])” 这段代码就是在使用lookup插件,含义是,使用名为'indexed_items'的lookup插件处理[‘a','b','c']这个列表,'indexed_items'就是一个lookup插件   字典示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"with_dict:\"{{ users }}\"# 等价于---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ lookup('dict',users) }}\"# 第一个示例使用”with_dict关键字”处理users字典变量# 第二个示例使用”loop关键字”配合”lookup插件”处理users字典变量# 上例中,”lookup(‘dict',users)”表示使用名为'dict'的lookup插件处理users字典变量,'dict'也是一个lookup插件  3,lookup插件的用法\n lookup(‘插件名',被处理数据或参数) 以”with_”开头的循环实际上就是”with_”和”lookup()”的组合,lookup插件可以作为循环的数据源  4,查看插件的帮助命令\n 查看有哪些lookup插件可以使用: ansible-doc -t lookup -l(”-t”选项用于指定插件类型,”-l”选项表示列出列表) 单独查看某个插件的使用方法,比如dict插件的使用方法: ansible-doc -t lookup dict file插件可以获取到指定文件的文件内容（注:文件位于ansible主机中）,示例如下  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ lookup('file','/testdir/testfile') }}\"# 如果想要获取多个文件中的内容,则可以传入多个文件路径,示例如下msg:\"{{ lookup('file','/testdir/testfile','/testdir/testfile1') }}\"# file插件获得多个文件中的内容时,会将多个文件中的内容放置在一个字符串中,并用”逗号”隔开每个文件中的内容# 想要获得一个字符串列表,将每个文件的内容当做列表中的一个独立的字符串msg:\"{{ lookup('file','/testdir/testfile','/testdir/testfile1',wantlist=true) }}\"  5,其他lookup插件用法示例\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  ---- hosts:node2remote_user:rootgather_facts:notasks:#file插件可以获取ansible主机中指定文件的内容- debug:msg:\"{{ lookup('file','/testdir/testfile') }}\"#env插件可以获取ansible主机中指定变量的值- debug:msg:\"{{ lookup('env','PATH') }}\"#first_found插件可以获取列表中第一个找到的文件#按照列表顺序在ansible主机中查找- debug:msg:\"{{ lookup('first_found',looklist) }}\"vars:looklist:- /testdir- /tmp/staging#当使用with_first_found时,可以在列表的最后添加- skip: true#表示如果列表中的所有文件都没有找到,则跳过当前任务,不会报错#当不确定有文件能够被匹配到时,推荐这种方式- debug:msg:\"{{item}}\"with_first_found:- /testdir1- /tmp/staging- skip:true#ini插件可以在ansible主机中的ini文件中查找对应key的值#如下示例表示从test.ini文件中的testA段落中查找testa1对应的值#测试文件/testdir/test.ini的内容如下(不包含注释符#号)#[testA]#testa1=Andy#testa2=Armand##[testB]#testb1=Ben- debug:msg:\"{{ lookup('ini','testa1 section=testA file=/testdir/test.ini') }}\"#当未找到对应key时,默认返回空字符串,如果想要指定返回值,可以使用default选项,如下#msg: \"{{ lookup('ini','test666 section=testA file=/testdir/test.ini default=notfound') }}\"#可以使用正则表达式匹配对应的键名,需要设置re=true,表示开启正则支持,如下#msg: \"{{ lookup('ini','testa[12] section=testA file=/testdir/test.ini re=true') }}\"#ini插件除了可以从ini类型的文件中查找对应key,也可以从properties类型的文件中查找key#默认在操作的文件类型为ini,可以使用type指定properties类型,如下例所示#如下示例中,application.properties文件内容如下(不包含注释符#号)#http.port=8080#redis.no=0#imageCode = 1,2,3- debug:msg:\"{{ lookup('ini','http.port type=properties file=/testdir/application.properties') }}\"#dig插件可以获取指定域名的IP地址#此插件依赖dnspython库,可使用pip安装pip install dnspython#如果域名使用了CDN,可能返回多个地址- debug:msg:\"{{ lookup('dig','www.baidu.com',wantlist=true) }}\"#password插件可以生成随机的密码并保存在指定文件中- debug:msg:\"{{ lookup('password','/tmp/testpasswdfile') }}\"#以上插件还有一些参数我们没有涉及到,而且也还有很多插件没有总结,等到用到对应的插件时,再行介绍吧#你也可以访问官网的lookup插件列表页面,查看各个插件的用法#https://docs.ansible.com/ansible/latest/plugins/lookup.html  循环(八) 1,在新版本的ansible中,官方推荐的循环的使用方式不同,在2.6推荐的方式为loop加lookup和loop加filter\n loop的简单使用方式:  1 2 3 4 5 6 7 8 9 10  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{ item }}\"loop:- teststr1- teststr2   loop加lookup插件替换with_X  1 2 3 4 5 6 7 8 9 10 11 12  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ lookup('dict',users) }}\"  2,在2.6版本开始,官方开始推荐使用\"loop加filter\"的方式来替代\"loop加lookup\"的方式\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:femalebob:maletasks:- debug:msg:\"{{item.key}} is {{item.value}}\"loop:\"{{ users | dict2items }}\"# users是一个字典格式的变量,它的结构是这样的# users:# alice: female# bob: male# 当users字典被dict2items转换处理以后,会变成如下模样# users:# - key: alice# value: female# - key: bob# value: male  3,无论是\"with_X\"、\"loop加lookup\"还是\"loop加filter\",都是使用不同的方式,实现相同的功能而已\n4,替换方式\n with_list  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #loop可以替代with_list,当处理嵌套的列表时,列表不会被拉平---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist}}\"   with_flattened  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #flatten过滤器可以替代with_flattened,当处理多层嵌套的列表时,列表中所有的嵌套层级都会被拉平#示例如下,flatten过滤器的用法在前文中已经总结过,此处不再赘述---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist | flatten}}\"   with_items  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #flatten过滤器（加参数）可以替代with_items,当处理多层嵌套的列表时,只有列表中的第一层会被拉平---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{item}}\"loop:\"{{testlist | flatten(levels=1)}}\"   with_indexed_items  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #flatten过滤器（加参数）,再配合loop_control关键字,可以替代with_indexed_items#当处理多层嵌套的列表时,只有列表中的第一层会被拉平,flatten过滤器的bug暂且忽略#示例如下,之后会对示例进行解释---- hosts:node2remote_user:rootgather_facts:novars:testlist:- a- [b,c]- dtasks:- debug:msg:\"{{index}}--{{item}}\"loop:\"{{testlist | flatten(levels=1)}}\"loop_control:index_var:index# \"loop_control\"关键字可以用于控制循环的行为,比如在循环时获取到元素的索引.# \"index_var\"是\"loop_control\"的一个设置选项,\"index_var\"的作用是让我们指定一个变量,\"loop_control\"会将列表元素的索引值存放到这个指定的变量中,比如如下配置loop_control:index_var:my_idx# 上述设置表示,在遍历列表时,当前被遍历元素的索引会被放置到\"my_idx\"变量中,也就是说,当进行循环操作时,只要获取到\"my_idx\"变量的值,就能获取到当前元素的索引值# loop_control还有其他的选项可以使用,当前暂时不列举   with_together  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #zip_longest过滤器配合list过滤器,可以替代with_together---- hosts:node2remote_user:rootgather_facts:novars:testlist1:[a, b ]testlist2:[1,2,3]testlist3:[A, B, C, D ]tasks:- debug:msg:\"{{ item.0 }} - {{ item.1 }} - {{item.2}}\"with_together:- \"{{testlist1}}\"- \"{{testlist2}}\"- \"{{testlist3}}\"- debug:msg:\"{{ item.0 }} - {{ item.1 }} - {{item.2}}\"loop:\"{{ testlist1 | zip_longest(testlist2,testlist3) | list }}\"   with_nested/with_cartesian  1 2 3 4 5 6 7 8 9 10 11 12 13  #product过滤器配合list过滤器,可以替代with_nested和with_cartesian#如果你忘了with_nested和with_cartesian的用法,可以回顾前文---- hosts:node2remote_user:rootgather_facts:novars:testlist1:[a, b, c ]testlist2:[1,2,3,4]tasks:- debug:msg:\"{{ item.0 }}--{{ item.1 }}\"loop:\"{{ testlist1 | product(testlist2) | list }}\"   with_sequence  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #range过滤器配合list过滤器可以代替with_sequence#你可以先回顾一下with_sequence的用法,然后再测试如下示例---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"loop:\"{{ range(0, 6, 2) | list }}\"# 需要格式化功能时:- debug:msg:\"{{ 'number is %0.2f' | format(item) }}\"loop:\"{{ range(2, 7, 2) | list }}\"   with_random_choice  1 2 3 4 5 6 7 8 9 10  #使用random函数可以替代with_random_choice,由于random函数是随机取出列表中的一个值,并不涉及循环操作,所以并不用使用loop关键字.---- hosts:node2remote_user:rootgather_facts:novars:testlist:[a, b, c ]tasks:- debug:msg:\"{{ testlist | random }}\"   with_dict  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #除了上文总结的dict2items过滤器,dictsort过滤器也可以替代with_dict---- hosts:node2remote_user:rootgather_facts:novars:users:d:daisyc:carola:aliceb:bobe:ellatasks:- debug:msg:\"{{item.key}} -- {{item.value}}\"loop:\"{{ users | dict2items }}\"- debug:msg:\"{{item.0}} -- {{item.1}}\"loop:\"{{ users | dictsort }}\"   with_subelements  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #subelements过滤器可以替代with_subelements---- hosts:node2remote_user:rootgather_facts:novars:users:- name:bobgender:malehobby:- Skateboard- VideoGame- name:alicegender:femalehobby:- Musictasks:- debug:msg:\"{{item.0.name}}'s hobby is {{item.1}}\"with_subelements:- \"{{users}}\"- hobby- debug:msg:\"{{item.0.name}}'s hobby is {{item.1}}\"loop:\"{{users | subelements('hobby')}}\"  5,loop_control的其他参数使用\n pause选项  1 2 3 4 5 6 7 8 9 10 11 12 13 14  ---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"{{item}}\"loop:- 1- 2- 3loop_control:pause:10# 上例表示每次循环之间间隔10秒   label  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  ---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item.key}}\"loop:\"{{users | dict2items}}\"# 此处输出内容太多,对于需要查找的内容较难找到# label选项的作用,它可以在循环输出信息时,简化输出item的信息---- hosts:node2remote_user:rootgather_facts:novars:users:alice:name:Alice Appleworthgender:femaletelephone:123-456-7890bob:name:Bob Bananaramagender:maletelephone:987-654-3210tasks:- debug:msg:\"{{item.key}}\"loop:\"{{users | dict2items}}\"loop_control:label:\"{{item.key}}\"  include 1,ansible中有类似编程语言中类似函数调用的功能,就是include,通过include,可以在一个playbook中包含另一个文件\n include模块可以指定一个文件,这个文件中的内容是一个任务列表（一个或多个任务）,使用include模块引用对应的文件时,文件中的任务会在被引用处执行,就像写在被引用处一样  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # cat lamp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:httpdstate:present# cat lnmp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:nginxstate:present# cat install_MysqlAndPhp.yml- yum:name:mysqlstate:present- yum:name:php-fpmstate:present  2,在handlers关键字中,也可以使用include,handlers也是一种任务,只是这种任务有相应的触发条件而已\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # cat test_include.yml---- hosts:node2remote_user:rootgather_facts:notasks:- file:path:/opt/tttstate:touchnotify:test include handlershandlers:- name:test include handlersinclude:include_handler.yml# cat include_handler.yml- debug:msg:\"task1 of handlers\"- debug:msg:\"task2 of handlers\"- debug:msg:\"task3 of handlers\"  3,\"include\"不仅能够引用任务列表,还能够引用playbook,比如,在一个playbook中引用另一个playbook\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13  # cat lamp.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:install_MysqlAndPhp.yml- yum:name:httpdstate:present- include:lnmp.yml# 在lamp.yml的结尾引入了lnmp.yml,当我们在执行lamp.yml时,会先执行lamp相关的任务,然后再执行lnmp.yml中的任务.  4,include还可以接受一些参数\n 如下所示  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in.ymltest_var1=hellotest_var2=test# cat in.yml- debug:msg:\"{{ test_var1 }}\"- debug:msg:\"{{ test_var2 }}\"   还能够使用vars关键字,以key: value变量的方式传入参数变量  1 2 3 4 5  tasks:- include:in.ymlvars:test_var1:hellotest_var2:test   通过vars关键字也能够传入结构稍微复杂的变量数据,以便在包含的文件中使用,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in.ymlvars:users:bob:gender:malelucy:gender:female# cat in.yml- debug:msg:\"{{ item.key}} is {{ item.value.gender }}\"loop:\"{{ users | dict2items }}\"  5,可以针对某个include去打标签\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in1.ymltags:t1- include:in2.ymltags:t2# cat in1.yml- debug:msg:\"task1 in in1.yml\"- debug:msg:\"task2 in in1.yml\"# cat in2.yml- debug:msg:\"task1 in in2.yml\"- debug:msg:\"task2 in in2.yml\"   可以对include添加条件判断,还可以对include进行循环操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # cat test_include1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:in3.ymlwhen:2\u003e 1- include:in3.ymlloop:- 1- 2- 3# cat in3.yml- debug:msg:\"task1 in in3.yml\"- debug:msg:\"task2 in in3.yml\"# 循环的调用多个任务,可以使用上例中的方法,将需要循环调用的多个任务写入到一个yml文件中,然后使用include调用这个yml文件,再配合loop进行循环即可  6,loop_control中loop_var的使用\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat A.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:B.ymlloop:- 1- 2# cat B.yml- debug:msg:\"{{item}}--task in B.yml\"loop:- a- b- c# B.yml中循环调用了debug模块,而在A.yml中,又循环的调用了B.yml,当出现这种\"双层循环\"的情况时,B文件中的item信息只打印B中的列表内容   若要获取上例中外层item的值,可以使用loop_control中loop_var选项  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat A.yml---- hosts:node2remote_user:rootgather_facts:notasks:- include:B.ymlloop:- 1- 2loop_control:loop_var:outer_item# cat B.yml- debug:msg:\"{{outer_item}}--{{item}}--task in B.yml\"loop:- a- b- c# 将loop_var选项的值设置为\"outer_item\",这表示,我们将外层循环的item值存放在了\"outer_item\"变量中,在B文件中的debug任务中,同时输出了\"outer_item\"变量和\"item\"变量的值  include(二) 1,\"include\"的某些原始用法在之后的版本中可能会被弃用,在之后的版本中,会使用一些新的关键字代替这些原始用法\n2,include_task模块\n include模块可以用来包含一个任务列表,include_tasks模块的作用也是用来包含一个任务列表,在之后的版本中,如果我们想要包含一个任务列表,那么就可以使用\"include_tasks\"关键字代替\"include\"关键字,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat intest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task1\"- include_tasks:in.yml- debug:msg:\"test task2\"# cat in.yml- debug:msg:\"task1 in in.yml\"- debug:msg:\"task2 in in.yml\"# 当我们使用\"include_tasks\"时,\"include_tasks\"本身会被当做一个\"task\",这个\"task\"会把被include的文件的路径输出在控制台中# \"include\"是透明的,\"include_tasks\"是可见的,\"include_tasks\"更像是一个任务,这个任务包含了其他的一些任务  3,在2.7版本之后,include_tasks模块加入了file和apply参数\n file参数  1 2 3 4  - include_tasks:file:in.yml- include_tasks:in.yml# 两种方式其实完全相同,只不过一个使用了\"file\"参数的方式,另一个使用了\"free_form\"的方式,虽然语法上不同,但是本质上没有区别   apply参数  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # cat intest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task1\"- include_tasks:file:in.ymltags:t1- debug:msg:\"test task2\"# \"include_tasks\"这个任务本身被调用了,而\"include_tasks\"对应文件中的任务却没有被调用# \"include_tasks\"与\"include\"并不相同,标签只会对\"include_tasks\"任务本身生效,而不会对其中包含的任务生效# 如果想要tags对\"include_tasks\"中包含的所有任务都生效,需要使用到\"include_tasks\"模块的apply参数---- hosts:node2remote_user:rootgather_facts:notasks:- include_tasks:file:in.ymlapply:tags:- t1# 但如上写法并未按预期执行,连include_tasks都没有执行,需要完成预期内容,需要如下配置---- hosts:node2remote_user:rootgather_facts:notasks:- include_tasks:file:in.ymlapply:tags:- t1tags:always# 在使用\"include_tasks\"时,不仅使用apply参数指定了tags,同时还使用tags关键字,对\"include_tasks\"本身添加了always标签  4,import_tasks\n 如果想要包含引用一个任务列表,也可以使用\"import_tasks\"关键字  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat intest1.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task\"- import_tasks:in.yml# cat in.yml- debug:msg:\"task1 in in.yml\"- debug:msg:\"task2 in in.yml\"# \"import_tasks\"模块并不会像\"include_tasks\"模块那样,在控制台中输出相关的任务信息,\"import_tasks\"是相对透明的   \"import_tasks\"是静态的,\"include_tasks\"是动态的  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # \"静态\"的意思就是被include的文件在playbook被加载时就展开了（是预处理的）.# \"动态\"的意思就是被include的文件在playbook运行时才会被展开（是实时处理的）.# 由于\"include_tasks\"是动态的,所以,被include的文件的文件名可以使用任何变量替换.# 由于\"import_tasks\"是静态的,所以,被include的文件的文件名不能使用动态的变量替换.# cat intest3.yml---- hosts:node2remote_user:rootgather_facts:novars:file_name:in.ymltasks:- import_tasks:\"{{file_name}}\"- include_tasks:\"{{file_name}}\"# 上述内容可以正常执行# cat intest3.yml---- hosts:node2remote_user:rootgather_facts:notasks:- set_fact:file_name:in.yml- import_tasks:\"{{file_name}}\"- include_tasks:\"{{file_name}}\"# 上述内容执行报错# 当使用静态的import时,请确保文件名中使用到的变量被定义在vars中、vars_files中、或者extra-vars中,静态的import不支持其他方式传入的变量   如果想要对包含的任务列表进行循环操作,则只能使用\"include_tasks\"关键字,不能使用\"import_tasks\"关键字,\"import_tasks\"并不支持循环操作,使用\"loop\"关键字或\"with_items\"关键字对include文件进行循环操作时,只能配合\"include_tasks\"才能正常运行 使用when做条件判断执行include_tasks和import_tasks时,区别很大  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  # 当对\"include_tasks\"使用when进行条件判断时,when对应的条件只会应用于\"include_tasks\"任务本身,当执行被包含的任务时,不会对这些被包含的任务重新进行条件判断.# 当对\"import_tasks\"使用when进行条件判断时,when对应的条件会应用于被include的文件中的每一个任务,当执行被包含的任务时,会对每一个被包含的任务进行同样的条件判断.# cat intest4.yml---- hosts:node2remote_user:rootgather_facts:notasks:- name:'----------set testvar to 0'set_fact:testnum:0- debug:msg:'-----include_tasks-----enter the in1.yml-----'- include_tasks:in1.ymlwhen:testnum == 0- name:'----------set testvar to 0'set_fact:testnum:0- debug:msg:'-----import_tasks-----enter the in1.yml-----'- import_tasks:in1.ymlwhen:testnum == 0# cat in1.yml- set_fact:testnum:1- debug:msg:\"task1 in in1.yml\"# 输出内容如下:PLAY [node2] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxTASK [----------set testvar to 0] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"-----include_tasks-----enter the in1.yml-----\"}TASK [include_tasks] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxincluded:/testdir/ansible/in1.yml for node2TASK [set_fact] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"task1 in in1.yml\"}TASK [----------set testvar to 0] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2] =\u003e {\"msg\": \"-----import_tasks-----enter the in1.yml-----\"}TASK [set_fact] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxok:[node2]TASK [debug] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxskipping:[node2]PLAY RECAP xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxnode2 :ok=8 changed=0 unreachable=0 failed=0   tags的使用,与\"include_tasks\"不同,当为\"import_tasks\"添加标签时,tags是针对被包含文件中的所有任务生效的,与\"include\"关键字的效果相同. \"include_tasks\"与\"import_tasks\"都可以在handlers中使用,并没有什么不同 5,import_playbook  使用\"include\"关键字除了能够引用任务列表,还能够引用整个playbook,在之后的版本中,如果想要引入整个playbook,则需要使用\"import_playbook\"模块代替\"include\"模块,因为在2.8版本以后,使用\"include\"关键字引用整个playbook的特性将会被弃用 示例如下:    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # cat intest6.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task in intest6.yml\"- import_playbook:intest7.yml# cat intest7.yml---- hosts:node2remote_user:rootgather_facts:notasks:- debug:msg:\"test task in intest7.yml\"  jinja2模板(一) 1,对远端机器进行操作时,很多场景下都需要根据主机信息进行配置,这个时候可以使用template模块来完成相应的目的\n 示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat temptest.yml---- hosts:node2remote_user:rootgather_facts:notasks:- yum:name:redisstate:present- template:src:/testdir/ansible/redis.confdest:/etc/redis.conf# cat /testdir/ansible/redis.conf,下列的ansible_host是host alias,需要注意......bind {{ansible_host}}......   template还有其他的选项  # owner,group,mode(mode=0644,mode=u+x) # force参数: 当远程主机的目标路径中已经存在同名文件,并且与最终生成的文件内容不同时,是否强制覆盖,可选值有yes和no,默认值为yes,表示覆盖,如果设置为no,则不会执行覆盖拷贝操作,远程主机中的文件保持不变 # backup参数: 当远程主机的目标路径中已经存在同名文件,并且与最终生成的文件内容不同时,是否对远程主机的文件进行备份,可选值有yes和no,当设置为yes时,会先备份远程主机中的文件,然后再将最终生成的文件拷贝到远程主机 2,上述例子中使用的template模块渲染,使用的都是jinja2模板引擎\n - \\{\\{ \\}\\} :用来装载表达式,比如变量、运算表达式、比较表达式等. - \\{\\% \\%\\} :用来装载控制语句,比如 if 控制结构,for循环控制结构. - \\{\\# \\#\\} :用来装载注释,模板文件被渲染后,注释不会包含在最终生成的文件中. 3,双花括号的使用\n 变量的引用,如下示例:  1 2 3 4 5 6 7 8 9 10  # ansible node2 -m template -e \"testvar1=teststr\" -a \"src=test.j2 dest=/opt/test\" # cat test.j2 test jinja2 variable test {{ testvar1 }} test # 输出内容如下: # cat test test jinja2 variable test teststr tesT # \"{{ }}\"中包含的就是一个变量,当模板被渲染后,变量的值被替换到了最终的配置文件中    包含表达式,示例如下:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119  ## 比较表达式: # cat test.j2 jinja2 test {{ 1 == 1 }} {{ 2 != 2 }} {{ 2 \u003e 1 }} {{ 2 \u003e= 1 }} 生成文件内容如下: # cat test jinja2 test True False True True ## 逻辑运算: # cat test.j2 jinja2 test {{ (2 \u003e 1) or (1 \u003e 2) }} {{ (2 \u003e 1) and (1 \u003e 2) }} {{ not true }} {{ not True }} # cat test jinja2 test True False False False ## 算数运算: # cat test.j2 jinja2 test {{ 3 + 2 }} {{ 3 - 4 }} {{ 3 * 5 }} {{ 2 ** 3 }} {{ 7 / 5 }} {{ 7 // 5 }} {{ 17 % 5 }} # cat test jinja2 test 5 -1 15 8 1.4 1 2 ## 成员运算: # cat test.j2 jinja2 test {{ 1 in [1,2,3,4] }} {{ 1 not in [1,2,3,4] }} # cat test jinja2 test True False ## 一些基础的数据类型,都可以包含在\"{{ }}\"中,jinja2本身就是基于python的模板引擎,所以,python的基础数据类型都可以包含在\"{{ }}\"中 # cat test.j2 jinja2 test ### str {{ 'testString' }} {{ \"testString\" }} ### num {{ 15 }} {{ 18.8 }} ### list {{ ['Aa','Bb','Cc','Dd'] }} {{ ['Aa','Bb','Cc','Dd'].1 }} {{ ['Aa','Bb','Cc','Dd'][1] }} ### tuple {{ ('Aa','Bb','Cc','Dd') }} {{ ('Aa','Bb','Cc','Dd').0 }} {{ ('Aa','Bb','Cc','Dd')[0] }} ### dic {{ {'name':'bob','age':18} }} {{ {'name':'bob','age':18}.name }} {{ {'name':'bob','age':18}['name'] }} ### Boolean {{ True }} {{ true }} {{ False }} {{ false }} 生成文件内容如下: # cat test jinja2 test ### str testString testString ### num 15 18.8 ### list ['Aa', 'Bb', 'Cc', 'Dd'] Bb Bb ### tuple ('Aa', 'Bb', 'Cc', 'Dd') Aa Aa ### dic {'age': 18, 'name': 'bob'} bob bob ### Boolean True True False False    过滤器也可以在双花括号中使用  1 2 3 4 5 6 7 8 9  # cat test.j2 jinja2 test {{ 'abc' | upper }} 生成文件内容 # cat test jinja2 test ABC    jinja2的tests自然也能够在\"双花括号\"中使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # cat test.j2 jinja2 test {{ testvar1 is defined }} {{ testvar1 is undefined }} {{ '/opt' is exists }} {{ '/opt' is file }} {{ '/opt' is directory }} # ansible node2 -m template -e \"testvar1=1 testvar2=2\" -a \"src=test.j2 dest=/opt/test\" 生成文件内容 # cat test jinja2 test True False True False True    lookup插件在双花括号中的使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # cat /testdir/ansible/test.j2 jinja2 test {{ lookup('file','/testdir/testfile') }} {{ lookup('env','PATH') }} test jinja2 # ansible主机中的testfile内容如下 # cat /testdir/testfile testfile in ansible These are for testing purposes only # 生成文件内容如下 # cat test jinja2 test testfile in ansible These are for testing purposes only /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin test jinja2   3,{# #}的使用\n 同编程语言中注释方式的使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # cat test.j2 jinja2 test {#这是一行注释信息#} jinja2 test {# 这是多行注释信息, 模板被渲染以后, 最终的文件中不会包含这些信息 #} jinja2 test 生成文件内容如下: # cat test jinja2 test jinja2 test jinja2 test   jinja2模板(二) 1,结合if的使用\n 通用结构  1 2 3 4 5 6 7  {% if 条件一 %}...{% elif 条件N %}...{% else %}...{% endif %}   三元运算  1 2 3 4 5 6 7  # cat test.j2 jinja2 test {{ 'a' if 2\u003e1 else 'b' }} # 输出内容如下: # cat /opt/test jinja2 test a   2,使用set\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat test.j2 jinja2 test {% set teststr='abc' %} {{ teststr }} # 在jinja2中,使用set关键字定义变量,执行如下ad-hoc命令渲染模板 ansible node2 -m template -a \"src=test.j2 dest=/opt/test\" # 输出内容如下: # cat /opt/test jinja2 test abc   3,结合for的使用\n 通用结构  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  {% for 迭代变量 in 可迭代对象 %} {{ 迭代变量 }} {% endfor %} # 注: jinja2的控制语句大多都会遵循这个规则,即\"XXX\"控制语句需要使用\"endXXX\"作为结尾 ## 默认换行方式: # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] %} {{ i }} {% endfor %} # ansible node2 -m template -a \"src=test.j2 dest=/opt/test\" # cat /opt/test jinja2 test 3 1 7 8 2 ## 不换行方式: # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i }} {%- endfor %} # 在for的结束控制符\"%}\"之前添加了减号\"-\" # 在endfor的开始控制符\"{%\"之后添加到了减号\"-\" # cat test jinja2 test 31782 ## 不换行,但有间隔方式 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i }}{{ ' ' }} {%- endfor %} # 在循环每一项时,在每一项后面加入了一个空格字符串 # cat test jinja2 test 3 1 7 8 2 ## 不换行,但有间隔方式二 # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] -%} {{ i~' ' }} {%- endfor %} # 在jinja2中,波浪符\"~\"就是字符串连接符,它会把所有的操作数转换为字符串,并且连接它们   4,结合for使用,循环字典\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat test.j2 jinja2 test {% for key,val in {'name':'bob','age':18}.iteritems() %} {{ key ~ ':' ~ val }} {% endfor %} # cat test jinja2 test age:18 name:bob   5,在使用for循环时,有一些内置的特殊变量可以使用\n 当前循环操作为整个循环的第几次操作,则可以借助\"loop.index\"特殊变量  1 2 3 4 5 6 7 8 9 10 11 12  # cat test.j2 jinja2 test {% for i in [3,1,7,8,2] %}{{ i ~ '----' ~ loop.index }}{% endfor %}# cat test jinja2 test 3----1 1----2 7----3 8----4 2----5    其他的一些循环变量  1 2 3 4 5 6 7 8 9 10  # loop.index 当前循环操作为整个循环的第几次循环,序号从1开始 # loop.index0 当前循环操作为整个循环的第几次循环,序号从0开始 # loop.revindex 当前循环操作距离整个循环结束还有几次,序号到1结束 # loop.revindex0 当前循环操作距离整个循环结束还有几次,序号到0结束 # loop.first 当操作可迭代对象中的第一个元素时,此变量的值为true # loop.last 当操作可迭代对象中的最后一个元素时,此变量的值为true # loop.length 可迭代对象的长度 # loop.depth 当使用递归的循环时,当前迭代所在的递归中的层级,层级序号从1开始 # loop.depth0 当使用递归的循环时,当前迭代所在的递归中的层级,层级序号从0开始 # loop.cycle() 这是一个辅助函数,通过这个函数我们可以在指定的一些值中进行轮询取值,具体参考之后的示例    对一段内容循环的生成指定的次数,则可以借助range函数完成  1 2 3 4  {% for i in range(3) %}something ... {% endfor %}  6,for的一些其他操作\n 当for循环中没有使用if内联表达式时,也可以使用else块  1 2 3 4 5 6  {% for u in userlist %}{{ u.name }}{%else%}no one {% endfor %}# 只有userlist列表为空时,才会渲染else块后的内容    for支持递归操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  {% set dictionary={ 'name':'bob','son':{ 'name':'tom','son':{ 'name':'jerry' } } } %}{% for key,value in dictionary.iteritems() recursive %}{% if key == 'name' %}{% set fathername=value %}{% endif %}{% if key == 'son' %}{{ fathername ~\"'s son is \"~ value.name}}{{ loop( value.iteritems() ) }}{% endif %}{% endfor %}# 使用了iteritems函数,在for循环的末尾,添加了recursive 修饰符,当for循环中有recursive时,表示这个循环是一个递归的循环,当需要在for循环中进行递归时,只要在需要进行递归的地方调用loop函数即可,上例中的\"loop( value.iteritems() )\"即为调用递归的部分,由于value也是一个字典,所以需要使用iteritems函数进行处理 bob's son is tom tom's son is jerry   jinja2模板(三) 1,jinja2模板文件中需要使用特殊字符\n 最简单的方法就是直接在\"双花括号\"中使用引号将这类符号引起,当做纯粹的字符串进行处理  1 2 3 4 5 6 7 8 9 10 11 12  # cat test.j2 {{ '{{' }}{{ '}}' }}{{ '{{ test string }}' }}{{ '{% test string %}' }}{{ '{# test string #}' }}# cat test {{ }}{{ test string }}{% test string %}{# test string #}   如果有较大的段落时,可以借助raw块,来实现需求  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # cat test.j2 {% raw %} {{ test }} {% test %} {# test #} {% if %} {% for %} {% endraw %}# \"{% raw %}\"与\"{% endraw %}\"之间的所有\"{{ }}\"、\"{% %}\"或者\"{# #}\"都不会被jinja2解析,上例模板被渲染后,raw块中的符号都会保持原样 # cat test {{ test }}{% test %}{# test #}{% if %}{% for %}  2,在调用模板引擎时,手动的指定一些符号,这些符号可以替换默认的区块\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat test.j2 {% set test='abc' %}(( test )) {{ test }}{{ test1 }}{{ 'test' }}{{ 'test1' }}# 使用variable_start_string参数指定一个符号,这个符号用于替换\"{{ }}\"中的\"{{“,同时,可以使用variable_end_string参数指定一个符号,这个符号用于替换\"{{ }}\"中的\"}}\" # ansible node2 -m template -a \"src=test.j2 dest=/opt/test variable_start_string='((' variable_end_string='))'\" # cat test abc {{ test }}{{ test1 }}{{ 'test' }}{{ 'test1' }}# 可以使用block_start_string参数指定一个符号, 这个符号用于替换\"{% %}\"中的\"{% \",可以使用block_end_string参数指定一个符号,这个符号用于替换\"{% %}\"中的\"%}\"   3,jinja2中也有类似函数的东西,名字叫做宏\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 最简单的宏 # cat test.j2 {% macro testfunc() %}test string {% endmacro %}{{ testfunc() }}# 指定参数的宏,包含默认值 {% macro testfunc(tv1=111) %}test string {{tv1}}{% endmacro %}{{ testfunc( ) }}{{ testfunc(666) }}  ansible中的role 1,ansible官方定义的规范\n role的标准目录结构  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  $ tree role role ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── tasks │ └── main.yml ├── templates └── vars └── main.yml # tasks目录:角色需要执行的主任务文件放置在此目录中,默认的主任务文件名为main.yml,当调用角色时,默认会执行main.yml文件中的任务,也可以将其他需要执行的任务文件通过include的方式包含在tasks/main.yml文件中. # handlers目录:当角色需要调用handlers时,默认会在此目录中的main.yml文件中查找对应的handler # defaults目录:角色会使用到的变量可以写入到此目录中的main.yml文件中,通常,defaults/main.yml文件中的变量都用于设置默认值,以便在你没有设置对应变量值时,变量有默认的值可以使用,定义在defaults/main.yml文件中的变量的优先级是最低的. # vars目录:角色会使用到的变量可以写入到此目录中的main.yml文件中,看到这里你肯定会有疑问,vars/main.yml文件和defaults/main.yml文件的区别在哪里呢？区别就是,defaults/main.yml文件中的变量的优先级是最低的,而vars/main.yml文件中的变量的优先级非常高,如果你只是想提供一个默认的配置,那么你可以把对应的变量定义在defaults/main.yml中,如果你想要确保别人在调用角色时,使用的值就是你指定的值,则可以将变量定义在vars/main.yml中,因为定义在vars/main.yml文件中的变量的优先级非常高,所以其值比较难以覆盖. # meta目录:如果你想要赋予这个角色一些元数据,则可以将元数据写入到meta/main.yml文件中,这些元数据用于描述角色的相关属性,比如 作者信息、角色主要作用等等,你也可以在meta/main.yml文件中定义这个角色依赖于哪些其他角色,或者改变角色的默认调用设定,在之后会有一些实际的示例,此处不用纠结. # templates目录: 角色相关的模板文件可以放置在此目录中,当使用角色相关的模板时,如果没有指定路径,会默认从此目录中查找对应名称的模板文件. # files目录:角色可能会用到的一些其他文件可以放置在此目录中,比如,当你定义nginx角色时,需要配置https,那么相关的证书文件即可放置在此目录中. # 当然,上述目录并不全是必须的,也就是说,如果你的角色并没有相关的模板文件,那么角色目录中并不用包含templates目录,同理,其他目录也一样,一般情况下,都至少会有一个tasks目录.   2,调用role的方式\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # ls testrole test.yml # cat test.yml - hosts: node2 roles: - testrole # ansible-playbook test.yml ## 调用testrole角色时,test.yml会从同级目录中查找与testrole角色同名的目录 ## 还有其他位置也可以被调用: ## 1,当前系统用户的家目录中的.ansible/roles目录,即 ~/.ansible/roles目录中 ## 2,同级目录中的roles目录中 ## 3,修改ansible的配置文件,编辑/etc/ansible/ansible.cfg配置文件,设置roles_path选项 roles_path = /etc/ansible/roles:/opt:/testdir ## 或者在playbook中,直接接上role的绝对路径   3,一些role使用的问题\n 在默认情况下,角色中的变量是全局可访问的,可以将变量的访问域变成角色所私有的,如果想要将变量变成角色私有的,则需要设置/etc/ansible/ansible.cfg文件,将private_role_vars的值设置为yes,默认情况下,\"private_role_vars = yes\"是被注释掉的,将前面的注释符去掉皆可 默认情况下,无法多次调用同一个角色,也就是说,如下playbook只会调用一次testrole角色:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # cat test.yml - hosts: node2 roles: - role: testrole - role: testrole # 如果想要多次调用同一个角色,有两种方法,如下: # 方法一:设置角色的allow_duplicates属性 ,让其支持重复的调用. # 方法二:调用角色时,传入的参数值不同. # 方法一需要为角色设置allow_duplicates属性,而此属性需要设置在meta/main.yml文件中,所以我们需要在testrole中创建meta/main.yml文件,写入如下内容: # cat testrole/meta/main.yml allow_duplicates: true # 方法二 # cat test.yml # cat test.yml - hosts: node2 roles: - role: testrole vars: testvar: \"zsythink\" - role: testrole vars: testvar: \"zsythink.net\"   4,除了使用\"-e\"传入的变量的优先级,其他变量（包括主机变量）的优先级均低于vars/main.yml中变量的优先级\n5,调试handler方法\n 如下示例:  1 2 3 4 5 6 7 8 9 10  # cat testrole/tasks/main.yml - debug: msg: \"hello testrole!\" changed_when: true notify: test_handler # cat testrole/handlers/main.yml - name: test_handler debug: msg: \"this is a test handler\"   常用技巧(一) 1,技巧一,在ansible中使用python字符串的一些特性\n ansible基于python实现,当我们在ansible中处理字符串时,能够借助一些python的字符串特性,比如,在python中可以使用中括号(方括号)截取字符串中的一部分,在ansible中也可以利用这一特性  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cat test.yml - hosts: me gather_facts: no vars: a: \"vaA12345\" tasks: - debug: msg: \"{{a[2]}}\" # 使用a[2:5]获取到a字符串的第3到第5个字符（不包含第6个字符） # 使用a[:5]获取到a字符串的第6个字符之前的所有字符（不包含第6个字符） # 使用a[5:]获取到a字符串的第6个字符之后的所有字符（包含第6个字符） ## 之前成员运算符\"in\"和\"not in\",也是python的字符串运算符 - hosts: me gather_facts: no vars: a: \"vaA12345\" tasks: - debug: msg: \"true\" when: \"'va' in a\"    运算符处理字符  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 使用加号\"+\"连接两个字符串- hosts:megather_facts:novars:a:\"vaA12345\"b:\"vbB67890\"tasks:- debug:msg:\"{{a+b}}\"# 使用乘号\"*\"连续的重复输出字符串- hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"{{a*3}}\"   使用find查找字符串中字符位置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  - hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"{{a.find('A1')}}\"# 输出如下:TASK [debug] xxxxxxxxxxxxxxxxxxxxxok:[me] =\u003e {\"msg\": \"2\"}# 用作条件判断- hosts:megather_facts:novars:a:\"vaA12345\"tasks:- debug:msg:\"not found\"when:a.find('A2') == -1  2,指定任务在某个节点上运行\n 通过\"delegate_to\"关键字,可以指定某个任务在特定的主机上执行,这个特定的主机可以是目标主机中的某一个,也可以不是目标主机中的任何一个  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  - hosts:node2,megather_facts:notasks:- file:path:\"/tmp/ttt\"state:touch- file:path:\"/tmp/delegate\"state:touchdelegate_to:node3- file:path:\"/tmp/ttt1\"state:touch  3,让某个人物在ansible主机上执行,不在目标主机上执行\n 有两种方式,如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  ## delegate_to- hosts:node2,node3gather_facts:notasks:- file:path:\"/tmp/inAnsible\"state:touchdelegate_to:local- file:path:\"/tmp/test\"state:touch## connection: local- hosts:node2,node3gather_facts:notasks:- file:path:\"/tmp/inAnsible\"state:touchconnection:local- file:path:\"/tmp/test\"state:touch  4,只跑一次的任务\n 从网站上下载包,但目标主机共有5台  1 2 3 4 5 6 7 8 9 10 11 12 13  - hosts:A,B,C,D,Egather_facts:notasks:- get_url:url:\"http://nexus.zsythink.net/repository/testraw/testfile/test.tar\"dest:/tmp/# 结合本机执行一起使用connection:localrun_once:true- copy:src:\"/tmp/test.tar\"dest:\"/tmp\"  常用技巧(二) 1,向列表中追加项\n 如下内容:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  - hosts:megather_facts:novars:l1:- 1- 2l2:- a- b- 2tasks:- set_fact:l3:\"{{ l1 + l2 }}\"- debug:var:l3# 直接列表相加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{{ tlist + ['a'] }}\"- debug:var:tlist# jinja2的语法,完成上述追加元素的过程- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{% set tlist = tlist + ['a'] %}{{tlist}}\"- debug:var:tlist# 使用extend()追加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{% set tlist = tlist + ['a'] %}{{tlist}}\"- debug:var:tlist# append追加- hosts:megather_facts:novars:tlist:- 1- 2tasks:- set_fact:tlist:\"{{ tlist.append('a') }}{{tlist}}\"- debug:var:tlist  2, 在列表中插入项\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13  # 使用insert()- hosts:megather_facts:novars:tlist:- 11- 2- 11tasks:- set_fact:tlist:\"{{ tlist.insert(1,'a') }}{{tlist}}\"- debug:var:tlist  3, 在列表中删除项\n 如下示例:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # 使用pop- hosts:megather_facts:novars:tlist:- 11- 2- 'a'- 'b'- 3tasks:- debug:msg:\"{{tlist.pop(2)}}\"# 使用remove()- hosts:megather_facts:novars:tlist:- 11- 'b'- 'a'- 'b'- 3tasks:- set_fact:tlist:\"{{ tlist.remove('b') }}{{tlist}}\"- debug:var:tlist# for循环匹配删除- hosts:megather_facts:novars:tlist:- 11- 'b'- 'a'- 'b'- 11- 'a11'- '1a'- '11'tasks:- set_fact:tlist:\"{%for i in tlist%}{% if 11 in tlist%}{{tlist.remove(11)}}{%endif%}{%endfor%}{{tlist}}\"- debug:var:tlist  ","description":"讲解ansible及ansible-playbook的使用","tags":["ansible","ops"],"title":"ansible及ansible-playbook的使用","uri":"/tech/ops/ansible%E5%AD%A6%E4%B9%A0/"},{"categories":["tech"],"content":"github+hexo+next搭建个人博客已经完成,使用一段时间后,发现存在多处编辑提交的需求. 在网上查询相关方案后,决定采取广大网友建议的方式: 将平时需要修改的内容存储在 hexo 分支,hexo 基于更改内容生成的文件提交到 master 分支 下列内容记录在 raspberry 上配置实现 hexo 编辑提交内容的过程\n1.安装基础包 在新机器上安装基础包，当前机器为 raspberry，以该机器为例说明 raspberry 安装系统是\"Raspbian GNU/Linux 10 (buster)\"，基于 debian 的发行，用如下命令安装\n1 2  # 安装nodejs、npm、git sudo apt install nodejs npm git   2.配置git及github 安装好基础包后，要配置 github 上个人资料/settings/SSH and GPG keys/SSH keys,用于提交代码使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # 在raspberry上,使用pi用户生成公私钥对 PI $ ssh-keygen -t rsa -P '' Generating public/private rsa key pair. Enter file in which to save the key (/home/pi/.ssh/id_rsa): Your identification has been saved in /home/pi/.ssh/id_rsa. Your public key has been saved in /home/pi/.ssh/id_rsa.pub. The key fingerprint is: SHA256:5C2iM9maPY/n+2iDwmodQJOjxTq2ZJkwv0xBy4EG68E pi@raspberrypi The keys randomart image is: +---[RSA 2048]----+ |o+o. | |=+Oo | |+E=+ . | |=*= o . | |+=.o . S . | | .o .+ . . | | o=... | | . +*o.+. | | ...o.o*=+. | +----[SHA256]-----+ # pi用户家目录下.ssh文件夹下新生成了id_rsa/id_rsa.pub文件 PI $ ls ~/.ssh -lrt total 16 -rw-r--r-- 1 pi pi 444 Feb 27 21:28 known_hosts -rw------- 1 pi pi 1366 Feb 28 13:06 authorized_keys -rw-r--r-- 1 pi pi 396 Mar 1 21:30 id_rsa.pub -rw------- 1 pi pi 1823 Mar 1 21:30 id_rsa # 复制id_rsa.pub内容,在github上SSH keys界面上点击New SSH key,添加复制的公钥内容并命名 PI $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaCxxxx.....   配置本地 git\n1 2 3  # 配置user.name和user.email PI $ git config --global user.email \"you@example.com\" PI $ git config --global user.name \"Your Name\"   3.npm安装hexo相关包 配置好 github SSH keys后,下载yourname.github.io库到本地\n1 2 3 4 5  # 进入相应的目录,下载hexo分支代码; 此处在家目录下新建了projects目录,进入projects目录进行操作 PI $ mkdir ~/projects \u0026\u0026 cd ~/projects # $yourname填写自己实际的名称 PI $ git clone git@github.com:$yourname/$yourname.github.io.git   下载完成后,进入yourname.github.io目录,安装 npm 相关包\n1 2 3 4 5 6 7 8 9 10 11 12  # 安装hexo PI $ cd $yourname.github.io \u0026\u0026 npm install hexo # 当前目录下已经包含package.json文件,直接安装相关包 PI $ npm install # hexo同步至github需要使用的包 PI $ npm install hexo-deployer-git # 安装完成后,需要将当前目录下node_modules/.bin加入到PATH中 PI $ echo 'export PATH=$PATH:/home/pi/projects/$yourname.github.io/node_modules/.bin' \u003e\u003e ~/.bashrc PI $ source ~/.bashrc   4.测试发布新文章 上述内容配置完成后,在新机器上测试新文章发布\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 新增文章 PI $ hexo n test # 编辑source/_post/test.md内容,可以在typora等markdown写作软件上先完成内容后再粘贴 PI $ vim source/_post/test.md # 生成内容 PI $ hexo g # 测试新文章内容,hexo s后访问localhost:4000查看文章效果 PI $ hexo s # 内容核对完成,发布到github yourname.github.io的master分支上 PI $ hexo d   ","description":"在新设备上准备hexo发布文章的配置过程","tags":["hexo"],"title":"hexo多设备管理","uri":"/tech/miscell/hexo%E5%A4%9A%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/"}]